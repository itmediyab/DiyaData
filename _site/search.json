[
  {
    "objectID": "posts/UFO/UFO.html",
    "href": "posts/UFO/UFO.html",
    "title": "UFO Dataset",
    "section": "",
    "text": "People keep spotting “UFOs” in different shapes, at random places on Earth, for weird amounts of time…and we analysed the patterns of when, where and how.\n\n\n\n\nlibrary(tidyverse) \n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic) \n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula) \nlibrary(skimr) \n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(janitor) \n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(naniar) \n\n\nAttaching package: 'naniar'\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\nlibrary(visdat) \nlibrary(tinytable) \n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(DT) \nlibrary(crosstable) \n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(RColorBrewer)\nlibrary(naniar)\nlibrary(tidyr)\nlibrary(dplyr)      \n\n\n\n\n\nufo_sightings &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2019/2019-06-25/ufo_sightings.csv\") %&gt;% \n  janitor::clean_names(case = \"snake\")\n\nRows: 80332 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): date_time, city_area, state, country, ufo_shape, described_encounte...\ndbl (3): encounter_length, latitude, longitude\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ndate_time\nDate time sighting occurred\n\n\ncity_area\nCity or area of sighting\n\n\nstate\nstate/region of sighting\n\n\ncountry\nCountry of sighting\n\n\nufo_shape\nUFO Shape\n\n\nencounter_length\nEncounter length in seconds\n\n\ndescribed_encounter_length\nEncounter length as described (eg 1 hour, etc\n\n\ndescription\nDescription of encounter\n\n\ndate_documented\nDate documented\n\n\nlatitude\nLatitude\n\n\nlongitude\nLongitude\n\n\n\n\n\n\n\nbase::names(ufo_sightings)\n\n [1] \"date_time\"                  \"city_area\"                 \n [3] \"state\"                      \"country\"                   \n [5] \"ufo_shape\"                  \"encounter_length\"          \n [7] \"described_encounter_length\" \"description\"               \n [9] \"date_documented\"            \"latitude\"                  \n[11] \"longitude\"                 \n\n\n\ndplyr::glimpse(ufo_sightings)\n\nRows: 80,332\nColumns: 11\n$ date_time                  &lt;chr&gt; \"10/10/1949 20:30\", \"10/10/1949 21:00\", \"10…\n$ city_area                  &lt;chr&gt; \"san marcos\", \"lackland afb\", \"chester (uk/…\n$ state                      &lt;chr&gt; \"tx\", \"tx\", NA, \"tx\", \"hi\", \"tn\", NA, \"ct\",…\n$ country                    &lt;chr&gt; \"us\", NA, \"gb\", \"us\", \"us\", \"us\", \"gb\", \"us…\n$ ufo_shape                  &lt;chr&gt; \"cylinder\", \"light\", \"circle\", \"circle\", \"l…\n$ encounter_length           &lt;dbl&gt; 2700, 7200, 20, 20, 900, 300, 180, 1200, 18…\n$ described_encounter_length &lt;chr&gt; \"45 minutes\", \"1-2 hrs\", \"20 seconds\", \"1/2…\n$ description                &lt;chr&gt; \"This event took place in early fall around…\n$ date_documented            &lt;chr&gt; \"4/27/2004\", \"12/16/2005\", \"1/21/2008\", \"1/…\n$ latitude                   &lt;dbl&gt; 29.88306, 29.38421, 53.20000, 28.97833, 21.…\n$ longitude                  &lt;dbl&gt; -97.941111, -98.581082, -2.916667, -96.6458…\n\n\n\nbase::dim(ufo_sightings)\n\n[1] 80332    11\n\n\n\nutils::str(ufo_sightings)\n\nspc_tbl_ [80,332 × 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ date_time                 : chr [1:80332] \"10/10/1949 20:30\" \"10/10/1949 21:00\" \"10/10/1955 17:00\" \"10/10/1956 21:00\" ...\n $ city_area                 : chr [1:80332] \"san marcos\" \"lackland afb\" \"chester (uk/england)\" \"edna\" ...\n $ state                     : chr [1:80332] \"tx\" \"tx\" NA \"tx\" ...\n $ country                   : chr [1:80332] \"us\" NA \"gb\" \"us\" ...\n $ ufo_shape                 : chr [1:80332] \"cylinder\" \"light\" \"circle\" \"circle\" ...\n $ encounter_length          : num [1:80332] 2700 7200 20 20 900 300 180 1200 180 120 ...\n $ described_encounter_length: chr [1:80332] \"45 minutes\" \"1-2 hrs\" \"20 seconds\" \"1/2 hour\" ...\n $ description               : chr [1:80332] \"This event took place in early fall around 1949-50. It occurred after a Boy Scout meeting in the Baptist Church\"| __truncated__ \"1949 Lackland AFB&#44 TX.  Lights racing across the sky &amp; making 90 degree turns on a dime.\" \"Green/Orange circular disc over Chester&#44 England\" \"My older brother and twin sister were leaving the only Edna theater at about 9 PM&#44...we had our bikes and I \"| __truncated__ ...\n $ date_documented           : chr [1:80332] \"4/27/2004\" \"12/16/2005\" \"1/21/2008\" \"1/17/2004\" ...\n $ latitude                  : num [1:80332] 29.9 29.4 53.2 29 21.4 ...\n $ longitude                 : num [1:80332] -97.94 -98.58 -2.92 -96.65 -157.8 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   date_time = col_character(),\n  ..   city_area = col_character(),\n  ..   state = col_character(),\n  ..   country = col_character(),\n  ..   ufo_shape = col_character(),\n  ..   encounter_length = col_double(),\n  ..   described_encounter_length = col_character(),\n  ..   description = col_character(),\n  ..   date_documented = col_character(),\n  ..   latitude = col_double(),\n  ..   longitude = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\n\n\nvisdat::vis_dat(ufo_sightings)\n\n\n\n\n\n\n\n\n\nvisdat::vis_miss(ufo_sightings)\n\n\n\n\n\n\n\n\n\n\n\n\nufo_sightings_withoutNA &lt;- ufo_sightings %&gt;% drop_na()\nglimpse(ufo_sightings_withoutNA)\n\nRows: 66,516\nColumns: 11\n$ date_time                  &lt;chr&gt; \"10/10/1949 20:30\", \"10/10/1956 21:00\", \"10…\n$ city_area                  &lt;chr&gt; \"san marcos\", \"edna\", \"kaneohe\", \"bristol\",…\n$ state                      &lt;chr&gt; \"tx\", \"tx\", \"hi\", \"tn\", \"ct\", \"al\", \"fl\", \"…\n$ country                    &lt;chr&gt; \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"…\n$ ufo_shape                  &lt;chr&gt; \"cylinder\", \"circle\", \"light\", \"sphere\", \"d…\n$ encounter_length           &lt;dbl&gt; 2700, 20, 900, 300, 1200, 180, 120, 300, 18…\n$ described_encounter_length &lt;chr&gt; \"45 minutes\", \"1/2 hour\", \"15 minutes\", \"5 …\n$ description                &lt;chr&gt; \"This event took place in early fall around…\n$ date_documented            &lt;chr&gt; \"4/27/2004\", \"1/17/2004\", \"1/22/2004\", \"4/2…\n$ latitude                   &lt;dbl&gt; 29.88306, 28.97833, 21.41806, 36.59500, 41.…\n$ longitude                  &lt;dbl&gt; -97.94111, -96.64583, -157.80361, -82.18889…\n\n\n\nsummary(ufo_sightings_withoutNA)\n\n  date_time          city_area            state             country         \n Length:66516       Length:66516       Length:66516       Length:66516      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  ufo_shape         encounter_length   described_encounter_length\n Length:66516       Min.   :       0   Length:66516              \n Class :character   1st Qu.:      30   Class :character          \n Mode  :character   Median :     180   Mode  :character          \n                    Mean   :    6573                             \n                    3rd Qu.:     600                             \n                    Max.   :82800000                             \n description        date_documented       latitude        longitude      \n Length:66516       Length:66516       Min.   :-37.81   Min.   :-176.66  \n Class :character   Class :character   1st Qu.: 34.20   1st Qu.:-114.18  \n Mode  :character   Mode  :character   Median : 39.25   Median : -89.60  \n                                       Mean   : 38.71   Mean   : -95.29  \n                                       3rd Qu.: 42.34   3rd Qu.: -80.40  \n                                       Max.   : 72.70   Max.   : 153.10"
  },
  {
    "objectID": "posts/UFO/UFO.html#setting-up-r-packages",
    "href": "posts/UFO/UFO.html#setting-up-r-packages",
    "title": "UFO Dataset",
    "section": "",
    "text": "library(tidyverse) \n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic) \n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula) \nlibrary(skimr) \n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(janitor) \n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(naniar) \n\n\nAttaching package: 'naniar'\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\nlibrary(visdat) \nlibrary(tinytable) \n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(DT) \nlibrary(crosstable) \n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(RColorBrewer)\nlibrary(naniar)\nlibrary(tidyr)\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/UFO/UFO.html#read-data",
    "href": "posts/UFO/UFO.html#read-data",
    "title": "UFO Dataset",
    "section": "",
    "text": "ufo_sightings &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2019/2019-06-25/ufo_sightings.csv\") %&gt;% \n  janitor::clean_names(case = \"snake\")\n\nRows: 80332 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): date_time, city_area, state, country, ufo_shape, described_encounte...\ndbl (3): encounter_length, latitude, longitude\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "posts/UFO/UFO.html#data-dictionary",
    "href": "posts/UFO/UFO.html#data-dictionary",
    "title": "UFO Dataset",
    "section": "",
    "text": "Variable\nDescription\n\n\n\n\ndate_time\nDate time sighting occurred\n\n\ncity_area\nCity or area of sighting\n\n\nstate\nstate/region of sighting\n\n\ncountry\nCountry of sighting\n\n\nufo_shape\nUFO Shape\n\n\nencounter_length\nEncounter length in seconds\n\n\ndescribed_encounter_length\nEncounter length as described (eg 1 hour, etc\n\n\ndescription\nDescription of encounter\n\n\ndate_documented\nDate documented\n\n\nlatitude\nLatitude\n\n\nlongitude\nLongitude"
  },
  {
    "objectID": "posts/UFO/UFO.html#examine-data",
    "href": "posts/UFO/UFO.html#examine-data",
    "title": "UFO Dataset",
    "section": "",
    "text": "base::names(ufo_sightings)\n\n [1] \"date_time\"                  \"city_area\"                 \n [3] \"state\"                      \"country\"                   \n [5] \"ufo_shape\"                  \"encounter_length\"          \n [7] \"described_encounter_length\" \"description\"               \n [9] \"date_documented\"            \"latitude\"                  \n[11] \"longitude\"                 \n\n\n\ndplyr::glimpse(ufo_sightings)\n\nRows: 80,332\nColumns: 11\n$ date_time                  &lt;chr&gt; \"10/10/1949 20:30\", \"10/10/1949 21:00\", \"10…\n$ city_area                  &lt;chr&gt; \"san marcos\", \"lackland afb\", \"chester (uk/…\n$ state                      &lt;chr&gt; \"tx\", \"tx\", NA, \"tx\", \"hi\", \"tn\", NA, \"ct\",…\n$ country                    &lt;chr&gt; \"us\", NA, \"gb\", \"us\", \"us\", \"us\", \"gb\", \"us…\n$ ufo_shape                  &lt;chr&gt; \"cylinder\", \"light\", \"circle\", \"circle\", \"l…\n$ encounter_length           &lt;dbl&gt; 2700, 7200, 20, 20, 900, 300, 180, 1200, 18…\n$ described_encounter_length &lt;chr&gt; \"45 minutes\", \"1-2 hrs\", \"20 seconds\", \"1/2…\n$ description                &lt;chr&gt; \"This event took place in early fall around…\n$ date_documented            &lt;chr&gt; \"4/27/2004\", \"12/16/2005\", \"1/21/2008\", \"1/…\n$ latitude                   &lt;dbl&gt; 29.88306, 29.38421, 53.20000, 28.97833, 21.…\n$ longitude                  &lt;dbl&gt; -97.941111, -98.581082, -2.916667, -96.6458…\n\n\n\nbase::dim(ufo_sightings)\n\n[1] 80332    11\n\n\n\nutils::str(ufo_sightings)\n\nspc_tbl_ [80,332 × 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ date_time                 : chr [1:80332] \"10/10/1949 20:30\" \"10/10/1949 21:00\" \"10/10/1955 17:00\" \"10/10/1956 21:00\" ...\n $ city_area                 : chr [1:80332] \"san marcos\" \"lackland afb\" \"chester (uk/england)\" \"edna\" ...\n $ state                     : chr [1:80332] \"tx\" \"tx\" NA \"tx\" ...\n $ country                   : chr [1:80332] \"us\" NA \"gb\" \"us\" ...\n $ ufo_shape                 : chr [1:80332] \"cylinder\" \"light\" \"circle\" \"circle\" ...\n $ encounter_length          : num [1:80332] 2700 7200 20 20 900 300 180 1200 180 120 ...\n $ described_encounter_length: chr [1:80332] \"45 minutes\" \"1-2 hrs\" \"20 seconds\" \"1/2 hour\" ...\n $ description               : chr [1:80332] \"This event took place in early fall around 1949-50. It occurred after a Boy Scout meeting in the Baptist Church\"| __truncated__ \"1949 Lackland AFB&#44 TX.  Lights racing across the sky &amp; making 90 degree turns on a dime.\" \"Green/Orange circular disc over Chester&#44 England\" \"My older brother and twin sister were leaving the only Edna theater at about 9 PM&#44...we had our bikes and I \"| __truncated__ ...\n $ date_documented           : chr [1:80332] \"4/27/2004\" \"12/16/2005\" \"1/21/2008\" \"1/17/2004\" ...\n $ latitude                  : num [1:80332] 29.9 29.4 53.2 29 21.4 ...\n $ longitude                 : num [1:80332] -97.94 -98.58 -2.92 -96.65 -157.8 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   date_time = col_character(),\n  ..   city_area = col_character(),\n  ..   state = col_character(),\n  ..   country = col_character(),\n  ..   ufo_shape = col_character(),\n  ..   encounter_length = col_double(),\n  ..   described_encounter_length = col_character(),\n  ..   description = col_character(),\n  ..   date_documented = col_character(),\n  ..   latitude = col_double(),\n  ..   longitude = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "posts/UFO/UFO.html#viewing-missing-data",
    "href": "posts/UFO/UFO.html#viewing-missing-data",
    "title": "UFO Dataset",
    "section": "",
    "text": "visdat::vis_dat(ufo_sightings)\n\n\n\n\n\n\n\n\n\nvisdat::vis_miss(ufo_sightings)"
  },
  {
    "objectID": "posts/UFO/UFO.html#removing-missing-data",
    "href": "posts/UFO/UFO.html#removing-missing-data",
    "title": "UFO Dataset",
    "section": "",
    "text": "ufo_sightings_withoutNA &lt;- ufo_sightings %&gt;% drop_na()\nglimpse(ufo_sightings_withoutNA)\n\nRows: 66,516\nColumns: 11\n$ date_time                  &lt;chr&gt; \"10/10/1949 20:30\", \"10/10/1956 21:00\", \"10…\n$ city_area                  &lt;chr&gt; \"san marcos\", \"edna\", \"kaneohe\", \"bristol\",…\n$ state                      &lt;chr&gt; \"tx\", \"tx\", \"hi\", \"tn\", \"ct\", \"al\", \"fl\", \"…\n$ country                    &lt;chr&gt; \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"…\n$ ufo_shape                  &lt;chr&gt; \"cylinder\", \"circle\", \"light\", \"sphere\", \"d…\n$ encounter_length           &lt;dbl&gt; 2700, 20, 900, 300, 1200, 180, 120, 300, 18…\n$ described_encounter_length &lt;chr&gt; \"45 minutes\", \"1/2 hour\", \"15 minutes\", \"5 …\n$ description                &lt;chr&gt; \"This event took place in early fall around…\n$ date_documented            &lt;chr&gt; \"4/27/2004\", \"1/17/2004\", \"1/22/2004\", \"4/2…\n$ latitude                   &lt;dbl&gt; 29.88306, 28.97833, 21.41806, 36.59500, 41.…\n$ longitude                  &lt;dbl&gt; -97.94111, -96.64583, -157.80361, -82.18889…\n\n\n\nsummary(ufo_sightings_withoutNA)\n\n  date_time          city_area            state             country         \n Length:66516       Length:66516       Length:66516       Length:66516      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  ufo_shape         encounter_length   described_encounter_length\n Length:66516       Min.   :       0   Length:66516              \n Class :character   1st Qu.:      30   Class :character          \n Mode  :character   Median :     180   Mode  :character          \n                    Mean   :    6573                             \n                    3rd Qu.:     600                             \n                    Max.   :82800000                             \n description        date_documented       latitude        longitude      \n Length:66516       Length:66516       Min.   :-37.81   Min.   :-176.66  \n Class :character   Class :character   1st Qu.: 34.20   1st Qu.:-114.18  \n Mode  :character   Mode  :character   Median : 39.25   Median : -89.60  \n                                       Mean   : 38.71   Mean   : -95.29  \n                                       3rd Qu.: 42.34   3rd Qu.: -80.40  \n                                       Max.   : 72.70   Max.   : 153.10"
  },
  {
    "objectID": "posts/UFO/UFO.html#removing-column-described_encounter_length",
    "href": "posts/UFO/UFO.html#removing-column-described_encounter_length",
    "title": "UFO Dataset",
    "section": "Removing column described_encounter_length",
    "text": "Removing column described_encounter_length\n\nufo_sightings_new &lt;- ufo_sightings_withoutNA %&gt;%\n  select(-described_encounter_length)\n\nglimpse(ufo_sightings_new)\n\nRows: 66,516\nColumns: 10\n$ date_time        &lt;chr&gt; \"10/10/1949 20:30\", \"10/10/1956 21:00\", \"10/10/1960 2…\n$ city_area        &lt;chr&gt; \"san marcos\", \"edna\", \"kaneohe\", \"bristol\", \"norwalk\"…\n$ state            &lt;chr&gt; \"tx\", \"tx\", \"hi\", \"tn\", \"ct\", \"al\", \"fl\", \"ca\", \"nc\",…\n$ country          &lt;chr&gt; \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\",…\n$ ufo_shape        &lt;chr&gt; \"cylinder\", \"circle\", \"light\", \"sphere\", \"disk\", \"dis…\n$ encounter_length &lt;dbl&gt; 2700, 20, 900, 300, 1200, 180, 120, 300, 180, 1800, 1…\n$ description      &lt;chr&gt; \"This event took place in early fall around 1949-50. …\n$ date_documented  &lt;chr&gt; \"4/27/2004\", \"1/17/2004\", \"1/22/2004\", \"4/27/2007\", \"…\n$ latitude         &lt;dbl&gt; 29.88306, 28.97833, 21.41806, 36.59500, 41.11750, 33.…\n$ longitude        &lt;dbl&gt; -97.94111, -96.64583, -157.80361, -82.18889, -73.4083…"
  },
  {
    "objectID": "posts/UFO/UFO.html#visualising-data",
    "href": "posts/UFO/UFO.html#visualising-data",
    "title": "UFO Dataset",
    "section": "Visualising Data",
    "text": "Visualising Data\n\n1. UFO Sightings throughout the years (date)\nLooking at ufo sightings found on the same date.\n\nufo_sightings_repeated &lt;- ufo_sightings_new %&gt;%\n  group_by(date_documented) %&gt;%       \n  summarise(count = n()) %&gt;%          \n  filter(count &gt; 1)  \n\nglimpse(ufo_sightings_repeated)\n\nRows: 314\nColumns: 2\n$ date_documented &lt;chr&gt; \"1/10/2009\", \"1/10/2014\", \"1/11/2002\", \"1/11/2005\", \"1…\n$ count           &lt;int&gt; 878, 513, 230, 127, 465, 133, 340, 138, 351, 98, 74, 1…\n\n\nThe above piece of code tells us that there are 314 unique dates where data was documented - dataset that had at least one sighting.\nSince the there will be countless data stored in each date, we plotted a graph where x as a timeline with the range of the first date data was collected and the latest and the y-axis with a count function inbuilt in ggformula.\n\nufo_sightings_new %&gt;%\n  count(date_documented, name = \"count\") %&gt;%\n  mutate(date_documented = mdy(date_documented)) %&gt;%\n  gf_line(count ~ date_documented)\n\n\n\n\n\n\n\n\nSeeing this graph we can see a stark differences around 2010, there is a high point and low point and its very erratic. Lets isolate the high and low points of the graph alone.\n\nufo_sightings_new%&gt;%\n  count(date_documented, name = \"count\") %&gt;%\n  mutate(date_documented = mdy(date_documented)) %&gt;%\n  gf_point(count ~ date_documented,\n           color = \"red\", size = 1.5) %&gt;%\n  gf_labs(\n    title = \"Reported UFO Sightings per Date\",\n    x = \"Date\",\n    y = \"Number of Sightings\"\n  )\n\n\n\n\n\n\n\n\nThis tells us that the data with lesser number of sightings is significantly more than data with higher number of sightings which makes intuitive sense. Lets make this more useful by making a gradient within the graph. Lowest - blue and highest - red\n\nlibrary(RColorBrewer)\n\nufo_sightings_new %&gt;%\n  count(date_documented, name = \"count\") %&gt;%\n  mutate(date_documented = mdy(date_documented)) %&gt;%\n  gf_point(count ~ date_documented, color = ~count, size = 1.5) %&gt;%\n  gf_refine(scale_color_gradient(low = \"blue\", high = \"red\")) %&gt;%\n  gf_labs(\n    title = \"Reported UFO Sightings per Date\",\n    x = \"Date\",\n    y = \"Number of Sightings\",\n    color = \"Sightings Count\"\n  )\n\n\n\n\n\n\n\n\nVisualising the graph with red points and the line graph:\n\nufo_sightings_new %&gt;%\n  mutate(date_documented = mdy(date_documented)) %&gt;%\n  group_by(date_documented) %&gt;%\n  summarise(count = n()) %&gt;%\n  gf_line(count ~ date_documented) %&gt;%\n  gf_point(color = \"red\", size = 1) %&gt;%\n  gf_labs(\n    title = \"Reported UFO Sightings Over Time\",\n    x = \"Date\",\n    y = \"Number of Sightings\"\n  )\n\n\n\n\n\n\n\n\nThe graph looks very congested so faceting it would give more precise graphs. Lets facet it into 8 different segments.\n\nufo_sightings_new %&gt;%\n  mutate(date_documented = mdy(date_documented),\n         segment = ntile(date_documented, 8)) %&gt;%\n  group_by(date_documented, segment) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  gf_line(count ~ date_documented) %&gt;%\n  gf_point(color = \"red\", size = 1) %&gt;%\n  gf_facet_wrap(~segment, scales = \"free_x\") %&gt;%\n  gf_labs(\n    title = \"Reported UFO Sightings Over Time\",\n    x = \"Date\",\n    y = \"Number of Sightings\"\n  )\n\n\n\n\n\n\n\n\nIt would be nice to see the highest and lowest point throughout the years. Lets try doing that:\n\nufo_highest_lowest &lt;-ufo_sightings_new %&gt;%\n  mutate(date_documented = mdy(date_documented)) %&gt;%\n  group_by(date_documented) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  summarise(\n    lowest_count = min(count),\n    lowest_date  = date_documented[which.min(count)],\n    highest_count = max(count),\n    highest_date  = date_documented[which.max(count)]\n  )\n\nglimpse(ufo_highest_lowest)\n\nRows: 1\nColumns: 4\n$ lowest_count  &lt;int&gt; 1\n$ lowest_date   &lt;date&gt; 2002-03-25\n$ highest_count &lt;int&gt; 1268\n$ highest_date  &lt;date&gt; 2009-12-12\n\n\nThe lowest count of 1 during 2002 makes me think whether there are other data with a count of 1, but during a different year making both equally competent dates for the lowest range.\n\nufo_sightings_new %&gt;%\n  mutate(date_documented = mdy(date_documented)) %&gt;%\n  group_by(date_documented) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  filter(count == min(count))\n\n# A tibble: 2 × 2\n  date_documented count\n  &lt;date&gt;          &lt;int&gt;\n1 2002-03-25          1\n2 2003-01-20          1\n\n\nIt turns out there are two dates - but the reason for 2002 showing up first is because it was parsed properly before hand itself.\nThis graph is plotted using the whole date - to make a bar graph or histogram we need to extract the year from the date. We will store this view format of viewing data as ufo_sightings_new1\n\nufo_sightings_new1 &lt;- ufo_sightings_new %&gt;%\n  mutate(\n    date_time_parsed = mdy_hm(date_time),\n    date_only = as.Date(date_time_parsed),\n    time_only = format(date_time_parsed, \"%H:%M\"),\n    year = year(date_time_parsed)\n  )\nglimpse(ufo_sightings_new1)\n\nRows: 66,516\nColumns: 14\n$ date_time        &lt;chr&gt; \"10/10/1949 20:30\", \"10/10/1956 21:00\", \"10/10/1960 2…\n$ city_area        &lt;chr&gt; \"san marcos\", \"edna\", \"kaneohe\", \"bristol\", \"norwalk\"…\n$ state            &lt;chr&gt; \"tx\", \"tx\", \"hi\", \"tn\", \"ct\", \"al\", \"fl\", \"ca\", \"nc\",…\n$ country          &lt;chr&gt; \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\",…\n$ ufo_shape        &lt;chr&gt; \"cylinder\", \"circle\", \"light\", \"sphere\", \"disk\", \"dis…\n$ encounter_length &lt;dbl&gt; 2700, 20, 900, 300, 1200, 180, 120, 300, 180, 1800, 1…\n$ description      &lt;chr&gt; \"This event took place in early fall around 1949-50. …\n$ date_documented  &lt;chr&gt; \"4/27/2004\", \"1/17/2004\", \"1/22/2004\", \"4/27/2007\", \"…\n$ latitude         &lt;dbl&gt; 29.88306, 28.97833, 21.41806, 36.59500, 41.11750, 33.…\n$ longitude        &lt;dbl&gt; -97.94111, -96.64583, -157.80361, -82.18889, -73.4083…\n$ date_time_parsed &lt;dttm&gt; 1949-10-10 20:30:00, 1956-10-10 21:00:00, 1960-10-10…\n$ date_only        &lt;date&gt; 1949-10-10, 1956-10-10, 1960-10-10, 1961-10-10, 1965…\n$ time_only        &lt;chr&gt; \"20:30\", \"21:00\", \"20:00\", \"19:00\", \"23:45\", \"20:00\",…\n$ year             &lt;dbl&gt; 1949, 1956, 1960, 1961, 1965, 1966, 1966, 1968, 1968,…\n\n\nLets parse the date_time and also seperate date and time - which might be useful to look at separately, and store them into ufo_sightings_new1\n\nufo_sightings_new1 &lt;- ufo_sightings_withoutNA %&gt;%\n  mutate(\n    date_time_parsed = mdy_hm(date_time),\n    date_only = as.Date(date_time_parsed),\n    time_only = format(date_time_parsed, \"%H:%M\"),\n    year = year(date_time_parsed)\n  )\n\nglimpse(ufo_sightings_new1)\n\nRows: 66,516\nColumns: 15\n$ date_time                  &lt;chr&gt; \"10/10/1949 20:30\", \"10/10/1956 21:00\", \"10…\n$ city_area                  &lt;chr&gt; \"san marcos\", \"edna\", \"kaneohe\", \"bristol\",…\n$ state                      &lt;chr&gt; \"tx\", \"tx\", \"hi\", \"tn\", \"ct\", \"al\", \"fl\", \"…\n$ country                    &lt;chr&gt; \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"…\n$ ufo_shape                  &lt;chr&gt; \"cylinder\", \"circle\", \"light\", \"sphere\", \"d…\n$ encounter_length           &lt;dbl&gt; 2700, 20, 900, 300, 1200, 180, 120, 300, 18…\n$ described_encounter_length &lt;chr&gt; \"45 minutes\", \"1/2 hour\", \"15 minutes\", \"5 …\n$ description                &lt;chr&gt; \"This event took place in early fall around…\n$ date_documented            &lt;chr&gt; \"4/27/2004\", \"1/17/2004\", \"1/22/2004\", \"4/2…\n$ latitude                   &lt;dbl&gt; 29.88306, 28.97833, 21.41806, 36.59500, 41.…\n$ longitude                  &lt;dbl&gt; -97.94111, -96.64583, -157.80361, -82.18889…\n$ date_time_parsed           &lt;dttm&gt; 1949-10-10 20:30:00, 1956-10-10 21:00:00, …\n$ date_only                  &lt;date&gt; 1949-10-10, 1956-10-10, 1960-10-10, 1961-1…\n$ time_only                  &lt;chr&gt; \"20:30\", \"21:00\", \"20:00\", \"19:00\", \"23:45\"…\n$ year                       &lt;dbl&gt; 1949, 1956, 1960, 1961, 1965, 1966, 1966, 1…\n\n\n\n\n2. UFO Shape count accross timeline\nFaceting the UFO shapes and plotting their counts over time.\n\nsightings_per_year &lt;- ufo_sightings_new1 %&gt;%\n  group_by(year, ufo_shape) %&gt;%\n  summarise(count = n(), .groups = \"drop\")\n\ngf_line(count ~ year, data = sightings_per_year, color = ~ufo_shape) %&gt;%\n  gf_facet_wrap(~ufo_shape)\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n\n\n\nThis tells us that the pyramid, hexagon and changed ufo_shapes have almost no data. But there should exist atleast one data for it to be part of ufo_shape - so lets see how many is its count.\n\nufo_sightings_new %&gt;%\n  filter(ufo_shape %in% c(\"pyramid\", \"hexagon\", \"changed\")) %&gt;%\n  count(ufo_shape)\n\n# A tibble: 3 × 2\n  ufo_shape     n\n  &lt;chr&gt;     &lt;int&gt;\n1 changed       1\n2 hexagon       1\n3 pyramid       1\n\n\nJust like predicted there is only 1 data in these ufo shape categories.\n\n\n3. UFO Shape count accross location\nWe created a cartograph — plotting each sighting by country to make a visual map of where the UFO sightings occurred.\n\ngf_point(latitude ~ longitude, data = ufo_sightings_new1, color = ~ufo_shape, size = ~encounter_length) %&gt;%\n  gf_labs(\n    x = \"Longitude\",\n    y = \"Latitude\",\n    color = \"UFO Shape\",\n    size = \"Encounter Length\",\n    title = \"UFO Sightings by Location\"\n  )\n\n\n\n\n\n\n\n\nThe cartograph shows an overview of the sighting locations and UFO shapes. We can see that U.S. is highlighted prominently.\nNext, the data can be plotted by longitude and latitude while keeping the faceting by UFO shape, to check for possible patterns.\n\ngf_point(latitude ~ longitude, data = ufo_sightings_new1, color = ~ufo_shape) %&gt;%\n  gf_facet_wrap(~ufo_shape) %&gt;%\n  gf_labs(\n    x = \"Longitude\",\n    y = \"Latitude\",\n    color = \"UFO Shape\",\n    title = \"UFO Sightings by Shape\"\n  )\n\n\n\n\n\n\n\n\nThis plot shows the geographic distribution of UFO sightings by shape, helping us see where each type is reported.\nFaceting by shape highlights patterns or rare sightings that might be hidden in the overall dataset.\n\n\nEncounter Length vs Latitude based on UFO shape\nVisualising encounter length instead of Latitude - just to check for interesting patterns.\n\nufo_sightings_new %&gt;%\n  filter(!is.na(ufo_shape)) %&gt;%\n  slice_sample(n = 150) %&gt;%\n  gf_point(encounter_length ~ latitude | ufo_shape,\n           colour = ~ufo_shape,\n           size = 2) %&gt;%\n  gf_labs(\n    title  = \"UFO Sightings Sample\",\n    x      = \"Latitude\",\n    y      = \"Encounter Length\",\n    colour = \"UFO Shape\"\n  )\n\n\n\n\n\n\n\n\nThis plot visualizes a random sample of UFO sightings, showing how encounter lengths vary with latitude for different shapes.\nFaceting by shape and coloring points highlights differences and patterns across UFO types in the sample.\n\n\n4. Reported UFO Sightings by Day\nIt would be interesting to check whether UFO sightings are more common on certain days of the week. A bar graph can help visualize this.\n\nufo_sightings_new %&gt;%\n  count(weekday = wday(mdy_hm(date_time), label = TRUE)) %&gt;%\n  gf_col(n ~ weekday, fill = \"orange\") %&gt;%\n  gf_labs(title = \"Reported UFO Sightings by Day\", x = \"Day\", y = \"No of Reported Sightings\")\n\n\n\n\n\n\n\n\nSaturday has the most number of UFO sightings reported but it isn’t exorbitantly high - but lets see a numeric representation for better understanding\n\nufo_sightings_byweek &lt;- ufo_sightings_new1 %&gt;%\n  mutate(weekday = wday(mdy_hm(date_time), label = TRUE)) %&gt;%\n  count(weekday) %&gt;%\n  arrange(match(weekday, c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\")))\n\nufo_sightings_byweek\n\n# A tibble: 7 × 2\n  weekday     n\n  &lt;ord&gt;   &lt;int&gt;\n1 Sun      9625\n2 Mon      8340\n3 Tue      8954\n4 Wed      9130\n5 Thu      9162\n6 Fri      9641\n7 Sat     11664\n\n\n\n\n5. Reported UFO Sightings by Hours\nLets try doing the same but instead of days of week - we will try hours of week\n\nufo_sightings_new %&gt;%\n  count(hour = hour(mdy_hm(date_time))) %&gt;%\n  gf_col(n ~ hour, fill = \"skyblue\") %&gt;%\n  gf_labs(title = \"Reported UFO Sightings by Hour\", x = \"Hour\", y = \"No of Reported Sightings\")\n\n\n\n\n\n\n\n\n\n\n6. UFO Sightings by US States\nSince US is the biggest factor in ufo sightings - lets take each of US state and view its counts\n\nus_sightings &lt;- ufo_sightings_new1 %&gt;%\n  filter(country == \"us\") %&gt;%\n  count(state, sort = TRUE)\nglimpse(us_sightings)\n\nRows: 52\nColumns: 2\n$ state &lt;chr&gt; \"ca\", \"fl\", \"wa\", \"tx\", \"ny\", \"il\", \"az\", \"pa\", \"oh\", \"mi\", \"nc\"…\n$ n     &lt;int&gt; 8683, 3754, 3707, 3398, 2915, 2447, 2362, 2319, 2251, 1781, 1722…\n\n\nVisualising this into bar graphs\n\nus_sightings %&gt;%\n  gf_col(n ~ state, fill = ~state) %&gt;%\n  gf_labs(\n    title = \"UFO Sightings by US State\",\n    x = \"State\",\n    y = \"No of Reported Sightings\",\n    fill = \"State\"\n  ) \n\n\n\n\n\n\n\n\nThe states since they aren’t abbreviated are very congested but the state coded California has a exorbidantly high number of reportings - lets find its value\n\nus_sightings %&gt;%\n  filter(state == \"ca\") %&gt;%\n  select(state, n)\n\n# A tibble: 1 × 2\n  state     n\n  &lt;chr&gt; &lt;int&gt;\n1 ca     8683\n\n\nCalifornia has 8683 ufo sightings which we can see is pretty high compared to the rest of the states but lets find the mean, median and mode to get an accurate understanding\n\nx &lt;- us_sightings$n\n\nsummary_table &lt;- tibble(\n  Statistic = c(\"Mean\", \"Median\", \"Mode\"),\n  Value = c(mean(x), median(x), as.numeric(names(sort(table(x), decreasing = TRUE)[1])))\n)\n\nsummary_table\n\n# A tibble: 3 × 2\n  Statistic Value\n  &lt;chr&gt;     &lt;dbl&gt;\n1 Mean      1222.\n2 Median     798 \n3 Mode         7 \n\n\nThe UFO sightings in CA is extremely high compared to all three mean, median and mode. So we can assume there is high delusion and hallucination rates in the state of California of the US."
  },
  {
    "objectID": "posts/Fertility/Fertility.html",
    "href": "posts/Fertility/Fertility.html",
    "title": "Fertility Dataset",
    "section": "",
    "text": "Exploring and Analysing patterns of a dataset about fertility, demographics and weeks worked in 1979.\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(dplyr)\nlibrary(naniar)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:naniar':\n\n    n_complete\n\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(tinytable)\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(ggformula)\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\nThe following object is masked from 'package:skimr':\n\n    n_missing\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\n\n\n\n\n\nFertility &lt;- readr::read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Fertility.csv\") %&gt;% \njanitor::clean_names(case=\"snake\")\n\nRows: 254654 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): morekids, gender1, gender2, afam, hispanic, other\ndbl (3): rownames, age, work\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nFertility\n\n# A tibble: 254,654 × 9\n   rownames morekids gender1 gender2   age afam  hispanic other  work\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;\n 1        1 no       male    female     27 no    no       no        0\n 2        2 no       female  male       30 no    no       no       30\n 3        3 no       male    female     27 no    no       no        0\n 4        4 no       male    female     35 yes   no       no        0\n 5        5 no       female  female     30 no    no       no       22\n 6        6 no       male    female     26 no    no       no       40\n 7        7 no       female  male       29 no    no       no        0\n 8        8 no       male    male       33 no    no       no       52\n 9        9 no       female  male       29 no    no       no        0\n10       10 no       male    female     27 no    no       no        0\n# ℹ 254,644 more rows\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nMorekids\nDoes the mother have more than 2 children?\n\n\nGender1\nFactor indicating gender of first child\n\n\nGender2\nFactor indicating gender of second child.\n\n\nAge\nAge of mother at census.\n\n\nAfam factor\nIs the mother African-American?\n\n\nHispanic factor\nIs the mother Hispanic?\n\n\nOther factor\nIs the mother’s ethnicity neither African-American nor Hispanic, nor Caucasian?\n\n\nWork\nNumber of weeks in which the mother worked in 1979.\n\n\n\n\n\n\n\nbase::names(Fertility)\n\n[1] \"rownames\" \"morekids\" \"gender1\"  \"gender2\"  \"age\"      \"afam\"     \"hispanic\"\n[8] \"other\"    \"work\"    \n\n\n\ndplyr::glimpse(Fertility)\n\nRows: 254,654\nColumns: 9\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ morekids &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ gender1  &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"female\",…\n$ gender2  &lt;chr&gt; \"female\", \"male\", \"female\", \"female\", \"female\", \"female\", \"ma…\n$ age      &lt;dbl&gt; 27, 30, 27, 35, 30, 26, 29, 33, 29, 27, 28, 28, 35, 34, 32, 2…\n$ afam     &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ hispanic &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ other    &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ work     &lt;dbl&gt; 0, 30, 0, 0, 22, 40, 0, 52, 0, 0, 0, 52, 52, 52, 8, 7, 0, 40,…\n\n\n\nbase::dim(Fertility)\n\n[1] 254654      9\n\n\n\nutils::str(Fertility)\n\nspc_tbl_ [254,654 × 9] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ rownames: num [1:254654] 1 2 3 4 5 6 7 8 9 10 ...\n $ morekids: chr [1:254654] \"no\" \"no\" \"no\" \"no\" ...\n $ gender1 : chr [1:254654] \"male\" \"female\" \"male\" \"male\" ...\n $ gender2 : chr [1:254654] \"female\" \"male\" \"female\" \"female\" ...\n $ age     : num [1:254654] 27 30 27 35 30 26 29 33 29 27 ...\n $ afam    : chr [1:254654] \"no\" \"no\" \"no\" \"yes\" ...\n $ hispanic: chr [1:254654] \"no\" \"no\" \"no\" \"no\" ...\n $ other   : chr [1:254654] \"no\" \"no\" \"no\" \"no\" ...\n $ work    : num [1:254654] 0 30 0 0 22 40 0 52 0 0 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   rownames = col_double(),\n  ..   morekids = col_character(),\n  ..   gender1 = col_character(),\n  ..   gender2 = col_character(),\n  ..   age = col_double(),\n  ..   afam = col_character(),\n  ..   hispanic = col_character(),\n  ..   other = col_character(),\n  ..   work = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\n\nViewing missing data was not working for the whole data set, so we used slice sample of 100000. The data set did not have any missing data.\n\nFertility_sample &lt;- Fertility %&gt;% dplyr::slice_sample(n = 100000) \nvisdat::vis_dat(Fertility_sample)\n\n\n\n\n\n\n\n\n\nvisdat::vis_miss(Fertility_sample)\n\n\n\n\n\n\n\n\n\n\n\nWe created a new column for ethnicity since the data set did not directly indicate whether a person was Caucasian. Based on the data dictionary, all “no” responses were Caucasian. To make the data easier to understand, we added a column to clearly show the ethnicity of a person.\n\nFertility %&gt;% filter(afam == \"no\", hispanic == \"no\", other == \"no\")\n\n# A tibble: 216,033 × 9\n   rownames morekids gender1 gender2   age afam  hispanic other  work\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;\n 1        1 no       male    female     27 no    no       no        0\n 2        2 no       female  male       30 no    no       no       30\n 3        3 no       male    female     27 no    no       no        0\n 4        5 no       female  female     30 no    no       no       22\n 5        6 no       male    female     26 no    no       no       40\n 6        7 no       female  male       29 no    no       no        0\n 7        8 no       male    male       33 no    no       no       52\n 8        9 no       female  male       29 no    no       no        0\n 9       10 no       male    female     27 no    no       no        0\n10       11 yes      male    male       28 no    no       no        0\n# ℹ 216,023 more rows\n\n\n\nFertility_ethnicity &lt;- Fertility %&gt;%\n  mutate(ethnicity = case_when(\n    afam == \"yes\" & hispanic == \"no\" & other == \"no\" ~ \"Afam\",\n    afam == \"no\" & hispanic == \"yes\" & other == \"no\" ~ \"Hispanic\",\n    afam == \"no\" & hispanic == \"no\" & other == \"yes\" ~ \"Other\",\n    afam == \"no\" & hispanic == \"no\" & other == \"no\" ~ \"Caucasian\",\n    afam == \"yes\" & hispanic == \"yes\" & other == \"no\" ~ \"AfamHispanic\",\n    afam == \"yes\" & hispanic == \"no\" & other == \"yes\" ~ \"AfamOther\",\n    afam == \"no\" & hispanic == \"yes\" & other == \"yes\" ~ \"HispanicOther\"\n  ))\n  \nFertility_ethnicity\n\n# A tibble: 254,654 × 10\n   rownames morekids gender1 gender2   age afam  hispanic other  work ethnicity\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    \n 1        1 no       male    female     27 no    no       no        0 Caucasian\n 2        2 no       female  male       30 no    no       no       30 Caucasian\n 3        3 no       male    female     27 no    no       no        0 Caucasian\n 4        4 no       male    female     35 yes   no       no        0 Afam     \n 5        5 no       female  female     30 no    no       no       22 Caucasian\n 6        6 no       male    female     26 no    no       no       40 Caucasian\n 7        7 no       female  male       29 no    no       no        0 Caucasian\n 8        8 no       male    male       33 no    no       no       52 Caucasian\n 9        9 no       female  male       29 no    no       no        0 Caucasian\n10       10 no       male    female     27 no    no       no        0 Caucasian\n# ℹ 254,644 more rows\n\n\n\n\n\n\nFertility_ethnicity_factor &lt;- Fertility_ethnicity %&gt;%\n  mutate(across(where(is.character), as.factor)) %&gt;% \n  relocate(where(is.factor), .after = rownames)\nglimpse(Fertility_ethnicity_factor)\n\nRows: 254,654\nColumns: 10\n$ rownames  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ morekids  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, yes, no, no, no, no,…\n$ gender1   &lt;fct&gt; male, female, male, male, female, male, female, male, female…\n$ gender2   &lt;fct&gt; female, male, female, female, female, female, male, male, ma…\n$ afam      &lt;fct&gt; no, no, no, yes, no, no, no, no, no, no, no, no, no, no, no,…\n$ hispanic  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ other     &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ ethnicity &lt;fct&gt; Caucasian, Caucasian, Caucasian, Afam, Caucasian, Caucasian,…\n$ age       &lt;dbl&gt; 27, 30, 27, 35, 30, 26, 29, 33, 29, 27, 28, 28, 35, 34, 32, …\n$ work      &lt;dbl&gt; 0, 30, 0, 0, 22, 40, 0, 52, 0, 0, 0, 52, 52, 52, 8, 7, 0, 40…\n\n\n\n\n\n\nFertility_ethnicity_factor\n\n# A tibble: 254,654 × 10\n   rownames morekids gender1 gender2 afam  hispanic other ethnicity   age  work\n      &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;   &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1        1 no       male    female  no    no       no    Caucasian    27     0\n 2        2 no       female  male    no    no       no    Caucasian    30    30\n 3        3 no       male    female  no    no       no    Caucasian    27     0\n 4        4 no       male    female  yes   no       no    Afam         35     0\n 5        5 no       female  female  no    no       no    Caucasian    30    22\n 6        6 no       male    female  no    no       no    Caucasian    26    40\n 7        7 no       female  male    no    no       no    Caucasian    29     0\n 8        8 no       male    male    no    no       no    Caucasian    33    52\n 9        9 no       female  male    no    no       no    Caucasian    29     0\n10       10 no       male    female  no    no       no    Caucasian    27     0\n# ℹ 254,644 more rows\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  dplyr::count(across(.cols = c (gender1 , gender2)))\n\n# A tibble: 4 × 3\n  gender1 gender2     n\n  &lt;fct&gt;   &lt;fct&gt;   &lt;int&gt;\n1 female  female  60946\n2 female  male    62724\n3 male    female  63185\n4 male    male    67799\n\n\n\nFertility_ethnicity_factor %&gt;% \n  group_by(morekids) %&gt;% \n  summarise(average_age=mean(age),count=n()) %&gt;% tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                morekids\n                average_age\n                count\n              \n        \n        \n        \n                \n                  no\n                  30.12810\n                  157742\n                \n                \n                  yes\n                  30.82487\n                  96912\n                \n        \n      \n    \n\n\n\n\ncrosstable(morekids ~ gender2 + gender1,\n  data = Fertility_ethnicity_factor\n) %&gt;%\n  crosstable::as_flextable()\n\ngender1femalemalegender2femalemalefemalemalemorekidsno35057 (22.22%)40987 (25.98%)41304 (26.18%)40394 (25.61%)yes25889 (26.71%)21737 (22.43%)21881 (22.58%)27405 (28.28%)\n\n\n\ncrosstable(ethnicity ~ morekids,\n  data = Fertility_ethnicity_factor\n) %&gt;%\n  crosstable::as_flextable()\n\nlabelvariablemorekidsnoyesethnicityAfam7027 (54.22%)5933 (45.78%)AfamHispanic104 (53.06%)92 (46.94%)Caucasian137344 (63.58%)78689 (36.42%)Hispanic5562 (50.03%)5555 (49.97%)HispanicOther3522 (46.44%)4062 (53.56%)Other4183 (61.84%)2581 (38.16%)\n\n\n\nFertility_ethnicity_factor %&gt;% \n  group_by(morekids) %&gt;% \n  summarize(average_workhours = mean(work)) %&gt;% tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                morekids\n                average_workhours\n              \n        \n        \n        \n                \n                  no\n                  21.06843\n                \n                \n                  yes\n                  15.68143\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n\n\nHypothesis: Families with two daughters (female.female) could have more children.\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  gf_bar(~interaction(gender1,gender2),\n    fill = ~morekids,\n    position = \"dodge\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Morekids vs Gender Composition\",\n    subtitle = \"How morekids is being effected based on current gender of kids\",\n    x=\"Gender of First Two Children\",\n    y=\"Count\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  gf_bar(~interaction(gender1,gender2),\n    fill = ~morekids,\n    position = \"fill\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Morekids vs Gender Composition\",\n    subtitle = \"How morekids is being effected based on current gender of kids\",\n    x=\"Gender of First Two Children\",\n    y=\"Count\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\nInferences\n\nFamilies with two girls are most likely to have more children.\nFamilies with one boy and one girl are least likely to continue growing their family.\nFamilies with two boys also show a high chance of having more kids.\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  gf_bar(~ethnicity,\n    fill = ~interaction(gender1,gender2),\n    position = \"dodge\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Ethnicity vs Gender Composition\",\n    x=\"Gender of First Two Children\",\n    y=\"Count of Families\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set2\"))\n\n\n\n\n\n\n\n\n\n\n\n\nHypothesis: Women who worked less number of weeks would have more kids.\n\n\n\n\ngf_histogram(~work,\n  data = Fertility_ethnicity_factor,\n  bins = 30,                \n  fill = ~morekids,         \n  position = \"dodge\"        \n) %&gt;%\n  gf_labs(\n    title = \"Distribution of Work Weeks by More Kids\",\n    subtitle = \"Number of Work Weeks in 1979 for Mothers with or without more kids\",\n    x = \"Work weeks in 1979\",\n    y = \"Count\",\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;% \n  count(morekids, work) %&gt;% \n  gf_line(n ~ work, color = ~morekids, linewidth = 0.8) %&gt;%\n  gf_labs(\n    title = \"Distribution of Work Weeks by More Kids\",\n    subtitle = \"Number of Work Weeks in 1979 for Mothers with or without more kids\",\n    x = \"Work weeks in 1979\",\n    y = \"Count\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;% \n  gf_boxplot(morekids ~ work, orientation = \"y\", fill=~morekids, color = \"black\") %&gt;%\n  gf_labs(y = \"More kids\", \n          x = \"Work weeks in 1979\", \n          title = \"Distribution of Work Weeks by More Kids\",\n          subtitle = \"Number of Work Weeks in 1979 for Mothers with or without more kids\")\n\n\n\n\n\n\n\n\n\nInferences\n\nMost individuals either worked a full year (52 weeks) or did not work at all (0 weeks)\nNot working mothers dominates - The largest group is those who worked 0 weeks.\nWorking full year (52 weeks) is the second largest group.\nMothers who worked between 2-50 weeks is a minority.\nThe difference between “more kids” and “no kids”:\n\nPeople with no kids lean more towards full-time work.\nPeople with kids lean more towards not working at all or working fewer weeks.\n\n\n\nOverall insight: The “no more kids” category is the largest overall especially among non working mothers. This shows most people in 1979 had only 2 kids.\n\n\n\n\n\nHypothesis: Older women would have more kids.\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  gf_density(~age, color = ~morekids, fill = ~morekids) %&gt;%\n  gf_labs(\n    title = \"Distribution of Age by More Kids\",\n    subtitle = \"Ages of Mothers with or without more kids\",\n    x = \"Age of Mothers\",\n    y = \"Density\",\n    color = \"More Kids\",\n    fill = \"More Kids\"\n  )\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;% \n  gf_boxplot(morekids ~ age, orientation = \"y\", fill=~morekids, color = \"black\") %&gt;%\n  gf_labs(y = \"Morekids\", x = \"Age of Mothers\", \n          title = \"Distribution of Age by More Kids\",\n          subtitle = \"Ages of Mothers with or without more kids\")\n\n\n\n\n\n\n\n\n\nInferences\n\nThe possibility of having more kids increases with age as seen as in the density distribution graph.\nThe age of people who have more kids (median 31) is only slightly higher than the age of people who do not have more kids (median 30)\nThe group that responded “no” (they do not want more kids) has a slightly wider Interquartile Range.\n\n50% of mothers in the “no” category are more spread out in age from 28 to 32 years\n50% of people in the “yes” group are more clustered in age from 30 to 32 years\n\nOutliers: A few mothers who have more kids are younger than others (around age 22-23).\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  count(ethnicity, morekids) %&gt;%  \n  gf_col(n ~ ethnicity, fill = ~morekids, position = \"dodge\") %&gt;%  \n  gf_labs(\n    title = \"Ethnic Group Distribution by More Kids\",\n    subtitle = \"Count of Respondents who have More Children \",\n    x = \"Ethnic Group\",\n    y = \"Number of People\",\n    fill = \"More Kids\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set2\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  count(ethnicity, morekids) %&gt;%  \n  gf_col(n ~ ethnicity, fill = ~morekids, position = \"fill\") %&gt;%  \n  gf_labs(\n    title = \"Ethnic Group Distribution by More Kids\",\n    subtitle = \"Count of Respondents who have More Children \",\n    x = \"Ethnic Group\",\n    y = \"Number of People\",\n    fill = \"More Kids\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set2\"))\n\n\n\n\n\n\n\n\n\nInferences\n\nThe Caucasian group is much larger than all other ethnic groups in the survey, as seen in the first graph.\nAfrican-Americans and Hispanics have the highest proportion of respondents who have more kids.\nThe Caucasian group and the Other group have a lower proportion of having more kids."
  },
  {
    "objectID": "posts/Fertility/Fertility.html#setting-up-r-packages",
    "href": "posts/Fertility/Fertility.html#setting-up-r-packages",
    "title": "Fertility Dataset",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(dplyr)\nlibrary(naniar)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:naniar':\n\n    n_complete\n\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(tinytable)\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(ggformula)\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\nThe following object is masked from 'package:skimr':\n\n    n_missing\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum"
  },
  {
    "objectID": "posts/Fertility/Fertility.html#read-data",
    "href": "posts/Fertility/Fertility.html#read-data",
    "title": "Fertility Dataset",
    "section": "",
    "text": "Fertility &lt;- readr::read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Fertility.csv\") %&gt;% \njanitor::clean_names(case=\"snake\")\n\nRows: 254654 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): morekids, gender1, gender2, afam, hispanic, other\ndbl (3): rownames, age, work\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nFertility\n\n# A tibble: 254,654 × 9\n   rownames morekids gender1 gender2   age afam  hispanic other  work\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;\n 1        1 no       male    female     27 no    no       no        0\n 2        2 no       female  male       30 no    no       no       30\n 3        3 no       male    female     27 no    no       no        0\n 4        4 no       male    female     35 yes   no       no        0\n 5        5 no       female  female     30 no    no       no       22\n 6        6 no       male    female     26 no    no       no       40\n 7        7 no       female  male       29 no    no       no        0\n 8        8 no       male    male       33 no    no       no       52\n 9        9 no       female  male       29 no    no       no        0\n10       10 no       male    female     27 no    no       no        0\n# ℹ 254,644 more rows"
  },
  {
    "objectID": "posts/Fertility/Fertility.html#data-dictionary",
    "href": "posts/Fertility/Fertility.html#data-dictionary",
    "title": "Fertility Dataset",
    "section": "",
    "text": "Variable\nDescription\n\n\n\n\nMorekids\nDoes the mother have more than 2 children?\n\n\nGender1\nFactor indicating gender of first child\n\n\nGender2\nFactor indicating gender of second child.\n\n\nAge\nAge of mother at census.\n\n\nAfam factor\nIs the mother African-American?\n\n\nHispanic factor\nIs the mother Hispanic?\n\n\nOther factor\nIs the mother’s ethnicity neither African-American nor Hispanic, nor Caucasian?\n\n\nWork\nNumber of weeks in which the mother worked in 1979."
  },
  {
    "objectID": "posts/Fertility/Fertility.html#examine-data",
    "href": "posts/Fertility/Fertility.html#examine-data",
    "title": "Fertility Dataset",
    "section": "",
    "text": "base::names(Fertility)\n\n[1] \"rownames\" \"morekids\" \"gender1\"  \"gender2\"  \"age\"      \"afam\"     \"hispanic\"\n[8] \"other\"    \"work\"    \n\n\n\ndplyr::glimpse(Fertility)\n\nRows: 254,654\nColumns: 9\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ morekids &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ gender1  &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"female\",…\n$ gender2  &lt;chr&gt; \"female\", \"male\", \"female\", \"female\", \"female\", \"female\", \"ma…\n$ age      &lt;dbl&gt; 27, 30, 27, 35, 30, 26, 29, 33, 29, 27, 28, 28, 35, 34, 32, 2…\n$ afam     &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ hispanic &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ other    &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ work     &lt;dbl&gt; 0, 30, 0, 0, 22, 40, 0, 52, 0, 0, 0, 52, 52, 52, 8, 7, 0, 40,…\n\n\n\nbase::dim(Fertility)\n\n[1] 254654      9\n\n\n\nutils::str(Fertility)\n\nspc_tbl_ [254,654 × 9] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ rownames: num [1:254654] 1 2 3 4 5 6 7 8 9 10 ...\n $ morekids: chr [1:254654] \"no\" \"no\" \"no\" \"no\" ...\n $ gender1 : chr [1:254654] \"male\" \"female\" \"male\" \"male\" ...\n $ gender2 : chr [1:254654] \"female\" \"male\" \"female\" \"female\" ...\n $ age     : num [1:254654] 27 30 27 35 30 26 29 33 29 27 ...\n $ afam    : chr [1:254654] \"no\" \"no\" \"no\" \"yes\" ...\n $ hispanic: chr [1:254654] \"no\" \"no\" \"no\" \"no\" ...\n $ other   : chr [1:254654] \"no\" \"no\" \"no\" \"no\" ...\n $ work    : num [1:254654] 0 30 0 0 22 40 0 52 0 0 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   rownames = col_double(),\n  ..   morekids = col_character(),\n  ..   gender1 = col_character(),\n  ..   gender2 = col_character(),\n  ..   age = col_double(),\n  ..   afam = col_character(),\n  ..   hispanic = col_character(),\n  ..   other = col_character(),\n  ..   work = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "posts/Fertility/Fertility.html#viewing-missing-data",
    "href": "posts/Fertility/Fertility.html#viewing-missing-data",
    "title": "Fertility Dataset",
    "section": "",
    "text": "Viewing missing data was not working for the whole data set, so we used slice sample of 100000. The data set did not have any missing data.\n\nFertility_sample &lt;- Fertility %&gt;% dplyr::slice_sample(n = 100000) \nvisdat::vis_dat(Fertility_sample)\n\n\n\n\n\n\n\n\n\nvisdat::vis_miss(Fertility_sample)"
  },
  {
    "objectID": "posts/Fertility/Fertility.html#new-column-for-labeling-ethnicity",
    "href": "posts/Fertility/Fertility.html#new-column-for-labeling-ethnicity",
    "title": "Fertility Dataset",
    "section": "",
    "text": "We created a new column for ethnicity since the data set did not directly indicate whether a person was Caucasian. Based on the data dictionary, all “no” responses were Caucasian. To make the data easier to understand, we added a column to clearly show the ethnicity of a person.\n\nFertility %&gt;% filter(afam == \"no\", hispanic == \"no\", other == \"no\")\n\n# A tibble: 216,033 × 9\n   rownames morekids gender1 gender2   age afam  hispanic other  work\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;\n 1        1 no       male    female     27 no    no       no        0\n 2        2 no       female  male       30 no    no       no       30\n 3        3 no       male    female     27 no    no       no        0\n 4        5 no       female  female     30 no    no       no       22\n 5        6 no       male    female     26 no    no       no       40\n 6        7 no       female  male       29 no    no       no        0\n 7        8 no       male    male       33 no    no       no       52\n 8        9 no       female  male       29 no    no       no        0\n 9       10 no       male    female     27 no    no       no        0\n10       11 yes      male    male       28 no    no       no        0\n# ℹ 216,023 more rows\n\n\n\nFertility_ethnicity &lt;- Fertility %&gt;%\n  mutate(ethnicity = case_when(\n    afam == \"yes\" & hispanic == \"no\" & other == \"no\" ~ \"Afam\",\n    afam == \"no\" & hispanic == \"yes\" & other == \"no\" ~ \"Hispanic\",\n    afam == \"no\" & hispanic == \"no\" & other == \"yes\" ~ \"Other\",\n    afam == \"no\" & hispanic == \"no\" & other == \"no\" ~ \"Caucasian\",\n    afam == \"yes\" & hispanic == \"yes\" & other == \"no\" ~ \"AfamHispanic\",\n    afam == \"yes\" & hispanic == \"no\" & other == \"yes\" ~ \"AfamOther\",\n    afam == \"no\" & hispanic == \"yes\" & other == \"yes\" ~ \"HispanicOther\"\n  ))\n  \nFertility_ethnicity\n\n# A tibble: 254,654 × 10\n   rownames morekids gender1 gender2   age afam  hispanic other  work ethnicity\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    \n 1        1 no       male    female     27 no    no       no        0 Caucasian\n 2        2 no       female  male       30 no    no       no       30 Caucasian\n 3        3 no       male    female     27 no    no       no        0 Caucasian\n 4        4 no       male    female     35 yes   no       no        0 Afam     \n 5        5 no       female  female     30 no    no       no       22 Caucasian\n 6        6 no       male    female     26 no    no       no       40 Caucasian\n 7        7 no       female  male       29 no    no       no        0 Caucasian\n 8        8 no       male    male       33 no    no       no       52 Caucasian\n 9        9 no       female  male       29 no    no       no        0 Caucasian\n10       10 no       male    female     27 no    no       no        0 Caucasian\n# ℹ 254,644 more rows"
  },
  {
    "objectID": "posts/Fertility/Fertility.html#munging",
    "href": "posts/Fertility/Fertility.html#munging",
    "title": "Fertility Dataset",
    "section": "",
    "text": "Fertility_ethnicity_factor &lt;- Fertility_ethnicity %&gt;%\n  mutate(across(where(is.character), as.factor)) %&gt;% \n  relocate(where(is.factor), .after = rownames)\nglimpse(Fertility_ethnicity_factor)\n\nRows: 254,654\nColumns: 10\n$ rownames  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ morekids  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, yes, no, no, no, no,…\n$ gender1   &lt;fct&gt; male, female, male, male, female, male, female, male, female…\n$ gender2   &lt;fct&gt; female, male, female, female, female, female, male, male, ma…\n$ afam      &lt;fct&gt; no, no, no, yes, no, no, no, no, no, no, no, no, no, no, no,…\n$ hispanic  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ other     &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ ethnicity &lt;fct&gt; Caucasian, Caucasian, Caucasian, Afam, Caucasian, Caucasian,…\n$ age       &lt;dbl&gt; 27, 30, 27, 35, 30, 26, 29, 33, 29, 27, 28, 28, 35, 34, 32, …\n$ work      &lt;dbl&gt; 0, 30, 0, 0, 22, 40, 0, 52, 0, 0, 0, 52, 52, 52, 8, 7, 0, 40…"
  },
  {
    "objectID": "posts/Fertility/Fertility.html#cleaned-table",
    "href": "posts/Fertility/Fertility.html#cleaned-table",
    "title": "Fertility Dataset",
    "section": "",
    "text": "Fertility_ethnicity_factor\n\n# A tibble: 254,654 × 10\n   rownames morekids gender1 gender2 afam  hispanic other ethnicity   age  work\n      &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;   &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1        1 no       male    female  no    no       no    Caucasian    27     0\n 2        2 no       female  male    no    no       no    Caucasian    30    30\n 3        3 no       male    female  no    no       no    Caucasian    27     0\n 4        4 no       male    female  yes   no       no    Afam         35     0\n 5        5 no       female  female  no    no       no    Caucasian    30    22\n 6        6 no       male    female  no    no       no    Caucasian    26    40\n 7        7 no       female  male    no    no       no    Caucasian    29     0\n 8        8 no       male    male    no    no       no    Caucasian    33    52\n 9        9 no       female  male    no    no       no    Caucasian    29     0\n10       10 no       male    female  no    no       no    Caucasian    27     0\n# ℹ 254,644 more rows"
  },
  {
    "objectID": "posts/Fertility/Fertility.html#summaries-examining-the-data",
    "href": "posts/Fertility/Fertility.html#summaries-examining-the-data",
    "title": "Fertility Dataset",
    "section": "",
    "text": "Fertility_ethnicity_factor %&gt;%\n  dplyr::count(across(.cols = c (gender1 , gender2)))\n\n# A tibble: 4 × 3\n  gender1 gender2     n\n  &lt;fct&gt;   &lt;fct&gt;   &lt;int&gt;\n1 female  female  60946\n2 female  male    62724\n3 male    female  63185\n4 male    male    67799\n\n\n\nFertility_ethnicity_factor %&gt;% \n  group_by(morekids) %&gt;% \n  summarise(average_age=mean(age),count=n()) %&gt;% tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                morekids\n                average_age\n                count\n              \n        \n        \n        \n                \n                  no\n                  30.12810\n                  157742\n                \n                \n                  yes\n                  30.82487\n                  96912\n                \n        \n      \n    \n\n\n\n\ncrosstable(morekids ~ gender2 + gender1,\n  data = Fertility_ethnicity_factor\n) %&gt;%\n  crosstable::as_flextable()\n\ngender1femalemalegender2femalemalefemalemalemorekidsno35057 (22.22%)40987 (25.98%)41304 (26.18%)40394 (25.61%)yes25889 (26.71%)21737 (22.43%)21881 (22.58%)27405 (28.28%)\n\n\n\ncrosstable(ethnicity ~ morekids,\n  data = Fertility_ethnicity_factor\n) %&gt;%\n  crosstable::as_flextable()\n\nlabelvariablemorekidsnoyesethnicityAfam7027 (54.22%)5933 (45.78%)AfamHispanic104 (53.06%)92 (46.94%)Caucasian137344 (63.58%)78689 (36.42%)Hispanic5562 (50.03%)5555 (49.97%)HispanicOther3522 (46.44%)4062 (53.56%)Other4183 (61.84%)2581 (38.16%)\n\n\n\nFertility_ethnicity_factor %&gt;% \n  group_by(morekids) %&gt;% \n  summarize(average_workhours = mean(work)) %&gt;% tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                morekids\n                average_workhours\n              \n        \n        \n        \n                \n                  no\n                  21.06843\n                \n                \n                  yes\n                  15.68143"
  },
  {
    "objectID": "posts/Fertility/Fertility.html#visualizing-the-data",
    "href": "posts/Fertility/Fertility.html#visualizing-the-data",
    "title": "Fertility Dataset",
    "section": "",
    "text": "Hypothesis: Families with two daughters (female.female) could have more children.\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  gf_bar(~interaction(gender1,gender2),\n    fill = ~morekids,\n    position = \"dodge\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Morekids vs Gender Composition\",\n    subtitle = \"How morekids is being effected based on current gender of kids\",\n    x=\"Gender of First Two Children\",\n    y=\"Count\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  gf_bar(~interaction(gender1,gender2),\n    fill = ~morekids,\n    position = \"fill\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Morekids vs Gender Composition\",\n    subtitle = \"How morekids is being effected based on current gender of kids\",\n    x=\"Gender of First Two Children\",\n    y=\"Count\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\nInferences\n\nFamilies with two girls are most likely to have more children.\nFamilies with one boy and one girl are least likely to continue growing their family.\nFamilies with two boys also show a high chance of having more kids.\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  gf_bar(~ethnicity,\n    fill = ~interaction(gender1,gender2),\n    position = \"dodge\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Ethnicity vs Gender Composition\",\n    x=\"Gender of First Two Children\",\n    y=\"Count of Families\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set2\"))\n\n\n\n\n\n\n\n\n\n\n\n\nHypothesis: Women who worked less number of weeks would have more kids.\n\n\n\n\ngf_histogram(~work,\n  data = Fertility_ethnicity_factor,\n  bins = 30,                \n  fill = ~morekids,         \n  position = \"dodge\"        \n) %&gt;%\n  gf_labs(\n    title = \"Distribution of Work Weeks by More Kids\",\n    subtitle = \"Number of Work Weeks in 1979 for Mothers with or without more kids\",\n    x = \"Work weeks in 1979\",\n    y = \"Count\",\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;% \n  count(morekids, work) %&gt;% \n  gf_line(n ~ work, color = ~morekids, linewidth = 0.8) %&gt;%\n  gf_labs(\n    title = \"Distribution of Work Weeks by More Kids\",\n    subtitle = \"Number of Work Weeks in 1979 for Mothers with or without more kids\",\n    x = \"Work weeks in 1979\",\n    y = \"Count\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;% \n  gf_boxplot(morekids ~ work, orientation = \"y\", fill=~morekids, color = \"black\") %&gt;%\n  gf_labs(y = \"More kids\", \n          x = \"Work weeks in 1979\", \n          title = \"Distribution of Work Weeks by More Kids\",\n          subtitle = \"Number of Work Weeks in 1979 for Mothers with or without more kids\")\n\n\n\n\n\n\n\n\n\nInferences\n\nMost individuals either worked a full year (52 weeks) or did not work at all (0 weeks)\nNot working mothers dominates - The largest group is those who worked 0 weeks.\nWorking full year (52 weeks) is the second largest group.\nMothers who worked between 2-50 weeks is a minority.\nThe difference between “more kids” and “no kids”:\n\nPeople with no kids lean more towards full-time work.\nPeople with kids lean more towards not working at all or working fewer weeks.\n\n\n\nOverall insight: The “no more kids” category is the largest overall especially among non working mothers. This shows most people in 1979 had only 2 kids.\n\n\n\n\n\nHypothesis: Older women would have more kids.\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  gf_density(~age, color = ~morekids, fill = ~morekids) %&gt;%\n  gf_labs(\n    title = \"Distribution of Age by More Kids\",\n    subtitle = \"Ages of Mothers with or without more kids\",\n    x = \"Age of Mothers\",\n    y = \"Density\",\n    color = \"More Kids\",\n    fill = \"More Kids\"\n  )\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;% \n  gf_boxplot(morekids ~ age, orientation = \"y\", fill=~morekids, color = \"black\") %&gt;%\n  gf_labs(y = \"Morekids\", x = \"Age of Mothers\", \n          title = \"Distribution of Age by More Kids\",\n          subtitle = \"Ages of Mothers with or without more kids\")\n\n\n\n\n\n\n\n\n\nInferences\n\nThe possibility of having more kids increases with age as seen as in the density distribution graph.\nThe age of people who have more kids (median 31) is only slightly higher than the age of people who do not have more kids (median 30)\nThe group that responded “no” (they do not want more kids) has a slightly wider Interquartile Range.\n\n50% of mothers in the “no” category are more spread out in age from 28 to 32 years\n50% of people in the “yes” group are more clustered in age from 30 to 32 years\n\nOutliers: A few mothers who have more kids are younger than others (around age 22-23).\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  count(ethnicity, morekids) %&gt;%  \n  gf_col(n ~ ethnicity, fill = ~morekids, position = \"dodge\") %&gt;%  \n  gf_labs(\n    title = \"Ethnic Group Distribution by More Kids\",\n    subtitle = \"Count of Respondents who have More Children \",\n    x = \"Ethnic Group\",\n    y = \"Number of People\",\n    fill = \"More Kids\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set2\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  count(ethnicity, morekids) %&gt;%  \n  gf_col(n ~ ethnicity, fill = ~morekids, position = \"fill\") %&gt;%  \n  gf_labs(\n    title = \"Ethnic Group Distribution by More Kids\",\n    subtitle = \"Count of Respondents who have More Children \",\n    x = \"Ethnic Group\",\n    y = \"Number of People\",\n    fill = \"More Kids\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set2\"))\n\n\n\n\n\n\n\n\n\nInferences\n\nThe Caucasian group is much larger than all other ethnic groups in the survey, as seen in the first graph.\nAfrican-Americans and Hispanics have the highest proportion of respondents who have more kids.\nThe Caucasian group and the Other group have a lower proportion of having more kids."
  },
  {
    "objectID": "classwork/maps/index.html",
    "href": "classwork/maps/index.html",
    "title": "Classwork 7",
    "section": "",
    "text": "library(rnaturalearth)\nlibrary(rnaturalearthdata)\n\n\nAttaching package: 'rnaturalearthdata'\n\n\nThe following object is masked from 'package:rnaturalearth':\n\n    countries110\n\n# Run this in your console first\n# devtools::install_github(\"ropensci/rnaturalearthhires\")\nlibrary(rnaturalearthhires)\n\n# Plotting Maps\nlibrary(tidyverse) # Maps using ggplot() + geom_sf()\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggformula) # Maps using gf_sf()\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(tmap) # Thematic Maps, static and interactive\nlibrary(tmaptools)\nlibrary(tmap.mapgl)\nlibrary(osmdata) # Fetch map data from osmdata.org\n\nData (c) OpenStreetMap contributors, ODbL 1.0. https://www.openstreetmap.org/copyright\n\nlibrary(sfheaders) # Handcrafted Map data\n## Interactive Maps\nlibrary(leaflet) # interactive Maps\nlibrary(leaflet)\nlibrary(leaflet.providers)\nlibrary(leaflet.extras)\nlibrary(threejs) # Globe maps in R. Part of the htmlwidgets family of packages\n\nLoading required package: igraph\n\nAttaching package: 'igraph'\n\nThe following objects are masked from 'package:lubridate':\n\n    %--%, union\n\nThe following objects are masked from 'package:dplyr':\n\n    as_data_frame, groups, union\n\nThe following objects are masked from 'package:purrr':\n\n    compose, simplify\n\nThe following object is masked from 'package:tidyr':\n\n    crossing\n\nThe following object is masked from 'package:tibble':\n\n    as_data_frame\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\nThe following object is masked from 'package:base':\n\n    union\n\n# For Spatial Data Frame Processing\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE\n\n\n\n# https://boundingbox.klokantech.com CSV:\n# 77.574028,12.917262,77.595073,12.939895\nbbox_1 &lt;- matrix(c(76.297617,9.945678,76.308722,9.967725), byrow = FALSE, nrow = 2,\n    ncol = 2, dimnames = list(c(\"x\", \"y\"), c(\"min\", \"max\")))\nbbox_1\n\n        min       max\nx 76.297617 76.308722\ny  9.945678  9.967725\n\n\n\nbbox_1\n\n        min       max\nx 76.297617 76.308722\ny  9.945678  9.967725\n\n\n\nbuildings &lt;- st_read(\"my-osm-data/buildings.gpkg\")\n\nReading layer `buildings' from data source \n  `C:\\Users\\diyab\\OneDrive\\Documents\\DiyaData\\classwork\\maps\\my-osm-data\\buildings.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1187 features and 82 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 76.29733 ymin: 9.945705 xmax: 76.30903 ymax: 9.967958\nGeodetic CRS:  WGS 84\n\n\n\nroads &lt;- st_read(\"my-osm-data/roads.gpkg\")\n\nReading layer `roads' from data source \n  `C:\\Users\\diyab\\OneDrive\\Documents\\DiyaData\\classwork\\maps\\my-osm-data\\roads.gpkg' \n  using driver `GPKG'\nSimple feature collection with 740 features and 45 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 76.29536 ymin: 9.943133 xmax: 76.31063 ymax: 9.978089\nGeodetic CRS:  WGS 84\n\n\n\ntrees &lt;- st_read(\"my-osm-data/trees.gpkg\")\n\nReading layer `trees' from data source \n  `C:\\Users\\diyab\\OneDrive\\Documents\\DiyaData\\classwork\\maps\\my-osm-data\\trees.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1003 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 76.29058 ymin: 9.936576 xmax: 76.31755 ymax: 9.979565\nGeodetic CRS:  WGS 84\n\n\n\ngreenery &lt;- st_read(\"my-osm-data/greenery.gpkg\")\n\nReading layer `greenery' from data source \n  `C:\\Users\\diyab\\OneDrive\\Documents\\DiyaData\\classwork\\maps\\my-osm-data\\greenery.gpkg' \n  using driver `GPKG'\nSimple feature collection with 11 features and 11 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 76.29058 ymin: 9.943617 xmax: 76.3092 ymax: 9.979565\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "classwork/maps/index.html#setup",
    "href": "classwork/maps/index.html#setup",
    "title": "Classwork 7",
    "section": "",
    "text": "library(rnaturalearth)\nlibrary(rnaturalearthdata)\n\n\nAttaching package: 'rnaturalearthdata'\n\n\nThe following object is masked from 'package:rnaturalearth':\n\n    countries110\n\n# Run this in your console first\n# devtools::install_github(\"ropensci/rnaturalearthhires\")\nlibrary(rnaturalearthhires)\n\n# Plotting Maps\nlibrary(tidyverse) # Maps using ggplot() + geom_sf()\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggformula) # Maps using gf_sf()\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(tmap) # Thematic Maps, static and interactive\nlibrary(tmaptools)\nlibrary(tmap.mapgl)\nlibrary(osmdata) # Fetch map data from osmdata.org\n\nData (c) OpenStreetMap contributors, ODbL 1.0. https://www.openstreetmap.org/copyright\n\nlibrary(sfheaders) # Handcrafted Map data\n## Interactive Maps\nlibrary(leaflet) # interactive Maps\nlibrary(leaflet)\nlibrary(leaflet.providers)\nlibrary(leaflet.extras)\nlibrary(threejs) # Globe maps in R. Part of the htmlwidgets family of packages\n\nLoading required package: igraph\n\nAttaching package: 'igraph'\n\nThe following objects are masked from 'package:lubridate':\n\n    %--%, union\n\nThe following objects are masked from 'package:dplyr':\n\n    as_data_frame, groups, union\n\nThe following objects are masked from 'package:purrr':\n\n    compose, simplify\n\nThe following object is masked from 'package:tidyr':\n\n    crossing\n\nThe following object is masked from 'package:tibble':\n\n    as_data_frame\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\nThe following object is masked from 'package:base':\n\n    union\n\n# For Spatial Data Frame Processing\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE\n\n\n\n# https://boundingbox.klokantech.com CSV:\n# 77.574028,12.917262,77.595073,12.939895\nbbox_1 &lt;- matrix(c(76.297617,9.945678,76.308722,9.967725), byrow = FALSE, nrow = 2,\n    ncol = 2, dimnames = list(c(\"x\", \"y\"), c(\"min\", \"max\")))\nbbox_1\n\n        min       max\nx 76.297617 76.308722\ny  9.945678  9.967725\n\n\n\nbbox_1\n\n        min       max\nx 76.297617 76.308722\ny  9.945678  9.967725\n\n\n\nbuildings &lt;- st_read(\"my-osm-data/buildings.gpkg\")\n\nReading layer `buildings' from data source \n  `C:\\Users\\diyab\\OneDrive\\Documents\\DiyaData\\classwork\\maps\\my-osm-data\\buildings.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1187 features and 82 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 76.29733 ymin: 9.945705 xmax: 76.30903 ymax: 9.967958\nGeodetic CRS:  WGS 84\n\n\n\nroads &lt;- st_read(\"my-osm-data/roads.gpkg\")\n\nReading layer `roads' from data source \n  `C:\\Users\\diyab\\OneDrive\\Documents\\DiyaData\\classwork\\maps\\my-osm-data\\roads.gpkg' \n  using driver `GPKG'\nSimple feature collection with 740 features and 45 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 76.29536 ymin: 9.943133 xmax: 76.31063 ymax: 9.978089\nGeodetic CRS:  WGS 84\n\n\n\ntrees &lt;- st_read(\"my-osm-data/trees.gpkg\")\n\nReading layer `trees' from data source \n  `C:\\Users\\diyab\\OneDrive\\Documents\\DiyaData\\classwork\\maps\\my-osm-data\\trees.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1003 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 76.29058 ymin: 9.936576 xmax: 76.31755 ymax: 9.979565\nGeodetic CRS:  WGS 84\n\n\n\ngreenery &lt;- st_read(\"my-osm-data/greenery.gpkg\")\n\nReading layer `greenery' from data source \n  `C:\\Users\\diyab\\OneDrive\\Documents\\DiyaData\\classwork\\maps\\my-osm-data\\greenery.gpkg' \n  using driver `GPKG'\nSimple feature collection with 11 features and 11 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 76.29058 ymin: 9.943617 xmax: 76.3092 ymax: 9.979565\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "classwork/classwork8/classwork8.html",
    "href": "classwork/classwork8/classwork8.html",
    "title": "classwork8",
    "section": "",
    "text": "library(tidyverse) # Data Processing in R\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic) # Our workhorse for stats, sampling\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(janitor) # Data Cleaning\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(skimr) # Good to Examine data\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(ggformula) # Formula interface for graphs\n\n# load the NHANES data library\nlibrary(NHANES)\nlibrary(infer)\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\n\n\ndata(\"NHANES\")\n\n\nNHANES_adult &lt;-\n  NHANES %&gt;%\n  distinct(ID, .keep_all = TRUE) %&gt;%\n  filter(Age &gt;= 18) %&gt;%\n  select(Height) %&gt;%\n  drop_na(Height)\nNHANES_adult %&gt;% glimpse()\n\nRows: 4,790\nColumns: 1\n$ Height &lt;dbl&gt; 164.7, 168.4, 166.7, 169.5, 181.9, 169.4, 148.1, 177.8, 181.3, …\n\n\n\n# NHANES_adult is assumed population\npop_mean &lt;- mosaic::mean(~Height, data = NHANES_adult)\npop_sd &lt;- mosaic::sd(~Height, data = NHANES_adult)\npop_mean\n\n[1] 168.3497\n\n\n\npop_sd\n\n[1] 10.15705\n\n\n\nset.seed(12345) # for reproducibility\nsample_50 &lt;- mosaic::sample(NHANES_adult, size = 50) %&gt;%\n  select(Height)\nsample_50\n\n# A tibble: 50 × 1\n   Height\n    &lt;dbl&gt;\n 1   155.\n 2   154.\n 3   173.\n 4   179.\n 5   170.\n 6   186.\n 7   159.\n 8   173.\n 9   175.\n10   170.\n# ℹ 40 more rows\n\nsample_mean_50 &lt;- mean(~Height, data = sample_50)\nsample_mean_50\n\n[1] 170.094\n\n# Plotting the histogram of this sample\nsample_50 %&gt;%\n  gf_histogram(~Height, bins = 10) %&gt;%\n  gf_vline(\n    xintercept = ~sample_mean_50,\n    color = \"purple\"\n  ) %&gt;%\n  gf_vline(\n    xintercept = ~pop_mean,\n    colour = \"black\"\n  ) %&gt;%\n  gf_annotate(\"label\",\n    y = 7, x = pop_mean - 8,\n    label = \"Population Mean\",\n    color = \"black\"\n  ) %&gt;%\n  gf_annotate(\"label\",\n    y = 7, x = sample_mean_50 + 8,\n    label = \"Sample Mean\", color = \"purple\"\n  ) %&gt;%\n  gf_annotate(\"curve\",\n    x = sample_mean_50 + 8, y = 6.5,\n    xend = sample_mean_50 + 1, yend = 2,\n    curvature = -0.2, color = \"purple\",\n    arrow = arrow(length = unit(0.5, \"cm\"))\n  ) %&gt;%\n  gf_annotate(\"curve\",\n    x = pop_mean - 8, y = 6.5,\n    xend = pop_mean - 1, yend = 2,\n    curvature = 0.2, color = \"black\", arrow = arrow(length = unit(0.5, \"cm\"))\n  ) %&gt;%\n  gf_labs(\n    y = \"Frequency\",\n    title = \"Distribution and Mean of a Single Sample\",\n    subtitle = \"Sample Size = 50\"\n  )\n\n\n\n\n\n\n\n\n\nsample_50_500 &lt;- do(500) * {\n  sample(NHANES_adult, size = 50) %&gt;%\n    select(Height) %&gt;% # drop sampling related column \"orig.id\"\n    summarise(\n      sample_mean = mean(Height),\n      sample_sd = sd(Height),\n      sample_min = min(Height),\n      sample_max = max(Height)\n    )\n}\nsample_50_500 &lt;-\n  sample_50_500 %&gt;%\n  select(.index, sample_mean, sample_sd, sample_min, sample_max)\nsample_50_500\n\n# A tibble: 500 × 5\n   .index sample_mean sample_sd sample_min sample_max\n    &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1      1        167.     11.2        147.       189.\n 2      2        168.      8.30       152.       187 \n 3      3        166.     10.3        148.       191.\n 4      4        169.     10.0        144.       188.\n 5      5        166.     10.6        148.       191.\n 6      6        169.      9.67       147.       185.\n 7      7        167.      9.90       148.       188.\n 8      8        170.     10.9        150.       187.\n 9      9        169.      8.23       155.       184.\n10     10        165.      9.64       142.       185.\n# ℹ 490 more rows\n\ndim(sample_50_500)\n\n[1] 500   5\n\n\n\nsample_50_500 %&gt;%\n  gf_point(.index ~ sample_mean,\n    color = \"purple\",\n    title = \"Sample Means are close to the Population Mean\",\n    subtitle = \"Sample Means are Random!\",\n    caption = \"Grey lines represent our 500 samples\"\n  ) %&gt;%\n  gf_segment(\n    .index + .index ~ sample_min + sample_max,\n    color = \"grey\",\n    linewidth = 0.3,\n    alpha = 0.3,\n    ylab = \"Sample Index (1-500)\",\n    xlab = \"Sample Means\"\n  ) %&gt;%\n  gf_vline(\n    xintercept = ~pop_mean,\n    color = \"black\"\n  ) %&gt;%\n  gf_annotate(\"label\",\n    y = -25, x = pop_mean,\n    label = \"Population Mean\",\n    color = \"black\"\n  )\n\n\n\n\n\n\n\n##\n\nsample_50_500 %&gt;%\n  gf_point(.index ~ sample_sd,\n    color = \"purple\",\n    title = \"Sample SDs are close to the Population SD\",\n    subtitle = \"Sample SDs are Random!\",\n  ) %&gt;%\n  gf_vline(\n    xintercept = ~pop_sd,\n    color = \"black\"\n  ) %&gt;%\n  gf_annotate(\"label\",\n    y = -25, x = pop_sd,\n    label = \"Population SD\",\n    color = \"black\"\n  ) %&gt;%\n  gf_refine(lims(x = c(4, 16))) %&gt;%\n  gf_labs(x = \"Sample SDs\", y = \"Sample Index (1-500)\")\n\n\n\n\n\n\n\n\n\nsample_50_500 %&gt;%\n  gf_dhistogram(~sample_mean, bins = 30, xlab = \"Sample Means only\") %&gt;%\n  gf_vline(\n    xintercept = pop_mean,\n    color = \"blue\"\n  ) %&gt;%\n  gf_label(0.01 ~ pop_mean,\n    label = \"Population Mean\",\n    color = \"blue\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Sampling Mean Distribution\",\n    subtitle = \"500 means\"\n  )\n\nWarning in (function (mapping = NULL, data = NULL, stat = \"identity\", position = \"nudge\", : All aesthetics have length 1, but the data has 500 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n# How does this **distribution of sample-means** compare with the\n# overall distribution of the population?\n#\nsample_50_500 %&gt;%\n  gf_dhistogram(~sample_mean, bins = 30, xlab = \"Sample Means, and the Height variable\") %&gt;%\n  gf_vline(\n    xintercept = pop_mean,\n    color = \"blue\"\n  ) %&gt;%\n  gf_label(0.01 ~ pop_mean,\n    label = \"Population Mean\",\n    color = \"blue\"\n  ) %&gt;%\n  ## Add the population histogram\n  gf_histogram(~Height,\n    data = NHANES_adult,\n    alpha = 0.2, fill = \"blue\",\n    bins = 30\n  ) %&gt;%\n  gf_label(0.025 ~ (pop_mean + 20),\n    label = \"Population Distribution of Height\",\n    color = \"blue\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Sampling Mean Distribution\",\n    subtitle = \"Original Population overlay\"\n  )\n\nWarning in (function (mapping = NULL, data = NULL, stat = \"identity\", position = \"nudge\", : All aesthetics have length 1, but the data has 500 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in (function (mapping = NULL, data = NULL, stat = \"identity\", position = \"nudge\", : All aesthetics have length 1, but the data has 500 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\n\nset.seed(12345)\nsamples_08_1000 &lt;- do(1000) * resample(NHANES_adult$Height,\n  size = 08\n) %&gt;% mean()\nsamples_08_1000\n\n       result\n1    169.1500\n2    174.1125\n3    171.2250\n4    166.3625\n5    170.2000\n6    165.1125\n7    170.9875\n8    168.6625\n9    166.5250\n10   164.9000\n11   167.3000\n12   162.7000\n13   171.9375\n14   168.1875\n15   162.8875\n16   162.0125\n17   173.2625\n18   169.4875\n19   165.6375\n20   164.4250\n21   171.8000\n22   170.3375\n23   160.1375\n24   172.2875\n25   167.0125\n26   172.7125\n27   165.3375\n28   164.2250\n29   162.7250\n30   161.9500\n31   170.8125\n32   169.5250\n33   166.1875\n34   173.1750\n35   166.0625\n36   167.9750\n37   166.1625\n38   169.6250\n39   171.8375\n40   166.2250\n41   164.6500\n42   163.9000\n43   165.3125\n44   174.0750\n45   173.1375\n46   169.7125\n47   168.6000\n48   162.6125\n49   161.5625\n50   163.3500\n51   159.9875\n52   166.4875\n53   172.7125\n54   174.6125\n55   162.2000\n56   168.1625\n57   170.0000\n58   175.6750\n59   166.8375\n60   169.8750\n61   170.4500\n62   174.2125\n63   162.1000\n64   166.1875\n65   166.1500\n66   174.6000\n67   169.8625\n68   170.6875\n69   164.4125\n70   158.6875\n71   165.6500\n72   164.0750\n73   170.0875\n74   171.8625\n75   165.5000\n76   169.0250\n77   161.8375\n78   167.7625\n79   167.5500\n80   167.6500\n81   171.9000\n82   164.3500\n83   173.5750\n84   174.7875\n85   165.1500\n86   170.2875\n87   163.1500\n88   171.1625\n89   168.8000\n90   166.4625\n91   172.2125\n92   163.4625\n93   166.8000\n94   171.5625\n95   160.7375\n96   169.4000\n97   168.9375\n98   168.7000\n99   164.9500\n100  166.1750\n101  168.6750\n102  175.1750\n103  175.0125\n104  162.9250\n105  165.7750\n106  170.2125\n107  163.2500\n108  166.4250\n109  167.1500\n110  174.6750\n111  167.7000\n112  163.7625\n113  173.0500\n114  166.0125\n115  170.6000\n116  160.6750\n117  162.1625\n118  165.8625\n119  165.4125\n120  171.2000\n121  169.5500\n122  167.8250\n123  166.4750\n124  169.3250\n125  166.4500\n126  177.2875\n127  174.0500\n128  165.9875\n129  165.7375\n130  169.0875\n131  168.6875\n132  170.2500\n133  158.9250\n134  171.3625\n135  161.4125\n136  167.7375\n137  162.8000\n138  170.9500\n139  174.4500\n140  169.4500\n141  162.8750\n142  166.0625\n143  169.1875\n144  163.5500\n145  175.7250\n146  165.5750\n147  167.5875\n148  171.3375\n149  171.7750\n150  166.5250\n151  168.8250\n152  172.3375\n153  169.2875\n154  170.1000\n155  169.3125\n156  171.2750\n157  167.8875\n158  170.5125\n159  162.9250\n160  168.0500\n161  166.9375\n162  169.9250\n163  168.9500\n164  175.6375\n165  166.2125\n166  176.4875\n167  169.8750\n168  173.1375\n169  162.5750\n170  166.0500\n171  171.5625\n172  170.9375\n173  169.3000\n174  166.7250\n175  171.5625\n176  166.1500\n177  168.4875\n178  168.8375\n179  166.7875\n180  173.1625\n181  171.6500\n182  168.8750\n183  166.2500\n184  165.5250\n185  160.4500\n186  170.9500\n187  170.3875\n188  164.2000\n189  163.8375\n190  163.8875\n191  164.6875\n192  169.3000\n193  172.1875\n194  168.7250\n195  166.1750\n196  170.9250\n197  159.8250\n198  166.2625\n199  164.6125\n200  166.6750\n201  169.3750\n202  167.6875\n203  165.3875\n204  169.1750\n205  169.7750\n206  168.4000\n207  167.3500\n208  170.4625\n209  169.1375\n210  171.3875\n211  167.0875\n212  170.4250\n213  166.3375\n214  169.0250\n215  167.1750\n216  167.4250\n217  163.0000\n218  168.0500\n219  167.2000\n220  166.4750\n221  171.0875\n222  169.8125\n223  165.1500\n224  166.6625\n225  166.7750\n226  169.6500\n227  168.3125\n228  172.7500\n229  163.9750\n230  165.9125\n231  168.8750\n232  170.6750\n233  166.6000\n234  171.4375\n235  171.1625\n236  168.8000\n237  167.1500\n238  168.9125\n239  168.1000\n240  166.5000\n241  169.7250\n242  169.2500\n243  166.2875\n244  167.8375\n245  171.6875\n246  165.8375\n247  168.8750\n248  169.6375\n249  174.6750\n250  168.3625\n251  171.2625\n252  170.4375\n253  165.9250\n254  169.3250\n255  169.9375\n256  174.0250\n257  168.1000\n258  172.4625\n259  167.5750\n260  167.2625\n261  165.6250\n262  171.7750\n263  164.3125\n264  166.8500\n265  164.4875\n266  165.2125\n267  166.2000\n268  165.4000\n269  168.8375\n270  167.3125\n271  169.1500\n272  169.3250\n273  164.8875\n274  165.3375\n275  169.2750\n276  177.1000\n277  161.4625\n278  169.6000\n279  166.8625\n280  171.5625\n281  162.1625\n282  167.5250\n283  169.8500\n284  164.1500\n285  168.3125\n286  165.7625\n287  160.0625\n288  171.4000\n289  176.1625\n290  170.2125\n291  173.4875\n292  166.6375\n293  175.2250\n294  163.9125\n295  169.2375\n296  169.5500\n297  167.7625\n298  170.4500\n299  165.9000\n300  169.4500\n301  174.9750\n302  175.0500\n303  175.2625\n304  163.7500\n305  171.6875\n306  169.8125\n307  168.1125\n308  169.9500\n309  160.8500\n310  168.0750\n311  168.5125\n312  162.3125\n313  168.1875\n314  173.7750\n315  162.1500\n316  168.8750\n317  170.3125\n318  172.4375\n319  168.9250\n320  167.1250\n321  165.6375\n322  164.6625\n323  169.7000\n324  167.4500\n325  171.8625\n326  171.9500\n327  165.7000\n328  174.7125\n329  170.4500\n330  168.5875\n331  165.3875\n332  170.4625\n333  168.4750\n334  167.1500\n335  163.9500\n336  168.1500\n337  169.2375\n338  162.6625\n339  164.7500\n340  166.7000\n341  166.4375\n342  162.7500\n343  166.9000\n344  166.9625\n345  169.7375\n346  166.1250\n347  167.9250\n348  170.5750\n349  163.4250\n350  171.5375\n351  163.5125\n352  174.1375\n353  168.0750\n354  168.3125\n355  165.6375\n356  163.6875\n357  166.5500\n358  175.6250\n359  169.0875\n360  174.9500\n361  163.1125\n362  173.0625\n363  169.1625\n364  169.9500\n365  172.6375\n366  168.3250\n367  164.2250\n368  164.1000\n369  175.0250\n370  175.8875\n371  167.8375\n372  174.1750\n373  167.4000\n374  165.8625\n375  164.8125\n376  167.6250\n377  171.4875\n378  170.3125\n379  167.5875\n380  164.7000\n381  170.1625\n382  169.2625\n383  165.8250\n384  167.9750\n385  162.6250\n386  168.0500\n387  168.8375\n388  167.1625\n389  161.6750\n390  170.4250\n391  174.2625\n392  168.5000\n393  163.5875\n394  169.5000\n395  167.9125\n396  164.4500\n397  161.2125\n398  167.3125\n399  162.2375\n400  165.3375\n401  169.8125\n402  168.5500\n403  171.6125\n404  170.0750\n405  171.0000\n406  167.2000\n407  162.4625\n408  175.3750\n409  160.5375\n410  175.0375\n411  166.7625\n412  170.3875\n413  168.3125\n414  163.8375\n415  164.1875\n416  171.0750\n417  170.5625\n418  172.5750\n419  167.7500\n420  177.3125\n421  169.6250\n422  176.5875\n423  169.9625\n424  167.8500\n425  169.5250\n426  166.6000\n427  171.8500\n428  169.8375\n429  163.4375\n430  170.9375\n431  163.3125\n432  167.1125\n433  163.4625\n434  165.8750\n435  163.2750\n436  168.0875\n437  164.2375\n438  164.2375\n439  176.6500\n440  169.9000\n441  171.0000\n442  160.5875\n443  174.8250\n444  169.8500\n445  170.8500\n446  174.9875\n447  166.0375\n448  169.8125\n449  163.0125\n450  173.0625\n451  172.9875\n452  172.5625\n453  169.7500\n454  174.0125\n455  168.7875\n456  165.6250\n457  166.9500\n458  176.7125\n459  169.2375\n460  178.2500\n461  170.9250\n462  174.7125\n463  166.4625\n464  163.4875\n465  167.1375\n466  164.4250\n467  165.6125\n468  174.9000\n469  162.7250\n470  167.4750\n471  168.7625\n472  169.3500\n473  162.9375\n474  165.8375\n475  174.3875\n476  168.9250\n477  162.0125\n478  170.0750\n479  163.3250\n480  171.7250\n481  170.5000\n482  170.3625\n483  170.8375\n484  167.5750\n485  164.4125\n486  174.9125\n487  165.9375\n488  171.6125\n489  166.3875\n490  163.7000\n491  168.5250\n492  171.4250\n493  172.3625\n494  160.7375\n495  164.7375\n496  165.1625\n497  168.9750\n498  168.1000\n499  165.4625\n500  166.8375\n501  169.0625\n502  169.2375\n503  166.2500\n504  170.6500\n505  172.6875\n506  171.5750\n507  167.8750\n508  168.6000\n509  168.9875\n510  167.8375\n511  168.9625\n512  169.5375\n513  169.9750\n514  169.5750\n515  168.6625\n516  166.2625\n517  169.9500\n518  163.8125\n519  168.1500\n520  169.8750\n521  170.2125\n522  170.1625\n523  167.4875\n524  162.2625\n525  170.9750\n526  174.4250\n527  167.5000\n528  168.0250\n529  167.5625\n530  167.6125\n531  160.4375\n532  168.4750\n533  167.0750\n534  171.9875\n535  169.3375\n536  172.7250\n537  168.5750\n538  166.6500\n539  164.7125\n540  164.4625\n541  167.3625\n542  163.7125\n543  163.1625\n544  166.4375\n545  164.8625\n546  167.6375\n547  172.3875\n548  170.4625\n549  160.9000\n550  169.7125\n551  171.5375\n552  170.2250\n553  165.7625\n554  166.8250\n555  167.2375\n556  165.5375\n557  160.4875\n558  170.4750\n559  163.3625\n560  158.6750\n561  172.1875\n562  164.8250\n563  170.4750\n564  167.1750\n565  165.7500\n566  163.6875\n567  164.3250\n568  158.6375\n569  168.8000\n570  166.9625\n571  170.7875\n572  172.9625\n573  167.2750\n574  170.7500\n575  168.9375\n576  165.4750\n577  166.4875\n578  169.2375\n579  178.9875\n580  164.9750\n581  168.0125\n582  165.4750\n583  169.3125\n584  164.0375\n585  168.7625\n586  169.9125\n587  167.7375\n588  163.7000\n589  167.9125\n590  170.8500\n591  171.4125\n592  166.6250\n593  169.2250\n594  174.6750\n595  171.9250\n596  170.8250\n597  169.8625\n598  166.4875\n599  172.1125\n600  164.5125\n601  174.3250\n602  178.1625\n603  165.4000\n604  165.7375\n605  168.1875\n606  166.4000\n607  169.1500\n608  167.2375\n609  169.7375\n610  170.4125\n611  174.9250\n612  168.9500\n613  171.4375\n614  170.8625\n615  166.8125\n616  174.3500\n617  168.9125\n618  167.4625\n619  171.4125\n620  165.6625\n621  168.9250\n622  166.5000\n623  163.9625\n624  172.0875\n625  164.5750\n626  164.4375\n627  171.6125\n628  171.5875\n629  168.0000\n630  170.8875\n631  167.5250\n632  171.9125\n633  173.4750\n634  172.7500\n635  165.5750\n636  167.5625\n637  176.8125\n638  164.5250\n639  168.8375\n640  167.9625\n641  164.5250\n642  174.8375\n643  166.5375\n644  168.2375\n645  177.0000\n646  169.9000\n647  171.2750\n648  166.8750\n649  174.7625\n650  163.5500\n651  171.2625\n652  169.8875\n653  169.2500\n654  172.8750\n655  170.2250\n656  170.1375\n657  166.6125\n658  174.6125\n659  166.7875\n660  169.0250\n661  170.8875\n662  167.2500\n663  172.4500\n664  163.4250\n665  167.8750\n666  166.9250\n667  164.6500\n668  171.7500\n669  164.5750\n670  162.7750\n671  167.2000\n672  173.5375\n673  169.3875\n674  164.6375\n675  161.6750\n676  162.9125\n677  165.7875\n678  164.1375\n679  174.0125\n680  162.6875\n681  166.3625\n682  170.0125\n683  170.8125\n684  167.4750\n685  161.4500\n686  159.4375\n687  166.1250\n688  170.9125\n689  163.8500\n690  168.0250\n691  167.4000\n692  164.5500\n693  170.2000\n694  170.3500\n695  171.5500\n696  170.6375\n697  173.0250\n698  170.1375\n699  171.9000\n700  169.8125\n701  171.1375\n702  170.8625\n703  166.4375\n704  163.9750\n705  162.6625\n706  164.2625\n707  166.6375\n708  165.5750\n709  171.7250\n710  168.8750\n711  165.6000\n712  164.8750\n713  167.2125\n714  166.5500\n715  170.8250\n716  168.6125\n717  170.1000\n718  164.9625\n719  160.3500\n720  159.8250\n721  170.0625\n722  163.7375\n723  165.7000\n724  169.6250\n725  180.7000\n726  169.2375\n727  169.7875\n728  170.2375\n729  171.1750\n730  170.5500\n731  167.4875\n732  165.5250\n733  166.2875\n734  163.8625\n735  166.3500\n736  166.8125\n737  165.9375\n738  170.8625\n739  168.3875\n740  160.6375\n741  164.1125\n742  162.3500\n743  170.9500\n744  161.9875\n745  163.9000\n746  173.9875\n747  164.5875\n748  164.8125\n749  168.0250\n750  166.2625\n751  170.5250\n752  166.1625\n753  168.2750\n754  170.8875\n755  171.7000\n756  169.0750\n757  170.1250\n758  174.8375\n759  165.5000\n760  160.6625\n761  165.1250\n762  171.4500\n763  171.2125\n764  165.8750\n765  169.6750\n766  169.9625\n767  162.9125\n768  167.5000\n769  165.1000\n770  166.9500\n771  172.7625\n772  168.2500\n773  172.0375\n774  168.2000\n775  162.4625\n776  163.4375\n777  167.8500\n778  166.0000\n779  169.8500\n780  162.7500\n781  161.4875\n782  164.2250\n783  169.6125\n784  165.9750\n785  164.2500\n786  170.0750\n787  167.8125\n788  171.0375\n789  167.7000\n790  173.7250\n791  169.6375\n792  166.9500\n793  175.0000\n794  168.6250\n795  172.4625\n796  166.0500\n797  166.9125\n798  167.7250\n799  166.3875\n800  167.4500\n801  169.2375\n802  175.0625\n803  174.7750\n804  171.9000\n805  166.3875\n806  171.5875\n807  173.6125\n808  171.9250\n809  169.8250\n810  169.1875\n811  172.3875\n812  164.9375\n813  164.7625\n814  174.7625\n815  173.5375\n816  164.2875\n817  172.6250\n818  171.1250\n819  174.8375\n820  169.7875\n821  176.2750\n822  168.0125\n823  167.7375\n824  168.0750\n825  171.6750\n826  169.0750\n827  161.4125\n828  167.6250\n829  170.2500\n830  159.5000\n831  169.3250\n832  168.2125\n833  169.5250\n834  169.5250\n835  171.7125\n836  164.9875\n837  168.6125\n838  162.4375\n839  166.9625\n840  167.6875\n841  169.7875\n842  165.4500\n843  167.2375\n844  170.5625\n845  172.1750\n846  165.3500\n847  172.8500\n848  165.7000\n849  165.4250\n850  165.8250\n851  176.3625\n852  166.3375\n853  174.1750\n854  165.9125\n855  177.9125\n856  164.3500\n857  167.8250\n858  172.9750\n859  167.5750\n860  166.3000\n861  165.9375\n862  164.6625\n863  169.2125\n864  166.8625\n865  168.0750\n866  164.7625\n867  170.3375\n868  163.8125\n869  176.2125\n870  160.6125\n871  172.5500\n872  165.7500\n873  166.8875\n874  171.7125\n875  165.8500\n876  169.2500\n877  165.1125\n878  168.9750\n879  166.9875\n880  167.4500\n881  172.3250\n882  164.3375\n883  172.9750\n884  172.5875\n885  161.5750\n886  172.7625\n887  171.4125\n888  167.0875\n889  167.6875\n890  168.0000\n891  168.5250\n892  167.2125\n893  162.0000\n894  162.6875\n895  166.7250\n896  169.4375\n897  171.5125\n898  170.9875\n899  171.8375\n900  175.2875\n901  167.8375\n902  166.1500\n903  170.4000\n904  172.9625\n905  168.5375\n906  168.1500\n907  167.2375\n908  162.2125\n909  166.0125\n910  172.0750\n911  172.0500\n912  169.9875\n913  165.6375\n914  165.3125\n915  174.0125\n916  167.9875\n917  173.9375\n918  166.5375\n919  162.8375\n920  174.8125\n921  167.1000\n922  164.7625\n923  172.6125\n924  171.0375\n925  164.0125\n926  169.1250\n927  169.7625\n928  163.6250\n929  173.4000\n930  164.0875\n931  167.5375\n932  172.9375\n933  167.6125\n934  165.5875\n935  166.7875\n936  172.7875\n937  168.9000\n938  166.8375\n939  167.4500\n940  171.4125\n941  162.4500\n942  167.7500\n943  165.4250\n944  167.5500\n945  173.5250\n946  170.7750\n947  167.5500\n948  170.8375\n949  168.8625\n950  170.0625\n951  167.4250\n952  175.3875\n953  168.9875\n954  168.8750\n955  174.7250\n956  176.0250\n957  170.6375\n958  165.9125\n959  169.3375\n960  172.7000\n961  166.7125\n962  157.7125\n963  171.7875\n964  162.4250\n965  167.5000\n966  168.5125\n967  167.5875\n968  161.5625\n969  173.2125\n970  175.1125\n971  168.5625\n972  168.0625\n973  170.3375\n974  164.5500\n975  165.1000\n976  166.1375\n977  162.6375\n978  168.1625\n979  170.3250\n980  168.2000\n981  170.8625\n982  164.4500\n983  165.7625\n984  171.4250\n985  163.8000\n986  166.2625\n987  169.3625\n988  161.2625\n989  165.8375\n990  164.7375\n991  163.1625\n992  169.2500\n993  164.4125\n994  165.1750\n995  173.1375\n996  165.9500\n997  166.8625\n998  170.0125\n999  165.1250\n1000 167.7375\n\nset.seed(12345)\nsamples_16_1000 &lt;- do(1000) * resample(NHANES_adult$Height,\n  size = 16\n) %&gt;% mean()\nsamples_16_1000\n\n       result\n1    172.6687\n2    168.2812\n3    168.0500\n4    167.5938\n5    166.1000\n6    167.3187\n7    165.5375\n8    167.6375\n9    167.5625\n10   168.1125\n11   165.2375\n12   169.6500\n13   169.0250\n14   163.4750\n15   166.3812\n16   167.8562\n17   169.6188\n18   167.0687\n19   170.7312\n20   165.4375\n21   164.6063\n22   173.6062\n23   169.1562\n24   162.0875\n25   161.6687\n26   169.6000\n27   168.4062\n28   169.0813\n29   171.2562\n30   170.1625\n31   168.1562\n32   166.1687\n33   172.2312\n34   167.5500\n35   162.1687\n36   167.0813\n37   168.6813\n38   165.4313\n39   167.6562\n40   169.7750\n41   168.9625\n42   169.9688\n43   166.7188\n44   169.9813\n45   169.3375\n46   165.1312\n47   166.1500\n48   169.1687\n49   166.8250\n50   167.4250\n51   175.0938\n52   164.3500\n53   166.7312\n54   166.7875\n55   171.1875\n56   168.4062\n57   168.3063\n58   161.4187\n59   165.6375\n60   170.3750\n61   167.1500\n62   167.8875\n63   175.6687\n64   165.8625\n65   168.8875\n66   164.5875\n67   166.3875\n68   165.2688\n69   172.7000\n70   166.1625\n71   167.6250\n72   169.6375\n73   166.5813\n74   171.5563\n75   167.6750\n76   170.8125\n77   169.7063\n78   169.5813\n79   166.7188\n80   167.4938\n81   169.4375\n82   170.9250\n83   173.1813\n84   167.8562\n85   168.8063\n86   170.1188\n87   169.1438\n88   167.3187\n89   167.8125\n90   172.4062\n91   167.5625\n92   162.9875\n93   170.6687\n94   164.0188\n95   164.2875\n96   170.7438\n97   167.4500\n98   165.3750\n99   165.4375\n100  168.0250\n101  166.5375\n102  169.4750\n103  167.8750\n104  169.8000\n105  169.2375\n106  168.3812\n107  168.1000\n108  165.2125\n109  167.6250\n110  168.7812\n111  167.4812\n112  166.7188\n113  168.9812\n114  168.3625\n115  167.3938\n116  168.6375\n117  171.3000\n118  167.9750\n119  168.5062\n120  168.1125\n121  167.7688\n122  169.7625\n123  167.3562\n124  172.1562\n125  169.8125\n126  168.1813\n127  169.6312\n128  171.0625\n129  170.0188\n130  166.4437\n131  168.0437\n132  165.6687\n133  165.7063\n134  167.1188\n135  168.2312\n136  167.1062\n137  167.3063\n138  169.2812\n139  168.2312\n140  166.8625\n141  168.6875\n142  166.2312\n143  162.9125\n144  173.7812\n145  171.8500\n146  170.9313\n147  166.5750\n148  168.6562\n149  168.1750\n150  172.2125\n151  175.1562\n152  167.7188\n153  168.9625\n154  165.4000\n155  168.2937\n156  165.2500\n157  167.9625\n158  169.5938\n159  170.6813\n160  166.3812\n161  167.1813\n162  169.6562\n163  168.8250\n164  172.5813\n165  166.9875\n166  169.4688\n167  165.5500\n168  168.6937\n169  163.7063\n170  166.5687\n171  164.8250\n172  168.3500\n173  167.0250\n174  167.0000\n175  167.5250\n176  171.1062\n177  166.9750\n178  165.1188\n179  172.3562\n180  169.0312\n181  171.1125\n182  171.2937\n183  166.2750\n184  169.5625\n185  171.8625\n186  170.7875\n187  165.3375\n188  169.5563\n189  168.9500\n190  167.4313\n191  167.5437\n192  165.3000\n193  168.4437\n194  164.4187\n195  172.3438\n196  166.0437\n197  168.7063\n198  162.8313\n199  164.7750\n200  167.5750\n201  170.0813\n202  170.5375\n203  164.8313\n204  167.9563\n205  170.9000\n206  169.3500\n207  164.0125\n208  170.8187\n209  170.1625\n210  173.4688\n211  173.2750\n212  168.6875\n213  169.2250\n214  166.6375\n215  167.1250\n216  165.2875\n217  164.5750\n218  166.1625\n219  170.4437\n220  170.4500\n221  167.7063\n222  170.3500\n223  170.5125\n224  166.4125\n225  173.0250\n226  171.1562\n227  171.4000\n228  166.2875\n229  172.9750\n230  174.5875\n231  170.5875\n232  165.3125\n233  165.0188\n234  168.8125\n235  168.1188\n236  166.1438\n237  170.1125\n238  165.4688\n239  166.7000\n240  171.1125\n241  170.6000\n242  165.9938\n243  170.4250\n244  169.0000\n245  166.1125\n246  171.8938\n247  162.7375\n248  167.0687\n249  166.7812\n250  167.9500\n251  167.7438\n252  171.6687\n253  169.7250\n254  168.7937\n255  168.4000\n256  169.7562\n257  169.1188\n258  168.1062\n259  165.9812\n260  170.0438\n261  168.8250\n262  166.6188\n263  170.9625\n264  167.7937\n265  164.0250\n266  167.7750\n267  170.6625\n268  170.6500\n269  165.6813\n270  165.9125\n271  163.4375\n272  165.6500\n273  170.0125\n274  165.6813\n275  170.6250\n276  167.9938\n277  167.0312\n278  163.0125\n279  166.9187\n280  165.4313\n281  167.6500\n282  166.4625\n283  164.0062\n284  163.7188\n285  168.8750\n286  170.1188\n287  169.8438\n288  165.9812\n289  174.1125\n290  166.4938\n291  167.3938\n292  166.4000\n293  168.8250\n294  165.8063\n295  171.1312\n296  167.9250\n297  173.3000\n298  170.3438\n299  169.3000\n300  169.4187\n301  171.7812\n302  166.9625\n303  167.7750\n304  168.4875\n305  172.6687\n306  170.1937\n307  168.8375\n308  171.6312\n309  169.4375\n310  167.2937\n311  165.2312\n312  168.3313\n313  168.0250\n314  169.7937\n315  169.2063\n316  172.6937\n317  169.1625\n318  172.1875\n319  166.6813\n320  166.2438\n321  170.6875\n322  172.6188\n323  170.5875\n324  170.8187\n325  167.4062\n326  169.5687\n327  171.5500\n328  168.3750\n329  170.7000\n330  169.9563\n331  169.8500\n332  165.6500\n333  165.7875\n334  168.1625\n335  164.9875\n336  171.4625\n337  163.1562\n338  164.3500\n339  169.0750\n340  164.5250\n341  170.4125\n342  164.4625\n343  162.7812\n344  167.3812\n345  167.7125\n346  167.3750\n347  170.9500\n348  171.8313\n349  171.0188\n350  170.4750\n351  168.6500\n352  163.3187\n353  165.4500\n354  168.6500\n355  167.2375\n356  166.0437\n357  168.6875\n358  169.3562\n359  162.6562\n360  164.9437\n361  164.7188\n362  175.1625\n363  169.5125\n364  170.7063\n365  169.0188\n366  165.9062\n367  165.1062\n368  166.3750\n369  169.6250\n370  162.3750\n371  166.6500\n372  162.9437\n373  169.2875\n374  166.4187\n375  168.3938\n376  167.2188\n377  171.2937\n378  169.6000\n379  170.1687\n380  162.8938\n381  171.3313\n382  167.7750\n383  166.4375\n384  166.3000\n385  169.8562\n386  170.1438\n387  165.3313\n388  165.6438\n389  167.9250\n390  162.1188\n391  166.9187\n392  165.1125\n393  168.9437\n394  169.3688\n395  171.6813\n396  170.9750\n397  170.5437\n398  166.4812\n399  167.0563\n400  168.3438\n401  174.9187\n402  169.1438\n403  172.6000\n404  170.8750\n405  170.7875\n406  164.8500\n407  174.1500\n408  168.4563\n409  172.9812\n410  173.0312\n411  167.8750\n412  169.8750\n413  165.2438\n414  168.9375\n415  164.4125\n416  168.8688\n417  170.6188\n418  166.8000\n419  164.7000\n420  168.7375\n421  166.3438\n422  171.3688\n423  169.1000\n424  165.5625\n425  171.0938\n426  170.2562\n427  171.9125\n428  166.0875\n429  170.2750\n430  166.1188\n431  166.9375\n432  167.4688\n433  167.5500\n434  170.0125\n435  166.5813\n436  166.3187\n437  168.7812\n438  167.1813\n439  167.9812\n440  169.8875\n441  168.6562\n442  167.0813\n443  172.0875\n444  167.3875\n445  168.2625\n446  164.6062\n447  164.7063\n448  170.4750\n449  171.4125\n450  171.5625\n451  168.2750\n452  170.7500\n453  167.6937\n454  164.1125\n455  172.0625\n456  167.8125\n457  169.6625\n458  170.9625\n459  164.6875\n460  170.9563\n461  168.6875\n462  167.5250\n463  169.4437\n464  168.5125\n465  165.8125\n466  170.2750\n467  166.1875\n468  170.8438\n469  167.1438\n470  166.9313\n471  166.5875\n472  170.5375\n473  169.1625\n474  169.8500\n475  168.7438\n476  172.1875\n477  171.8000\n478  173.3313\n479  167.6250\n480  169.7063\n481  164.7500\n482  164.9625\n483  168.0500\n484  167.3875\n485  171.8375\n486  169.2000\n487  164.8250\n488  164.3875\n489  169.2438\n490  169.5312\n491  165.1062\n492  167.6125\n493  167.8125\n494  163.5500\n495  163.9500\n496  166.8313\n497  169.1562\n498  166.4062\n499  167.5687\n500  162.2812\n501  172.2375\n502  170.7250\n503  170.1125\n504  166.9062\n505  170.9000\n506  169.3000\n507  168.3875\n508  167.8313\n509  166.7375\n510  168.6813\n511  165.7500\n512  168.0375\n513  169.4250\n514  166.7562\n515  169.1875\n516  168.5312\n517  163.5250\n518  165.2250\n519  168.7312\n520  165.6750\n521  163.0500\n522  163.9375\n523  166.7188\n524  162.9250\n525  166.2250\n526  168.4000\n527  162.7750\n528  167.8750\n529  169.6125\n530  167.6312\n531  170.6625\n532  163.6687\n533  166.7875\n534  170.3500\n535  172.4750\n536  167.9062\n537  167.2063\n538  168.5188\n539  168.2063\n540  167.0813\n541  166.6937\n542  172.0625\n543  171.7188\n544  170.7688\n545  167.0813\n546  167.6250\n547  165.3500\n548  171.1625\n549  169.8562\n550  170.8187\n551  167.3438\n552  165.7312\n553  172.7000\n554  169.0500\n555  164.9750\n556  171.5563\n557  168.0500\n558  169.0437\n559  166.2812\n560  169.2125\n561  170.5437\n562  174.5563\n563  167.4437\n564  166.5375\n565  166.1875\n566  168.7312\n567  165.9437\n568  168.1312\n569  166.7500\n570  167.0625\n571  164.9250\n572  168.2063\n573  169.9875\n574  165.4000\n575  164.1188\n576  171.1125\n577  169.1438\n578  162.6062\n579  163.3438\n580  166.9125\n581  163.6062\n582  170.6125\n583  170.7562\n584  171.3812\n585  166.4750\n586  169.0687\n587  166.1250\n588  167.7312\n589  165.7688\n590  169.8500\n591  165.4375\n592  163.4000\n593  168.3688\n594  170.2250\n595  166.6562\n596  168.9437\n597  168.2562\n598  171.9062\n599  169.0188\n600  168.4688\n601  169.2562\n602  164.7250\n603  170.0625\n604  170.7875\n605  166.1562\n606  167.8375\n607  165.7688\n608  163.1188\n609  167.6438\n610  164.3125\n611  168.5375\n612  171.4187\n613  169.4062\n614  167.6875\n615  168.7562\n616  164.3500\n617  163.8688\n618  171.0188\n619  163.4250\n620  167.1375\n621  169.6875\n622  169.6438\n623  169.7500\n624  168.7375\n625  173.8812\n626  168.2500\n627  169.8250\n628  168.8250\n629  166.9750\n630  174.2000\n631  168.4313\n632  172.7500\n633  168.7938\n634  162.9375\n635  168.0875\n636  166.3500\n637  168.9375\n638  169.8938\n639  167.7562\n640  168.3000\n641  168.8438\n642  165.9125\n643  168.7125\n644  170.4625\n645  167.1687\n646  171.4938\n647  171.0563\n648  165.0250\n649  165.5875\n650  165.2438\n651  170.4250\n652  167.6750\n653  162.8562\n654  164.1438\n655  169.6625\n656  165.0938\n657  167.0750\n658  169.4375\n659  171.9125\n660  170.0750\n661  164.1250\n662  168.1312\n663  168.6062\n664  170.1438\n665  166.0062\n666  163.5250\n667  170.0188\n668  168.8750\n669  163.9812\n670  170.8187\n671  167.1125\n672  164.5188\n673  168.8750\n674  170.2937\n675  166.8750\n676  167.5813\n677  166.0938\n678  166.9875\n679  165.4875\n680  169.9000\n681  162.6750\n682  169.8812\n683  170.5687\n684  164.6500\n685  166.9000\n686  168.0500\n687  166.1375\n688  169.5188\n689  172.1562\n690  168.3187\n691  166.0875\n692  167.8500\n693  170.0062\n694  168.7688\n695  171.2875\n696  169.6250\n697  170.7562\n698  166.2750\n699  169.7063\n700  166.0750\n701  171.1062\n702  171.3500\n703  166.1000\n704  172.3562\n705  166.7375\n706  171.8438\n707  170.7562\n708  167.8313\n709  172.0687\n710  167.6875\n711  169.6562\n712  168.8438\n713  166.3125\n714  168.7688\n715  172.9500\n716  167.0188\n717  169.0312\n718  170.2312\n719  165.8125\n720  172.3438\n721  171.2125\n722  168.6062\n723  168.3375\n724  175.2812\n725  176.6250\n726  167.0938\n727  169.8937\n728  172.0125\n729  168.8438\n730  161.9125\n731  169.8562\n732  168.2375\n733  169.2000\n734  167.5625\n735  172.8625\n736  167.9000\n737  167.2188\n738  166.0813\n739  173.0563\n740  163.2188\n741  169.1813\n742  173.4187\n743  170.2312\n744  166.6062\n745  167.1125\n746  175.7250\n747  167.8000\n748  168.4500\n749  167.9625\n750  170.3562\n751  166.9750\n752  169.3688\n753  166.7625\n754  170.1625\n755  168.8625\n756  167.9375\n757  168.8938\n758  166.4313\n759  168.6438\n760  168.8125\n761  167.4375\n762  169.2312\n763  167.2937\n764  170.5500\n765  167.9250\n766  170.1125\n767  170.1687\n768  168.6687\n769  170.9625\n770  167.7188\n771  165.3875\n772  167.1438\n773  169.4563\n774  169.0062\n775  162.0563\n776  166.6188\n777  170.0375\n778  170.8562\n779  168.1562\n780  169.6438\n781  167.3562\n782  166.5188\n783  167.5062\n784  167.5625\n785  169.4688\n786  169.8875\n787  167.4062\n788  166.4000\n789  172.4625\n790  167.5250\n791  168.3750\n792  166.4688\n793  171.1750\n794  168.6000\n795  167.8500\n796  169.1312\n797  173.9062\n798  166.9563\n799  168.3625\n800  165.0437\n801  169.6687\n802  166.2063\n803  165.8812\n804  165.1875\n805  171.8313\n806  170.0563\n807  165.7063\n808  168.9688\n809  168.7250\n810  167.5188\n811  165.8313\n812  169.5625\n813  167.4688\n814  170.3000\n815  169.1375\n816  169.5062\n817  168.5188\n818  169.2750\n819  169.9437\n820  164.8938\n821  170.2625\n822  159.2812\n823  170.5875\n824  167.5375\n825  164.0625\n826  167.4500\n827  168.6250\n828  170.3125\n829  169.9000\n830  168.2562\n831  167.0125\n832  167.9875\n833  167.0938\n834  169.5375\n835  168.3000\n836  165.0938\n837  165.5625\n838  167.7562\n839  165.6625\n840  165.3125\n841  166.9688\n842  167.1562\n843  165.7625\n844  168.5625\n845  163.3000\n846  166.0000\n847  169.8750\n848  168.7312\n849  172.5250\n850  169.9375\n851  164.1625\n852  167.6813\n853  167.3812\n854  173.7125\n855  169.2875\n856  172.5687\n857  163.0437\n858  169.8812\n859  167.1000\n860  167.7937\n861  168.6438\n862  170.6500\n863  169.2000\n864  166.0188\n865  165.8500\n866  165.0875\n867  165.3063\n868  169.8562\n869  163.4500\n870  169.3500\n871  168.6750\n872  167.9500\n873  162.4563\n874  166.9125\n875  172.5312\n876  168.6625\n877  170.0813\n878  161.3125\n879  171.4875\n880  168.5250\n881  170.6000\n882  169.4688\n883  167.8812\n884  172.9250\n885  169.1250\n886  173.1687\n887  171.3312\n888  163.8562\n889  169.4750\n890  173.3562\n891  163.0312\n892  166.3375\n893  163.3125\n894  163.2063\n895  171.1188\n896  170.2188\n897  170.7875\n898  168.9875\n899  171.1062\n900  168.4750\n901  163.6375\n902  165.2375\n903  170.3250\n904  165.1687\n905  166.6125\n906  165.3313\n907  167.9250\n908  168.7375\n909  167.0312\n910  169.8250\n911  171.1000\n912  166.5375\n913  172.6875\n914  172.0687\n915  169.2250\n916  172.0437\n917  172.1312\n918  167.4437\n919  164.8625\n920  166.8125\n921  173.3438\n922  167.2125\n923  163.7188\n924  166.3063\n925  169.0938\n926  167.0625\n927  165.8875\n928  165.9125\n929  171.7250\n930  166.9563\n931  165.5188\n932  173.4688\n933  167.7063\n934  170.6813\n935  172.1687\n936  167.2937\n937  167.1438\n938  168.1312\n939  167.0563\n940  173.9375\n941  171.1125\n942  172.2125\n943  169.6125\n944  165.5812\n945  170.2562\n946  166.2875\n947  170.8125\n948  164.3125\n949  166.7188\n950  165.3000\n951  164.5938\n952  169.3438\n953  173.0563\n954  176.3875\n955  168.0938\n956  168.7812\n957  166.7250\n958  163.7500\n959  164.8688\n960  163.3187\n961  167.9187\n962  166.7687\n963  166.8812\n964  166.8250\n965  167.8250\n966  169.3125\n967  168.2063\n968  170.7063\n969  168.4187\n970  172.3313\n971  172.1500\n972  169.2250\n973  167.6500\n974  168.5125\n975  164.5188\n976  166.5000\n977  170.1312\n978  170.5938\n979  168.9688\n980  168.5750\n981  169.8063\n982  163.1562\n983  167.7687\n984  169.7562\n985  166.1750\n986  171.8375\n987  167.7125\n988  168.5250\n989  170.6250\n990  167.7125\n991  169.5188\n992  164.7375\n993  165.2375\n994  167.3562\n995  166.0938\n996  167.6312\n997  172.2812\n998  166.2438\n999  164.8750\n1000 173.0375\n\nset.seed(12345)\nsamples_32_1000 &lt;- do(1000) * resample(NHANES_adult$Height,\n  size = 32\n) %&gt;% mean()\nsamples_32_1000\n\n       result\n1    168.1656\n2    166.8469\n3    166.4281\n4    167.6000\n5    166.6750\n6    169.3375\n7    164.9281\n8    168.7375\n9    168.9000\n10   165.0219\n11   171.3812\n12   161.8781\n13   169.0031\n14   170.1687\n15   169.1594\n16   169.2000\n17   164.8594\n18   167.8812\n19   166.5437\n20   169.3688\n21   168.3438\n22   169.6594\n23   165.6406\n24   167.9969\n25   171.2594\n26   165.5406\n27   168.9875\n28   168.3562\n29   163.5281\n30   168.7625\n31   171.7781\n32   167.3750\n33   165.4875\n34   168.9844\n35   166.8938\n36   168.1094\n37   169.6156\n38   170.2594\n39   168.1500\n40   168.4656\n41   172.0531\n42   168.3313\n43   169.6312\n44   167.5656\n45   169.9844\n46   166.8281\n47   164.1531\n48   169.0969\n49   165.4062\n50   167.2812\n51   168.6750\n52   169.5188\n53   168.2406\n54   166.4187\n55   168.1312\n56   167.8500\n57   167.8781\n58   169.9688\n59   168.2406\n60   167.9406\n61   168.5594\n62   170.9844\n63   168.9062\n64   170.5406\n65   167.2438\n66   165.6875\n67   167.6750\n68   167.2063\n69   168.7562\n70   167.7750\n71   164.5719\n72   172.8156\n73   168.7531\n74   168.4156\n75   173.6844\n76   168.3406\n77   166.8469\n78   166.6062\n79   170.1375\n80   166.7812\n81   169.2406\n82   169.7844\n83   167.5094\n84   166.2000\n85   165.6969\n86   167.6875\n87   167.2625\n88   169.0406\n89   168.7375\n90   170.0719\n91   168.7844\n92   170.7125\n93   168.0625\n94   169.2531\n95   167.4875\n96   166.8719\n97   168.3812\n98   167.3750\n99   163.8031\n100  168.8281\n101  167.6844\n102  169.4281\n103  166.6813\n104  170.4906\n105  173.3719\n106  168.9563\n107  166.8812\n108  164.9313\n109  168.3031\n110  169.0781\n111  170.4313\n112  169.7188\n113  171.2781\n114  169.6312\n115  172.5875\n116  165.1656\n117  168.4656\n118  168.1281\n119  166.0844\n120  170.8562\n121  168.2094\n122  167.5563\n123  167.3156\n124  166.9250\n125  167.8469\n126  170.6969\n127  168.5969\n128  169.4375\n129  167.0437\n130  169.4344\n131  168.7906\n132  165.9094\n133  169.2188\n134  168.1656\n135  164.6750\n136  167.8313\n137  168.1531\n138  167.5125\n139  164.9656\n140  166.5406\n141  165.2344\n142  166.2969\n143  169.9812\n144  170.0469\n145  166.9437\n146  167.6125\n147  168.4688\n148  170.6125\n149  169.8219\n150  170.6000\n151  167.3688\n152  170.5781\n153  169.5156\n154  170.5344\n155  166.2625\n156  168.1781\n157  169.5000\n158  170.9281\n159  169.4344\n160  168.4656\n161  171.6031\n162  169.1125\n163  170.5594\n164  169.5375\n165  169.9031\n166  165.7188\n167  166.5750\n168  167.3094\n169  166.7125\n170  167.4688\n171  163.6219\n172  167.5469\n173  169.1625\n174  171.4250\n175  169.5625\n176  164.3844\n177  167.9437\n178  167.3656\n179  166.0062\n180  164.8313\n181  172.3375\n182  169.8625\n183  165.5062\n184  168.0000\n185  164.5125\n186  166.1156\n187  167.4062\n188  169.2562\n189  169.8844\n190  167.1125\n191  167.1062\n192  168.0781\n193  167.7375\n194  166.7844\n195  164.5188\n196  167.0281\n197  170.5250\n198  170.7594\n199  166.7688\n200  171.6312\n201  170.8719\n202  170.8313\n203  169.5000\n204  170.7188\n205  170.4531\n206  167.5594\n207  166.6750\n208  169.7438\n209  165.7500\n210  167.5406\n211  170.2344\n212  168.3281\n213  171.0844\n214  168.1813\n215  166.5281\n216  167.5094\n217  168.2969\n218  167.5500\n219  167.5813\n220  169.2719\n221  169.5844\n222  167.8250\n223  164.6562\n224  170.9437\n225  169.9187\n226  169.2219\n227  168.0875\n228  168.7375\n229  167.8250\n230  169.8219\n231  168.4844\n232  167.1625\n233  168.2312\n234  168.9938\n235  166.7594\n236  169.8500\n237  169.2969\n238  171.9938\n239  170.4781\n240  167.2281\n241  166.5062\n242  169.6125\n243  167.0125\n244  166.8156\n245  167.3187\n246  167.7125\n247  163.7500\n248  167.9938\n249  166.9875\n250  167.2594\n251  170.4187\n252  168.9031\n253  168.8438\n254  167.2844\n255  167.2156\n256  168.7312\n257  167.9719\n258  166.0281\n259  166.9781\n260  164.3625\n261  165.3281\n262  164.5750\n263  165.5875\n264  168.7438\n265  169.1469\n266  165.2281\n267  171.4125\n268  167.5563\n269  168.3625\n270  166.8875\n271  171.8906\n272  168.9250\n273  166.4875\n274  170.5094\n275  169.0813\n276  169.2156\n277  167.0125\n278  169.8031\n279  167.6625\n280  169.8781\n281  171.0000\n282  166.3625\n283  167.3375\n284  167.4406\n285  165.9938\n286  169.0969\n287  164.7594\n288  170.1281\n289  162.9750\n290  165.2594\n291  170.6844\n292  168.9281\n293  167.5969\n294  166.7500\n295  167.6438\n296  165.8844\n297  168.4406\n298  168.6000\n299  170.4625\n300  168.8625\n301  167.3938\n302  168.4719\n303  166.8031\n304  165.3812\n305  166.4250\n306  170.4125\n307  168.2219\n308  164.1094\n309  167.2219\n310  168.4125\n311  169.6969\n312  171.3094\n313  169.0375\n314  167.9000\n315  171.3156\n316  170.7719\n317  165.5125\n318  167.6438\n319  168.8250\n320  168.5719\n321  167.3125\n322  168.8156\n323  171.2750\n324  165.3063\n325  167.8344\n326  165.2656\n327  166.9031\n328  166.0844\n329  170.6750\n330  167.1000\n331  168.3688\n332  168.0750\n333  166.7719\n334  166.4281\n335  168.9656\n336  166.6969\n337  168.5844\n338  166.8375\n339  166.2375\n340  166.2875\n341  170.2250\n342  165.7750\n343  167.0938\n344  170.8375\n345  167.2031\n346  168.9281\n347  170.0281\n348  170.1906\n349  167.9906\n350  168.5906\n351  168.7250\n352  169.5469\n353  171.3000\n354  169.9500\n355  168.6719\n356  167.5781\n357  170.8594\n358  168.0250\n359  168.0219\n360  171.7781\n361  168.4719\n362  175.9531\n363  168.4938\n364  170.4281\n365  165.8844\n366  168.7188\n367  170.2125\n368  167.5594\n369  169.5687\n370  166.2000\n371  171.8250\n372  166.8594\n373  171.7625\n374  168.2063\n375  168.6656\n376  168.0656\n377  169.5125\n378  168.4156\n379  167.5375\n380  168.1250\n381  168.2625\n382  169.2375\n383  170.1406\n384  169.8156\n385  166.5531\n386  168.3000\n387  165.5312\n388  168.3281\n389  169.5062\n390  168.5000\n391  167.0125\n392  168.5156\n393  168.6469\n394  169.4313\n395  167.9500\n396  168.8219\n397  168.2250\n398  171.5188\n399  167.6594\n400  167.3562\n401  166.0437\n402  168.5094\n403  167.8812\n404  168.8469\n405  166.6750\n406  168.5156\n407  169.7188\n408  169.0125\n409  169.6094\n410  167.5781\n411  164.9344\n412  165.8000\n413  168.0375\n414  170.1062\n415  167.6344\n416  167.5406\n417  168.9187\n418  165.3281\n419  166.7094\n420  166.1406\n421  166.4594\n422  165.9313\n423  167.9375\n424  170.6281\n425  167.0500\n426  167.5312\n427  171.5000\n428  167.8063\n429  168.4906\n430  168.2188\n431  169.9250\n432  165.9344\n433  165.1969\n434  166.6531\n435  169.0125\n436  165.2031\n437  169.7219\n438  169.3719\n439  166.4000\n440  169.5625\n441  168.6750\n442  171.0250\n443  172.2500\n444  166.6656\n445  168.1937\n446  164.8250\n447  167.1625\n448  170.5031\n449  170.0469\n450  166.0563\n451  167.7812\n452  165.8906\n453  166.6281\n454  167.8844\n455  170.4625\n456  169.6125\n457  170.6469\n458  172.0875\n459  166.1531\n460  170.0781\n461  165.4656\n462  167.7000\n463  166.4750\n464  168.8187\n465  166.2375\n466  170.5875\n467  171.4250\n468  167.2188\n469  167.5938\n470  172.5250\n471  170.9125\n472  167.9187\n473  168.5500\n474  165.5156\n475  164.9469\n476  171.2000\n477  172.2406\n478  167.7531\n479  164.3094\n480  165.6188\n481  166.8250\n482  167.3250\n483  168.7594\n484  169.5625\n485  172.2406\n486  168.4375\n487  166.5156\n488  168.3156\n489  169.7812\n490  169.1906\n491  165.4625\n492  167.9656\n493  169.7750\n494  169.5750\n495  168.6156\n496  164.9875\n497  166.7250\n498  169.9563\n499  165.5594\n500  169.4156\n501  167.8875\n502  164.0875\n503  167.7625\n504  167.5531\n505  169.3656\n506  169.6813\n507  165.7156\n508  168.2375\n509  170.4437\n510  170.1562\n511  167.0344\n512  169.7969\n513  167.9469\n514  169.1188\n515  166.1719\n516  167.5813\n517  170.4375\n518  169.1406\n519  173.6406\n520  167.8969\n521  167.9688\n522  169.2094\n523  167.7312\n524  171.5344\n525  166.1781\n526  166.6687\n527  168.8063\n528  167.7094\n529  165.8625\n530  165.4594\n531  169.6781\n532  168.0156\n533  170.4125\n534  170.0437\n535  167.7594\n536  167.3063\n537  167.3938\n538  168.2750\n539  166.7531\n540  167.2750\n541  171.3969\n542  171.2156\n543  169.1281\n544  168.1125\n545  167.6719\n546  168.2375\n547  168.9938\n548  169.1281\n549  167.3219\n550  167.3344\n551  170.2219\n552  169.0563\n553  170.5781\n554  168.9906\n555  166.5219\n556  168.1312\n557  167.4094\n558  166.3812\n559  169.3562\n560  169.0875\n561  169.7406\n562  166.3688\n563  165.7969\n564  168.7406\n565  169.5219\n566  168.8000\n567  165.8187\n568  165.9125\n569  168.2125\n570  170.1781\n571  171.4156\n572  169.2469\n573  167.0781\n574  167.9500\n575  171.5250\n576  167.7781\n577  166.9000\n578  166.9625\n579  169.8000\n580  166.0656\n581  167.2500\n582  169.5969\n583  167.9781\n584  169.7937\n585  168.8656\n586  169.6469\n587  167.1656\n588  166.9563\n589  164.0938\n590  169.6906\n591  173.1781\n592  169.8688\n593  165.4344\n594  167.1531\n595  169.1375\n596  166.4313\n597  168.7594\n598  167.4938\n599  168.4250\n600  167.8469\n601  168.0125\n602  169.3875\n603  169.1844\n604  167.1937\n605  165.6438\n606  170.7625\n607  167.9125\n608  164.6687\n609  167.4875\n610  168.5125\n611  170.0469\n612  166.2594\n613  166.3875\n614  165.9719\n615  167.3438\n616  166.6531\n617  167.5813\n618  170.3281\n619  168.2250\n620  167.3875\n621  168.8094\n622  166.1438\n623  169.2906\n624  169.0250\n625  168.6062\n626  165.6656\n627  168.8656\n628  171.5250\n629  167.7125\n630  166.0563\n631  168.6406\n632  166.6250\n633  168.4781\n634  168.6937\n635  170.5906\n636  169.2438\n637  167.0094\n638  165.6750\n639  166.6969\n640  168.0906\n641  166.0938\n642  169.1500\n643  168.4469\n644  168.6250\n645  170.6000\n646  166.4219\n647  169.1813\n648  168.5094\n649  170.9719\n650  166.7781\n651  167.8562\n652  167.9156\n653  168.2531\n654  168.1219\n655  169.4531\n656  165.9844\n657  164.0250\n658  168.8469\n659  168.9375\n660  168.7469\n661  168.7812\n662  171.0219\n663  167.4969\n664  169.4156\n665  168.3812\n666  171.2656\n667  169.4563\n668  169.9625\n669  170.0750\n670  167.7406\n671  166.5156\n672  167.7969\n673  168.8063\n674  167.5687\n675  169.6781\n676  167.4094\n677  169.8344\n678  169.1625\n679  167.5312\n680  166.8969\n681  168.1156\n682  169.4906\n683  169.5875\n684  165.2875\n685  171.9719\n686  166.9313\n687  169.3938\n688  167.7750\n689  169.0281\n690  166.7125\n691  167.8656\n692  166.5875\n693  169.7562\n694  165.2125\n695  171.2250\n696  166.3063\n697  167.0625\n698  168.9062\n699  167.8000\n700  169.1469\n701  167.8500\n702  168.1844\n703  166.2250\n704  167.6125\n705  167.2031\n706  166.4187\n707  167.9531\n708  165.5062\n709  166.8812\n710  164.9281\n711  168.7719\n712  166.5719\n713  169.2344\n714  165.7750\n715  167.7906\n716  167.8125\n717  165.9125\n718  166.4844\n719  168.2688\n720  167.4344\n721  169.6719\n722  170.2531\n723  171.0625\n724  166.2500\n725  166.9594\n726  168.4219\n727  170.8344\n728  171.3250\n729  167.3375\n730  169.4187\n731  166.1906\n732  170.5250\n733  169.5125\n734  167.3688\n735  168.2406\n736  169.2562\n737  173.1344\n738  166.6469\n739  170.2312\n740  169.3375\n741  168.5031\n742  170.0969\n743  168.0844\n744  168.1969\n745  168.8375\n746  167.9375\n747  168.9437\n748  170.5344\n749  168.8281\n750  167.9187\n751  168.9719\n752  168.1156\n753  165.6406\n754  168.6125\n755  168.6281\n756  163.3313\n757  169.8562\n758  167.5094\n759  168.5750\n760  167.6625\n761  165.7094\n762  166.5125\n763  166.3406\n764  169.7344\n765  172.9375\n766  168.5813\n767  169.0406\n768  165.8625\n769  167.8156\n770  169.0406\n771  169.4750\n772  168.6312\n773  167.6062\n774  167.3844\n775  170.1312\n776  169.2156\n777  168.7406\n778  170.1469\n779  168.4062\n780  165.6906\n781  166.7406\n782  168.6438\n783  167.9563\n784  167.2844\n785  165.0437\n786  169.0500\n787  170.9375\n788  170.9906\n789  172.4187\n790  168.5469\n791  168.2594\n792  169.2656\n793  167.4062\n794  169.2031\n795  170.0500\n796  170.0750\n797  171.1531\n798  168.5594\n799  169.6594\n800  169.5312\n801  168.8219\n802  171.0000\n803  164.4469\n804  168.5312\n805  166.7937\n806  170.4000\n807  166.0563\n808  167.7094\n809  166.9750\n810  169.4688\n811  169.3000\n812  171.8125\n813  172.0250\n814  171.4250\n815  169.2063\n816  172.1375\n817  165.7500\n818  166.8812\n819  169.4375\n820  171.4406\n821  170.4094\n822  172.4156\n823  172.7719\n824  166.3500\n825  169.3469\n826  170.5906\n827  172.2906\n828  167.6813\n829  166.5781\n830  166.6813\n831  171.3250\n832  167.7281\n833  165.6375\n834  166.5813\n835  165.0437\n836  164.5219\n837  164.6469\n838  168.9531\n839  167.7969\n840  171.2281\n841  167.7594\n842  167.8719\n843  168.8719\n844  170.7219\n845  172.4125\n846  168.1094\n847  168.6687\n848  168.7937\n849  167.7875\n850  168.1969\n851  169.3719\n852  168.1406\n853  169.6312\n854  168.5312\n855  167.3406\n856  171.6375\n857  166.7375\n858  170.5000\n859  166.2375\n860  168.0031\n861  166.5687\n862  168.7156\n863  166.6719\n864  166.1656\n865  170.2750\n866  169.5250\n867  170.6125\n868  166.3531\n869  166.1031\n870  170.1406\n871  169.6469\n872  167.1375\n873  167.2656\n874  167.2438\n875  167.7062\n876  166.2781\n877  169.0625\n878  172.1469\n879  169.9781\n880  167.5062\n881  170.1594\n882  167.3906\n883  166.3406\n884  168.8187\n885  168.3406\n886  168.3125\n887  167.5312\n888  166.4500\n889  168.1844\n890  170.9938\n891  170.2125\n892  170.6094\n893  169.1937\n894  165.5469\n895  169.1281\n896  166.5344\n897  167.2438\n898  169.1844\n899  167.8469\n900  168.4969\n901  167.5687\n902  170.7719\n903  168.2844\n904  168.0406\n905  169.0156\n906  169.7438\n907  169.0500\n908  168.1937\n909  167.3781\n910  166.7344\n911  169.7344\n912  167.6406\n913  166.4844\n914  170.0156\n915  168.7438\n916  168.0125\n917  164.2375\n918  171.0281\n919  165.4719\n920  168.8063\n921  168.1562\n922  167.9594\n923  167.8812\n924  167.0031\n925  171.7531\n926  168.9469\n927  165.9563\n928  170.2438\n929  170.4406\n930  165.6219\n931  172.1562\n932  171.9000\n933  169.0625\n934  169.4000\n935  169.1594\n936  167.8031\n937  172.0094\n938  171.2156\n939  167.4031\n940  168.1062\n941  168.7031\n942  168.1344\n943  169.7219\n944  164.4031\n945  168.1781\n946  168.0906\n947  170.4344\n948  169.6906\n949  168.6188\n950  168.1250\n951  166.0344\n952  169.9156\n953  169.0656\n954  171.3063\n955  167.5344\n956  169.5969\n957  170.6656\n958  166.4406\n959  165.8500\n960  165.0531\n961  168.6813\n962  170.4437\n963  169.6000\n964  168.0781\n965  169.3094\n966  171.2250\n967  167.5469\n968  170.7656\n969  170.3875\n970  169.7344\n971  167.2094\n972  166.1344\n973  172.1719\n974  169.7781\n975  167.9094\n976  168.8344\n977  166.7844\n978  171.7906\n979  166.4281\n980  170.5437\n981  168.7500\n982  168.3500\n983  171.3094\n984  166.3187\n985  167.3688\n986  169.3750\n987  164.9844\n988  167.8094\n989  167.6750\n990  167.2719\n991  166.2562\n992  169.9781\n993  167.5563\n994  170.1750\n995  169.6937\n996  168.4437\n997  172.1781\n998  167.3187\n999  167.0875\n1000 168.0563\n\nset.seed(12345)\nsamples_64_1000 &lt;- do(1000) * resample(NHANES_adult$Height,\n  size = 64\n) %&gt;% mean()\nsamples_64_1000\n\n       result\n1    166.6375\n2    167.1375\n3    167.1328\n4    168.8187\n5    168.2016\n6    165.4406\n7    169.6641\n8    167.0297\n9    167.2125\n10   168.8562\n11   167.6500\n12   169.6281\n13   167.2641\n14   165.9422\n15   170.2703\n16   166.4313\n17   167.9391\n18   168.8625\n19   169.2047\n20   170.2594\n21   168.9812\n22   168.7750\n23   165.4906\n24   167.2516\n25   167.9781\n26   168.8797\n27   167.2750\n28   167.8641\n29   169.1047\n30   168.2500\n31   169.9453\n32   168.8922\n33   166.6813\n34   167.9812\n35   166.1734\n36   170.7844\n37   171.0500\n38   167.5938\n39   168.3719\n40   168.0109\n41   168.6469\n42   165.9484\n43   167.4750\n44   168.8891\n45   169.4281\n46   169.3875\n47   168.3703\n48   167.6266\n49   165.5891\n50   168.2562\n51   168.0547\n52   171.9313\n53   167.9187\n54   166.6172\n55   169.7547\n56   170.4984\n57   171.1094\n58   166.8156\n59   167.1062\n60   169.5328\n61   167.4359\n62   167.3859\n63   169.6469\n64   168.2406\n65   169.1125\n66   167.5641\n67   166.4203\n68   167.9922\n69   166.2391\n70   165.8875\n71   168.1391\n72   168.4953\n73   168.0406\n74   170.2172\n75   168.9844\n76   170.0469\n77   168.3984\n78   168.8391\n79   170.1813\n80   170.0344\n81   169.8359\n82   169.7203\n83   166.1469\n84   167.0109\n85   165.5453\n86   168.3547\n87   170.4938\n88   166.1641\n89   166.6859\n90   168.5844\n91   167.6844\n92   166.2562\n93   166.7609\n94   169.5703\n95   167.1094\n96   167.9078\n97   165.6516\n98   168.7766\n99   168.7641\n100  171.2516\n101  170.1656\n102  170.5859\n103  167.1172\n104  167.7469\n105  168.8875\n106  169.7063\n107  167.3547\n108  167.9031\n109  167.5656\n110  169.4281\n111  166.2406\n112  170.4313\n113  168.6547\n114  168.2812\n115  169.1531\n116  167.6969\n117  167.8766\n118  169.5734\n119  171.2359\n120  166.8672\n121  168.3125\n122  167.0672\n123  165.7312\n124  167.4906\n125  168.8391\n126  168.8734\n127  167.2500\n128  168.3516\n129  166.5031\n130  164.8453\n131  165.0813\n132  168.9453\n133  168.3203\n134  167.9594\n135  169.3891\n136  167.7063\n137  169.7953\n138  168.1141\n139  168.7328\n140  170.4391\n141  166.8500\n142  166.7172\n143  166.9281\n144  166.5516\n145  167.9719\n146  168.2625\n147  167.1969\n148  167.1625\n149  169.5312\n150  168.1281\n151  167.6375\n152  165.9031\n153  169.3172\n154  165.6656\n155  169.0547\n156  170.1734\n157  169.6078\n158  168.1422\n159  168.2344\n160  167.9422\n161  170.0453\n162  166.5703\n163  166.0844\n164  168.3797\n165  167.7344\n166  167.4234\n167  167.6969\n168  167.6406\n169  166.5375\n170  168.2562\n171  166.4344\n172  169.0203\n173  169.4781\n174  169.0906\n175  168.6578\n176  170.4234\n177  169.3109\n178  169.2188\n179  168.0234\n180  170.1250\n181  172.2234\n182  168.1562\n183  169.4656\n184  168.5641\n185  169.0125\n186  169.3109\n187  168.4359\n188  168.7891\n189  167.9766\n190  168.1937\n191  169.6891\n192  168.1844\n193  166.9156\n194  168.9172\n195  167.7562\n196  168.5813\n197  168.6906\n198  168.5234\n199  169.5891\n200  166.7000\n201  168.1953\n202  167.7609\n203  169.1172\n204  169.3109\n205  166.2562\n206  166.9187\n207  168.8703\n208  168.2297\n209  166.0188\n210  166.3000\n211  166.9344\n212  168.8391\n213  169.5156\n214  168.1484\n215  169.0719\n216  165.5656\n217  167.8328\n218  167.4625\n219  167.8859\n220  169.1188\n221  171.6375\n222  167.4297\n223  165.9938\n224  170.2750\n225  166.9187\n226  166.2594\n227  169.1734\n228  170.1297\n229  169.1203\n230  167.7719\n231  167.0875\n232  167.5281\n233  171.0062\n234  167.4062\n235  171.7188\n236  168.2344\n237  165.2312\n238  171.7203\n239  166.0312\n240  166.2219\n241  168.0422\n242  170.9016\n243  167.4766\n244  169.0484\n245  167.3266\n246  168.8703\n247  169.0953\n248  165.8562\n249  167.7578\n250  168.6516\n251  165.9250\n252  168.4594\n253  167.6984\n254  169.3406\n255  168.5953\n256  168.8719\n257  167.6453\n258  169.0094\n259  171.3906\n260  167.9328\n261  168.4703\n262  168.8562\n263  167.7375\n264  166.7859\n265  167.5687\n266  169.2141\n267  168.9016\n268  167.3500\n269  167.5141\n270  169.3359\n271  170.1719\n272  167.8922\n273  168.6156\n274  168.2250\n275  168.7781\n276  169.8172\n277  167.7562\n278  167.7703\n279  167.8688\n280  169.4141\n281  166.0828\n282  169.1312\n283  167.3094\n284  167.0625\n285  170.7969\n286  168.1625\n287  169.7375\n288  167.3391\n289  168.3812\n290  166.6578\n291  168.7875\n292  169.3297\n293  168.4062\n294  165.5250\n295  171.4344\n296  167.6516\n297  168.1453\n298  167.5953\n299  167.9594\n300  167.9297\n301  169.2859\n302  166.4187\n303  169.3375\n304  166.0781\n305  169.2797\n306  166.3234\n307  166.6578\n308  167.1172\n309  169.2766\n310  168.0984\n311  167.7172\n312  168.8156\n313  167.2656\n314  169.6188\n315  167.3484\n316  167.5516\n317  169.6422\n318  168.1266\n319  166.1859\n320  167.0922\n321  168.7984\n322  169.6125\n323  167.8016\n324  169.7406\n325  167.3172\n326  168.0844\n327  168.7875\n328  165.0047\n329  168.8922\n330  168.7641\n331  169.2594\n332  168.8984\n333  170.3609\n334  170.0188\n335  167.1281\n336  168.3016\n337  168.6234\n338  168.6219\n339  168.3469\n340  167.5062\n341  169.5391\n342  168.6297\n343  168.1625\n344  168.4016\n345  167.2891\n346  168.1719\n347  168.2188\n348  166.6844\n349  168.3531\n350  168.4984\n351  167.2047\n352  167.4078\n353  167.1859\n354  166.1937\n355  166.8500\n356  167.9031\n357  166.7828\n358  166.8625\n359  167.3766\n360  168.5531\n361  170.6578\n362  166.6047\n363  169.6281\n364  169.3313\n365  167.8047\n366  170.0188\n367  167.8047\n368  171.1953\n369  168.4391\n370  168.9203\n371  169.0906\n372  168.5172\n373  168.4406\n374  169.6813\n375  168.4453\n376  166.8781\n377  168.6203\n378  166.5938\n379  168.0422\n380  166.6859\n381  166.4266\n382  171.3359\n383  168.8109\n384  166.8391\n385  169.2578\n386  168.1188\n387  168.7578\n388  168.9781\n389  169.2766\n390  166.2156\n391  168.3000\n392  166.1641\n393  169.9938\n394  171.7047\n395  168.4031\n396  168.3359\n397  169.6266\n398  170.6141\n399  169.1094\n400  169.1766\n401  167.7234\n402  167.6625\n403  168.2281\n404  167.3422\n405  169.3844\n406  171.9187\n407  170.3156\n408  168.9437\n409  168.1594\n410  170.9250\n411  172.5938\n412  167.8484\n413  171.4406\n414  167.1297\n415  169.0031\n416  166.6828\n417  165.8125\n418  164.5844\n419  168.3750\n420  169.4938\n421  168.3719\n422  171.5672\n423  168.3891\n424  168.2906\n425  168.7844\n426  168.8859\n427  167.9359\n428  169.1875\n429  168.3688\n430  167.2859\n431  167.6937\n432  168.2203\n433  170.0687\n434  166.2281\n435  169.8938\n436  167.2016\n437  167.4750\n438  167.6703\n439  171.0625\n440  168.8328\n441  166.8656\n442  168.5797\n443  167.9219\n444  167.3172\n445  170.6031\n446  169.9016\n447  167.3375\n448  166.8891\n449  168.5156\n450  168.0328\n451  169.5281\n452  168.5281\n453  169.3969\n454  167.7859\n455  168.2344\n456  167.0625\n457  169.3797\n458  166.1250\n459  168.2500\n460  168.4812\n461  167.9203\n462  169.3781\n463  167.4516\n464  170.3422\n465  168.8891\n466  170.4812\n467  169.2797\n468  169.9062\n469  169.3094\n470  168.4047\n471  168.9281\n472  166.2906\n473  169.2625\n474  169.1547\n475  167.0797\n476  169.4906\n477  169.4203\n478  170.1312\n479  166.1453\n480  166.8672\n481  170.0219\n482  168.6937\n483  169.3859\n484  170.5766\n485  168.4719\n486  169.1531\n487  168.8438\n488  167.8094\n489  169.1094\n490  169.6469\n491  169.8297\n492  166.8438\n493  167.1797\n494  167.7422\n495  166.7641\n496  168.7672\n497  169.9344\n498  170.3109\n499  167.2031\n500  169.5766\n501  169.0656\n502  166.5938\n503  168.9922\n504  167.2547\n505  165.6828\n506  166.6797\n507  166.8984\n508  168.0516\n509  167.4719\n510  169.0969\n511  169.8578\n512  166.5922\n513  167.4812\n514  170.9125\n515  167.9703\n516  168.7188\n517  168.9000\n518  169.6813\n519  169.1750\n520  166.6297\n521  168.5797\n522  168.0938\n523  167.8375\n524  168.3906\n525  168.7656\n526  169.8750\n527  169.4656\n528  169.3078\n529  168.3516\n530  170.4953\n531  168.8969\n532  169.1469\n533  168.4688\n534  169.9672\n535  168.6734\n536  168.4313\n537  168.3672\n538  171.2141\n539  168.3281\n540  168.9609\n541  168.7453\n542  166.8625\n543  167.4891\n544  167.2891\n545  168.1219\n546  168.5531\n547  168.4391\n548  167.6109\n549  169.5625\n550  168.0234\n551  168.2734\n552  169.1687\n553  169.3938\n554  167.7875\n555  168.2750\n556  167.0922\n557  168.4797\n558  167.2984\n559  167.3469\n560  166.5016\n561  167.9547\n562  169.9844\n563  166.6984\n564  167.6922\n565  169.9391\n566  167.1281\n567  169.2922\n568  169.8547\n569  168.0016\n570  168.9500\n571  170.0203\n572  167.0328\n573  167.5406\n574  166.9750\n575  166.3641\n576  167.5766\n577  167.0266\n578  168.5250\n579  168.6000\n580  170.4031\n581  166.8438\n582  167.6484\n583  169.5453\n584  167.8344\n585  169.1594\n586  169.3031\n587  167.8719\n588  169.9547\n589  167.2078\n590  169.9812\n591  166.1188\n592  169.7250\n593  169.2641\n594  167.6250\n595  170.3875\n596  164.9531\n597  169.2609\n598  169.4234\n599  169.7750\n600  171.4469\n601  168.3781\n602  170.1328\n603  168.3203\n604  166.4406\n605  167.7609\n606  169.1687\n607  170.0500\n608  170.0719\n609  168.3016\n610  165.9203\n611  168.1734\n612  167.8812\n613  171.0125\n614  167.7219\n615  168.7750\n616  167.1828\n617  167.4906\n618  167.6047\n619  169.7125\n620  167.4703\n621  167.6969\n622  167.1875\n623  168.1297\n624  170.0531\n625  169.0734\n626  168.1031\n627  169.7562\n628  169.4375\n629  167.2188\n630  168.8375\n631  168.5516\n632  166.4641\n633  165.7516\n634  169.1906\n635  168.7531\n636  166.1000\n637  168.8094\n638  168.9203\n639  170.1266\n640  169.2094\n641  166.8984\n642  169.3484\n643  168.1609\n644  167.9234\n645  170.0844\n646  166.8812\n647  168.6047\n648  168.6500\n649  170.3469\n650  167.1562\n651  167.5609\n652  168.6000\n653  169.7937\n654  169.2172\n655  167.8750\n656  167.4172\n657  164.8172\n658  168.2078\n659  168.7672\n660  169.1656\n661  165.8688\n662  168.8484\n663  168.4219\n664  167.0078\n665  169.9141\n666  167.9719\n667  169.3031\n668  169.4891\n669  167.3750\n670  169.8703\n671  166.4000\n672  169.6969\n673  167.4172\n674  166.9062\n675  166.7562\n676  165.9156\n677  168.4938\n678  168.7063\n679  168.7937\n680  168.1641\n681  169.5437\n682  167.3703\n683  167.4781\n684  168.0875\n685  167.6578\n686  168.3328\n687  166.4141\n688  169.6359\n689  167.3938\n690  169.8328\n691  169.3391\n692  168.4797\n693  168.2016\n694  169.6969\n695  169.3203\n696  169.3109\n697  169.9453\n698  169.3016\n699  167.9906\n700  168.1344\n701  167.7969\n702  166.0531\n703  168.6047\n704  168.0344\n705  169.6297\n706  169.3391\n707  167.8906\n708  168.8422\n709  166.4172\n710  168.2156\n711  169.0859\n712  168.2641\n713  166.5703\n714  167.0859\n715  166.1297\n716  168.3172\n717  169.9203\n718  167.9938\n719  167.9375\n720  168.4688\n721  166.1687\n722  171.1141\n723  167.9391\n724  167.7953\n725  170.5547\n726  167.4938\n727  167.5922\n728  167.6312\n729  169.0625\n730  169.8422\n731  167.2031\n732  168.7922\n733  168.7031\n734  168.7344\n735  169.8234\n736  165.8313\n737  166.8172\n738  166.9734\n739  169.7547\n740  166.7031\n741  168.4516\n742  169.3719\n743  169.4672\n744  168.5547\n745  167.6594\n746  168.3906\n747  170.0453\n748  168.6203\n749  168.6906\n750  166.5594\n751  168.9500\n752  167.1547\n753  168.0078\n754  169.8828\n755  171.1234\n756  169.8438\n757  169.1734\n758  167.2969\n759  167.3266\n760  167.2547\n761  169.3703\n762  167.8281\n763  168.8797\n764  167.5516\n765  169.5359\n766  169.9641\n767  169.1672\n768  168.7891\n769  166.6922\n770  171.2469\n771  167.1562\n772  169.2594\n773  171.1469\n774  168.2562\n775  169.3000\n776  166.0656\n777  170.8500\n778  167.6141\n779  167.9016\n780  167.5469\n781  166.0016\n782  165.8016\n783  168.4609\n784  165.9781\n785  167.6953\n786  167.8922\n787  167.4203\n788  167.4125\n789  169.9891\n790  168.2375\n791  169.5547\n792  169.8281\n793  168.4906\n794  169.9078\n795  167.2859\n796  170.4875\n797  167.5875\n798  169.2844\n799  167.6281\n800  169.7578\n801  167.9281\n802  168.0484\n803  167.2891\n804  168.0609\n805  168.9578\n806  167.9437\n807  169.5172\n808  168.4984\n809  170.3797\n810  168.1547\n811  170.1094\n812  169.4125\n813  168.6375\n814  167.9156\n815  170.5703\n816  167.5125\n817  168.1687\n818  170.7344\n819  169.5359\n820  168.9625\n821  169.2828\n822  170.1156\n823  169.6719\n824  168.6687\n825  168.3281\n826  167.0016\n827  168.3547\n828  167.9391\n829  166.5922\n830  167.4906\n831  167.6172\n832  170.8625\n833  167.9844\n834  165.8812\n835  168.8516\n836  169.2516\n837  168.4250\n838  168.9375\n839  168.7672\n840  169.8938\n841  167.5922\n842  168.6937\n843  168.8547\n844  167.2297\n845  170.1906\n846  168.6797\n847  167.9766\n848  168.3812\n849  168.3672\n850  169.9000\n851  168.4859\n852  167.6797\n853  168.2234\n854  166.1125\n855  169.1188\n856  168.2656\n857  168.8734\n858  166.9688\n859  170.8953\n860  167.7937\n861  171.0359\n862  167.3500\n863  167.2359\n864  169.4078\n865  169.5219\n866  167.0203\n867  167.2609\n868  171.4516\n869  170.8969\n870  168.3391\n871  169.2328\n872  167.7625\n873  166.1125\n874  169.4781\n875  168.9516\n876  167.4875\n877  169.8594\n878  168.8438\n879  168.8422\n880  168.3688\n881  169.3781\n882  167.3406\n883  168.9641\n884  169.2688\n885  164.1094\n886  168.9031\n887  169.4078\n888  167.7734\n889  168.7875\n890  167.2406\n891  168.8281\n892  168.6781\n893  168.0188\n894  171.1797\n895  167.9500\n896  165.6266\n897  168.5641\n898  167.5250\n899  166.8891\n900  166.7047\n901  167.0484\n902  168.5172\n903  167.6047\n904  167.8016\n905  167.8156\n906  168.8328\n907  166.7422\n908  168.1156\n909  168.7516\n910  167.1266\n911  167.3109\n912  169.5953\n913  166.0188\n914  168.3828\n915  169.3016\n916  167.2937\n917  166.5766\n918  169.4719\n919  170.1312\n920  169.0000\n921  167.3219\n922  168.6141\n923  167.3969\n924  169.8391\n925  170.7984\n926  168.4594\n927  168.3688\n928  167.6531\n929  167.1047\n930  167.3578\n931  168.8906\n932  169.3500\n933  169.2156\n934  169.8156\n935  167.9828\n936  169.3547\n937  170.0984\n938  168.9672\n939  168.7891\n940  169.2719\n941  169.8734\n942  170.3719\n943  166.7781\n944  169.2391\n945  167.4156\n946  169.1531\n947  168.5000\n948  169.4500\n949  168.7016\n950  168.4313\n951  164.6438\n952  167.9078\n953  169.8688\n954  170.8703\n955  167.2625\n956  167.1453\n957  170.0375\n958  169.6219\n959  168.4938\n960  168.6188\n961  168.0875\n962  169.8984\n963  171.1500\n964  168.4531\n965  169.7156\n966  168.7031\n967  169.6172\n968  168.4766\n969  166.7812\n970  170.9469\n971  169.4750\n972  169.0141\n973  169.5359\n974  167.0453\n975  167.8750\n976  167.5172\n977  169.8734\n978  168.1953\n979  168.7188\n980  168.3219\n981  169.7063\n982  168.2500\n983  168.5750\n984  168.2375\n985  167.7609\n986  166.7891\n987  170.2781\n988  166.2734\n989  170.0906\n990  169.5859\n991  169.4422\n992  167.5578\n993  169.8656\n994  169.2625\n995  167.9484\n996  168.1078\n997  169.0625\n998  165.8516\n999  166.7203\n1000 167.7000\n\n\n\n# Let us overlay their individual histograms to compare them:\np5 &lt;- gf_dhistogram(~result,\n  data = samples_08_1000,\n  color = \"grey\",\n  fill = \"dodgerblue\", title = \"N = 8\"\n) %&gt;%\n  gf_fitdistr(linewidth = 1) %&gt;%\n  gf_vline(\n    xintercept = pop_mean, inherit = FALSE,\n    color = \"blue\"\n  ) %&gt;%\n  gf_label(-0.025 ~ pop_mean,\n    label = \"Population Mean\",\n    color = \"blue\"\n  ) %&gt;%\n  gf_theme(scale_y_continuous(expand = expansion(mult = c(0.08, 0.02))))\n##\np6 &lt;- gf_dhistogram(~result,\n  data = samples_16_1000,\n  color = \"grey\",\n  fill = \"sienna\", title = \"N = 16\"\n) %&gt;%\n  gf_fitdistr(linewidth = 1) %&gt;%\n  gf_vline(\n    xintercept = pop_mean,\n    color = \"blue\"\n  ) %&gt;%\n  gf_label(-.025 ~ pop_mean,\n    label = \"Population Mean\",\n    color = \"blue\"\n  ) %&gt;%\n  gf_theme(scale_y_continuous(expand = expansion(mult = c(0.08, 0.02))))\n##\np7 &lt;- gf_dhistogram(~result,\n  data = samples_32_1000,\n  na.rm = TRUE,\n  color = \"grey\",\n  fill = \"palegreen\", title = \"N = 32\"\n) %&gt;%\n  gf_fitdistr(linewidth = 1) %&gt;%\n  gf_vline(\n    xintercept = pop_mean,\n    color = \"blue\"\n  ) %&gt;%\n  gf_label(-.025 ~ pop_mean,\n    label = \"Population Mean\", color = \"blue\"\n  ) %&gt;%\n  gf_theme(scale_y_continuous(expand = expansion(mult = c(0.08, 0.02))))\n\np8 &lt;- gf_dhistogram(~result,\n  data = samples_64_1000,\n  na.rm = TRUE,\n  color = \"grey\",\n  fill = \"violetred\", title = \"N = 64\"\n) %&gt;%\n  gf_fitdistr(linewidth = 1) %&gt;%\n  gf_vline(\n    xintercept = pop_mean,\n    color = \"blue\"\n  ) %&gt;%\n  gf_label(-.025 ~ pop_mean,\n    label = \"Population Mean\", color = \"blue\"\n  ) %&gt;%\n  gf_theme(scale_y_continuous(expand = expansion(mult = c(0.08, 0.02))))\n\n# patchwork::wrap_plots(p5,p6,p7,p8)\np5\n\nWarning in (function (mapping = NULL, data = NULL, stat = \"identity\", position = \"nudge\", : All aesthetics have length 1, but the data has 1000 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\np6\n\nWarning in (function (mapping = NULL, data = NULL, stat = \"identity\", position = \"nudge\", : All aesthetics have length 1, but the data has 1000 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\np7\n\nWarning in (function (mapping = NULL, data = NULL, stat = \"identity\", position = \"nudge\", : All aesthetics have length 1, but the data has 1000 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\np8\n\nWarning in (function (mapping = NULL, data = NULL, stat = \"identity\", position = \"nudge\", : All aesthetics have length 1, but the data has 1000 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_dhistogram(~result,\n  data = samples_32_1000,\n  na.rm = TRUE,\n  color = \"grey\",\n  fill = \"palegreen\", title = \"N = 32\"\n) %&gt;%\n  gf_fitdistr(linewidth = 1) %&gt;%\n  gf_vline(\n    xintercept = pop_mean,\n    color = \"blue\"\n  ) %&gt;%\n  gf_label(-.025 ~ pop_mean,\n    label = \"Population Mean\", color = \"blue\"\n  ) %&gt;%\n  gf_dhistogram(~result,\n  data = samples_16_1000,\n  color = \"grey\",\n  fill = \"sienna\", title = \"N = 16\"\n) %&gt;%\n  gf_fitdistr(linewidth = 1) %&gt;%\n  gf_vline(\n    xintercept = pop_mean,\n    color = \"blue\"\n  ) %&gt;%\n  gf_label(-.025 ~ pop_mean,\n    label = \"Population Mean\",\n    color = \"blue\"\n  )\n\nWarning in (function (mapping = NULL, data = NULL, stat = \"identity\", position = \"nudge\", : All aesthetics have length 1, but the data has 1000 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in (function (mapping = NULL, data = NULL, stat = \"identity\", position = \"nudge\", : All aesthetics have length 1, but the data has 1000 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`."
  },
  {
    "objectID": "classwork/classwork5/classwork5.html",
    "href": "classwork/classwork5/classwork5.html",
    "title": "Classwork 5",
    "section": "",
    "text": "library(tidyverse) # Tidy data processing and plotting\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggformula)# Formula based plots\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(ggplot2)\nlibrary(mosaic) # Our go-to package\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(skimr) # Another Data inspection package\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(GGally) # Corr plots\nlibrary(broom) # Clean reports from Stats / ML outputs\n\n# library(devtools)\n# devtools::install_github(\"rpruim/Lock5withR\")\nlibrary(Lock5withR) # Datasets\n\nlibrary(easystats) # Easy Statistical Analysis and Charts\n\n# Attaching packages: easystats 0.7.5 (red = needs update)\n✔ bayestestR  0.17.0   ✔ correlation 0.8.8 \n✖ datawizard  1.2.0    ✔ effectsize  1.0.1 \n✔ insight     1.4.2    ✔ modelbased  0.13.0\n✖ performance 0.15.1   ✔ parameters  0.28.2\n✖ report      0.6.1    ✔ see         0.12.0\n\nRestart the R-Session and update packages with `easystats::easystats_update()`.\n\nlibrary(correlation) # Different Types of Correlations\n\nlibrary(janitor) # Data cleaning and tidying package\n\n\nAttaching package: 'janitor'\n\nThe following object is masked from 'package:insight':\n\n    clean_names\n\nThe following objects are masked from 'package:datawizard':\n\n    remove_empty, remove_empty_rows\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(visdat) # Visualize whole dataframes for missing data\nlibrary(naniar) # Clean missing data\n\n\nAttaching package: 'naniar'\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\nlibrary(DT) # Interactive Tables for our data\nlibrary(tinytable) # Elegant Tables for our data\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(ggrepel) # Repelled Text Labels in ggplot\nlibrary(marquee) # Marquee Text Labels in ggplot\nlibrary(dplyr)\n\n\ndata(HollywoodMovies2011, package = \"Lock5withR\")\nmovies_modified &lt;- HollywoodMovies2011 %&gt;%\n  janitor::clean_names(case = \"snake\") %&gt;%\n  janitor::remove_empty(which = c(\"rows\", \"cols\")) %&gt;%\n  dplyr::mutate(\n    across(where(is.character), as.factor)\n  ) %&gt;%\n  dplyr::relocate(where(is.factor))\n\n\nmovies_quant &lt;- movies_modified %&gt;%\n  drop_na() %&gt;%\n  select(where(is.numeric))\nmovies_quant %&gt;% names()\n\n [1] \"rotten_tomatoes\"      \"audience_score\"       \"theaters_open_week\"  \n [4] \"bo_average_open_week\" \"domestic_gross\"       \"foreign_gross\"       \n [7] \"world_gross\"          \"budget\"               \"profitability\"       \n[10] \"opening_weekend\"     \n\n\n\nmovies_modified %&gt;%\n  drop_na() %&gt;%\n  gf_point(profitability ~ budget) %&gt;%\n  gf_smooth() %&gt;%\n  gf_labs(\n    title = \"Profitability vs budget\",\n    subtitle = \"Movie profitability: Does budget affect profitability?\"\n  )\n\n`geom_smooth()` using method = 'loess'\n\n\n\n\n\n\n\n\n\n\nmovies_modified %&gt;%\n  drop_na() %&gt;%\n  gf_point(profitability ~ budget, color = ~story) %&gt;%\n  gf_lm() %&gt;%\n  gf_labs(\n    title = \"Profitability vs budget\",\n    subtitle = \"Movie profitability: Does budget affect profitability?\"\n  )\n\n\n\n\n\n\n\n\n\nmovies_modified %&gt;% count(lead_studio) %&gt;% slice_min(n = 10, order_by = n)\n\n                 lead_studio n\n1         Aardman Animations 1\n2                  CBS Films 1\n3       DreamWorks Animation 1\n4  Happy Madison Productions 1\n5              Miramax Films 1\n6   Morgan Creek Productions 1\n7            New Line Cinema 1\n8                      Pixar 1\n9        Regency Enterprises 1\n10               Relativity  1\n11    Reliance Entertainment 1\n12   Sony Pictures Animation 1\n13     Vertigo Entertainment 1\n14 Village Roadshow Pictures 1\n15                    Virgin 1\n\n\n\nmovies_modified %&gt;% count(lead_studio) %&gt;% arrange(desc(n)) %&gt;% head(5)\n\n       lead_studio  n\n1      Independent 32\n2      Warner Bros 12\n3 20th Century Fox  9\n4        Universal  9\n5           Disney  8\n\n\n\nGGally::ggpairs(\n  movies_modified %&gt;% drop_na(),\n  columns = c(\n    \"profitability\", \"budget\", \"domestic_gross\",\"theaters_open_week\",\"opening_weekend\",\"rotten_tomatoes\"),\n  switch = \"both\",\n  progress = FALSE,\n  diag = list(continuous = \"densityDiag\"),\n  lower = list(continuous = wrap(\"smooth\", alpha = 0.3, se = FALSE)),\n  title = \"Movies Data Correlations Plot #1\"\n)\n\n\n\n\n\n\n\n\n\nGGally::ggpairs(\n  movies_modified %&gt;% drop_na(),\n  columns = c(\n    \"profitability\", \"budget\", \"domestic_gross\",\"theaters_open_week\",\"genre\",\"rotten_tomatoes\"),\n  switch = \"both\",\n  progress = FALSE,\n  diag = list(continuous = \"barDiag\"),\n  lower = list(continuous = wrap(\"smooth\", alpha = 0.3, se = FALSE)),\n  title = \"Movies Data Correlations Plot #1\"\n)\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\nmosaic::cor_test(domestic_gross ~ budget, data = movies_modified) %&gt;%\n  broom::tidy() %&gt;%\n  knitr::kable(\n    digits = 2,\n    caption = \"Movie Domestic Gross vs budget\"\n  )\n\n\nMovie Domestic Gross vs budget\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n0.7\n11.06\n0\n131\n0.6\n0.77\nPearson’s product-moment correlation\ntwo.sided"
  },
  {
    "objectID": "classwork/classwork3/index.html",
    "href": "classwork/classwork3/index.html",
    "title": "Classwork 3",
    "section": "",
    "text": "library(tidyverse) # Sine qua non\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic) # Out all-in-one package\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula) # Graphing package\nlibrary(skimr) # Looking at Data\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(janitor) # Clean the data\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(naniar) # Handle missing data\n\n\nAttaching package: 'naniar'\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\nlibrary(visdat) # Visualise missing data\nlibrary(tinytable) # Printing Static Tables for our data\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(DT) # Interactive Tables for our data\nlibrary(crosstable) # Multiple variable summaries\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(ggplot2)\n\n\ndocVisits &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/AER/DoctorVisits.csv\")\n\nRows: 5190 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): gender, private, freepoor, freerepat, nchronic, lchronic\ndbl (7): rownames, visits, age, income, illness, reduced, health\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(docVisits)\n\nRows: 5,190\nColumns: 13\n$ rownames  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ visits    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, …\n$ gender    &lt;chr&gt; \"female\", \"female\", \"male\", \"male\", \"male\", \"female\", \"femal…\n$ age       &lt;dbl&gt; 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, …\n$ income    &lt;dbl&gt; 0.55, 0.45, 0.90, 0.15, 0.45, 0.35, 0.55, 0.15, 0.65, 0.15, …\n$ illness   &lt;dbl&gt; 1, 1, 3, 1, 2, 5, 4, 3, 2, 1, 1, 2, 3, 4, 3, 2, 1, 1, 1, 1, …\n$ reduced   &lt;dbl&gt; 4, 2, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 13, 7, 1, 0, 0, 1, 0, 0,…\n$ health    &lt;dbl&gt; 1, 1, 0, 0, 1, 9, 2, 6, 5, 0, 0, 2, 1, 6, 0, 7, 5, 0, 0, 0, …\n$ private   &lt;chr&gt; \"yes\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"yes\", \"ye…\n$ freepoor  &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ freerepat &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ nchronic  &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"yes\", \"yes\", \"no\", \"no\", \"no\", \"no\"…\n$ lchronic  &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n\n\n\ndocVisits_modified &lt;- docVisits %&gt;%\n  # Replace common NA strings and numbers with actual NA\n  naniar::replace_with_na_all(condition = ~ .x %in% common_na_strings) %&gt;%\n  naniar::replace_with_na_all(condition = ~ .x %in% common_na_numbers) %&gt;%\n  # Clean variable names\n  janitor::clean_names(case = \"snake\") %&gt;% # clean names\n\n  # Convert character variables to factors\n  mutate(\n    gender = as_factor(gender),\n    private = as_factor(private),\n    freepoor = as_factor(freepoor),\n    freerepat = as_factor(freerepat),\n    nchronic = as_factor(nchronic),\n    lchronic = as_factor(lchronic)\n  ) %&gt;%\n  # arrange the character variables first\n  dplyr::relocate(where(is.factor), .after = rownames)\n\n\ndocVisits_modified %&gt;% glimpse()\n\nRows: 5,190\nColumns: 13\n$ rownames  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ gender    &lt;fct&gt; female, female, male, male, male, female, female, female, fe…\n$ private   &lt;fct&gt; yes, yes, no, no, no, no, no, no, yes, yes, no, no, no, no, …\n$ freepoor  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ freerepat &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, yes, no, no, no,…\n$ nchronic  &lt;fct&gt; no, no, no, no, yes, yes, no, no, no, no, no, no, yes, yes, …\n$ lchronic  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ visits    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, …\n$ age       &lt;dbl&gt; 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, …\n$ income    &lt;dbl&gt; 0.55, 0.45, 0.90, 0.15, 0.45, 0.35, 0.55, 0.15, 0.65, 0.15, …\n$ illness   &lt;dbl&gt; 1, 1, 3, 1, 2, 5, 4, 3, 2, 1, 1, 2, 3, 4, 3, 2, 1, 1, 1, 1, …\n$ reduced   &lt;dbl&gt; 4, 2, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 13, 7, 1, 0, 0, 1, 0, 0,…\n$ health    &lt;dbl&gt; 1, 1, 0, 0, 1, 9, 2, 6, 5, 0, 0, 2, 1, 6, 0, 7, 5, 0, 0, 0, …\n\n\n\ndocVisits_modified %&gt;%\n  DT::datatable(\n    caption = htmltools::tags$caption(\n      style = \"caption-side: top; text-align: left; color: black; font-size: 150%;\",\n      \"Doctor Visits Dataset (Clean)\"\n    ),\n    options = list(pageLength = 10, autoWidth = TRUE)\n  ) %&gt;%\n  DT::formatStyle(\n    columns = names(docVisits_modified),\n    fontFamily = \"Roboto Condensed\",\n    fontSize = \"12px\"\n  )"
  },
  {
    "objectID": "classwork/classwork3/index.html#setup",
    "href": "classwork/classwork3/index.html#setup",
    "title": "Classwork 3",
    "section": "",
    "text": "library(tidyverse) # Sine qua non\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic) # Out all-in-one package\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula) # Graphing package\nlibrary(skimr) # Looking at Data\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(janitor) # Clean the data\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(naniar) # Handle missing data\n\n\nAttaching package: 'naniar'\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\nlibrary(visdat) # Visualise missing data\nlibrary(tinytable) # Printing Static Tables for our data\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(DT) # Interactive Tables for our data\nlibrary(crosstable) # Multiple variable summaries\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(ggplot2)\n\n\ndocVisits &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/AER/DoctorVisits.csv\")\n\nRows: 5190 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): gender, private, freepoor, freerepat, nchronic, lchronic\ndbl (7): rownames, visits, age, income, illness, reduced, health\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(docVisits)\n\nRows: 5,190\nColumns: 13\n$ rownames  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ visits    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, …\n$ gender    &lt;chr&gt; \"female\", \"female\", \"male\", \"male\", \"male\", \"female\", \"femal…\n$ age       &lt;dbl&gt; 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, …\n$ income    &lt;dbl&gt; 0.55, 0.45, 0.90, 0.15, 0.45, 0.35, 0.55, 0.15, 0.65, 0.15, …\n$ illness   &lt;dbl&gt; 1, 1, 3, 1, 2, 5, 4, 3, 2, 1, 1, 2, 3, 4, 3, 2, 1, 1, 1, 1, …\n$ reduced   &lt;dbl&gt; 4, 2, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 13, 7, 1, 0, 0, 1, 0, 0,…\n$ health    &lt;dbl&gt; 1, 1, 0, 0, 1, 9, 2, 6, 5, 0, 0, 2, 1, 6, 0, 7, 5, 0, 0, 0, …\n$ private   &lt;chr&gt; \"yes\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"yes\", \"ye…\n$ freepoor  &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ freerepat &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ nchronic  &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"yes\", \"yes\", \"no\", \"no\", \"no\", \"no\"…\n$ lchronic  &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n\n\n\ndocVisits_modified &lt;- docVisits %&gt;%\n  # Replace common NA strings and numbers with actual NA\n  naniar::replace_with_na_all(condition = ~ .x %in% common_na_strings) %&gt;%\n  naniar::replace_with_na_all(condition = ~ .x %in% common_na_numbers) %&gt;%\n  # Clean variable names\n  janitor::clean_names(case = \"snake\") %&gt;% # clean names\n\n  # Convert character variables to factors\n  mutate(\n    gender = as_factor(gender),\n    private = as_factor(private),\n    freepoor = as_factor(freepoor),\n    freerepat = as_factor(freerepat),\n    nchronic = as_factor(nchronic),\n    lchronic = as_factor(lchronic)\n  ) %&gt;%\n  # arrange the character variables first\n  dplyr::relocate(where(is.factor), .after = rownames)\n\n\ndocVisits_modified %&gt;% glimpse()\n\nRows: 5,190\nColumns: 13\n$ rownames  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ gender    &lt;fct&gt; female, female, male, male, male, female, female, female, fe…\n$ private   &lt;fct&gt; yes, yes, no, no, no, no, no, no, yes, yes, no, no, no, no, …\n$ freepoor  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ freerepat &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, yes, no, no, no,…\n$ nchronic  &lt;fct&gt; no, no, no, no, yes, yes, no, no, no, no, no, no, yes, yes, …\n$ lchronic  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ visits    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, …\n$ age       &lt;dbl&gt; 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, …\n$ income    &lt;dbl&gt; 0.55, 0.45, 0.90, 0.15, 0.45, 0.35, 0.55, 0.15, 0.65, 0.15, …\n$ illness   &lt;dbl&gt; 1, 1, 3, 1, 2, 5, 4, 3, 2, 1, 1, 2, 3, 4, 3, 2, 1, 1, 1, 1, …\n$ reduced   &lt;dbl&gt; 4, 2, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 13, 7, 1, 0, 0, 1, 0, 0,…\n$ health    &lt;dbl&gt; 1, 1, 0, 0, 1, 9, 2, 6, 5, 0, 0, 2, 1, 6, 0, 7, 5, 0, 0, 0, …\n\n\n\ndocVisits_modified %&gt;%\n  DT::datatable(\n    caption = htmltools::tags$caption(\n      style = \"caption-side: top; text-align: left; color: black; font-size: 150%;\",\n      \"Doctor Visits Dataset (Clean)\"\n    ),\n    options = list(pageLength = 10, autoWidth = TRUE)\n  ) %&gt;%\n  DT::formatStyle(\n    columns = names(docVisits_modified),\n    fontFamily = \"Roboto Condensed\",\n    fontSize = \"12px\"\n  )"
  },
  {
    "objectID": "classwork/classwork3/index.html#summarising-qual-variables",
    "href": "classwork/classwork3/index.html#summarising-qual-variables",
    "title": "Classwork 3",
    "section": "Summarising Qual Variables",
    "text": "Summarising Qual Variables\n\ndocVisits_modified %&gt;% count(gender) %&gt;% tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                gender\n                n\n              \n        \n        \n        \n                \n                  female\n                  2702\n                \n                \n                  male\n                  2488\n                \n        \n      \n    \n\n\n\n\ndocVisits_modified %&gt;% count(private) %&gt;% tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                private\n                n\n              \n        \n        \n        \n                \n                  yes\n                  2298\n                \n                \n                  no\n                  2892\n                \n        \n      \n    \n\n\n\n\ndocVisits_modified %&gt;% count(across(.cols = c(gender,private))) %&gt;% tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                gender\n                private\n                n\n              \n        \n        \n        \n                \n                  female\n                  yes\n                  1269\n                \n                \n                  female\n                  no\n                  1433\n                \n                \n                  male\n                  yes\n                  1029\n                \n                \n                  male\n                  no\n                  1459\n                \n        \n      \n    \n\n\n\n\ndocVisits_modified %&gt;% count(across(where(is.character))) %&gt;% tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                n\n              \n        \n        \n        \n                \n                  5190"
  },
  {
    "objectID": "classwork/classwork3/index.html#summarising-quant-variables",
    "href": "classwork/classwork3/index.html#summarising-quant-variables",
    "title": "Classwork 3",
    "section": "Summarising Quant Variables",
    "text": "Summarising Quant Variables\n\ndocVisits_modified %&gt;% dplyr::summarise(mean_income = mean(income, na.rm = T))\n\n# A tibble: 1 × 1\n  mean_income\n        &lt;dbl&gt;\n1       0.583\n\n\n\nSingle Variable, Multiple Summaries\n\ndocVisits_modified %&gt;%\n  dplyr::summarise(\n    mean_visits = mean(visits, na.rm = T),\n    sd_visits = sd(visits, na.rm = T),\n    min_visits = min(visits, na.rm = T),\n    max_visits = max(visits, na.rm = T)\n  )\n\n# A tibble: 1 × 4\n  mean_visits sd_visits min_visits max_visits\n        &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1       0.302     0.798          0          9\n\n\n\n\nMultiple Variables, Multiple Summaries\n\ndocVisits_modified %&gt;%\n  dplyr::summarise(across(.cols = c(visits, income), # select columns\n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 1 × 8\n  visits_mean visits_sd visits_min visits_max income_mean income_sd income_min\n        &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1       0.302     0.798          0          9       0.583     0.369          0\n# ℹ 1 more variable: income_max &lt;dbl&gt;\n\n\n\n\nGrouped Summaries\n\nOne qual variable\n\ndocVisits_modified %&gt;%\n  group_by(gender) %&gt;%\n  summarize(average_visits = mean(visits), count = n())\n\n# A tibble: 2 × 3\n  gender average_visits count\n  &lt;fct&gt;           &lt;dbl&gt; &lt;int&gt;\n1 female          0.362  2702\n2 male            0.236  2488\n\n\n\n\nTwo qual variable\n\ndocVisits_modified %&gt;%\n  group_by(age, gender) %&gt;%\n  summarize(average_visits = mean(visits), \n            max_visits = max(visits),\n            min_visits = min(visits),count = n())\n\n`summarise()` has grouped output by 'age'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 24 × 6\n# Groups:   age [12]\n     age gender average_visits max_visits min_visits count\n   &lt;dbl&gt; &lt;fct&gt;           &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;\n 1  0.19 female          0.276          8          0   351\n 2  0.19 male            0.157          4          0   401\n 3  0.22 female          0.229          5          0   484\n 4  0.22 male            0.182          7          0   729\n 5  0.27 female          0.425          7          0   186\n 6  0.27 male            0.166          5          0   337\n 7  0.32 female          0.356          7          0   104\n 8  0.32 male            0.183          3          0   197\n 9  0.37 female          0.377          3          0    61\n10  0.37 male            0.153          3          0    85\n# ℹ 14 more rows\n\n\n\n\nMultiple Variables, Multiple Summaries\n\ndocVisits_modified %&gt;%\n  dplyr::summarise(across(\n    .cols = c(visits, income),\n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 1 × 8\n  visits_mean visits_sd visits_min visits_max income_mean income_sd income_min\n        &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1       0.302     0.798          0          9       0.583     0.369          0\n# ℹ 1 more variable: income_max &lt;dbl&gt;\n\n\n\n\nCross Table\n\ncrosstable(visits + income ~ gender + freepoor,\n  data = docVisits_modified\n) %&gt;%\n  crosstable::as_flextable()\n\nfreepoornoyesgenderfemalemalefemalemalevisitsMin / Max0 / 8.00 / 9.00 / 5.00 / 7.0Med [IQR]0 [0;0]0 [0;0]0 [0;0]0 [0;0]Mean (std)0.4 (0.9)0.2 (0.7)0.2 (0.8)0.1 (0.6)N (NA)2618 (0)2350 (0)84 (0)138 (0)incomeMin / Max0 / 1.50 / 1.50 / 1.10 / 1.1Med [IQR]0.3 [0.2;0.6]0.6 [0.3;0.9]0.2 [0.1;0.3]0.2 [0.1;0.4]Mean (std)0.5 (0.3)0.7 (0.4)0.2 (0.2)0.3 (0.2)N (NA)2618 (0)2350 (0)84 (0)138 (0)\n\n\n\nUsing Qualitative variables\n\ncrosstable(freerepat + private ~ gender + freepoor,\n  data = docVisits_modified\n) %&gt;%\n  crosstable::as_flextable()\n\nfreepoornoyesgenderfemalemalefemalemalefreerepatno1801 (43.94%)2076 (50.65%)84 (2.05%)138 (3.37%)yes817 (74.89%)274 (25.11%)0 (0%)0 (0%)privateyes1269 (55.22%)1029 (44.78%)0 (0%)0 (0%)no1349 (46.65%)1321 (45.68%)84 (2.90%)138 (4.77%)\n\n\n\nglimpse(docVisits_modified)\n\nRows: 5,190\nColumns: 13\n$ rownames  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ gender    &lt;fct&gt; female, female, male, male, male, female, female, female, fe…\n$ private   &lt;fct&gt; yes, yes, no, no, no, no, no, no, yes, yes, no, no, no, no, …\n$ freepoor  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ freerepat &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, yes, no, no, no,…\n$ nchronic  &lt;fct&gt; no, no, no, no, yes, yes, no, no, no, no, no, no, yes, yes, …\n$ lchronic  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ visits    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, …\n$ age       &lt;dbl&gt; 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, …\n$ income    &lt;dbl&gt; 0.55, 0.45, 0.90, 0.15, 0.45, 0.35, 0.55, 0.15, 0.65, 0.15, …\n$ illness   &lt;dbl&gt; 1, 1, 3, 1, 2, 5, 4, 3, 2, 1, 1, 2, 3, 4, 3, 2, 1, 1, 1, 1, …\n$ reduced   &lt;dbl&gt; 4, 2, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 13, 7, 1, 0, 0, 1, 0, 0,…\n$ health    &lt;dbl&gt; 1, 1, 0, 0, 1, 9, 2, 6, 5, 0, 0, 2, 1, 6, 0, 7, 5, 0, 0, 0, …"
  },
  {
    "objectID": "classwork/classwork10/index.html",
    "href": "classwork/classwork10/index.html",
    "title": "Classwork 9",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(infer)\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\n## Datasets from Chihara and Hesterberg's book (Second Edition)\nlibrary(resampledata)\n\n\nAttaching package: 'resampledata'\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n\n## Datasets from Cetinkaya-Rundel and Hardin's book (First Edition)\nlibrary(openintro)\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:mosaic':\n\n    dotPlot\n\nThe following objects are masked from 'package:lattice':\n\n    ethanol, lsegments\n\n\n\ndata(yrbss, package = \"openintro\")\nyrbss\n\n# A tibble: 13,583 × 13\n     age gender grade hispanic race                     height weight helmet_12m\n   &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;                     &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;     \n 1    14 female 9     not      Black or African Americ…  NA      NA   never     \n 2    14 female 9     not      Black or African Americ…  NA      NA   never     \n 3    15 female 9     hispanic Native Hawaiian or Othe…   1.73   84.4 never     \n 4    15 female 9     not      Black or African Americ…   1.6    55.8 never     \n 5    15 female 9     not      Black or African Americ…   1.5    46.7 did not r…\n 6    15 female 9     not      Black or African Americ…   1.57   67.1 did not r…\n 7    15 female 9     not      Black or African Americ…   1.65  132.  did not r…\n 8    14 male   9     not      Black or African Americ…   1.88   71.2 never     \n 9    15 male   9     not      Black or African Americ…   1.75   63.5 never     \n10    15 male   10    not      Black or African Americ…   1.37   97.1 did not r…\n# ℹ 13,573 more rows\n# ℹ 5 more variables: text_while_driving_30d &lt;chr&gt;, physically_active_7d &lt;int&gt;,\n#   hours_tv_per_school_day &lt;chr&gt;, strength_training_7d &lt;int&gt;,\n#   school_night_hours_sleep &lt;chr&gt;\n\n\n\nyrbss %&gt;%\n  group_by(helmet_12m) %&gt;%\n  count()\n\n# A tibble: 7 × 2\n# Groups:   helmet_12m [7]\n  helmet_12m       n\n  &lt;chr&gt;        &lt;int&gt;\n1 always         399\n2 did not ride  4549\n3 most of time   293\n4 never         6977\n5 rarely         713\n6 sometimes      341\n7 &lt;NA&gt;           311\n\n\n\nyrbss %&gt;%\n  group_by(text_while_driving_30d) %&gt;%\n  count()\n\n# A tibble: 9 × 2\n# Groups:   text_while_driving_30d [9]\n  text_while_driving_30d     n\n  &lt;chr&gt;                  &lt;int&gt;\n1 0                       4792\n2 1-2                      925\n3 10-19                    373\n4 20-29                    298\n5 3-5                      493\n6 30                       827\n7 6-9                      311\n8 did not drive           4646\n9 &lt;NA&gt;                     918\n\n\n\nno_helmet_text &lt;- yrbss %&gt;%\n  filter(helmet_12m == \"never\") %&gt;%\n  mutate(text_ind = ifelse(text_while_driving_30d == \"30\", \"yes\", \"no\")) %&gt;%\n  # removing most of the other variables\n  select(age, gender, text_ind)\nno_helmet_text\n\n# A tibble: 6,977 × 3\n     age gender text_ind\n   &lt;int&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1    14 female no      \n 2    14 female &lt;NA&gt;    \n 3    15 female yes     \n 4    15 female no      \n 5    14 male   &lt;NA&gt;    \n 6    15 male   &lt;NA&gt;    \n 7    16 male   no      \n 8    14 male   no      \n 9    15 male   no      \n10    16 male   no      \n# ℹ 6,967 more rows\n\n\n\nno_helmet_text %&gt;%\n  drop_na() %&gt;%\n  count(text_ind)\n\n# A tibble: 2 × 2\n  text_ind     n\n  &lt;chr&gt;    &lt;int&gt;\n1 no        6025\n2 yes        462\n\n\n\nno_helmet_text %&gt;%\n  drop_na() %&gt;%\n  summarize(prop = prop(text_ind, success = \"yes\"), n = n())\n\n# A tibble: 1 × 2\n    prop     n\n   &lt;dbl&gt; &lt;int&gt;\n1 0.0712  6487\n\n\n\nno_helmet_text %&gt;%\n  drop_na() %&gt;%\n  gf_bar(~text_ind) %&gt;%\n  gf_labs(\n    x = \"texted?\",\n    title = \"High-Schoolers who texted every day\",\n    subtitle = \"While driving with no helmet on!!\"\n  )\n\n\n\n\n\n\n\n\n\nmosaic::binom.test(~text_ind, data = no_helmet_text, success = \"yes\")\n\n\n\n\ndata:  no_helmet_text$text_ind  [with success = yes]\nnumber of successes = 463, number of trials = 6503, p-value &lt; 2.2e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.06506429 0.07771932\nsample estimates:\nprobability of success \n            0.07119791 \n\n\n\nmosaic::binom.test(~text_ind, data = no_helmet_text, success = \"yes\") %&gt;%\n  broom::tidy()\n\n# A tibble: 1 × 7\n  estimate statistic p.value parameter conf.low conf.high alternative\n     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      \n1   0.0712       463       0      6503   0.0651    0.0777 two.sided  \n\n\n\n\nMultiple Proportions\n\ndata(GSS2002, package = \"resampledata\")\nglimpse(GSS2002)\n\nRows: 2,765\nColumns: 21\n$ ID            &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ Region        &lt;fct&gt; South Central, South Central, South Central, South Centr…\n$ Gender        &lt;fct&gt; Female, Male, Female, Female, Male, Male, Female, Female…\n$ Race          &lt;fct&gt; White, White, White, White, White, White, White, White, …\n$ Education     &lt;fct&gt; HS, Bachelors, HS, Left HS, Left HS, HS, Bachelors, HS, …\n$ Marital       &lt;fct&gt; Divorced, Married, Separated, Divorced, Divorced, Divorc…\n$ Religion      &lt;fct&gt; Inter-nondenominational, Protestant, Protestant, Protest…\n$ Happy         &lt;fct&gt; Pretty happy, Pretty happy, NA, NA, NA, Pretty happy, NA…\n$ Income        &lt;fct&gt; 30000-34999, 75000-89999, 35000-39999, 50000-59999, 4000…\n$ PolParty      &lt;fct&gt; \"Strong Rep\", \"Not Str Rep\", \"Strong Rep\", \"Ind, Near De…\n$ Politics      &lt;fct&gt; Conservative, Conservative, NA, NA, NA, Conservative, NA…\n$ Marijuana     &lt;fct&gt; NA, Not legal, NA, NA, NA, NA, NA, NA, Legal, NA, NA, NA…\n$ DeathPenalty  &lt;fct&gt; Favor, Favor, NA, NA, NA, Favor, NA, NA, Favor, NA, NA, …\n$ OwnGun        &lt;fct&gt; No, Yes, NA, NA, NA, Yes, NA, NA, Yes, NA, NA, NA, NA, N…\n$ GunLaw        &lt;fct&gt; Favor, Oppose, NA, NA, NA, Oppose, NA, NA, Oppose, NA, N…\n$ SpendMilitary &lt;fct&gt; Too little, About right, NA, About right, NA, Too little…\n$ SpendEduc     &lt;fct&gt; Too little, Too little, NA, Too little, NA, Too little, …\n$ SpendEnv      &lt;fct&gt; About right, About right, NA, Too little, NA, Too little…\n$ SpendSci      &lt;fct&gt; About right, About right, NA, Too little, NA, Too little…\n$ Pres00        &lt;fct&gt; Bush, Bush, Bush, NA, NA, Bush, Bush, Bush, Bush, NA, NA…\n$ Postlife      &lt;fct&gt; Yes, Yes, NA, NA, NA, Yes, NA, NA, Yes, NA, NA, NA, NA, …\n\n\n\nGSS2002 %&gt;% count(Education)\n\n  Education    n\n1   Left HS  400\n2        HS 1485\n3    Jr Col  202\n4 Bachelors  443\n5  Graduate  230\n6      &lt;NA&gt;    5\n\n\n\nGSS2002 %&gt;% count(DeathPenalty)\n\n  DeathPenalty    n\n1        Favor  899\n2       Oppose  409\n3         &lt;NA&gt; 1457\n\n\n\nGSS2002_modified &lt;- GSS2002 %&gt;%\n  dplyr::select(Education, DeathPenalty) %&gt;%\n  tidyr::drop_na(., c(Education, DeathPenalty)) %&gt;%\n  # Re-level the factors\n  mutate(\n    Education = factor(Education,\n      levels = c(\"Left HS\", \"HS\", \"Jr Col\", \"Bachelors\", \"Graduate\"),\n      labels = c(\"Left HS\", \"HS\", \"Jr Col\", \"Bachelors\", \"Graduate\"),\n      # ordered = TRUE # Nope can't use this. See below\n    ),\n    DeathPenalty = factor(DeathPenalty,\n      levels = c(\"Favor\", \"Oppose\"),\n      labels = c(\"Favor\", \"Oppose\")\n      # ordered = TRUE # Nope can't use this. See below\n    )\n  )\nglimpse(GSS2002_modified)\n\nRows: 1,307\nColumns: 2\n$ Education    &lt;fct&gt; HS, Bachelors, HS, HS, HS, HS, HS, Jr Col, HS, Bachelors,…\n$ DeathPenalty &lt;fct&gt; Favor, Favor, Favor, Favor, Favor, Favor, Favor, Favor, O…\n\n\n\ngss_vcd_table &lt;- vcd::structable(Education ~ DeathPenalty, # cols ~ rows\n  data = GSS2002_modified\n)\ngss_vcd_table %&gt;% addmargins()\n\n            Education\nDeathPenalty Left HS  HS Jr Col Bachelors Graduate  Sum\n      Favor      117 511     71       135       64  898\n      Oppose      72 200     16        71       50  409\n      Sum        189 711     87       206      114 1307\n\n\n\n# If not already installed, install the package\n# install.packages(\"vcdExtra\")\n\n# Load the required package\nlibrary(vcdExtra) \n\nLoading required package: vcd\n\n\nLoading required package: grid\n\n\n\nAttaching package: 'vcd'\n\n\nThe following object is masked from 'package:mosaic':\n\n    mplot\n\n\nLoading required package: gnm\n\n\n\nAttaching package: 'gnm'\n\n\nThe following object is masked from 'package:lattice':\n\n    barley\n\n\n\nAttaching package: 'vcdExtra'\n\n\nThe following object is masked from 'package:resampledata':\n\n    TV\n\n\nThe following object is masked from 'package:dplyr':\n\n    summarise\n\ngss_vcd_table %&gt;%\n  vcd::mosaic(direction = \"h\",\n    main = \"GSS2002 Education vs Death Penalty Mosaic Chart\",\n    legend = TRUE,\n    labeling = labeling_border(\n      varnames = c(\"F\", \"F\"), \n      rot_labels = c(90, 0, 0, 0), \n      just_labels = c(\n        \"left\", \n        \"left\", \n        \"left\", \n        \"right\"\n      )\n    )\n  )\n\n\n\n\n\n\n\n\n\ncounts_table &lt;- vcd::structable(Education ~ DeathPenalty,\n  data = GSS2002_modified\n) # No margins added\nvcd::mosaic(counts_table,\n  gp = shading_max, legend = TRUE,\n  labeling = labeling_border(\n    varnames = c(\"F\", \"F\"), # Remove variable name labels\n    rot_labels = c(90, 0, 0, 0), # t,r,b,l?\n    just_labels = c(\n      \"left\", # Top Side. How?\n      \"left\", # Right side\n      \"left\", # Bottom side\n      \"right\"\n    )\n  )\n) # Left side. How?\n\n\n\n\n\n\n\nvcd::mosaic(counts_table,\n  type = \"expected\", gp = shading_max, legend = TRUE,\n  labeling = labeling_border(\n    varnames = c(\"F\", \"F\"), # Remove variable name labels\n    rot_labels = c(90, 0, 0, 0), # t,r,b,l?\n    just_labels = c(\n      \"left\", # Top Side. How?\n      \"left\", # Right side\n      \"left\", # Bottom side\n      \"right\"\n    )\n  )\n) # Left side. How?)\n\n\n\n\n\n\n\nvcd::assoc(counts_table,\n  gp = shading_max, legend = TRUE,\n  labeling = labeling_border(\n    varnames = c(\"F\", \"F\"), # Remove variable name labels\n    rot_labels = c(90, 0, 0, 0), # t,r,b,l?\n    just_labels = c(\n      \"left\", # Top Side. How?\n      \"left\", # Right side\n      \"left\", # Bottom side\n      \"right\"\n    )\n  )\n) # Left side. How?)\n\n\n\n\n\n\n\n\n\ncontingency_table &lt;- vcd::structable(Education ~ DeathPenalty,\n  data = GSS2002_modified\n)\ncontingency_table\n\n             Education Left HS  HS Jr Col Bachelors Graduate\nDeathPenalty                                                \nFavor                      117 511     71       135       64\nOppose                      72 200     16        71       50\n\n\n\nxq_test_object &lt;- xchisq.test(contingency_table)\n\n\n    Pearson's Chi-squared test\n\ndata:  x\nX-squared = 23.451, df = 4, p-value = 0.0001029\n\n  117      511       71      135       64   \n(129.86) (488.51) ( 59.78) (141.54) ( 78.33)\n [1.27]   [1.04]   [2.11]   [0.30]   [2.62] \n&lt;-1.13&gt;  &lt; 1.02&gt;  &lt; 1.45&gt;  &lt;-0.55&gt;  &lt;-1.62&gt; \n         \n   72      200       16       71       50   \n( 59.14) (222.49) ( 27.22) ( 64.46) ( 35.67)\n [2.79]   [2.27]   [4.63]   [0.66]   [5.75] \n&lt; 1.67&gt;  &lt;-1.51&gt;  &lt;-2.15&gt;  &lt; 0.81&gt;  &lt; 2.40&gt; \n         \nkey:\n    observed\n    (expected)\n    [contribution to X-squared]\n    &lt;Pearson residual&gt;"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "A3/Weekly_expense/expense.html",
    "href": "A3/Weekly_expense/expense.html",
    "title": "Is the average weekly expenditure for boys equal to girls?",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(infer)\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(broom) # Clean test results in tibble form\nlibrary(resampledata) # Datasets from Chihara and Hesterberg's book\n\n\nAttaching package: 'resampledata'\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n\nlibrary(openintro) # More datasets\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:mosaic':\n\n    dotPlot\n\nThe following objects are masked from 'package:lattice':\n\n    ethanol, lsegments\n\nlibrary(visStatistics) # One package to rule them all\nlibrary(ggstatsplot)\n\nYou can cite this package as:\n     Patil, I. (2021). Visualizations with statistical details: The 'ggstatsplot' approach.\n     Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167"
  },
  {
    "objectID": "A3/Weekly_expense/expense.html#r-packages-setup",
    "href": "A3/Weekly_expense/expense.html#r-packages-setup",
    "title": "Is the average weekly expenditure for boys equal to girls?",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(infer)\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(broom) # Clean test results in tibble form\nlibrary(resampledata) # Datasets from Chihara and Hesterberg's book\n\n\nAttaching package: 'resampledata'\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n\nlibrary(openintro) # More datasets\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:mosaic':\n\n    dotPlot\n\nThe following objects are masked from 'package:lattice':\n\n    ethanol, lsegments\n\nlibrary(visStatistics) # One package to rule them all\nlibrary(ggstatsplot)\n\nYou can cite this package as:\n     Patil, I. (2021). Visualizations with statistical details: The 'ggstatsplot' approach.\n     Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167"
  },
  {
    "objectID": "A3/Weekly_expense/expense.html#reading-file",
    "href": "A3/Weekly_expense/expense.html#reading-file",
    "title": "Is the average weekly expenditure for boys equal to girls?",
    "section": "Reading file",
    "text": "Reading file\n\nexp &lt;- read.csv(\"4-weekly_expenditure.csv\")\nglimpse(exp)\n\nRows: 40\nColumns: 6\n$ Name                        &lt;chr&gt; \"Radha\", \"Prerana\", \"Chris\", \"Nireeksha\", …\n$ Gender                      &lt;chr&gt; \"Female\", \"Female\", \"Male\", \"Female\", \"Mal…\n$ Total_Expenditure_Last_Week &lt;dbl&gt; 2000.0, 1200.0, 15000.0, 3620.0, 560.0, 22…\n$ X                           &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ X.1                         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ X.2                         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…"
  },
  {
    "objectID": "A3/Weekly_expense/expense.html#munging",
    "href": "A3/Weekly_expense/expense.html#munging",
    "title": "Is the average weekly expenditure for boys equal to girls?",
    "section": "Munging",
    "text": "Munging\n\nexp_modified &lt;- exp %&gt;%\n  select(c(\"Name\",\"Gender\",\"Total_Expenditure_Last_Week\")) %&gt;% \n  mutate(across(where(is.character), as.factor))%&gt;%\n  dplyr::relocate(where(is.factor), .before = Total_Expenditure_Last_Week)\nglimpse(exp_modified)\n\nRows: 40\nColumns: 3\n$ Name                        &lt;fct&gt; Radha, Prerana, Chris, Nireeksha, Supraj, …\n$ Gender                      &lt;fct&gt; Female, Female, Male, Female, Male, Male, …\n$ Total_Expenditure_Last_Week &lt;dbl&gt; 2000.0, 1200.0, 15000.0, 3620.0, 560.0, 22…"
  },
  {
    "objectID": "A3/Weekly_expense/expense.html#examining-the-data",
    "href": "A3/Weekly_expense/expense.html#examining-the-data",
    "title": "Is the average weekly expenditure for boys equal to girls?",
    "section": "Examining the Data",
    "text": "Examining the Data\n\nexp_modified %&gt;% \n  count(Gender)\n\n  Gender  n\n1 Female 20\n2   Male 20\n\n\n\nexp_modified %&gt;% \n  group_by(Gender) %&gt;% \n  summarise(\n    avg_exp = mean(Total_Expenditure_Last_Week, narm = TRUE),\n     sd_exp = sd(Total_Expenditure_Last_Week, na.rm = TRUE),\n  )\n\n# A tibble: 2 × 3\n  Gender avg_exp sd_exp\n  &lt;fct&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 Female   2582   2465.\n2 Male     7085. 11501."
  },
  {
    "objectID": "A3/Weekly_expense/expense.html#visualising-the-data",
    "href": "A3/Weekly_expense/expense.html#visualising-the-data",
    "title": "Is the average weekly expenditure for boys equal to girls?",
    "section": "Visualising the Data",
    "text": "Visualising the Data\n\nexp_modified %&gt;% \n  gf_boxplot(Gender~Total_Expenditure_Last_Week, fill =~ Gender,orientation = \"y\") %&gt;% \n  gf_labs(\n    title=\"Last Week Expenditure Girls vs Guys\",\n    x =\"Expense Last Week\",\n    y = \"Gender\") %&gt;% \n  gf_theme(theme_minimal())\n\n\n\n\n\n\n\n\n\nexp_mod2 &lt;-exp_modified %&gt;% \n  slice_max(n = 15, order_by = Total_Expenditure_Last_Week)\n  \nexp_mod2 %&gt;%  \n  gf_col(reorder(Name, Total_Expenditure_Last_Week)~Total_Expenditure_Last_Week, fill = \"steelblue\") %&gt;% \n  gf_labs(\n    title = \"Top 15 highest expenses\",\n    x=\"Expenses\",\n    y = \"Names\"\n  ) %&gt;% \n  gf_theme(theme_minimal)\n\n\n\n\n\n\n\n\n\navg &lt;- exp_mod2 %&gt;% \n  group_by(Gender) %&gt;% \n  summarise(\n    avg_expense = mean(Total_Expenditure_Last_Week)\n  )\n\navg %&gt;% \n  gf_col(avg_expense~Gender, fill = ~ Gender) %&gt;% \n  gf_labs(\n    title = \"Average expense of Girls & Boys\",\n    x = \"Gender\",\n    y = \"Average Expense\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\")) %&gt;% \n  gf_theme(theme_minimal)\n\n\n\n\n\n\n\n\n\nexp_modified %&gt;%\n  gf_density(\n    ~Total_Expenditure_Last_Week,\n    fill = ~Gender, colour = ~Gender,\n    alpha = 0.5,\n    title = \"Expenditure Last Week Densities\",\n    subtitle = \"Boys vs Girls\"\n  ) %&gt;% \n  gf_theme(theme_minimal)"
  },
  {
    "objectID": "A3/Weekly_expense/expense.html#null-hypothesis-alternative-hypothesis",
    "href": "A3/Weekly_expense/expense.html#null-hypothesis-alternative-hypothesis",
    "title": "Is the average weekly expenditure for boys equal to girls?",
    "section": "Null Hypothesis & Alternative Hypothesis",
    "text": "Null Hypothesis & Alternative Hypothesis\n\nH0: Weekly expenditure is independent of gender (There is no difference between girls expenditure & boys expenditure)\nH1: Weekly expenditure is dependent on gender."
  },
  {
    "objectID": "A3/Weekly_expense/expense.html#check-for-normality",
    "href": "A3/Weekly_expense/expense.html#check-for-normality",
    "title": "Is the average weekly expenditure for boys equal to girls?",
    "section": "1. Check for Normality",
    "text": "1. Check for Normality\n\nexp_modified %&gt;%\n    gf_density(~Total_Expenditure_Last_Week,\n    fill = ~Gender,\n    alpha = 0.5,\n    title = \"Weekly Expenditure for boys and girls\"\n  ) %&gt;%\n  gf_facet_grid(~Gender) %&gt;%\n  gf_fitdistr(dist = \"dnorm\") %&gt;%\n  gf_theme(theme(legend.position = \"none\")) \n\n\n\n\n\n\n\nexp_modified %&gt;%\n  gf_qqline(~Total_Expenditure_Last_Week,\n    color = ~Gender,\n    title = \"Weekly Expenditure\",\n    subtitle = \"Are they Normally Distributed?\"\n  ) %&gt;%\n  gf_qq() %&gt;%\n  gf_facet_wrap(~Gender) %&gt;% \n\n  gf_theme(theme(legend.position = \"none\")) \n\n\n\n\n\n\n\n\n\nboys_expense &lt;- exp_modified %&gt;%\n  filter(Gender == \"Male\") %&gt;%\n  select(Total_Expenditure_Last_Week)\n\ngirls_expense &lt;- exp_modified %&gt;%\n  filter(Gender == \"Female\") %&gt;%\n  select(Total_Expenditure_Last_Week)\n\n\nshapiro.test(boys_expense$Total_Expenditure_Last_Week)\n\n\n    Shapiro-Wilk normality test\n\ndata:  boys_expense$Total_Expenditure_Last_Week\nW = 0.56351, p-value = 1.261e-06\n\nshapiro.test(girls_expense$Total_Expenditure_Last_Week)\n\n\n    Shapiro-Wilk normality test\n\ndata:  girls_expense$Total_Expenditure_Last_Week\nW = 0.78317, p-value = 0.0004899\n\n\nP value for both boys & girls is less than 0.05, therefore its not normally distributed. This means that the distributions of weekly expenditure for both boys and girls deviate significantly from a normal distribution."
  },
  {
    "objectID": "A3/Weekly_expense/expense.html#check-for-variances",
    "href": "A3/Weekly_expense/expense.html#check-for-variances",
    "title": "Is the average weekly expenditure for boys equal to girls?",
    "section": "2. Check for Variances",
    "text": "2. Check for Variances\n\nexp_modified %&gt;%\n  dplyr::select(Total_Expenditure_Last_Week, Gender) %&gt;%\n  dplyr::group_by(Gender) %&gt;%\n  dplyr::summarize(variance = var(Total_Expenditure_Last_Week), n = n())\n\n# A tibble: 2 × 3\n  Gender   variance     n\n  &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;\n1 Female   6074125.    20\n2 Male   132268687.    20\n\nvar.test(Total_Expenditure_Last_Week ~ Gender,\n  data = exp_modified,\n  conf.int = TRUE, conf.level = 0.95\n) %&gt;%\n  broom::tidy()\n\nMultiple parameters; naming those columns num.df and den.df.\n\n\n# A tibble: 1 × 9\n  estimate num.df den.df statistic p.value conf.low conf.high method alternative\n     &lt;dbl&gt;  &lt;int&gt;  &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;      \n1   0.0459     19     19    0.0459 8.53e-9   0.0182     0.116 F tes… two.sided  \n\n##\nqf(0.975, 275, 322)\n\n[1] 1.254823\n\n\nThe variance is way off with a p value 8.53 * 10^-9 which is much less than 0.05, so therefore the variance for the variables is significantly different.\n\nInference\n\nThe two variables are not normally distributed.\nThe two variances are also significantly different.\n\nThis means that its Non-Parametric so the Mann-Whitney Test & Permutation Test must be done since its not normally distributed and the variances is different."
  },
  {
    "objectID": "A3/Weekly_expense/expense.html#mann-whitney-test",
    "href": "A3/Weekly_expense/expense.html#mann-whitney-test",
    "title": "Is the average weekly expenditure for boys equal to girls?",
    "section": "1. Mann-Whitney Test",
    "text": "1. Mann-Whitney Test\n\nH0: The rank sums for girls and boys do not differ significantly.\nH1: The rank sums for girls and boys do differ significantly.\n\n\nlibrary(ggprism)\nlibrary(ggtext)\nlibrary(glue)\nlibrary(latex2exp)\n\nexp_modified %&gt;%\n  gf_jitter(rank(Total_Expenditure_Last_Week) ~ Gender,\n    color = ~Gender,\n    show.legend = FALSE,\n    width = 0.05, alpha = 0.25,\n    ylab = \"Ranks of Total Expenditure\",\n    title = \"Ranked Expenditure for Boys and Girls\"\n  ) %&gt;%\n  gf_summary(\n    group = ~1, \n    fun = \"mean\", geom = \"line\", colour = \"lightblue\",\n    lty = 1, linewidth = 2\n  ) %&gt;%\n  gf_summary(fun = \"mean\", colour = \"firebrick\", size = 4, geom = \"point\") %&gt;%\n  gf_refine(scale_x_discrete(\n    breaks = c(\"Male\", \"Female\"),\n    labels = c(\"Male\", \"Female\"),\n    guide = \"prism_bracket\"\n  )) %&gt;%\n  gf_annotate(\"label\",\n    label = \"Mean Rank \\nBoys Scores\",\n    y = 300, x = 0.75, inherit = FALSE\n  ) %&gt;%\n  gf_annotate(\"label\",\n    label = \"Mean Rank \\nGirls Scores\",\n    y = 320, x = 2.25, inherit = FALSE\n  )\n\nWarning in ggplot2::annotate(geom = geom, x = x, y = y, xmin = xmin, xmax = xmax, : Ignoring unknown parameters: `inherit`\nIgnoring unknown parameters: `inherit`\n\n\nWarning: The S3 guide system was deprecated in ggplot2 3.5.0.\nℹ It has been replaced by a ggproto system that can be extended.\n\n\n\n\n\n\n\n\n\n\nwilcox.test(Total_Expenditure_Last_Week ~ Gender,\n  data = exp_modified,\n  conf.int = TRUE\n) %&gt;%\n  broom::tidy()\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact p-value with ties\n\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact confidence intervals with ties\n\n\n# A tibble: 1 × 7\n  estimate statistic p.value conf.low conf.high method               alternative\n     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                &lt;chr&gt;      \n1   -1100.      132.  0.0657   -3075.      60.0 Wilcoxon rank sum t… two.sided  \n\n\nHere, we see that the p value = 0.06 which is &gt;0.05, so we fail to reject the Null Hypothesis. This means there is no statistically significant difference in weekly expenditure between boys and girls.\n\nmosaic::t_test(Total_Expenditure_Last_Week ~ Gender,\n  var.equal = FALSE, # Welch Correction\n  data = exp_modified\n) %&gt;%\n  broom::tidy()\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1   -4503.      2582     7085.     -1.71   0.102      20.7   -9976.      971.\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n\n\nInferences:-\n\nThe p-value was 0.06, which is slightly greater than the 0.05 threshold.\nWe fail to reject the null hypothesis, which means that there is no statistically significant difference in the distribution of weekly expenditure between boys and girls."
  },
  {
    "objectID": "A3/Weekly_expense/expense.html#permutations-test",
    "href": "A3/Weekly_expense/expense.html#permutations-test",
    "title": "Is the average weekly expenditure for boys equal to girls?",
    "section": "2. Permutations Test",
    "text": "2. Permutations Test\n\nobs_diff_infer &lt;- exp_modified %&gt;% \n  infer::specify(Total_Expenditure_Last_Week ~ Gender) %&gt;%\n  infer::calculate(\n    stat = \"diff in means\",\n    order = c(\"Male\", \"Female\")\n  )\nobs_diff_infer\n\nResponse: Total_Expenditure_Last_Week (numeric)\nExplanatory: Gender (factor)\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1 4503.\n\n\nOn average, males spent Rs. 4502.75 more than females last week. Is this difference due to random chance or is it statistically significant?\n\nnull_dist_infer &lt;- exp_modified %&gt;% \n  specify(Total_Expenditure_Last_Week ~ Gender) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  generate(reps = 4999, type = \"permute\") %&gt;% \n  calculate(\n    stat = \"diff in means\",\n    order = c(\"Male\", \"Female\") \n  )\nnull_dist_infer\n\nResponse: Total_Expenditure_Last_Week (numeric)\nExplanatory: Gender (factor)\n...\n# A tibble: 4,999 × 2\n   replicate   stat\n       &lt;int&gt;  &lt;dbl&gt;\n 1         1 -3680.\n 2         2  3696.\n 3         3 -2997.\n 4         4  2828.\n 5         5 -2935.\n 6         6  3881.\n 7         7  1753.\n 8         8  3548.\n 9         9 -2063.\n10        10  -155.\n# ℹ 4,989 more rows\n\n\n\nnull_dist_infer %&gt;%\n  visualise() + \n  shade_p_value(obs_diff_infer,\n    direction = \"two-sided\"\n  ) +\n  scale_y_continuous(expand = c(0, 0))\n\n\n\n\n\n\n\n\n\nnull_dist_infer %&gt;%\n  get_p_value(obs_stat = obs_diff_infer, direction = \"two-sided\")\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1  0.0556\n\n\n\nInferences:-\n\nThe p value = 0.059 (5.9%), which is greater than the 0.05 threshold.\nSo we fail to reject the Null Hypothesis that weekly expenditure is independent of gender. So the observed difference of Rs. 4502.75 has occurred due to random chance."
  },
  {
    "objectID": "A3/Weekly_expense/expense.html#conclusion",
    "href": "A3/Weekly_expense/expense.html#conclusion",
    "title": "Is the average weekly expenditure for boys equal to girls?",
    "section": "Conclusion",
    "text": "Conclusion\nTo conclude, while boys appear to have spent a bit more on average than girls, statistical tests show that this difference is not significant. Both the Mann Whitney and permutation tests indicate that gender does not play a major role in determining weekly spending. Overall, weekly expenditure patterns are fairly similar between boys and girls."
  },
  {
    "objectID": "A3/Tattoo_Attraction/tat.html",
    "href": "A3/Tattoo_Attraction/tat.html",
    "title": "Do tattoos make people look attractive or not?",
    "section": "",
    "text": "library(ggformula)\n\nLoading required package: ggplot2\n\n\nLoading required package: scales\n\n\nLoading required package: ggridges\n\n\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(naniar)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:naniar':\n\n    n_complete\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.1.0     ✔ tidyr     1.3.1\n✔ readr     2.1.5     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ mosaic::count()     masks dplyr::count()\n✖ purrr::cross()      masks mosaic::cross()\n✖ purrr::discard()    masks scales::discard()\n✖ mosaic::do()        masks dplyr::do()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ mosaic::stat()      masks ggplot2::stat()\n✖ mosaic::tally()     masks dplyr::tally()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tinytable)\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(visdat)\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(RColorBrewer)\nlibrary(naniar)\nlibrary(GGally)\nlibrary(ggplot2)\nlibrary(correlation)\n\n\nAttaching package: 'correlation'\n\nThe following object is masked from 'package:mosaic':\n\n    cor_test\n\nlibrary(dplyr)\nlibrary(RColorBrewer)\nlibrary(DT)\nlibrary(infer)\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(resampledata)\n\n\nAttaching package: 'resampledata'\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n\nlibrary(openintro)\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:GGally':\n\n    tips\n\nThe following object is masked from 'package:mosaic':\n\n    dotPlot\n\nThe following objects are masked from 'package:lattice':\n\n    ethanol, lsegments\n\nlibrary(vcd)\n\nLoading required package: grid\n\nAttaching package: 'vcd'\n\nThe following object is masked from 'package:mosaic':\n\n    mplot\n\nlibrary(visStatistics)"
  },
  {
    "objectID": "A3/Tattoo_Attraction/tat.html#r-packages-setup",
    "href": "A3/Tattoo_Attraction/tat.html#r-packages-setup",
    "title": "Do tattoos make people look attractive or not?",
    "section": "",
    "text": "library(ggformula)\n\nLoading required package: ggplot2\n\n\nLoading required package: scales\n\n\nLoading required package: ggridges\n\n\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(naniar)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:naniar':\n\n    n_complete\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.1.0     ✔ tidyr     1.3.1\n✔ readr     2.1.5     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ mosaic::count()     masks dplyr::count()\n✖ purrr::cross()      masks mosaic::cross()\n✖ purrr::discard()    masks scales::discard()\n✖ mosaic::do()        masks dplyr::do()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ mosaic::stat()      masks ggplot2::stat()\n✖ mosaic::tally()     masks dplyr::tally()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tinytable)\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(visdat)\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(RColorBrewer)\nlibrary(naniar)\nlibrary(GGally)\nlibrary(ggplot2)\nlibrary(correlation)\n\n\nAttaching package: 'correlation'\n\nThe following object is masked from 'package:mosaic':\n\n    cor_test\n\nlibrary(dplyr)\nlibrary(RColorBrewer)\nlibrary(DT)\nlibrary(infer)\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(resampledata)\n\n\nAttaching package: 'resampledata'\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n\nlibrary(openintro)\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:GGally':\n\n    tips\n\nThe following object is masked from 'package:mosaic':\n\n    dotPlot\n\nThe following objects are masked from 'package:lattice':\n\n    ethanol, lsegments\n\nlibrary(vcd)\n\nLoading required package: grid\n\nAttaching package: 'vcd'\n\nThe following object is masked from 'package:mosaic':\n\n    mplot\n\nlibrary(visStatistics)"
  },
  {
    "objectID": "A3/Tattoo_Attraction/tat.html#reading-the-file",
    "href": "A3/Tattoo_Attraction/tat.html#reading-the-file",
    "title": "Do tattoos make people look attractive or not?",
    "section": "Reading the file",
    "text": "Reading the file\n\ntat &lt;- read.csv(\"tattoo_attraction.csv\")\nglimpse(tat)\n\nRows: 40\nColumns: 3\n$ Name              &lt;chr&gt; \"Aadya\", \"Abhinav\", \"Aditya\", \"Akash\", \"Amit\", \"Amog…\n$ Gender            &lt;chr&gt; \"F\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"F\", \"M…\n$ Tattoo_Attractive &lt;chr&gt; \"Yes\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\"…"
  },
  {
    "objectID": "A3/Tattoo_Attraction/tat.html#munging-data",
    "href": "A3/Tattoo_Attraction/tat.html#munging-data",
    "title": "Do tattoos make people look attractive or not?",
    "section": "Munging Data",
    "text": "Munging Data\n\ntat_modified &lt;- tat %&gt;%\n  mutate(across(where(is.character), as.factor))%&gt;%\n  dplyr::relocate(where(is.factor), .after = Name)\nglimpse(tat_modified)\n\nRows: 40\nColumns: 3\n$ Name              &lt;fct&gt; Aadya, Abhinav, Aditya, Akash, Amit, Amogh, Anurag, …\n$ Gender            &lt;fct&gt; F, M, M, M, M, M, M, M, M, F, M, F, M, F, M, F, F, M…\n$ Tattoo_Attractive &lt;fct&gt; Yes, Yes, No, Yes, No, Yes, Yes, Yes, Yes, No, Yes, …"
  },
  {
    "objectID": "A3/Tattoo_Attraction/tat.html#examining-the-data",
    "href": "A3/Tattoo_Attraction/tat.html#examining-the-data",
    "title": "Do tattoos make people look attractive or not?",
    "section": "Examining the Data",
    "text": "Examining the Data\n\ntat_modified %&gt;%\n  group_by(Gender) %&gt;%\n  count()\n\n# A tibble: 2 × 2\n# Groups:   Gender [2]\n  Gender     n\n  &lt;fct&gt;  &lt;int&gt;\n1 F         20\n2 M         20\n\n\n\ntat_modified %&gt;%\n  group_by(Tattoo_Attractive) %&gt;%\n  count()\n\n# A tibble: 2 × 2\n# Groups:   Tattoo_Attractive [2]\n  Tattoo_Attractive     n\n  &lt;fct&gt;             &lt;int&gt;\n1 No                   10\n2 Yes                  30\n\n\n\ntat_modified %&gt;%\n  group_by(Gender) %&gt;%\n  count(Tattoo_Attractive)\n\n# A tibble: 4 × 3\n# Groups:   Gender [2]\n  Gender Tattoo_Attractive     n\n  &lt;fct&gt;  &lt;fct&gt;             &lt;int&gt;\n1 F      No                    5\n2 F      Yes                  15\n3 M      No                    5\n4 M      Yes                  15\n\n\n\ntat_modified %&gt;%\n  summarize(prop = prop(Tattoo_Attractive, success = \"Yes\"), n = n())\n\n  prop  n\n1 0.75 40"
  },
  {
    "objectID": "A3/Tattoo_Attraction/tat.html#visualising-the-data",
    "href": "A3/Tattoo_Attraction/tat.html#visualising-the-data",
    "title": "Do tattoos make people look attractive or not?",
    "section": "Visualising the Data",
    "text": "Visualising the Data\n\ntat_modified %&gt;%\n  gf_bar(~Tattoo_Attractive, fill = ~ Tattoo_Attractive) %&gt;%\n  gf_labs(\n    x = \"Attractive?\",\n    y = \"Count\",\n    title = \"Do tattoos make people look attractive or not?\",\n    subtitle = \"Proportion of yes & no\"\n  ) \n\n\n\n\n\n\n\n\n\ntat_modified %&gt;%\n  gf_bar(~Tattoo_Attractive | Gender, fill = ~ Tattoo_Attractive) %&gt;%\n  gf_labs(\n    x = \"Attractive?\",\n    y = \"Count\",\n    title = \"Do tattoos make people look attractive or not?\",\n    subtitle = \"Proportion of yes & no\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\ntat_modified %&gt;%\n  gf_bar(~Tattoo_Attractive, fill = ~ Gender, position = \"fill\") %&gt;%\n  gf_labs(\n    x = \"Attractive?\",\n    y = \"Count\",\n    title = \"Do tattoos make people look attractive or not?\",\n    subtitle = \"Proportion of yes & no\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set2\"))\n\n\n\n\n\n\n\n\n\ntat_modified %&gt;%\n  gf_bar(~Gender, fill = ~ Tattoo_Attractive, position = \"stack\") %&gt;%\n  gf_labs(\n    x = \"Gender\",\n    y = \"Count\",\n    title = \"Count of Belief in God, Stacked by Gender\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))"
  },
  {
    "objectID": "A3/Tattoo_Attraction/tat.html#prop-test-does-a-majority-of-the-population-find-tattoos-attractive",
    "href": "A3/Tattoo_Attraction/tat.html#prop-test-does-a-majority-of-the-population-find-tattoos-attractive",
    "title": "Do tattoos make people look attractive or not?",
    "section": "Prop Test: Does a majority of the population find tattoos attractive?",
    "text": "Prop Test: Does a majority of the population find tattoos attractive?\nH0: p=0.5 (Half of the students think tattoos are attractive & Half of the students think tattoos are not attractive)\nH1: p≠0.5\n\nmosaic::binom.test(~Tattoo_Attractive, data = tat_modified, success = \"Yes\") %&gt;% \n  broom::tidy()\n\n# A tibble: 1 × 7\n  estimate statistic p.value parameter conf.low conf.high alternative\n     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      \n1     0.75        30 0.00222        40    0.588     0.873 two.sided  \n\n\n\nInference:-\nSince the p value &lt;0.05, we reject the Null Hypothesis. Therefore, a high number of people find tattoos attractive (75%)"
  },
  {
    "objectID": "A3/Tattoo_Attraction/tat.html#chisq.test-is-there-a-difference-in-the-proportion-of-males-and-females-who-find-tattoos-attractive",
    "href": "A3/Tattoo_Attraction/tat.html#chisq.test-is-there-a-difference-in-the-proportion-of-males-and-females-who-find-tattoos-attractive",
    "title": "Do tattoos make people look attractive or not?",
    "section": "Chisq.test: Is there a difference in the proportion of males and females who find tattoos attractive?",
    "text": "Chisq.test: Is there a difference in the proportion of males and females who find tattoos attractive?\nH0: Proportion of males who find tattoos attractive is equal to the true proportion of females who find tattoos attractive.\nH1: There is a difference between the proportion of males & females who find tattoos attractive.\n\ncontingency_table &lt;- vcd::structable(Tattoo_Attractive~ Gender,\n  data = tat_modified\n)\ncontingency_table\n\n       Tattoo_Attractive No Yes\nGender                         \nF                         5  15\nM                         5  15\n\n\n\ngss_vcd_table &lt;- vcd::structable(Tattoo_Attractive ~ Gender, data = tat_modified)\ngss_vcd_table %&gt;%\n  vcd::mosaic(\n    gp = shading_hsv, direction = \"v\",\n    main = \"Gender vs Tattoo Attractiveness\",\n    legend = TRUE,\n    labeling = labeling_border(\n      varnames = c(\"F\", \"F\"), # Remove variable name labels\n      rot_labels = c(90, 0, 0, 0), # t,r,b,l?\n      just_labels = c(\n        \"left\", # Top Side. How?\n        \"left\", # Right side\n        \"left\", # Bottom side\n        \"right\"\n      )\n    )\n  ) \n\nWarning in legend(residuals, gpfun, residuals_type): All residuals are zero.\n\n\n\n\n\n\n\n\n\n\nInsight:\nWe see that from the plot above - all residuals are zero which confirms the null hypothesis that there isn’t a difference between both the groups.\n\nxq_test_object &lt;- chisq.test(contingency_table)\nxq_test_object\n\n\n    Pearson's Chi-squared test\n\ndata:  contingency_table\nX-squared = 0, df = 1, p-value = 1\n\n\n\nxq_test_object %&gt;%\n  broom::tidy() %&gt;%\n  select(statistic) %&gt;%\n  as.numeric() -&gt; X_squared_observed\nX_squared_observed\n\n[1] 0\n\n\n\n# Determine the Chi-Square critical value\nX_squared_critical &lt;- qchisq(\n  p = .05,\n  df = (2 - 1) * (2 - 1), # (nrows-1) * (ncols-1)\n  lower.tail = FALSE\n)\nX_squared_critical\n\n[1] 3.841459\n\n\n\nmosaic::xqchisq(\n  p = 0.95, df = 1,\n  return = c(\"plot\"), verbose = F,\n  system = \"gg\"\n) %&gt;%\n  gf_labs(\n    x = \"Chi-Square Value\", \n    title = \"Critical and Observed Chi-Square Values\"\n  ) %&gt;%\n  gf_vline(\n    xintercept = X_squared_observed,\n    color = \"red\", linewidth = 1\n  ) %&gt;%\n  gf_vline(\n    xintercept = X_squared_critical,\n    color = \"dodgerblue\", linewidth = 1\n  ) %&gt;%\n  gf_annotate(\n    x = X_squared_observed + 0.2, y = 0.05,\n    geom = \"label\", label = \"Observed\\nChi-Square\",\n    fill = \"red\", alpha = 0.3\n  ) %&gt;%\n  gf_annotate(\n    x = X_squared_critical - 0.5, y = 0.05,\n    geom = \"label\", label = \"Critical\\nChi-Square\",\n    fill = \"lightblue\"\n  )\n\n\n\n\n\n\n\n\n\n\nInference:-\nSince the observed value is less than the critical value and the p-value is greater than 0.05, we fail to reject the null hypothesis.\nThere is no significant difference between male and female respondents in how they perceive tattoos. Both genders gave almost identical responses which suggests that gender does not play a major role in determining whether tattoos are attractive or not."
  },
  {
    "objectID": "A3/Tattoo_Attraction/tat.html#conclusion",
    "href": "A3/Tattoo_Attraction/tat.html#conclusion",
    "title": "Do tattoos make people look attractive or not?",
    "section": "Conclusion",
    "text": "Conclusion\nTo sum up, most of the people found tattoos attractive (75%). The proportion test confirmed that it is statistically significant. A chi-square test was conducted to see if opinions differ from men to women. The test showed no significant difference as both males and females gave the same responses. Overall, we see that tattoos are found attractive and gender doesn’t play a role in how it’s perceived."
  },
  {
    "objectID": "A2/tastyR/cuisines.html",
    "href": "A2/tastyR/cuisines.html",
    "title": "Cuisines Dataset",
    "section": "",
    "text": "Exploring and Analysing patterns of an Allrecipes Cuisines Dataset\n\n\nData Dictionary\nA data frame with 2218 rows and 17 variables:\n\n\n\nVariable\nDescription\n\n\n\n\nname\nName of the recipe\n\n\ncountry\nThe country/region the cuisine is from\n\n\nurl\nLink to the recipe\n\n\nauthor\nAuthor of the recipe\n\n\ndate_published\nWhen the recipe was published/updated\n\n\ningredients\nThe ingredients of the recipe\n\n\ncalories\nCalories per serving\n\n\nfat\nFat per serving\n\n\ncarbs\nCarbs per serving\n\n\nprotein\nProteins per serving\n\n\navg_rating\nAverage rating out of 5 stars\n\n\ntotal_ratings\nNumber of ratings received\n\n\nreviews\nNumber of written reviews\n\n\nprep_time\nPreparation time in minutes\n\n\ncook_time\nCooking time in minutes\n\n\ntotal_time\nPrep + cook time in minutes\n\n\nservings\nNumber of servings\n\n\n\n\n\n\n\nlibrary(ggformula)\n\nLoading required package: ggplot2\n\n\nLoading required package: scales\n\n\nLoading required package: ggridges\n\n\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(naniar)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:naniar':\n\n    n_complete\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.1.0     ✔ tidyr     1.3.1\n✔ readr     2.1.5     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ mosaic::count()     masks dplyr::count()\n✖ purrr::cross()      masks mosaic::cross()\n✖ purrr::discard()    masks scales::discard()\n✖ mosaic::do()        masks dplyr::do()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ mosaic::stat()      masks ggplot2::stat()\n✖ mosaic::tally()     masks dplyr::tally()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tinytable)\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(visdat)\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(RColorBrewer)\nlibrary(naniar)\nlibrary(GGally)\nlibrary(ggplot2)\nlibrary(correlation)\n\n\nAttaching package: 'correlation'\n\nThe following object is masked from 'package:mosaic':\n\n    cor_test\n\nlibrary(dplyr)\nlibrary(RColorBrewer)\nlibrary(DT)\n\n\n\n\n\ndata(\"cuisines\", package = \"tastyR\")\nglimpse(cuisines)   \n\nRows: 2,218\nColumns: 17\n$ name           &lt;chr&gt; \"Saganaki (Flaming Greek Cheese)\", \"Coney Island Knishe…\n$ country        &lt;chr&gt; \"Greek\", \"Jewish\", \"Australian and New Zealander\", \"Chi…\n$ url            &lt;chr&gt; \"https://www.allrecipes.com/recipe/263750/flaming-greek…\n$ author         &lt;chr&gt; \"John Mitzewich\", \"John Mitzewich\", \"CHIPPENDALE\", \"Hei…\n$ date_published &lt;date&gt; 2024-02-07, 2024-11-26, 2022-07-14, 2025-01-31, 2025-0…\n$ ingredients    &lt;chr&gt; \"1 (4 ounce) package kasseri cheese, 1 tablespoon water…\n$ calories       &lt;dbl&gt; 391, 301, 64, 106, 449, 958, 378, 90, 157, 322, 4, NA, …\n$ fat            &lt;dbl&gt; 25, 17, 3, 9, 23, 24, 10, 5, 6, 16, 0, NA, 21, 2, 66, 8…\n$ carbs          &lt;dbl&gt; 15, 31, 9, 7, 58, 144, 59, 10, 25, 39, 1, NA, 16, 63, 7…\n$ protein        &lt;dbl&gt; 16, 7, 1, 1, 7, 46, 14, 1, 2, 7, 0, NA, 28, 6, 54, 17, …\n$ avg_rating     &lt;dbl&gt; 4.8, 4.6, 4.3, 5.0, 3.8, 4.4, 4.3, NA, 4.6, 5.0, 4.7, 4…\n$ total_ratings  &lt;dbl&gt; 25, 10, 126, 1, 13, 40, 3, NA, 65, 2, 182, 2, 19, 16, 9…\n$ reviews        &lt;dbl&gt; 22, 9, 104, 1, 11, 32, 3, NA, 55, 2, 138, 2, 15, 16, 84…\n$ prep_time      &lt;dbl&gt; 10, 30, 20, 10, 30, 30, 30, 40, 0, 5, 5, 5, 10, 10, 20,…\n$ cook_time      &lt;dbl&gt; 5, 75, 15, 0, 15, 165, 75, 30, 0, 5, 0, 25, 10, 50, 16,…\n$ total_time     &lt;dbl&gt; 15, 180, 180, 10, 45, 675, 585, 155, 0, 10, 5, 30, 50, …\n$ servings       &lt;dbl&gt; 2, 16, 12, 6, 15, 6, 6, 84, 24, 1, 21, 8, 4, 10, 4, 8, …\n\n\n\n\n\n\ncuisines_modified &lt;- cuisines %&gt;%\n  naniar::replace_with_na_all(data = ., condition = ~ .x %in% common_na_numbers) %&gt;%\n  naniar::replace_with_na_all(data = ., condition = ~ .x %in% common_na_strings)\nglimpse(cuisines_modified)\n\nRows: 2,218\nColumns: 17\n$ name           &lt;chr&gt; \"Saganaki (Flaming Greek Cheese)\", \"Coney Island Knishe…\n$ country        &lt;chr&gt; \"Greek\", \"Jewish\", \"Australian and New Zealander\", \"Chi…\n$ url            &lt;chr&gt; \"https://www.allrecipes.com/recipe/263750/flaming-greek…\n$ author         &lt;chr&gt; \"John Mitzewich\", \"John Mitzewich\", \"CHIPPENDALE\", \"Hei…\n$ date_published &lt;date&gt; 2024-02-07, 2024-11-26, 2022-07-14, 2025-01-31, 2025-0…\n$ ingredients    &lt;chr&gt; \"1 (4 ounce) package kasseri cheese, 1 tablespoon water…\n$ calories       &lt;dbl&gt; 391, 301, 64, 106, 449, 958, 378, 90, 157, 322, 4, NA, …\n$ fat            &lt;dbl&gt; 25, 17, 3, 9, 23, 24, 10, 5, 6, 16, 0, NA, 21, 2, NA, 8…\n$ carbs          &lt;dbl&gt; 15, 31, 9, 7, 58, 144, 59, 10, 25, 39, 1, NA, 16, 63, 7…\n$ protein        &lt;dbl&gt; 16, 7, 1, 1, 7, 46, 14, 1, 2, 7, 0, NA, 28, 6, 54, 17, …\n$ avg_rating     &lt;dbl&gt; 4.8, 4.6, 4.3, 5.0, 3.8, 4.4, 4.3, NA, 4.6, 5.0, 4.7, 4…\n$ total_ratings  &lt;dbl&gt; 25, 10, 126, 1, 13, 40, 3, NA, 65, 2, 182, 2, 19, 16, 9…\n$ reviews        &lt;dbl&gt; 22, 9, 104, 1, 11, 32, 3, NA, 55, 2, 138, 2, 15, 16, 84…\n$ prep_time      &lt;dbl&gt; 10, 30, 20, 10, 30, 30, 30, 40, 0, 5, 5, 5, 10, 10, 20,…\n$ cook_time      &lt;dbl&gt; 5, 75, 15, 0, 15, 165, 75, 30, 0, 5, 0, 25, 10, 50, 16,…\n$ total_time     &lt;dbl&gt; 15, 180, 180, 10, 45, 675, 585, 155, 0, 10, 5, 30, 50, …\n$ servings       &lt;dbl&gt; 2, 16, 12, 6, 15, 6, 6, 84, 24, 1, 21, 8, 4, 10, 4, 8, …\n\n\n\n\n\n\nvisdat::vis_miss(cuisines_modified)\n\n\n\n\n\n\n\nvisdat::vis_dat(cuisines_modified)\n\n\n\n\n\n\n\n\n\n\n\n\ncuisines_modified_new &lt;- cuisines_modified %&gt;% drop_na()\nglimpse(cuisines_modified_new)\n\nRows: 1,989\nColumns: 17\n$ name           &lt;chr&gt; \"Saganaki (Flaming Greek Cheese)\", \"Coney Island Knishe…\n$ country        &lt;chr&gt; \"Greek\", \"Jewish\", \"Australian and New Zealander\", \"Chi…\n$ url            &lt;chr&gt; \"https://www.allrecipes.com/recipe/263750/flaming-greek…\n$ author         &lt;chr&gt; \"John Mitzewich\", \"John Mitzewich\", \"CHIPPENDALE\", \"Hei…\n$ date_published &lt;date&gt; 2024-02-07, 2024-11-26, 2022-07-14, 2025-01-31, 2025-0…\n$ ingredients    &lt;chr&gt; \"1 (4 ounce) package kasseri cheese, 1 tablespoon water…\n$ calories       &lt;dbl&gt; 391, 301, 64, 106, 449, 958, 378, 157, 322, 4, 389, 253…\n$ fat            &lt;dbl&gt; 25, 17, 3, 9, 23, 24, 10, 6, 16, 0, 21, 2, 8, 31, 19, 7…\n$ carbs          &lt;dbl&gt; 15, 31, 9, 7, 58, 144, 59, 25, 39, 1, 16, 63, 53, 43, 4…\n$ protein        &lt;dbl&gt; 16, 7, 1, 1, 7, 46, 14, 2, 7, 0, 28, 6, 17, 25, 7, 29, …\n$ avg_rating     &lt;dbl&gt; 4.8, 4.6, 4.3, 5.0, 3.8, 4.4, 4.3, 4.6, 5.0, 4.7, 4.4, …\n$ total_ratings  &lt;dbl&gt; 25, 10, 126, 1, 13, 40, 3, 65, 2, 182, 19, 16, 20, 43, …\n$ reviews        &lt;dbl&gt; 22, 9, 104, 1, 11, 32, 3, 55, 2, 138, 15, 16, 15, 39, 2…\n$ prep_time      &lt;dbl&gt; 10, 30, 20, 10, 30, 30, 30, 0, 5, 5, 10, 10, 15, 60, 10…\n$ cook_time      &lt;dbl&gt; 5, 75, 15, 0, 15, 165, 75, 0, 5, 0, 10, 50, 15, 10, 45,…\n$ total_time     &lt;dbl&gt; 15, 180, 180, 10, 45, 675, 585, 0, 10, 5, 50, 300, 60, …\n$ servings       &lt;dbl&gt; 2, 16, 12, 6, 15, 6, 6, 24, 1, 21, 4, 10, 8, 6, 10, 6, …\n\n\n\n\n\n\nsummary(cuisines_modified_new)\n\n     name             country              url               author         \n Length:1989        Length:1989        Length:1989        Length:1989       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n date_published       ingredients           calories           fat        \n Min.   :2009-02-09   Length:1989        Min.   :   3.0   Min.   :  0.00  \n 1st Qu.:2022-11-08   Class :character   1st Qu.: 194.0   1st Qu.:  7.00  \n Median :2024-07-15   Mode  :character   Median : 318.0   Median : 15.00  \n Mean   :2023-11-08                      Mean   : 355.4   Mean   : 18.38  \n 3rd Qu.:2024-12-19                      3rd Qu.: 475.0   3rd Qu.: 25.00  \n Max.   :2025-07-29                      Max.   :2010.0   Max.   :151.00  \n     carbs           protein         avg_rating   total_ratings   \n Min.   :  1.00   Min.   :  0.00   Min.   :1.00   Min.   :  1.00  \n 1st Qu.: 13.00   1st Qu.:  4.00   1st Qu.:4.30   1st Qu.:  6.00  \n Median : 26.00   Median : 12.00   Median :4.60   Median : 24.00  \n Mean   : 31.62   Mean   : 16.49   Mean   :4.51   Mean   : 87.23  \n 3rd Qu.: 45.00   3rd Qu.: 25.00   3rd Qu.:4.80   3rd Qu.: 90.00  \n Max.   :264.00   Max.   :135.00   Max.   :5.00   Max.   :997.00  \n    reviews         prep_time         cook_time        total_time   \n Min.   :  1.00   Min.   :   0.00   Min.   :  0.00   Min.   :    0  \n 1st Qu.:  6.00   1st Qu.:  10.00   1st Qu.: 10.00   1st Qu.:   35  \n Median : 21.00   Median :  15.00   Median : 25.00   Median :   60  \n Mean   : 78.73   Mean   :  21.18   Mean   : 42.96   Mean   :  176  \n 3rd Qu.: 76.00   3rd Qu.:  25.00   3rd Qu.: 45.00   3rd Qu.:  120  \n Max.   :975.00   Max.   :1800.00   Max.   :600.00   Max.   :14440  \n    servings     \n Min.   :  1.00  \n 1st Qu.:  4.00  \n Median :  8.00  \n Mean   : 10.29  \n 3rd Qu.: 12.00  \n Max.   :200.00  \n\n\n\ndim(cuisines_modified_new)\n\n[1] 1989   17\n\n\n\nskim(cuisines_modified_new)\n\n\nData summary\n\n\nName\ncuisines_modified_new\n\n\nNumber of rows\n1989\n\n\nNumber of columns\n17\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nDate\n1\n\n\nnumeric\n11\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1\n4\n87\n0\n1987\n0\n\n\ncountry\n0\n1\n4\n28\n0\n49\n0\n\n\nurl\n0\n1\n45\n110\n0\n1989\n0\n\n\nauthor\n0\n1\n1\n35\n0\n1507\n0\n\n\ningredients\n0\n1\n29\n1081\n0\n1989\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate_published\n0\n1\n2009-02-09\n2025-07-29\n2024-07-15\n696\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncalories\n0\n1\n355.36\n224.49\n3\n194.0\n318.0\n475.0\n2010\n▇▅▁▁▁\n\n\nfat\n0\n1\n18.38\n15.65\n0\n7.0\n15.0\n25.0\n151\n▇▂▁▁▁\n\n\ncarbs\n0\n1\n31.62\n25.55\n1\n13.0\n26.0\n45.0\n264\n▇▂▁▁▁\n\n\nprotein\n0\n1\n16.49\n15.61\n0\n4.0\n12.0\n25.0\n135\n▇▂▁▁▁\n\n\navg_rating\n0\n1\n4.51\n0.39\n1\n4.3\n4.6\n4.8\n5\n▁▁▁▂▇\n\n\ntotal_ratings\n0\n1\n87.23\n150.36\n1\n6.0\n24.0\n90.0\n997\n▇▁▁▁▁\n\n\nreviews\n0\n1\n78.73\n144.62\n1\n6.0\n21.0\n76.0\n975\n▇▁▁▁▁\n\n\nprep_time\n0\n1\n21.18\n54.60\n0\n10.0\n15.0\n25.0\n1800\n▇▁▁▁▁\n\n\ncook_time\n0\n1\n42.96\n64.70\n0\n10.0\n25.0\n45.0\n600\n▇▁▁▁▁\n\n\ntotal_time\n0\n1\n175.99\n673.15\n0\n35.0\n60.0\n120.0\n14440\n▇▁▁▁▁\n\n\nservings\n0\n1\n10.29\n12.42\n1\n4.0\n8.0\n12.0\n200\n▇▁▁▁▁\n\n\n\n\n\n\nnames(cuisines_modified_new)\n\n [1] \"name\"           \"country\"        \"url\"            \"author\"        \n [5] \"date_published\" \"ingredients\"    \"calories\"       \"fat\"           \n [9] \"carbs\"          \"protein\"        \"avg_rating\"     \"total_ratings\" \n[13] \"reviews\"        \"prep_time\"      \"cook_time\"      \"total_time\"    \n[17] \"servings\"      \n\n\n\nglimpse(cuisines_modified_new)\n\nRows: 1,989\nColumns: 17\n$ name           &lt;chr&gt; \"Saganaki (Flaming Greek Cheese)\", \"Coney Island Knishe…\n$ country        &lt;chr&gt; \"Greek\", \"Jewish\", \"Australian and New Zealander\", \"Chi…\n$ url            &lt;chr&gt; \"https://www.allrecipes.com/recipe/263750/flaming-greek…\n$ author         &lt;chr&gt; \"John Mitzewich\", \"John Mitzewich\", \"CHIPPENDALE\", \"Hei…\n$ date_published &lt;date&gt; 2024-02-07, 2024-11-26, 2022-07-14, 2025-01-31, 2025-0…\n$ ingredients    &lt;chr&gt; \"1 (4 ounce) package kasseri cheese, 1 tablespoon water…\n$ calories       &lt;dbl&gt; 391, 301, 64, 106, 449, 958, 378, 157, 322, 4, 389, 253…\n$ fat            &lt;dbl&gt; 25, 17, 3, 9, 23, 24, 10, 6, 16, 0, 21, 2, 8, 31, 19, 7…\n$ carbs          &lt;dbl&gt; 15, 31, 9, 7, 58, 144, 59, 25, 39, 1, 16, 63, 53, 43, 4…\n$ protein        &lt;dbl&gt; 16, 7, 1, 1, 7, 46, 14, 2, 7, 0, 28, 6, 17, 25, 7, 29, …\n$ avg_rating     &lt;dbl&gt; 4.8, 4.6, 4.3, 5.0, 3.8, 4.4, 4.3, 4.6, 5.0, 4.7, 4.4, …\n$ total_ratings  &lt;dbl&gt; 25, 10, 126, 1, 13, 40, 3, 65, 2, 182, 19, 16, 20, 43, …\n$ reviews        &lt;dbl&gt; 22, 9, 104, 1, 11, 32, 3, 55, 2, 138, 15, 16, 15, 39, 2…\n$ prep_time      &lt;dbl&gt; 10, 30, 20, 10, 30, 30, 30, 0, 5, 5, 10, 10, 15, 60, 10…\n$ cook_time      &lt;dbl&gt; 5, 75, 15, 0, 15, 165, 75, 0, 5, 0, 10, 50, 15, 10, 45,…\n$ total_time     &lt;dbl&gt; 15, 180, 180, 10, 45, 675, 585, 0, 10, 5, 50, 300, 60, …\n$ servings       &lt;dbl&gt; 2, 16, 12, 6, 15, 6, 6, 24, 1, 21, 4, 10, 8, 6, 10, 6, …\n\n\n\n\n\n\ncuisines_factor &lt;- cuisines_modified_new %&gt;%\n  mutate(across(where(is.character), as.factor))%&gt;%\n  dplyr::relocate(where(is.factor), .before = name)\nglimpse(cuisines_factor)\n\nRows: 1,989\nColumns: 17\n$ name           &lt;fct&gt; \"Saganaki (Flaming Greek Cheese)\", \"Coney Island Knishe…\n$ country        &lt;fct&gt; Greek, Jewish, Australian and New Zealander, Chilean, T…\n$ url            &lt;fct&gt; https://www.allrecipes.com/recipe/263750/flaming-greek-…\n$ author         &lt;fct&gt; \"John Mitzewich\", \"John Mitzewich\", \"CHIPPENDALE\", \"Hei…\n$ ingredients    &lt;fct&gt; \"1 (4 ounce) package kasseri cheese, 1 tablespoon water…\n$ date_published &lt;date&gt; 2024-02-07, 2024-11-26, 2022-07-14, 2025-01-31, 2025-0…\n$ calories       &lt;dbl&gt; 391, 301, 64, 106, 449, 958, 378, 157, 322, 4, 389, 253…\n$ fat            &lt;dbl&gt; 25, 17, 3, 9, 23, 24, 10, 6, 16, 0, 21, 2, 8, 31, 19, 7…\n$ carbs          &lt;dbl&gt; 15, 31, 9, 7, 58, 144, 59, 25, 39, 1, 16, 63, 53, 43, 4…\n$ protein        &lt;dbl&gt; 16, 7, 1, 1, 7, 46, 14, 2, 7, 0, 28, 6, 17, 25, 7, 29, …\n$ avg_rating     &lt;dbl&gt; 4.8, 4.6, 4.3, 5.0, 3.8, 4.4, 4.3, 4.6, 5.0, 4.7, 4.4, …\n$ total_ratings  &lt;dbl&gt; 25, 10, 126, 1, 13, 40, 3, 65, 2, 182, 19, 16, 20, 43, …\n$ reviews        &lt;dbl&gt; 22, 9, 104, 1, 11, 32, 3, 55, 2, 138, 15, 16, 15, 39, 2…\n$ prep_time      &lt;dbl&gt; 10, 30, 20, 10, 30, 30, 30, 0, 5, 5, 10, 10, 15, 60, 10…\n$ cook_time      &lt;dbl&gt; 5, 75, 15, 0, 15, 165, 75, 0, 5, 0, 10, 50, 15, 10, 45,…\n$ total_time     &lt;dbl&gt; 15, 180, 180, 10, 45, 675, 585, 0, 10, 5, 50, 300, 60, …\n$ servings       &lt;dbl&gt; 2, 16, 12, 6, 15, 6, 6, 24, 1, 21, 4, 10, 8, 6, 10, 6, …\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    count = n()\n  ) %&gt;%\n  arrange(desc(count)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_calories = mean(calories, na.rm = TRUE),\n  ) %&gt;%\n  arrange(desc(avg_calories)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_fat = mean(fat, na.rm = TRUE),\n  ) %&gt;%\n  arrange(desc(avg_fat)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_carbs = mean(carbs, na.rm = TRUE),\n  ) %&gt;%\n  arrange(desc(avg_carbs)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_protien = mean(protein, na.rm = TRUE),\n  ) %&gt;%\n  arrange(desc(avg_protien)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country, name) %&gt;%\n  summarise(\n    avg_calories = mean(calories, na.rm = TRUE),\n    average_fat = mean(fat, na.rm = TRUE),\n    avg_carbs = mean(carbs, na.rm = TRUE),\n    avg_protein = mean(protein, na.rm = TRUE)\n  ) %&gt;%\n  arrange(desc(avg_calories)) %&gt;% \n  datatable(cuisines_factor)\n\n`summarise()` has grouped output by 'country'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country, name) %&gt;%\n  summarise(\n    avg_calories = mean(calories, na.rm = TRUE),\n    avg_rating = mean(avg_rating, narm = TRUE)\n  ) %&gt;%\n  arrange(desc(avg_calories)) %&gt;% \n  datatable(cuisines_factor)\n\n`summarise()` has grouped output by 'country'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country, name) %&gt;%\n  summarise(\n    avg_calories = mean(calories, na.rm = TRUE),\n    avg_fat = mean(fat, na.rm = TRUE),\n    avg_carbs = mean(carbs, na.rm = TRUE),\n    avg_protein = mean(protein, na.rm = TRUE)\n  ) %&gt;%\n  arrange(desc(avg_fat)) %&gt;% \n  datatable(cuisines_factor)\n\n`summarise()` has grouped output by 'country'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country, name) %&gt;%\n  summarise(\n    avg_calories = mean(calories, na.rm = TRUE),\n    avg_fat = mean(fat, na.rm = TRUE),\n    avg_carbs = mean(carbs, na.rm = TRUE),\n    avg_protein = mean(protein, na.rm = TRUE)\n  ) %&gt;%\n  arrange(desc(avg_carbs)) %&gt;% \n  datatable(cuisines_factor)\n\n`summarise()` has grouped output by 'country'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country, name) %&gt;%\n  summarise(\n    avg_calories = mean(calories, na.rm = TRUE),\n    avg_fat = mean(fat, na.rm = TRUE),\n    avg_carbs = mean(carbs, na.rm = TRUE),\n    avg_protein = mean(protein, na.rm = TRUE)\n  ) %&gt;%\n  arrange(desc(avg_protein)) %&gt;% \n  datatable(cuisines_factor)\n\n`summarise()` has grouped output by 'country'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_prep_time = mean(prep_time, na.rm = TRUE),\n    avg_cook_time = mean(cook_time, na.rm = TRUE),\n    avg_total_time = mean(total_time, na.rm = TRUE),\n    avg_rating = mean(avg_rating, na.rm = TRUE),\n    avg_total_ratings = mean(total_ratings, na.rm = TRUE),\n    avg_reviews = mean(reviews, na.rm = TRUE),\n    avg_servings = mean(servings, na.rm = TRUE),\n  ) %&gt;%\n  arrange(desc(avg_total_time)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_prep_time = mean(prep_time, na.rm = TRUE),\n    avg_cook_time = mean(cook_time, na.rm = TRUE),\n    avg_total_time = mean(total_time, na.rm = TRUE),\n    avg_rating = mean(avg_rating, na.rm = TRUE),\n    avg_total_ratings = mean(total_ratings, na.rm = TRUE),\n    avg_reviews = mean(reviews, na.rm = TRUE),\n    avg_servings = mean(servings, na.rm = TRUE),\n  ) %&gt;%\n  arrange(desc(avg_total_ratings)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(name, country) %&gt;%\n  summarise(\n    max_prep_time = mean(prep_time, na.rm = TRUE),\n    max_cook_time = mean(cook_time, na.rm = TRUE),\n    max_total_time = mean(total_time, na.rm = TRUE),\n    max_servings = mean(servings, na.rm = TRUE)\n  ) %&gt;%\n  arrange(desc(max_total_time)) %&gt;% \n  datatable(cuisines_factor)\n\n`summarise()` has grouped output by 'name'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\nHere we see that for certain dishes, the prep time, cook time & total time is 0 - which is inaccurate.\nThe prep_time + cook_time doesn’t add up to the total_time as mentioned in the data dictionary.\n\n\n\n\ncuisines_clean &lt;- cuisines_factor %&gt;%\n  filter(prep_time &gt; 0, cook_time &gt; 0, total_time &gt; 0)\ncuisines_clean %&gt;% arrange(desc(total_time)) %&gt;% select(name, country, prep_time,cook_time, total_time) %&gt;% \n  datatable(cuisines_clean)\n\n\n\n\n\n\ncuisine_correct_time &lt;- cuisines_clean %&gt;%\n  mutate(sum_time = prep_time + cook_time)\ncuisine_correct_time %&gt;% \n  select(name, country, prep_time,cook_time, total_time, sum_time) %&gt;% \n  datatable(cuisine_correct_time)\n\n\n\n\n\n\ncuisine_correct_time %&gt;% filter(total_time!=sum_time) %&gt;% \n  select(name, country, prep_time,cook_time, total_time, sum_time) %&gt;% \n  datatable(cuisine_correct_time)\n\n\n\n\n\nFrom the data dictionary, cook_time does not account for fermentation, marination, waiting periods which is done in dishes like breads, chicken etc.\n\nprep_time = before heat (chopping, mixing)\ncook_time = with heat (boil, bake, fry etc)\ntotal_time = prep + cook (but not fermentation/marination)\n\nWe also observed that the total_time values do not match the sum of prep_time and cook_time, even when excluding processes like fermentation or marination. This shows inconsistencies in the dataset due to missing or incorrectly recorded values from the original sources.\n\ncuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(avg_rating = mean(avg_rating, na.rm = TRUE),\n            total_reviews = sum(reviews, na.rm = TRUE)) %&gt;% arrange(desc(avg_rating)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(name) %&gt;%\n  summarise(max_rating = max(avg_rating, na.rm = TRUE),\n            total_reviews = sum(reviews, na.rm = TRUE)) %&gt;% arrange(desc(max_rating)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(name,servings) %&gt;%\n  summarise(prep_time_avg = mean(prep_time)) %&gt;% arrange(desc(servings)) %&gt;% \n  datatable(cuisines_factor)\n\n`summarise()` has grouped output by 'name'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\ncuisines_continent &lt;- cuisines_factor %&gt;%\n  mutate(\n    continent = case_when(\n      country %in% c(\"Tex-Mex\", \"Amish and Mennonite\", \"Southern Recipes\", \n                     \"Cajun and Creole\", \"Canadian\", \"Soul Food\") ~ \"North America\",\n      \n      country %in% c(\"Greek\", \"Polish\", \"Danish\", \"Belgian\", \"Spanish\", \"Portuguese\", \n                     \"Norwegian\", \"Austrian\", \"Swiss\", \"Russian\", \"Dutch\", \"German\", \n                     \"Swedish\", \"Finnish\", \"French\", \"Italian\", \"Scandinavian\") ~ \"Europe\",\n      \n      country %in% c(\"Peruvian\", \"Argentinian\", \"Colombian\", \n                     \"Brazilian\", \"Chilean\") ~ \"South America\",\n      \n      country %in% c(\"Vietnamese\", \"Japanese\", \"Israeli\", \"Thai\", \"Chinese\", \"Turkish\", \n                     \"Korean\", \"Lebanese\", \"Jewish\", \"Malaysian\", \"Bangladeshi\", \n                     \"Persian\", \"Indonesian\", \"Indian\", \"Pakistani\", \"Filipino\") ~ \"Asia\",\n      \n      country %in% c(\"Australian and New Zealander\") ~ \"Oceania\",\n      \n      country %in% c(\"Puerto Rican\", \"Jamaican\", \"South African\", \"Cuban\") ~ \"Caribbean/Africa\",\n      \n      TRUE ~ \"Other\"\n    )\n  )\n\ncuisines_continent %&gt;% \n  select(name, country, continent) %&gt;% \n  datatable(cuisines_continent) \n\n\n\n\n\n\n\n\n\n\n\n\ntop_dishes &lt;- cuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(count = n()) %&gt;%\n  slice_max(n = 15, order_by = count) %&gt;%    \n  arrange(desc(count))\ntop_dishes %&gt;% \n  gf_col(count~reorder(country,count), fill = \"orchid4\") %&gt;%\n  gf_labs(x = \"Country\", y = \"Number of Dishes\", title = \"Top 10 Countries by Recipe Count\") %&gt;% \n  gf_theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nRussian, Fillipino, Chinese and Canadian (63 recipes each) are the highest number of recipes present on the website.\n\n\n\n\n\ntop_continents &lt;- cuisines_continent %&gt;%\n  group_by(continent) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(desc(count))\n\ntop_continents %&gt;% \n  gf_col(count ~ reorder(continent, count), fill = \"blue4\") %&gt;%\n  gf_labs(\n    x = \"Continent\",\n    y = \"Number of Dishes\",\n    title = \"Number of Dishes by Continent\"\n  ) %&gt;%\n  gf_theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nAsian Recipes are found maximum on the Allrepices website where as Oceania recipes are least found on the website.\n\n\n\n\n\ntop_10_countries_calorie &lt;- cuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_calories = mean(calories, na.rm = TRUE),\n  ) %&gt;%\n  slice_max(n=10, order_by = avg_calories) %&gt;% \n  slice_head(n = 10)\ntop_10_countries_calorie %&gt;%\n  gf_col(reorder(country, avg_calories)~avg_calories, fill = \"steelblue\") %&gt;%\n  gf_labs(\n    title = \"Top 10 Countries by Average Calories\",\n    x = \"Average Calories\",\n    y = \"Country\"\n  )\n\n\n\n\n\n\n\n\n\ntop_10_continent_calorie &lt;- cuisines_continent %&gt;%\n  group_by(continent) %&gt;%\n  summarise(\n    avg_calories = mean(calories, na.rm = TRUE),\n  ) %&gt;%\n  slice_max(n=10, order_by = avg_calories) %&gt;% \n  slice_head(n = 10)\ntop_10_continent_calorie %&gt;%\n  gf_col(reorder(continent, avg_calories)~avg_calories, fill = \"steelblue2\") %&gt;%\n  gf_labs(\n    title = \"Top 10 Continents by Average Calories\",\n    x = \"Average Calories\",\n    y = \"Continent\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\ntop_10_countries_protein &lt;- cuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_protein = mean(protein, na.rm = TRUE),\n  ) %&gt;%\n  slice_max(n=10, order_by = avg_protein)\ntop_10_countries_protein %&gt;%\n  gf_col(reorder(country, avg_protein)~avg_protein, fill = \"darkorchid3\") %&gt;%\n  gf_labs(\n    title = \"Top Countries by Average protein\",\n    x = \"Average Protein\",\n    y = \"Country\"\n  )\n\n\n\n\n\n\n\n\n\ntop_10_continent_protein &lt;- cuisines_continent %&gt;%\n  group_by(continent) %&gt;%\n  summarise(\n    avg_protein = mean(protein, na.rm = TRUE),\n  ) %&gt;%\n  slice_max(n=10, order_by = avg_protein)\ntop_10_continent_protein %&gt;%\n  gf_col(reorder(continent, avg_protein)~avg_protein, fill = \"darkorchid4\") %&gt;%\n  gf_labs(\n    title = \"Top Continent by Average protein\",\n    x = \"Average Protein\",\n    y = \"Country\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\ntop_15_countries_carbs &lt;- cuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_carbs = mean(carbs, na.rm = TRUE),\n  ) %&gt;%\n   slice_max(n=20, order_by = avg_carbs)\ntop_15_countries_carbs %&gt;%\n  gf_col(reorder(country, avg_carbs)~avg_carbs, fill = \"rosybrown\") %&gt;%\n  gf_labs(\n    title = \"Top 20 Countries by Average Carbs\",\n    x = \"Average Carbs\",\n    y = \"Country\"\n  )\n\n\n\n\n\n\n\n\n\ntop_15_continent_carbs &lt;- cuisines_continent %&gt;%\n  group_by(continent) %&gt;%\n  summarise(\n    avg_carbs = mean(carbs, na.rm = TRUE),\n  ) %&gt;%\n   slice_max(n=20, order_by = avg_carbs)\ntop_15_continent_carbs %&gt;%\n  gf_col(reorder(continent, avg_carbs)~avg_carbs, fill = \"rosybrown4\") %&gt;%\n  gf_labs(\n    title = \"Top 20 Continent by Average Carbs\",\n    x = \"Average Carbs\",\n    y = \"Continent\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\ntop_5_countries_fat &lt;- cuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_fat = mean(fat, na.rm = TRUE),\n  ) %&gt;%\n   slice_max(n=10, order_by = avg_fat)\ntop_5_countries_fat %&gt;% \n  gf_col(reorder(country, avg_fat)~avg_fat, fill = \"royalblue3\") %&gt;%\n  gf_labs(\n    title = \"Top Countries by Average Fat\",\n    x = \"Average Fat\",\n    y = \"Country\"\n  )\n\n\n\n\n\n\n\n\n\ntop_5_continent_fat &lt;- cuisines_continent %&gt;%\n  group_by(continent) %&gt;%\n  summarise(\n    avg_fat = mean(fat, na.rm = TRUE),\n  ) %&gt;%\n   slice_max(n=10, order_by = avg_fat)\ntop_5_continent_fat %&gt;% \n  gf_col(reorder(continent, avg_fat)~avg_fat, fill = \"royalblue4\") %&gt;%\n  gf_labs(\n    title = \"Top Continents by Average Fat\",\n    x = \"Average Fat\",\n    y = \"Continent\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nAfter viewing the carbs, protein, fat content by countries- it is seen that Italian food have higher average nutrient content than other countries.\n\n\n\ncuisines_factor %&gt;%\n  mutate(is_italian = ifelse(country == \"Italian\",\"Italian\", \"Other\")) %&gt;%\n  gf_boxplot(calories ~ is_italian, fill = c(\"paleturquoise3\", \"paleturquoise4\"), orientation = \"x\") %&gt;%\n  gf_labs(\n    title = \"Calories: Italian vs. Other Cuisines\",\n    x = \"Cuisine Category\",\n    y = \"Calories\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  mutate(is_italian = ifelse(country == \"Italian\",\"Italian\", \"Other\")) %&gt;%\n  gf_boxplot(protein ~ is_italian, fill = c(\"palegreen3\", \"palegreen4\"), orientation = \"x\") %&gt;%\n  gf_labs(\n    title = \"Protein: Italian vs. Other Cuisines\",\n    x = \"Cuisine Category\",\n    y = \"Protein\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  mutate(is_italian = ifelse(country == \"Italian\",\"Italian\", \"Other\")) %&gt;%\n  gf_boxplot(fat ~ is_italian, fill = c(\"royalblue\", \"royalblue4\"), orientation = \"x\") %&gt;%\n  gf_labs(\n    title = \"Fat Content: Italian vs. Other Cuisines\",\n    x = \"Cuisine Category\",\n    y = \"Fat\"\n  )\n\n\n\n\n\n\n\n\nWe seen there’s an higher median for Italian food nutrients - does having higher calories, fat and protein make it unhealthy?\nItalian cooking is deeply rooted in the Mediterranean diet, which is widely recognized by nutritionists and health experts for its numerous benefits. A common misconception is having high number of calories, protein and fats - makes food unhealthy. However, not all high-calorie or high-fat foods are unhealthy. Italian diet uses whole grains, fruits, vegetables, legumes and olive oil as the primary sources of fat. Therefore, many traditional Italian dishes naturally incorporate these healthy elements.\n\nOlive Oil: Rich in monounsaturated fats, known for their heart-healthy properties. Tomatoes: Packed with antioxidants like lycopene.\nGarlic and Onions: Offer various health benefits and add flavor without excessive calories.\n\n\n\n\n\n\nGGally::ggpairs(\n  cuisines_factor %&gt;% drop_na(),\n  columns = c(\n    \"fat\", \"calories\", \"protein\", \"servings\"\n  ),\n  switch = \"both\",\n  progress = FALSE,\n\n  diag = list(continuous = \"barDiag\"),\n  lower = list(continuous = wrap(\"smooth\", alpha = 0.3, se = FALSE)),\n\n  title = \"Cuisine Data Correlations Plot\"\n)\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\nFat & Protein have a high +ve correlation.\nCalories & Fat have a high +ve correlation which shows that fat is a major contributor to calories.\nCalories & Protein have a high +ve correlation which shows that protein is a major contributor to calories.\nNumber of servings, calories, fat and protein have a very low correlation.\n\n\nGGally::ggpairs(\n  cuisine_correct_time %&gt;% drop_na(),\n  columns = c(\n    \"servings\", \"sum_time\", \"cook_time\", \"prep_time\", \"total_ratings\",\"reviews\",\"avg_rating\"\n  ),\n  switch = \"both\",\n  progress = FALSE,\n\n  diag = list(continuous = \"barDiag\"),\n  lower = list(continuous = wrap(\"smooth\", alpha = 0.3, se = FALSE)),\n\n  title = \"Cuisine Data Correlations Plot\"\n)\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\nFrom the above plot, it is seen that Reviews and Total Rating have a high +ve correlation.Which means the number of Reviews is an important factor for a recipe to get a high rating.\n\n\n\n\ncuisine_correct_time %&gt;%\n  gf_point(sum_time ~ servings, alpha = 0.5, color = \"darkblue\") %&gt;%\n  gf_labs(\n    title = \"Total Time vs. Number of Servings\",\n    x = \"Servings\",\n    y = \"Total Time\"\n  ) %&gt;%\n  gf_lm(color=\"black\")\n\n\n\n\n\n\n\n\n\nThe trend is not that significant - not a strong correlation between the 2 variables.\n\n\n\n\n\ncuisines_factor %&gt;%\n  gf_point(reviews~total_ratings, alpha = 0.5, color = \"darkviolet\") %&gt;%\n  gf_labs(\n    title = \"Scatter Plot of Total Ratings vs. Reviews\",\n    x = \"Total Reviews\",\n    y = \"Total Ratings\"\n  ) %&gt;%\n  gf_lm(color = \"black\")\n\n\n\n\n\n\n\n\nThe scatterplot shows a high +ve relation - which proves the hypothesis that total reviews and total ratings are +vely correlated.\n\n\n\n\ncuisines_factor %&gt;% \n  gf_point(total_ratings~calories, alpha = 0.5, color = \"seagreen\") %&gt;% \n  gf_lm(color = \"black\") %&gt;% \n  gf_labs(title =\"Calories vs Total Ratings\",\n          x = \"Calories\",\n          y =\"Total Ratings\")\n\n\n\n\n\n\n\n\nThe scatterplot shows that Calories and Total Ratings have no correlation - which disproves the hypothesis.\n\n\n\n\ncuisine_correct_time %&gt;% \n  gf_point(sum_time~total_ratings, alpha = 0.5, color = \"royalblue\") %&gt;% \n  gf_labs(title=\"Time vs Reviews\",\n          x = \"Total Time\",\n          y = \"Total Ratings\") %&gt;% \n  gf_lm(color = \"black\")\n\n\n\n\n\n\n\n\nHere it is seen that, the r value is -0.02 which is a very low relation. Therefore, having a longer or shorter preparation time is not a strong determining factor in how many people review a recipe.\n\ncuisines_factor %&gt;%\n  gf_point(calories ~ servings, alpha = 0.5, color = \"darkred\") %&gt;%\n  gf_labs(\n    title = \"Calories vs. Servings\",\n    x = \"Servings\",\n    y = \"Calories\"\n  ) %&gt;%\n  gf_lm(color = \"black\")\n\n\n\n\n\n\n\n\n\nmosaic::cor_test(calories ~ servings, data = cuisines_factor) %&gt;%\n  broom::tidy() %&gt;%\n  knitr::kable(\n    digits = 2,\n    caption = \"Total Time vs Total Ratings\"\n  )\n\n\nTotal Time vs Total Ratings\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n-0.32\n-15.31\n0\n1987\n-0.36\n-0.28\nPearson’s product-moment correlation\ntwo.sided\n\n\n\n\n\n\nThe correlation between Calories and Servings is present but is weak (r= -0.32)\n\n\n\n\n\n\ntop_5_countries_time&lt;- cuisine_correct_time %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_tt= mean(sum_time, na.rm = TRUE),\n  )\ntop_5_countries_time %&gt;% arrange(desc(avg_tt)) %&gt;% \n  datatable(top_5_countries_time)\n\n\n\n\n\n\ntop_5_countries_time&lt;- cuisine_correct_time %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_tt= mean(sum_time, na.rm = TRUE),\n  ) %&gt;%\n   slice_max(n=35, order_by = avg_tt)\ntop_5_countries_time %&gt;% \n  gf_col(reorder(country, avg_tt)~avg_tt, fill = \"seagreen\")%&gt;%\n  gf_labs(\n    title = \"Top Countries by Average Time\",\n    x = \"Average Time\",\n    y = \"Country\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nHighest Total Time\n\nNorwegian and Portuguese have the highest average time to cook their food.\nCuban, Soul Food, Polish, German, Jewish, Persian also have very long total times.\nThese cuisines rely heavily on slow cooking, roasting etc\n\nModerate Total Time\n\nBrazilian, Greek, South African, Belgian, Swiss, Spanish, Indonesian, Southern Recipes, Canadian, Malaysian, Pakistani, Peruvian have moderate time of preparation\n\nQuick Cooking Cuisines\n\nChinese, Colombian, Japanese, Thai, Swedish, Indian, Vietnamese, Dutch\nThese cuisines use fast stir-fry, steaming etc.\n\n\n\n\n\n\n\ntop_10_dishes_rating &lt;- cuisines_factor %&gt;%\n  group_by(name) %&gt;%\n  summarise(\n    max_total_rating = max(total_ratings, na.rm = TRUE),\n    max_reviews = max(reviews, na.rm = TRUE)\n  ) %&gt;%\n\n  arrange(desc(max_total_rating)) %&gt;% \n  slice_head(n=20)\n\n\ntop_10_dishes_rating %&gt;%\n  gf_col(reorder(name, max_total_rating) ~ max_total_rating, fill = \"indianred\") %&gt;%\n  gf_labs(\n    title = \"Top 20 Highest Rated Recipes\",\n    x = \"Total Rating\",\n    y = \"Dish Name\"\n  )\n\n\n\n\n\n\n\n\n\ntop_10_dishes_rating %&gt;% \n  gf_col(reorder(name, max_reviews) ~ max_reviews, fill = \"indianred\") %&gt;%\n  gf_labs(\n    title = \"Top 20 Highest Reviewed Recipes\",\n    x = \"Max Reviews\",\n    y = \"Dish Name\"\n  )\n\n\n\n\n\n\n\n\nAs we saw in the previous correlation graph, Reviews and Rating have a high +ve correlation.\nThe top three recipes are the same in both charts:\n\nCheesy Amish Breakfast Casserole\nBlender Hollandaise Sauce\nBoneless Buffalo Wings\n\nThe similarity in the rankings implies that getting a high amount of reviews is a major factor of a high total rating. If a recipe is good, it gets a lot of reviews which increases the Total Rating. Whereas, a poor recipe wouldn’t maintain both a high review volume or a high total rating.\n\n\n\nIn conclusion, we see that cuisine recipes in the Allrecipes website are:\n1. Some cuisines, like Italian - have more Calories, Fat and Protein than average. This doesn’t mean its unhealthy, as the ingredients used matter.\n2. If a recipe is high in calories, it’s usually high in Fat and Protein too. Fats and Protein are highly contribute to calories.\n3. Recipes from places like Norway and Portugal take the longest to make because they rely on slow cooking. Whereas recipes from China and Japan are usually the fastest.\n4. Reviews are a major contributor to the total rating on the website.\n5. Russian, Fillipino, Chinese and Canadian (63 recipes each) are the highest number of recipes present on the website.\n6 - North America has the highest calorie, protein & fat consumption. - Oceania has the highes carbs consumption.\nOverall, it was interesting to analyse the understand the cuisine characteristic around the world and user preferences on the Allrecipes website."
  },
  {
    "objectID": "A2/tastyR/cuisines.html#section",
    "href": "A2/tastyR/cuisines.html#section",
    "title": "Cuisines Dataset",
    "section": "",
    "text": "Data Dictionary\nA data frame with 2218 rows and 17 variables:\n\n\n\nVariable\nDescription\n\n\n\n\nname\nName of the recipe\n\n\ncountry\nThe country/region the cuisine is from\n\n\nurl\nLink to the recipe\n\n\nauthor\nAuthor of the recipe\n\n\ndate_published\nWhen the recipe was published/updated\n\n\ningredients\nThe ingredients of the recipe\n\n\ncalories\nCalories per serving\n\n\nfat\nFat per serving\n\n\ncarbs\nCarbs per serving\n\n\nprotein\nProteins per serving\n\n\navg_rating\nAverage rating out of 5 stars\n\n\ntotal_ratings\nNumber of ratings received\n\n\nreviews\nNumber of written reviews\n\n\nprep_time\nPreparation time in minutes\n\n\ncook_time\nCooking time in minutes\n\n\ntotal_time\nPrep + cook time in minutes\n\n\nservings\nNumber of servings"
  },
  {
    "objectID": "A2/tastyR/cuisines.html#setting-up-r-packages",
    "href": "A2/tastyR/cuisines.html#setting-up-r-packages",
    "title": "Cuisines Dataset",
    "section": "",
    "text": "library(ggformula)\n\nLoading required package: ggplot2\n\n\nLoading required package: scales\n\n\nLoading required package: ggridges\n\n\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(naniar)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:naniar':\n\n    n_complete\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.1.0     ✔ tidyr     1.3.1\n✔ readr     2.1.5     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ mosaic::count()     masks dplyr::count()\n✖ purrr::cross()      masks mosaic::cross()\n✖ purrr::discard()    masks scales::discard()\n✖ mosaic::do()        masks dplyr::do()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ mosaic::stat()      masks ggplot2::stat()\n✖ mosaic::tally()     masks dplyr::tally()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tinytable)\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(visdat)\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(RColorBrewer)\nlibrary(naniar)\nlibrary(GGally)\nlibrary(ggplot2)\nlibrary(correlation)\n\n\nAttaching package: 'correlation'\n\nThe following object is masked from 'package:mosaic':\n\n    cor_test\n\nlibrary(dplyr)\nlibrary(RColorBrewer)\nlibrary(DT)"
  },
  {
    "objectID": "A2/tastyR/cuisines.html#viewing-the-dataset",
    "href": "A2/tastyR/cuisines.html#viewing-the-dataset",
    "title": "Cuisines Dataset",
    "section": "",
    "text": "data(\"cuisines\", package = \"tastyR\")\nglimpse(cuisines)   \n\nRows: 2,218\nColumns: 17\n$ name           &lt;chr&gt; \"Saganaki (Flaming Greek Cheese)\", \"Coney Island Knishe…\n$ country        &lt;chr&gt; \"Greek\", \"Jewish\", \"Australian and New Zealander\", \"Chi…\n$ url            &lt;chr&gt; \"https://www.allrecipes.com/recipe/263750/flaming-greek…\n$ author         &lt;chr&gt; \"John Mitzewich\", \"John Mitzewich\", \"CHIPPENDALE\", \"Hei…\n$ date_published &lt;date&gt; 2024-02-07, 2024-11-26, 2022-07-14, 2025-01-31, 2025-0…\n$ ingredients    &lt;chr&gt; \"1 (4 ounce) package kasseri cheese, 1 tablespoon water…\n$ calories       &lt;dbl&gt; 391, 301, 64, 106, 449, 958, 378, 90, 157, 322, 4, NA, …\n$ fat            &lt;dbl&gt; 25, 17, 3, 9, 23, 24, 10, 5, 6, 16, 0, NA, 21, 2, 66, 8…\n$ carbs          &lt;dbl&gt; 15, 31, 9, 7, 58, 144, 59, 10, 25, 39, 1, NA, 16, 63, 7…\n$ protein        &lt;dbl&gt; 16, 7, 1, 1, 7, 46, 14, 1, 2, 7, 0, NA, 28, 6, 54, 17, …\n$ avg_rating     &lt;dbl&gt; 4.8, 4.6, 4.3, 5.0, 3.8, 4.4, 4.3, NA, 4.6, 5.0, 4.7, 4…\n$ total_ratings  &lt;dbl&gt; 25, 10, 126, 1, 13, 40, 3, NA, 65, 2, 182, 2, 19, 16, 9…\n$ reviews        &lt;dbl&gt; 22, 9, 104, 1, 11, 32, 3, NA, 55, 2, 138, 2, 15, 16, 84…\n$ prep_time      &lt;dbl&gt; 10, 30, 20, 10, 30, 30, 30, 40, 0, 5, 5, 5, 10, 10, 20,…\n$ cook_time      &lt;dbl&gt; 5, 75, 15, 0, 15, 165, 75, 30, 0, 5, 0, 25, 10, 50, 16,…\n$ total_time     &lt;dbl&gt; 15, 180, 180, 10, 45, 675, 585, 155, 0, 10, 5, 30, 50, …\n$ servings       &lt;dbl&gt; 2, 16, 12, 6, 15, 6, 6, 84, 24, 1, 21, 8, 4, 10, 4, 8, …"
  },
  {
    "objectID": "A2/tastyR/cuisines.html#replacing-common-na-representations-with-actual-na-values-in-the-dataset.",
    "href": "A2/tastyR/cuisines.html#replacing-common-na-representations-with-actual-na-values-in-the-dataset.",
    "title": "Cuisines Dataset",
    "section": "",
    "text": "cuisines_modified &lt;- cuisines %&gt;%\n  naniar::replace_with_na_all(data = ., condition = ~ .x %in% common_na_numbers) %&gt;%\n  naniar::replace_with_na_all(data = ., condition = ~ .x %in% common_na_strings)\nglimpse(cuisines_modified)\n\nRows: 2,218\nColumns: 17\n$ name           &lt;chr&gt; \"Saganaki (Flaming Greek Cheese)\", \"Coney Island Knishe…\n$ country        &lt;chr&gt; \"Greek\", \"Jewish\", \"Australian and New Zealander\", \"Chi…\n$ url            &lt;chr&gt; \"https://www.allrecipes.com/recipe/263750/flaming-greek…\n$ author         &lt;chr&gt; \"John Mitzewich\", \"John Mitzewich\", \"CHIPPENDALE\", \"Hei…\n$ date_published &lt;date&gt; 2024-02-07, 2024-11-26, 2022-07-14, 2025-01-31, 2025-0…\n$ ingredients    &lt;chr&gt; \"1 (4 ounce) package kasseri cheese, 1 tablespoon water…\n$ calories       &lt;dbl&gt; 391, 301, 64, 106, 449, 958, 378, 90, 157, 322, 4, NA, …\n$ fat            &lt;dbl&gt; 25, 17, 3, 9, 23, 24, 10, 5, 6, 16, 0, NA, 21, 2, NA, 8…\n$ carbs          &lt;dbl&gt; 15, 31, 9, 7, 58, 144, 59, 10, 25, 39, 1, NA, 16, 63, 7…\n$ protein        &lt;dbl&gt; 16, 7, 1, 1, 7, 46, 14, 1, 2, 7, 0, NA, 28, 6, 54, 17, …\n$ avg_rating     &lt;dbl&gt; 4.8, 4.6, 4.3, 5.0, 3.8, 4.4, 4.3, NA, 4.6, 5.0, 4.7, 4…\n$ total_ratings  &lt;dbl&gt; 25, 10, 126, 1, 13, 40, 3, NA, 65, 2, 182, 2, 19, 16, 9…\n$ reviews        &lt;dbl&gt; 22, 9, 104, 1, 11, 32, 3, NA, 55, 2, 138, 2, 15, 16, 84…\n$ prep_time      &lt;dbl&gt; 10, 30, 20, 10, 30, 30, 30, 40, 0, 5, 5, 5, 10, 10, 20,…\n$ cook_time      &lt;dbl&gt; 5, 75, 15, 0, 15, 165, 75, 30, 0, 5, 0, 25, 10, 50, 16,…\n$ total_time     &lt;dbl&gt; 15, 180, 180, 10, 45, 675, 585, 155, 0, 10, 5, 30, 50, …\n$ servings       &lt;dbl&gt; 2, 16, 12, 6, 15, 6, 6, 84, 24, 1, 21, 8, 4, 10, 4, 8, …"
  },
  {
    "objectID": "A2/tastyR/cuisines.html#viewing-missing-data",
    "href": "A2/tastyR/cuisines.html#viewing-missing-data",
    "title": "Cuisines Dataset",
    "section": "",
    "text": "visdat::vis_miss(cuisines_modified)\n\n\n\n\n\n\n\nvisdat::vis_dat(cuisines_modified)"
  },
  {
    "objectID": "A2/tastyR/cuisines.html#removing-missing-data",
    "href": "A2/tastyR/cuisines.html#removing-missing-data",
    "title": "Cuisines Dataset",
    "section": "",
    "text": "cuisines_modified_new &lt;- cuisines_modified %&gt;% drop_na()\nglimpse(cuisines_modified_new)\n\nRows: 1,989\nColumns: 17\n$ name           &lt;chr&gt; \"Saganaki (Flaming Greek Cheese)\", \"Coney Island Knishe…\n$ country        &lt;chr&gt; \"Greek\", \"Jewish\", \"Australian and New Zealander\", \"Chi…\n$ url            &lt;chr&gt; \"https://www.allrecipes.com/recipe/263750/flaming-greek…\n$ author         &lt;chr&gt; \"John Mitzewich\", \"John Mitzewich\", \"CHIPPENDALE\", \"Hei…\n$ date_published &lt;date&gt; 2024-02-07, 2024-11-26, 2022-07-14, 2025-01-31, 2025-0…\n$ ingredients    &lt;chr&gt; \"1 (4 ounce) package kasseri cheese, 1 tablespoon water…\n$ calories       &lt;dbl&gt; 391, 301, 64, 106, 449, 958, 378, 157, 322, 4, 389, 253…\n$ fat            &lt;dbl&gt; 25, 17, 3, 9, 23, 24, 10, 6, 16, 0, 21, 2, 8, 31, 19, 7…\n$ carbs          &lt;dbl&gt; 15, 31, 9, 7, 58, 144, 59, 25, 39, 1, 16, 63, 53, 43, 4…\n$ protein        &lt;dbl&gt; 16, 7, 1, 1, 7, 46, 14, 2, 7, 0, 28, 6, 17, 25, 7, 29, …\n$ avg_rating     &lt;dbl&gt; 4.8, 4.6, 4.3, 5.0, 3.8, 4.4, 4.3, 4.6, 5.0, 4.7, 4.4, …\n$ total_ratings  &lt;dbl&gt; 25, 10, 126, 1, 13, 40, 3, 65, 2, 182, 19, 16, 20, 43, …\n$ reviews        &lt;dbl&gt; 22, 9, 104, 1, 11, 32, 3, 55, 2, 138, 15, 16, 15, 39, 2…\n$ prep_time      &lt;dbl&gt; 10, 30, 20, 10, 30, 30, 30, 0, 5, 5, 10, 10, 15, 60, 10…\n$ cook_time      &lt;dbl&gt; 5, 75, 15, 0, 15, 165, 75, 0, 5, 0, 10, 50, 15, 10, 45,…\n$ total_time     &lt;dbl&gt; 15, 180, 180, 10, 45, 675, 585, 0, 10, 5, 50, 300, 60, …\n$ servings       &lt;dbl&gt; 2, 16, 12, 6, 15, 6, 6, 24, 1, 21, 4, 10, 8, 6, 10, 6, …"
  },
  {
    "objectID": "A2/tastyR/cuisines.html#examining-data",
    "href": "A2/tastyR/cuisines.html#examining-data",
    "title": "Cuisines Dataset",
    "section": "",
    "text": "summary(cuisines_modified_new)\n\n     name             country              url               author         \n Length:1989        Length:1989        Length:1989        Length:1989       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n date_published       ingredients           calories           fat        \n Min.   :2009-02-09   Length:1989        Min.   :   3.0   Min.   :  0.00  \n 1st Qu.:2022-11-08   Class :character   1st Qu.: 194.0   1st Qu.:  7.00  \n Median :2024-07-15   Mode  :character   Median : 318.0   Median : 15.00  \n Mean   :2023-11-08                      Mean   : 355.4   Mean   : 18.38  \n 3rd Qu.:2024-12-19                      3rd Qu.: 475.0   3rd Qu.: 25.00  \n Max.   :2025-07-29                      Max.   :2010.0   Max.   :151.00  \n     carbs           protein         avg_rating   total_ratings   \n Min.   :  1.00   Min.   :  0.00   Min.   :1.00   Min.   :  1.00  \n 1st Qu.: 13.00   1st Qu.:  4.00   1st Qu.:4.30   1st Qu.:  6.00  \n Median : 26.00   Median : 12.00   Median :4.60   Median : 24.00  \n Mean   : 31.62   Mean   : 16.49   Mean   :4.51   Mean   : 87.23  \n 3rd Qu.: 45.00   3rd Qu.: 25.00   3rd Qu.:4.80   3rd Qu.: 90.00  \n Max.   :264.00   Max.   :135.00   Max.   :5.00   Max.   :997.00  \n    reviews         prep_time         cook_time        total_time   \n Min.   :  1.00   Min.   :   0.00   Min.   :  0.00   Min.   :    0  \n 1st Qu.:  6.00   1st Qu.:  10.00   1st Qu.: 10.00   1st Qu.:   35  \n Median : 21.00   Median :  15.00   Median : 25.00   Median :   60  \n Mean   : 78.73   Mean   :  21.18   Mean   : 42.96   Mean   :  176  \n 3rd Qu.: 76.00   3rd Qu.:  25.00   3rd Qu.: 45.00   3rd Qu.:  120  \n Max.   :975.00   Max.   :1800.00   Max.   :600.00   Max.   :14440  \n    servings     \n Min.   :  1.00  \n 1st Qu.:  4.00  \n Median :  8.00  \n Mean   : 10.29  \n 3rd Qu.: 12.00  \n Max.   :200.00  \n\n\n\ndim(cuisines_modified_new)\n\n[1] 1989   17\n\n\n\nskim(cuisines_modified_new)\n\n\nData summary\n\n\nName\ncuisines_modified_new\n\n\nNumber of rows\n1989\n\n\nNumber of columns\n17\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nDate\n1\n\n\nnumeric\n11\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1\n4\n87\n0\n1987\n0\n\n\ncountry\n0\n1\n4\n28\n0\n49\n0\n\n\nurl\n0\n1\n45\n110\n0\n1989\n0\n\n\nauthor\n0\n1\n1\n35\n0\n1507\n0\n\n\ningredients\n0\n1\n29\n1081\n0\n1989\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate_published\n0\n1\n2009-02-09\n2025-07-29\n2024-07-15\n696\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncalories\n0\n1\n355.36\n224.49\n3\n194.0\n318.0\n475.0\n2010\n▇▅▁▁▁\n\n\nfat\n0\n1\n18.38\n15.65\n0\n7.0\n15.0\n25.0\n151\n▇▂▁▁▁\n\n\ncarbs\n0\n1\n31.62\n25.55\n1\n13.0\n26.0\n45.0\n264\n▇▂▁▁▁\n\n\nprotein\n0\n1\n16.49\n15.61\n0\n4.0\n12.0\n25.0\n135\n▇▂▁▁▁\n\n\navg_rating\n0\n1\n4.51\n0.39\n1\n4.3\n4.6\n4.8\n5\n▁▁▁▂▇\n\n\ntotal_ratings\n0\n1\n87.23\n150.36\n1\n6.0\n24.0\n90.0\n997\n▇▁▁▁▁\n\n\nreviews\n0\n1\n78.73\n144.62\n1\n6.0\n21.0\n76.0\n975\n▇▁▁▁▁\n\n\nprep_time\n0\n1\n21.18\n54.60\n0\n10.0\n15.0\n25.0\n1800\n▇▁▁▁▁\n\n\ncook_time\n0\n1\n42.96\n64.70\n0\n10.0\n25.0\n45.0\n600\n▇▁▁▁▁\n\n\ntotal_time\n0\n1\n175.99\n673.15\n0\n35.0\n60.0\n120.0\n14440\n▇▁▁▁▁\n\n\nservings\n0\n1\n10.29\n12.42\n1\n4.0\n8.0\n12.0\n200\n▇▁▁▁▁\n\n\n\n\n\n\nnames(cuisines_modified_new)\n\n [1] \"name\"           \"country\"        \"url\"            \"author\"        \n [5] \"date_published\" \"ingredients\"    \"calories\"       \"fat\"           \n [9] \"carbs\"          \"protein\"        \"avg_rating\"     \"total_ratings\" \n[13] \"reviews\"        \"prep_time\"      \"cook_time\"      \"total_time\"    \n[17] \"servings\"      \n\n\n\nglimpse(cuisines_modified_new)\n\nRows: 1,989\nColumns: 17\n$ name           &lt;chr&gt; \"Saganaki (Flaming Greek Cheese)\", \"Coney Island Knishe…\n$ country        &lt;chr&gt; \"Greek\", \"Jewish\", \"Australian and New Zealander\", \"Chi…\n$ url            &lt;chr&gt; \"https://www.allrecipes.com/recipe/263750/flaming-greek…\n$ author         &lt;chr&gt; \"John Mitzewich\", \"John Mitzewich\", \"CHIPPENDALE\", \"Hei…\n$ date_published &lt;date&gt; 2024-02-07, 2024-11-26, 2022-07-14, 2025-01-31, 2025-0…\n$ ingredients    &lt;chr&gt; \"1 (4 ounce) package kasseri cheese, 1 tablespoon water…\n$ calories       &lt;dbl&gt; 391, 301, 64, 106, 449, 958, 378, 157, 322, 4, 389, 253…\n$ fat            &lt;dbl&gt; 25, 17, 3, 9, 23, 24, 10, 6, 16, 0, 21, 2, 8, 31, 19, 7…\n$ carbs          &lt;dbl&gt; 15, 31, 9, 7, 58, 144, 59, 25, 39, 1, 16, 63, 53, 43, 4…\n$ protein        &lt;dbl&gt; 16, 7, 1, 1, 7, 46, 14, 2, 7, 0, 28, 6, 17, 25, 7, 29, …\n$ avg_rating     &lt;dbl&gt; 4.8, 4.6, 4.3, 5.0, 3.8, 4.4, 4.3, 4.6, 5.0, 4.7, 4.4, …\n$ total_ratings  &lt;dbl&gt; 25, 10, 126, 1, 13, 40, 3, 65, 2, 182, 19, 16, 20, 43, …\n$ reviews        &lt;dbl&gt; 22, 9, 104, 1, 11, 32, 3, 55, 2, 138, 15, 16, 15, 39, 2…\n$ prep_time      &lt;dbl&gt; 10, 30, 20, 10, 30, 30, 30, 0, 5, 5, 10, 10, 15, 60, 10…\n$ cook_time      &lt;dbl&gt; 5, 75, 15, 0, 15, 165, 75, 0, 5, 0, 10, 50, 15, 10, 45,…\n$ total_time     &lt;dbl&gt; 15, 180, 180, 10, 45, 675, 585, 0, 10, 5, 50, 300, 60, …\n$ servings       &lt;dbl&gt; 2, 16, 12, 6, 15, 6, 6, 24, 1, 21, 4, 10, 8, 6, 10, 6, …"
  },
  {
    "objectID": "A2/tastyR/cuisines.html#munging",
    "href": "A2/tastyR/cuisines.html#munging",
    "title": "Cuisines Dataset",
    "section": "",
    "text": "cuisines_factor &lt;- cuisines_modified_new %&gt;%\n  mutate(across(where(is.character), as.factor))%&gt;%\n  dplyr::relocate(where(is.factor), .before = name)\nglimpse(cuisines_factor)\n\nRows: 1,989\nColumns: 17\n$ name           &lt;fct&gt; \"Saganaki (Flaming Greek Cheese)\", \"Coney Island Knishe…\n$ country        &lt;fct&gt; Greek, Jewish, Australian and New Zealander, Chilean, T…\n$ url            &lt;fct&gt; https://www.allrecipes.com/recipe/263750/flaming-greek-…\n$ author         &lt;fct&gt; \"John Mitzewich\", \"John Mitzewich\", \"CHIPPENDALE\", \"Hei…\n$ ingredients    &lt;fct&gt; \"1 (4 ounce) package kasseri cheese, 1 tablespoon water…\n$ date_published &lt;date&gt; 2024-02-07, 2024-11-26, 2022-07-14, 2025-01-31, 2025-0…\n$ calories       &lt;dbl&gt; 391, 301, 64, 106, 449, 958, 378, 157, 322, 4, 389, 253…\n$ fat            &lt;dbl&gt; 25, 17, 3, 9, 23, 24, 10, 6, 16, 0, 21, 2, 8, 31, 19, 7…\n$ carbs          &lt;dbl&gt; 15, 31, 9, 7, 58, 144, 59, 25, 39, 1, 16, 63, 53, 43, 4…\n$ protein        &lt;dbl&gt; 16, 7, 1, 1, 7, 46, 14, 2, 7, 0, 28, 6, 17, 25, 7, 29, …\n$ avg_rating     &lt;dbl&gt; 4.8, 4.6, 4.3, 5.0, 3.8, 4.4, 4.3, 4.6, 5.0, 4.7, 4.4, …\n$ total_ratings  &lt;dbl&gt; 25, 10, 126, 1, 13, 40, 3, 65, 2, 182, 19, 16, 20, 43, …\n$ reviews        &lt;dbl&gt; 22, 9, 104, 1, 11, 32, 3, 55, 2, 138, 15, 16, 15, 39, 2…\n$ prep_time      &lt;dbl&gt; 10, 30, 20, 10, 30, 30, 30, 0, 5, 5, 10, 10, 15, 60, 10…\n$ cook_time      &lt;dbl&gt; 5, 75, 15, 0, 15, 165, 75, 0, 5, 0, 10, 50, 15, 10, 45,…\n$ total_time     &lt;dbl&gt; 15, 180, 180, 10, 45, 675, 585, 0, 10, 5, 50, 300, 60, …\n$ servings       &lt;dbl&gt; 2, 16, 12, 6, 15, 6, 6, 24, 1, 21, 4, 10, 8, 6, 10, 6, …"
  },
  {
    "objectID": "A2/tastyR/cuisines.html#summaries-examining-the-data",
    "href": "A2/tastyR/cuisines.html#summaries-examining-the-data",
    "title": "Cuisines Dataset",
    "section": "",
    "text": "cuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    count = n()\n  ) %&gt;%\n  arrange(desc(count)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_calories = mean(calories, na.rm = TRUE),\n  ) %&gt;%\n  arrange(desc(avg_calories)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_fat = mean(fat, na.rm = TRUE),\n  ) %&gt;%\n  arrange(desc(avg_fat)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_carbs = mean(carbs, na.rm = TRUE),\n  ) %&gt;%\n  arrange(desc(avg_carbs)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_protien = mean(protein, na.rm = TRUE),\n  ) %&gt;%\n  arrange(desc(avg_protien)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country, name) %&gt;%\n  summarise(\n    avg_calories = mean(calories, na.rm = TRUE),\n    average_fat = mean(fat, na.rm = TRUE),\n    avg_carbs = mean(carbs, na.rm = TRUE),\n    avg_protein = mean(protein, na.rm = TRUE)\n  ) %&gt;%\n  arrange(desc(avg_calories)) %&gt;% \n  datatable(cuisines_factor)\n\n`summarise()` has grouped output by 'country'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country, name) %&gt;%\n  summarise(\n    avg_calories = mean(calories, na.rm = TRUE),\n    avg_rating = mean(avg_rating, narm = TRUE)\n  ) %&gt;%\n  arrange(desc(avg_calories)) %&gt;% \n  datatable(cuisines_factor)\n\n`summarise()` has grouped output by 'country'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country, name) %&gt;%\n  summarise(\n    avg_calories = mean(calories, na.rm = TRUE),\n    avg_fat = mean(fat, na.rm = TRUE),\n    avg_carbs = mean(carbs, na.rm = TRUE),\n    avg_protein = mean(protein, na.rm = TRUE)\n  ) %&gt;%\n  arrange(desc(avg_fat)) %&gt;% \n  datatable(cuisines_factor)\n\n`summarise()` has grouped output by 'country'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country, name) %&gt;%\n  summarise(\n    avg_calories = mean(calories, na.rm = TRUE),\n    avg_fat = mean(fat, na.rm = TRUE),\n    avg_carbs = mean(carbs, na.rm = TRUE),\n    avg_protein = mean(protein, na.rm = TRUE)\n  ) %&gt;%\n  arrange(desc(avg_carbs)) %&gt;% \n  datatable(cuisines_factor)\n\n`summarise()` has grouped output by 'country'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country, name) %&gt;%\n  summarise(\n    avg_calories = mean(calories, na.rm = TRUE),\n    avg_fat = mean(fat, na.rm = TRUE),\n    avg_carbs = mean(carbs, na.rm = TRUE),\n    avg_protein = mean(protein, na.rm = TRUE)\n  ) %&gt;%\n  arrange(desc(avg_protein)) %&gt;% \n  datatable(cuisines_factor)\n\n`summarise()` has grouped output by 'country'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_prep_time = mean(prep_time, na.rm = TRUE),\n    avg_cook_time = mean(cook_time, na.rm = TRUE),\n    avg_total_time = mean(total_time, na.rm = TRUE),\n    avg_rating = mean(avg_rating, na.rm = TRUE),\n    avg_total_ratings = mean(total_ratings, na.rm = TRUE),\n    avg_reviews = mean(reviews, na.rm = TRUE),\n    avg_servings = mean(servings, na.rm = TRUE),\n  ) %&gt;%\n  arrange(desc(avg_total_time)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_prep_time = mean(prep_time, na.rm = TRUE),\n    avg_cook_time = mean(cook_time, na.rm = TRUE),\n    avg_total_time = mean(total_time, na.rm = TRUE),\n    avg_rating = mean(avg_rating, na.rm = TRUE),\n    avg_total_ratings = mean(total_ratings, na.rm = TRUE),\n    avg_reviews = mean(reviews, na.rm = TRUE),\n    avg_servings = mean(servings, na.rm = TRUE),\n  ) %&gt;%\n  arrange(desc(avg_total_ratings)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(name, country) %&gt;%\n  summarise(\n    max_prep_time = mean(prep_time, na.rm = TRUE),\n    max_cook_time = mean(cook_time, na.rm = TRUE),\n    max_total_time = mean(total_time, na.rm = TRUE),\n    max_servings = mean(servings, na.rm = TRUE)\n  ) %&gt;%\n  arrange(desc(max_total_time)) %&gt;% \n  datatable(cuisines_factor)\n\n`summarise()` has grouped output by 'name'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\nHere we see that for certain dishes, the prep time, cook time & total time is 0 - which is inaccurate.\nThe prep_time + cook_time doesn’t add up to the total_time as mentioned in the data dictionary.\n\n\n\n\ncuisines_clean &lt;- cuisines_factor %&gt;%\n  filter(prep_time &gt; 0, cook_time &gt; 0, total_time &gt; 0)\ncuisines_clean %&gt;% arrange(desc(total_time)) %&gt;% select(name, country, prep_time,cook_time, total_time) %&gt;% \n  datatable(cuisines_clean)\n\n\n\n\n\n\ncuisine_correct_time &lt;- cuisines_clean %&gt;%\n  mutate(sum_time = prep_time + cook_time)\ncuisine_correct_time %&gt;% \n  select(name, country, prep_time,cook_time, total_time, sum_time) %&gt;% \n  datatable(cuisine_correct_time)\n\n\n\n\n\n\ncuisine_correct_time %&gt;% filter(total_time!=sum_time) %&gt;% \n  select(name, country, prep_time,cook_time, total_time, sum_time) %&gt;% \n  datatable(cuisine_correct_time)\n\n\n\n\n\nFrom the data dictionary, cook_time does not account for fermentation, marination, waiting periods which is done in dishes like breads, chicken etc.\n\nprep_time = before heat (chopping, mixing)\ncook_time = with heat (boil, bake, fry etc)\ntotal_time = prep + cook (but not fermentation/marination)\n\nWe also observed that the total_time values do not match the sum of prep_time and cook_time, even when excluding processes like fermentation or marination. This shows inconsistencies in the dataset due to missing or incorrectly recorded values from the original sources.\n\ncuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(avg_rating = mean(avg_rating, na.rm = TRUE),\n            total_reviews = sum(reviews, na.rm = TRUE)) %&gt;% arrange(desc(avg_rating)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(name) %&gt;%\n  summarise(max_rating = max(avg_rating, na.rm = TRUE),\n            total_reviews = sum(reviews, na.rm = TRUE)) %&gt;% arrange(desc(max_rating)) %&gt;% \n  datatable(cuisines_factor)\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  group_by(name,servings) %&gt;%\n  summarise(prep_time_avg = mean(prep_time)) %&gt;% arrange(desc(servings)) %&gt;% \n  datatable(cuisines_factor)\n\n`summarise()` has grouped output by 'name'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\ncuisines_continent &lt;- cuisines_factor %&gt;%\n  mutate(\n    continent = case_when(\n      country %in% c(\"Tex-Mex\", \"Amish and Mennonite\", \"Southern Recipes\", \n                     \"Cajun and Creole\", \"Canadian\", \"Soul Food\") ~ \"North America\",\n      \n      country %in% c(\"Greek\", \"Polish\", \"Danish\", \"Belgian\", \"Spanish\", \"Portuguese\", \n                     \"Norwegian\", \"Austrian\", \"Swiss\", \"Russian\", \"Dutch\", \"German\", \n                     \"Swedish\", \"Finnish\", \"French\", \"Italian\", \"Scandinavian\") ~ \"Europe\",\n      \n      country %in% c(\"Peruvian\", \"Argentinian\", \"Colombian\", \n                     \"Brazilian\", \"Chilean\") ~ \"South America\",\n      \n      country %in% c(\"Vietnamese\", \"Japanese\", \"Israeli\", \"Thai\", \"Chinese\", \"Turkish\", \n                     \"Korean\", \"Lebanese\", \"Jewish\", \"Malaysian\", \"Bangladeshi\", \n                     \"Persian\", \"Indonesian\", \"Indian\", \"Pakistani\", \"Filipino\") ~ \"Asia\",\n      \n      country %in% c(\"Australian and New Zealander\") ~ \"Oceania\",\n      \n      country %in% c(\"Puerto Rican\", \"Jamaican\", \"South African\", \"Cuban\") ~ \"Caribbean/Africa\",\n      \n      TRUE ~ \"Other\"\n    )\n  )\n\ncuisines_continent %&gt;% \n  select(name, country, continent) %&gt;% \n  datatable(cuisines_continent)"
  },
  {
    "objectID": "A2/tastyR/cuisines.html#visualising-information",
    "href": "A2/tastyR/cuisines.html#visualising-information",
    "title": "Cuisines Dataset",
    "section": "",
    "text": "top_dishes &lt;- cuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(count = n()) %&gt;%\n  slice_max(n = 15, order_by = count) %&gt;%    \n  arrange(desc(count))\ntop_dishes %&gt;% \n  gf_col(count~reorder(country,count), fill = \"orchid4\") %&gt;%\n  gf_labs(x = \"Country\", y = \"Number of Dishes\", title = \"Top 10 Countries by Recipe Count\") %&gt;% \n  gf_theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nRussian, Fillipino, Chinese and Canadian (63 recipes each) are the highest number of recipes present on the website.\n\n\n\n\n\ntop_continents &lt;- cuisines_continent %&gt;%\n  group_by(continent) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(desc(count))\n\ntop_continents %&gt;% \n  gf_col(count ~ reorder(continent, count), fill = \"blue4\") %&gt;%\n  gf_labs(\n    x = \"Continent\",\n    y = \"Number of Dishes\",\n    title = \"Number of Dishes by Continent\"\n  ) %&gt;%\n  gf_theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nAsian Recipes are found maximum on the Allrepices website where as Oceania recipes are least found on the website.\n\n\n\n\n\ntop_10_countries_calorie &lt;- cuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_calories = mean(calories, na.rm = TRUE),\n  ) %&gt;%\n  slice_max(n=10, order_by = avg_calories) %&gt;% \n  slice_head(n = 10)\ntop_10_countries_calorie %&gt;%\n  gf_col(reorder(country, avg_calories)~avg_calories, fill = \"steelblue\") %&gt;%\n  gf_labs(\n    title = \"Top 10 Countries by Average Calories\",\n    x = \"Average Calories\",\n    y = \"Country\"\n  )\n\n\n\n\n\n\n\n\n\ntop_10_continent_calorie &lt;- cuisines_continent %&gt;%\n  group_by(continent) %&gt;%\n  summarise(\n    avg_calories = mean(calories, na.rm = TRUE),\n  ) %&gt;%\n  slice_max(n=10, order_by = avg_calories) %&gt;% \n  slice_head(n = 10)\ntop_10_continent_calorie %&gt;%\n  gf_col(reorder(continent, avg_calories)~avg_calories, fill = \"steelblue2\") %&gt;%\n  gf_labs(\n    title = \"Top 10 Continents by Average Calories\",\n    x = \"Average Calories\",\n    y = \"Continent\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\ntop_10_countries_protein &lt;- cuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_protein = mean(protein, na.rm = TRUE),\n  ) %&gt;%\n  slice_max(n=10, order_by = avg_protein)\ntop_10_countries_protein %&gt;%\n  gf_col(reorder(country, avg_protein)~avg_protein, fill = \"darkorchid3\") %&gt;%\n  gf_labs(\n    title = \"Top Countries by Average protein\",\n    x = \"Average Protein\",\n    y = \"Country\"\n  )\n\n\n\n\n\n\n\n\n\ntop_10_continent_protein &lt;- cuisines_continent %&gt;%\n  group_by(continent) %&gt;%\n  summarise(\n    avg_protein = mean(protein, na.rm = TRUE),\n  ) %&gt;%\n  slice_max(n=10, order_by = avg_protein)\ntop_10_continent_protein %&gt;%\n  gf_col(reorder(continent, avg_protein)~avg_protein, fill = \"darkorchid4\") %&gt;%\n  gf_labs(\n    title = \"Top Continent by Average protein\",\n    x = \"Average Protein\",\n    y = \"Country\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\ntop_15_countries_carbs &lt;- cuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_carbs = mean(carbs, na.rm = TRUE),\n  ) %&gt;%\n   slice_max(n=20, order_by = avg_carbs)\ntop_15_countries_carbs %&gt;%\n  gf_col(reorder(country, avg_carbs)~avg_carbs, fill = \"rosybrown\") %&gt;%\n  gf_labs(\n    title = \"Top 20 Countries by Average Carbs\",\n    x = \"Average Carbs\",\n    y = \"Country\"\n  )\n\n\n\n\n\n\n\n\n\ntop_15_continent_carbs &lt;- cuisines_continent %&gt;%\n  group_by(continent) %&gt;%\n  summarise(\n    avg_carbs = mean(carbs, na.rm = TRUE),\n  ) %&gt;%\n   slice_max(n=20, order_by = avg_carbs)\ntop_15_continent_carbs %&gt;%\n  gf_col(reorder(continent, avg_carbs)~avg_carbs, fill = \"rosybrown4\") %&gt;%\n  gf_labs(\n    title = \"Top 20 Continent by Average Carbs\",\n    x = \"Average Carbs\",\n    y = \"Continent\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\ntop_5_countries_fat &lt;- cuisines_factor %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_fat = mean(fat, na.rm = TRUE),\n  ) %&gt;%\n   slice_max(n=10, order_by = avg_fat)\ntop_5_countries_fat %&gt;% \n  gf_col(reorder(country, avg_fat)~avg_fat, fill = \"royalblue3\") %&gt;%\n  gf_labs(\n    title = \"Top Countries by Average Fat\",\n    x = \"Average Fat\",\n    y = \"Country\"\n  )\n\n\n\n\n\n\n\n\n\ntop_5_continent_fat &lt;- cuisines_continent %&gt;%\n  group_by(continent) %&gt;%\n  summarise(\n    avg_fat = mean(fat, na.rm = TRUE),\n  ) %&gt;%\n   slice_max(n=10, order_by = avg_fat)\ntop_5_continent_fat %&gt;% \n  gf_col(reorder(continent, avg_fat)~avg_fat, fill = \"royalblue4\") %&gt;%\n  gf_labs(\n    title = \"Top Continents by Average Fat\",\n    x = \"Average Fat\",\n    y = \"Continent\"\n  )"
  },
  {
    "objectID": "A2/tastyR/cuisines.html#case-study-italian-food",
    "href": "A2/tastyR/cuisines.html#case-study-italian-food",
    "title": "Cuisines Dataset",
    "section": "",
    "text": "After viewing the carbs, protein, fat content by countries- it is seen that Italian food have higher average nutrient content than other countries.\n\n\n\ncuisines_factor %&gt;%\n  mutate(is_italian = ifelse(country == \"Italian\",\"Italian\", \"Other\")) %&gt;%\n  gf_boxplot(calories ~ is_italian, fill = c(\"paleturquoise3\", \"paleturquoise4\"), orientation = \"x\") %&gt;%\n  gf_labs(\n    title = \"Calories: Italian vs. Other Cuisines\",\n    x = \"Cuisine Category\",\n    y = \"Calories\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  mutate(is_italian = ifelse(country == \"Italian\",\"Italian\", \"Other\")) %&gt;%\n  gf_boxplot(protein ~ is_italian, fill = c(\"palegreen3\", \"palegreen4\"), orientation = \"x\") %&gt;%\n  gf_labs(\n    title = \"Protein: Italian vs. Other Cuisines\",\n    x = \"Cuisine Category\",\n    y = \"Protein\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\ncuisines_factor %&gt;%\n  mutate(is_italian = ifelse(country == \"Italian\",\"Italian\", \"Other\")) %&gt;%\n  gf_boxplot(fat ~ is_italian, fill = c(\"royalblue\", \"royalblue4\"), orientation = \"x\") %&gt;%\n  gf_labs(\n    title = \"Fat Content: Italian vs. Other Cuisines\",\n    x = \"Cuisine Category\",\n    y = \"Fat\"\n  )\n\n\n\n\n\n\n\n\nWe seen there’s an higher median for Italian food nutrients - does having higher calories, fat and protein make it unhealthy?\nItalian cooking is deeply rooted in the Mediterranean diet, which is widely recognized by nutritionists and health experts for its numerous benefits. A common misconception is having high number of calories, protein and fats - makes food unhealthy. However, not all high-calorie or high-fat foods are unhealthy. Italian diet uses whole grains, fruits, vegetables, legumes and olive oil as the primary sources of fat. Therefore, many traditional Italian dishes naturally incorporate these healthy elements.\n\nOlive Oil: Rich in monounsaturated fats, known for their heart-healthy properties. Tomatoes: Packed with antioxidants like lycopene.\nGarlic and Onions: Offer various health benefits and add flavor without excessive calories."
  },
  {
    "objectID": "A2/tastyR/cuisines.html#correlation-between-variables",
    "href": "A2/tastyR/cuisines.html#correlation-between-variables",
    "title": "Cuisines Dataset",
    "section": "",
    "text": "GGally::ggpairs(\n  cuisines_factor %&gt;% drop_na(),\n  columns = c(\n    \"fat\", \"calories\", \"protein\", \"servings\"\n  ),\n  switch = \"both\",\n  progress = FALSE,\n\n  diag = list(continuous = \"barDiag\"),\n  lower = list(continuous = wrap(\"smooth\", alpha = 0.3, se = FALSE)),\n\n  title = \"Cuisine Data Correlations Plot\"\n)\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\nFat & Protein have a high +ve correlation.\nCalories & Fat have a high +ve correlation which shows that fat is a major contributor to calories.\nCalories & Protein have a high +ve correlation which shows that protein is a major contributor to calories.\nNumber of servings, calories, fat and protein have a very low correlation.\n\n\nGGally::ggpairs(\n  cuisine_correct_time %&gt;% drop_na(),\n  columns = c(\n    \"servings\", \"sum_time\", \"cook_time\", \"prep_time\", \"total_ratings\",\"reviews\",\"avg_rating\"\n  ),\n  switch = \"both\",\n  progress = FALSE,\n\n  diag = list(continuous = \"barDiag\"),\n  lower = list(continuous = wrap(\"smooth\", alpha = 0.3, se = FALSE)),\n\n  title = \"Cuisine Data Correlations Plot\"\n)\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\nFrom the above plot, it is seen that Reviews and Total Rating have a high +ve correlation.Which means the number of Reviews is an important factor for a recipe to get a high rating.\n\n\n\n\ncuisine_correct_time %&gt;%\n  gf_point(sum_time ~ servings, alpha = 0.5, color = \"darkblue\") %&gt;%\n  gf_labs(\n    title = \"Total Time vs. Number of Servings\",\n    x = \"Servings\",\n    y = \"Total Time\"\n  ) %&gt;%\n  gf_lm(color=\"black\")\n\n\n\n\n\n\n\n\n\nThe trend is not that significant - not a strong correlation between the 2 variables.\n\n\n\n\n\ncuisines_factor %&gt;%\n  gf_point(reviews~total_ratings, alpha = 0.5, color = \"darkviolet\") %&gt;%\n  gf_labs(\n    title = \"Scatter Plot of Total Ratings vs. Reviews\",\n    x = \"Total Reviews\",\n    y = \"Total Ratings\"\n  ) %&gt;%\n  gf_lm(color = \"black\")\n\n\n\n\n\n\n\n\nThe scatterplot shows a high +ve relation - which proves the hypothesis that total reviews and total ratings are +vely correlated.\n\n\n\n\ncuisines_factor %&gt;% \n  gf_point(total_ratings~calories, alpha = 0.5, color = \"seagreen\") %&gt;% \n  gf_lm(color = \"black\") %&gt;% \n  gf_labs(title =\"Calories vs Total Ratings\",\n          x = \"Calories\",\n          y =\"Total Ratings\")\n\n\n\n\n\n\n\n\nThe scatterplot shows that Calories and Total Ratings have no correlation - which disproves the hypothesis.\n\n\n\n\ncuisine_correct_time %&gt;% \n  gf_point(sum_time~total_ratings, alpha = 0.5, color = \"royalblue\") %&gt;% \n  gf_labs(title=\"Time vs Reviews\",\n          x = \"Total Time\",\n          y = \"Total Ratings\") %&gt;% \n  gf_lm(color = \"black\")\n\n\n\n\n\n\n\n\nHere it is seen that, the r value is -0.02 which is a very low relation. Therefore, having a longer or shorter preparation time is not a strong determining factor in how many people review a recipe.\n\ncuisines_factor %&gt;%\n  gf_point(calories ~ servings, alpha = 0.5, color = \"darkred\") %&gt;%\n  gf_labs(\n    title = \"Calories vs. Servings\",\n    x = \"Servings\",\n    y = \"Calories\"\n  ) %&gt;%\n  gf_lm(color = \"black\")\n\n\n\n\n\n\n\n\n\nmosaic::cor_test(calories ~ servings, data = cuisines_factor) %&gt;%\n  broom::tidy() %&gt;%\n  knitr::kable(\n    digits = 2,\n    caption = \"Total Time vs Total Ratings\"\n  )\n\n\nTotal Time vs Total Ratings\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n-0.32\n-15.31\n0\n1987\n-0.36\n-0.28\nPearson’s product-moment correlation\ntwo.sided\n\n\n\n\n\n\nThe correlation between Calories and Servings is present but is weak (r= -0.32)"
  },
  {
    "objectID": "A2/tastyR/cuisines.html#total-time-vs-country",
    "href": "A2/tastyR/cuisines.html#total-time-vs-country",
    "title": "Cuisines Dataset",
    "section": "",
    "text": "top_5_countries_time&lt;- cuisine_correct_time %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_tt= mean(sum_time, na.rm = TRUE),\n  )\ntop_5_countries_time %&gt;% arrange(desc(avg_tt)) %&gt;% \n  datatable(top_5_countries_time)\n\n\n\n\n\n\ntop_5_countries_time&lt;- cuisine_correct_time %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    avg_tt= mean(sum_time, na.rm = TRUE),\n  ) %&gt;%\n   slice_max(n=35, order_by = avg_tt)\ntop_5_countries_time %&gt;% \n  gf_col(reorder(country, avg_tt)~avg_tt, fill = \"seagreen\")%&gt;%\n  gf_labs(\n    title = \"Top Countries by Average Time\",\n    x = \"Average Time\",\n    y = \"Country\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nHighest Total Time\n\nNorwegian and Portuguese have the highest average time to cook their food.\nCuban, Soul Food, Polish, German, Jewish, Persian also have very long total times.\nThese cuisines rely heavily on slow cooking, roasting etc\n\nModerate Total Time\n\nBrazilian, Greek, South African, Belgian, Swiss, Spanish, Indonesian, Southern Recipes, Canadian, Malaysian, Pakistani, Peruvian have moderate time of preparation\n\nQuick Cooking Cuisines\n\nChinese, Colombian, Japanese, Thai, Swedish, Indian, Vietnamese, Dutch\nThese cuisines use fast stir-fry, steaming etc."
  },
  {
    "objectID": "A2/tastyR/cuisines.html#dish-rating",
    "href": "A2/tastyR/cuisines.html#dish-rating",
    "title": "Cuisines Dataset",
    "section": "",
    "text": "top_10_dishes_rating &lt;- cuisines_factor %&gt;%\n  group_by(name) %&gt;%\n  summarise(\n    max_total_rating = max(total_ratings, na.rm = TRUE),\n    max_reviews = max(reviews, na.rm = TRUE)\n  ) %&gt;%\n\n  arrange(desc(max_total_rating)) %&gt;% \n  slice_head(n=20)\n\n\ntop_10_dishes_rating %&gt;%\n  gf_col(reorder(name, max_total_rating) ~ max_total_rating, fill = \"indianred\") %&gt;%\n  gf_labs(\n    title = \"Top 20 Highest Rated Recipes\",\n    x = \"Total Rating\",\n    y = \"Dish Name\"\n  )\n\n\n\n\n\n\n\n\n\ntop_10_dishes_rating %&gt;% \n  gf_col(reorder(name, max_reviews) ~ max_reviews, fill = \"indianred\") %&gt;%\n  gf_labs(\n    title = \"Top 20 Highest Reviewed Recipes\",\n    x = \"Max Reviews\",\n    y = \"Dish Name\"\n  )\n\n\n\n\n\n\n\n\nAs we saw in the previous correlation graph, Reviews and Rating have a high +ve correlation.\nThe top three recipes are the same in both charts:\n\nCheesy Amish Breakfast Casserole\nBlender Hollandaise Sauce\nBoneless Buffalo Wings\n\nThe similarity in the rankings implies that getting a high amount of reviews is a major factor of a high total rating. If a recipe is good, it gets a lot of reviews which increases the Total Rating. Whereas, a poor recipe wouldn’t maintain both a high review volume or a high total rating."
  },
  {
    "objectID": "A2/tastyR/cuisines.html#conclusion-inferences",
    "href": "A2/tastyR/cuisines.html#conclusion-inferences",
    "title": "Cuisines Dataset",
    "section": "",
    "text": "In conclusion, we see that cuisine recipes in the Allrecipes website are:\n1. Some cuisines, like Italian - have more Calories, Fat and Protein than average. This doesn’t mean its unhealthy, as the ingredients used matter.\n2. If a recipe is high in calories, it’s usually high in Fat and Protein too. Fats and Protein are highly contribute to calories.\n3. Recipes from places like Norway and Portugal take the longest to make because they rely on slow cooking. Whereas recipes from China and Japan are usually the fastest.\n4. Reviews are a major contributor to the total rating on the website.\n5. Russian, Fillipino, Chinese and Canadian (63 recipes each) are the highest number of recipes present on the website.\n6 - North America has the highest calorie, protein & fat consumption. - Oceania has the highes carbs consumption.\nOverall, it was interesting to analyse the understand the cuisine characteristic around the world and user preferences on the Allrecipes website."
  },
  {
    "objectID": "A2/DataSetsVerse/Police_shootings.html",
    "href": "A2/DataSetsVerse/Police_shootings.html",
    "title": "Police Shootings Dataset",
    "section": "",
    "text": "It’s a real-world data set that compiles incidents of fatal police shootings in the US, originally sourced from The Washington Post’s “Fatal Force” database.\n\n\n\n\nlibrary(DataSetsVerse)\n\nLoading required package: timeSeriesDataSets\n\n\nLoading required package: educationR\n\n\nLoading required package: crimedatasets\n\n\nLoading required package: MedDataSets\n\n\nLoading required package: OncoDataSets\n\n\n═══════════════════════════ Welcome to DataSetsVerse ═══════════════════════════\n\n\nA metapackage for thematic and domain-specific datasets in R.\n\n\n✔ timeSeriesDataSets v0.1.0\n\n\n✔ educationR         v0.1.0\n\n\n✔ crimedatasets      v0.1.0\n\n\n✔ MedDataSets        v0.1.0\n\n\n✔ OncoDataSets       v0.1.0\n\nDataSetsVerse()\n\n═══════════════════════════ Welcome to DataSetsVerse ═══════════════════════════ \nA metapackage for thematic and domain-specific datasets in R.\n\n✔ timeSeriesDataSets v0.1.0\n✔ educationR         v0.1.0\n✔ crimedatasets      v0.1.0\n✔ MedDataSets        v0.1.0\n✔ OncoDataSets       v0.1.0 \n\n\n\nlibrary(crimedatasets)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nglimpse(police_shootings_tbl_df)\n\nRows: 6,421\nColumns: 12\n$ date                    &lt;date&gt; 2015-01-02, 2015-01-02, 2015-01-03, 2015-01-0…\n$ manner_of_death         &lt;chr&gt; \"shot\", \"shot\", \"shot and Tasered\", \"shot\", \"s…\n$ armed                   &lt;chr&gt; \"gun\", \"gun\", \"unarmed\", \"toy weapon\", \"nail g…\n$ age                     &lt;dbl&gt; 53, 47, 23, 32, 39, 18, 22, 35, 34, 47, 25, 31…\n$ gender                  &lt;chr&gt; \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"F\", \"…\n$ race                    &lt;chr&gt; \"A\", \"W\", \"H\", \"W\", \"H\", \"W\", \"H\", \"W\", \"W\", \"…\n$ city                    &lt;chr&gt; \"Shelton\", \"Aloha\", \"Wichita\", \"San Francisco\"…\n$ state                   &lt;chr&gt; \"WA\", \"OR\", \"KS\", \"CA\", \"CO\", \"OK\", \"AZ\", \"KS\"…\n$ signs_of_mental_illness &lt;lgl&gt; TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE,…\n$ threat_level            &lt;chr&gt; \"attack\", \"attack\", \"other\", \"attack\", \"attack…\n$ flee                    &lt;chr&gt; \"Not fleeing\", \"Not fleeing\", \"Not fleeing\", \"…\n$ body_camera             &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n\n\n\n\n\ndate: Date when the shooting occurred\nmanner_of_death: How the person died\narmed: What the victim was reportedly armed with\nage: Age of the victim\ngender: Gender of the victim ( M = Male, F = Female)\nrace: Race / ethnicity of the victim (W = White, B = Black, H = Hispanic, A = Asian, N = Native, O = Other)\ncity: City where the shooting took place\nstate: U.S. state abbreviation\nthreat_level: The perceived threat level\nflee: Whether the person was fleeing\nbody_camera: Whether a body camera was in use during the shooting\nsigns_of_mental_illness: Whether there were reported signs of mental illness\n\n\n\n\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\n\nAttaching package: 'naniar'\n\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\n\n\nAttaching package: 'tinytable'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\n\n\nAttaching package: 'crosstable'\n\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\n\nLoading required package: grid\n\n\n\nAttaching package: 'vcd'\n\n\nThe following object is masked from 'package:mosaic':\n\n    mplot\n\n\nLoading required package: gnm\n\n\n\nAttaching package: 'gnm'\n\n\nThe following object is masked from 'package:lattice':\n\n    barley\n\n\n\nAttaching package: 'vcdExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    summarise\n\n\n\nAttaching package: 'resampledata'\n\n\nThe following object is masked from 'package:vcdExtra':\n\n    TV\n\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n\n\n\nAttaching package: 'ggmosaic'\n\n\nThe following objects are masked from 'package:vcd':\n\n    mosaic, spine\n\n\n\n\nTo analyze patterns in police shootings in the US, including demographic, situational and geographic factors.\nOur analyses might explore:\n\nVariation by race, gender, age\nWhether victims were armed\nThe role of mental health indicators\nThe effect of fleeing behavior and perceived threat levels\nGeographic & state‐level patterns\nYearly and monthly trends\n\n\npolice_shootings &lt;- police_shootings_tbl_df\nglimpse(police_shootings)\n\nRows: 6,421\nColumns: 12\n$ date                    &lt;date&gt; 2015-01-02, 2015-01-02, 2015-01-03, 2015-01-0…\n$ manner_of_death         &lt;chr&gt; \"shot\", \"shot\", \"shot and Tasered\", \"shot\", \"s…\n$ armed                   &lt;chr&gt; \"gun\", \"gun\", \"unarmed\", \"toy weapon\", \"nail g…\n$ age                     &lt;dbl&gt; 53, 47, 23, 32, 39, 18, 22, 35, 34, 47, 25, 31…\n$ gender                  &lt;chr&gt; \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"F\", \"…\n$ race                    &lt;chr&gt; \"A\", \"W\", \"H\", \"W\", \"H\", \"W\", \"H\", \"W\", \"W\", \"…\n$ city                    &lt;chr&gt; \"Shelton\", \"Aloha\", \"Wichita\", \"San Francisco\"…\n$ state                   &lt;chr&gt; \"WA\", \"OR\", \"KS\", \"CA\", \"CO\", \"OK\", \"AZ\", \"KS\"…\n$ signs_of_mental_illness &lt;lgl&gt; TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE,…\n$ threat_level            &lt;chr&gt; \"attack\", \"attack\", \"other\", \"attack\", \"attack…\n$ flee                    &lt;chr&gt; \"Not fleeing\", \"Not fleeing\", \"Not fleeing\", \"…\n$ body_camera             &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n\njanitor::clean_names(police_shootings)\n\n# A tibble: 6,421 × 12\n   date       manner_of_death  armed        age gender race  city          state\n   &lt;date&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt;\n 1 2015-01-02 shot             gun           53 M      A     Shelton       WA   \n 2 2015-01-02 shot             gun           47 M      W     Aloha         OR   \n 3 2015-01-03 shot and Tasered unarmed       23 M      H     Wichita       KS   \n 4 2015-01-04 shot             toy weapon    32 M      W     San Francisco CA   \n 5 2015-01-04 shot             nail gun      39 M      H     Evans         CO   \n 6 2015-01-04 shot             gun           18 M      W     Guthrie       OK   \n 7 2015-01-05 shot             gun           22 M      H     Chandler      AZ   \n 8 2015-01-06 shot             gun           35 M      W     Assaria       KS   \n 9 2015-01-06 shot             unarmed       34 F      W     Burlington    IA   \n10 2015-01-06 shot             toy weapon    47 M      B     Knoxville     PA   \n# ℹ 6,411 more rows\n# ℹ 4 more variables: signs_of_mental_illness &lt;lgl&gt;, threat_level &lt;chr&gt;,\n#   flee &lt;chr&gt;, body_camera &lt;lgl&gt;\n\n\n\n\n\n\n\nvisdat::vis_dat(police_shootings)\n\n\n\n\n\n\n\n\nThere are many missing entries; hence dropping the NA’s\n\npolice_shootings_mod1 &lt;- police_shootings %&gt;% \n  naniar::replace_with_na_all(condition = ~ .x %in% common_na_strings) %&gt;%\n  naniar::replace_with_na_all(condition = ~ .x %in% common_na_numbers) %&gt;% \ndrop_na()\npolice_shootings_mod1\n\n# A tibble: 5,106 × 12\n   date       manner_of_death  armed        age gender race  city          state\n   &lt;date&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt;\n 1 2015-01-02 shot             gun           53 M      A     Shelton       WA   \n 2 2015-01-02 shot             gun           47 M      W     Aloha         OR   \n 3 2015-01-03 shot and Tasered unarmed       23 M      H     Wichita       KS   \n 4 2015-01-04 shot             toy weapon    32 M      W     San Francisco CA   \n 5 2015-01-04 shot             nail gun      39 M      H     Evans         CO   \n 6 2015-01-04 shot             gun           18 M      W     Guthrie       OK   \n 7 2015-01-05 shot             gun           22 M      H     Chandler      AZ   \n 8 2015-01-06 shot             gun           35 M      W     Assaria       KS   \n 9 2015-01-06 shot             unarmed       34 F      W     Burlington    IA   \n10 2015-01-06 shot             toy weapon    47 M      B     Knoxville     PA   \n# ℹ 5,096 more rows\n# ℹ 4 more variables: signs_of_mental_illness &lt;lgl&gt;, threat_level &lt;chr&gt;,\n#   flee &lt;chr&gt;, body_camera &lt;lgl&gt;\n\n\n\n\n\n\npolice_shootings_mod1 %&gt;%  \nmutate(\n    manner_of_death = as_factor(manner_of_death),\n    armed = as_factor(armed),\n    gender = as_factor(gender),\n    race = as_factor(race),\n    city = as_factor(city),\n    state = as_factor(state),\n    signs_of_mental_illness = as_factor(signs_of_mental_illness),\n    threat_level = as_factor(threat_level),\n    flee = as_factor(flee),\n    body_camera = as_factor(body_camera)\n )\n\n# A tibble: 5,106 × 12\n   date       manner_of_death  armed        age gender race  city          state\n   &lt;date&gt;     &lt;fct&gt;            &lt;fct&gt;      &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt;         &lt;fct&gt;\n 1 2015-01-02 shot             gun           53 M      A     Shelton       WA   \n 2 2015-01-02 shot             gun           47 M      W     Aloha         OR   \n 3 2015-01-03 shot and Tasered unarmed       23 M      H     Wichita       KS   \n 4 2015-01-04 shot             toy weapon    32 M      W     San Francisco CA   \n 5 2015-01-04 shot             nail gun      39 M      H     Evans         CO   \n 6 2015-01-04 shot             gun           18 M      W     Guthrie       OK   \n 7 2015-01-05 shot             gun           22 M      H     Chandler      AZ   \n 8 2015-01-06 shot             gun           35 M      W     Assaria       KS   \n 9 2015-01-06 shot             unarmed       34 F      W     Burlington    IA   \n10 2015-01-06 shot             toy weapon    47 M      B     Knoxville     PA   \n# ℹ 5,096 more rows\n# ℹ 4 more variables: signs_of_mental_illness &lt;fct&gt;, threat_level &lt;fct&gt;,\n#   flee &lt;fct&gt;, body_camera &lt;fct&gt;\n\n\n\n\n\n\n\n\n# Race\npolice_shootings_mod1 %&gt;%\n  dplyr::count(race) %&gt;%\n  arrange(desc(n)) %&gt;% \n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                race\n                n\n              \n        \n        \n        \n                \n                  W\n                  2599\n                \n                \n                  B\n                  1363\n                \n                \n                  H\n                  931\n                \n                \n                  A\n                  93\n                \n                \n                  N\n                  78\n                \n                \n                  O\n                  42\n                \n        \n      \n    \n\n\n# Gender\npolice_shootings_mod1 %&gt;%\n  dplyr::count(gender) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                gender\n                n\n              \n        \n        \n        \n                \n                  F\n                  246\n                \n                \n                  M\n                  4860\n                \n        \n      \n    \n\n\n# Age\npolice_shootings_mod1 %&gt;%\n  dplyr::count(age) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                age\n                n\n              \n        \n        \n        \n                \n                  6\n                  2\n                \n                \n                  12\n                  1\n                \n                \n                  13\n                  2\n                \n                \n                  14\n                  3\n                \n                \n                  15\n                  12\n                \n                \n                  16\n                  29\n                \n                \n                  17\n                  51\n                \n                \n                  18\n                  100\n                \n                \n                  19\n                  84\n                \n                \n                  20\n                  81\n                \n                \n                  21\n                  105\n                \n                \n                  22\n                  120\n                \n                \n                  23\n                  126\n                \n                \n                  24\n                  153\n                \n                \n                  25\n                  182\n                \n                \n                  26\n                  145\n                \n                \n                  27\n                  183\n                \n                \n                  28\n                  164\n                \n                \n                  29\n                  168\n                \n                \n                  30\n                  162\n                \n                \n                  31\n                  178\n                \n                \n                  32\n                  169\n                \n                \n                  33\n                  168\n                \n                \n                  34\n                  177\n                \n                \n                  35\n                  159\n                \n                \n                  36\n                  156\n                \n                \n                  37\n                  152\n                \n                \n                  38\n                  127\n                \n                \n                  39\n                  135\n                \n                \n                  40\n                  114\n                \n                \n                  41\n                  117\n                \n                \n                  42\n                  95\n                \n                \n                  43\n                  89\n                \n                \n                  44\n                  83\n                \n                \n                  45\n                  112\n                \n                \n                  46\n                  88\n                \n                \n                  47\n                  97\n                \n                \n                  48\n                  83\n                \n                \n                  49\n                  79\n                \n                \n                  50\n                  79\n                \n                \n                  51\n                  72\n                \n                \n                  52\n                  65\n                \n                \n                  53\n                  60\n                \n                \n                  54\n                  50\n                \n                \n                  55\n                  51\n                \n                \n                  56\n                  60\n                \n                \n                  57\n                  47\n                \n                \n                  58\n                  50\n                \n                \n                  59\n                  52\n                \n                \n                  60\n                  35\n                \n                \n                  61\n                  35\n                \n                \n                  62\n                  32\n                \n                \n                  63\n                  24\n                \n                \n                  64\n                  18\n                \n                \n                  65\n                  21\n                \n                \n                  67\n                  17\n                \n                \n                  68\n                  13\n                \n                \n                  69\n                  14\n                \n                \n                  70\n                  9\n                \n                \n                  71\n                  7\n                \n                \n                  72\n                  5\n                \n                \n                  73\n                  4\n                \n                \n                  74\n                  5\n                \n                \n                  75\n                  4\n                \n                \n                  76\n                  8\n                \n                \n                  78\n                  1\n                \n                \n                  79\n                  4\n                \n                \n                  80\n                  2\n                \n                \n                  81\n                  2\n                \n                \n                  82\n                  1\n                \n                \n                  83\n                  2\n                \n                \n                  84\n                  4\n                \n                \n                  91\n                  2\n                \n        \n      \n    \n\n\n\n\n\n\n\npolice_shootings_mod1 %&gt;% \ngf_bar(~ fct_infreq(race), fill = \"skyblue\") %&gt;%\n  gf_labs(\n     x = \"Race\",\n    y = \"Number of victims\",\n    title = \"Race distribution of victims\")\n\n\n\n\n\n\n\n\n\n\n\nWhite individuals represent the majority (about half) of police shooting victims\nBlack individuals are the second largest group (about 1/4th), approximately half the frequency of White victims, followed by Hispanics\nAsian, Native, and Other racial groups collectively represent only 4% of total incidents\n\n\n\n\n\nThe data suggests potential racial disparities in police shooting incidents\nThe 2:1 ratio between White and Black victims may indicate either population distribution patterns or systemic factors\nWhen adjusted for population demographics, Black individuals may experience higher per-capita rates of police shootings\n\n\n\n\n\n\npolice_shootings_mod1 %&gt;% \ngf_bar(~ gender, fill = \"steelblue\") %&gt;%\n  gf_labs(\n     x = \"Gender\",\n    y = \"Number of victims\",\n    title = \"Gender distribution of victims\")\n\n\n\n\n\n\n\n\n\n\n\nThe gender disparity is extreme, with males being about 20 time more to be involved in police shootings than females\n\n\n\n\nMales are disproportionately involved in situations that are critical and need the use of deadly force, potentially due to:\n\nHigher rates of violent crime commission\nDifferent patterns of resistance or confrontation with law enforcement\nOccupational exposure (certain professions with police interaction)\n\n\n\n\n\n\npolice_shootings_mod1 %&gt;% \n  count(age) %&gt;% \ngf_line(n ~ age, colour = \"navyblue\") %&gt;%\n  gf_labs(\n     x = \"Age\",\n    y = \"Number of victims\",\n    title = \"Age distribution of victims\") %&gt;% \n  gf_refine(\n    scale_x_continuous(breaks = seq(0, 100, 5)) \n  )\n\n\n\n\n\n\n\n\n\n\n\n\nThere is a strongconcentrationofage between 20-40 years old, with peak incidence at ages 25-35\nThere is a sharpincrease from teenage years, peaking in mid-to-late 20s, then a gradual decline after age 35\nElderly victims are rare but present, with incidents documented up to age 91\n\n\n\n\n\nThe peak in late 20s and 30s aligns with ages of highest criminal offense rates and police encounters\nThis suggests that most incidents occur during police responses to criminal activity\n\n\n\n\n\n# Manner of Death\npolice_shootings_mod1 %&gt;%\n  dplyr::count(manner_of_death) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                manner_of_death\n                n\n              \n        \n        \n        \n                \n                  shot\n                  4829\n                \n                \n                  shot and Tasered\n                  277\n                \n        \n      \n    \n\n\n# Armed status\npolice_shootings_mod1 %&gt;%\n  dplyr::count(armed) %&gt;%\n  arrange(desc(n)) %&gt;% \n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                armed\n                n\n              \n        \n        \n        \n                \n                  gun\n                  3008\n                \n                \n                  knife\n                  780\n                \n                \n                  unarmed\n                  390\n                \n                \n                  toy weapon\n                  193\n                \n                \n                  vehicle\n                  168\n                \n                \n                  undetermined\n                  95\n                \n                \n                  unknown weapon\n                  55\n                \n                \n                  machete\n                  44\n                \n                \n                  Taser\n                  27\n                \n                \n                  sword\n                  22\n                \n                \n                  baseball bat\n                  17\n                \n                \n                  ax\n                  16\n                \n                \n                  hammer\n                  16\n                \n                \n                  gun and vehicle\n                  15\n                \n                \n                  gun and knife\n                  14\n                \n                \n                  metal pipe\n                  14\n                \n                \n                  screwdriver\n                  13\n                \n                \n                  box cutter\n                  12\n                \n                \n                  sharp object\n                  12\n                \n                \n                  hatchet\n                  11\n                \n                \n                  BB gun\n                  9\n                \n                \n                  gun and car\n                  9\n                \n                \n                  scissors\n                  8\n                \n                \n                  piece of wood\n                  7\n                \n                \n                  pipe\n                  6\n                \n                \n                  rock\n                  6\n                \n                \n                  shovel\n                  6\n                \n                \n                  blunt object\n                  5\n                \n                \n                  crossbow\n                  5\n                \n                \n                  meat cleaver\n                  5\n                \n                \n                  straight edge razor\n                  5\n                \n                \n                  vehicle and gun\n                  5\n                \n                \n                  baton\n                  4\n                \n                \n                  chair\n                  4\n                \n                \n                  crowbar\n                  4\n                \n                \n                  metal pole\n                  4\n                \n                \n                  pick-axe\n                  4\n                \n                \n                  samurai sword\n                  4\n                \n                \n                  chain\n                  3\n                \n                \n                  guns and explosives\n                  3\n                \n                \n                  metal object\n                  3\n                \n                \n                  metal stick\n                  3\n                \n                \n                  pellet gun\n                  3\n                \n                \n                  pole\n                  3\n                \n                \n                  Airsoft pistol\n                  2\n                \n                \n                  beer bottle\n                  2\n                \n                \n                  brick\n                  2\n                \n                \n                  flashlight\n                  2\n                \n                \n                  glass shard\n                  2\n                \n                \n                  gun and machete\n                  2\n                \n                \n                  hatchet and gun\n                  2\n                \n                \n                  lawn mower blade\n                  2\n                \n                \n                  metal hand tool\n                  2\n                \n                \n                  pitchfork\n                  2\n                \n                \n                  pole and knife\n                  2\n                \n                \n                  spear\n                  2\n                \n                \n                  tire iron\n                  2\n                \n                \n                  BB gun and vehicle\n                  1\n                \n                \n                  air conditioner\n                  1\n                \n                \n                  air pistol\n                  1\n                \n                \n                  barstool\n                  1\n                \n                \n                  baseball bat and bottle\n                  1\n                \n                \n                  baseball bat and fireplace poker\n                  1\n                \n                \n                  baseball bat and knife\n                  1\n                \n                \n                  bean-bag gun\n                  1\n                \n                \n                  binoculars\n                  1\n                \n                \n                  bottle\n                  1\n                \n                \n                  bow and arrow\n                  1\n                \n                \n                  car, knife and mace\n                  1\n                \n                \n                  carjack\n                  1\n                \n                \n                  chain saw\n                  1\n                \n                \n                  chainsaw\n                  1\n                \n                \n                  contractor's level\n                  1\n                \n                \n                  cordless drill\n                  1\n                \n                \n                  fireworks\n                  1\n                \n                \n                  flagpole\n                  1\n                \n                \n                  garden tool\n                  1\n                \n                \n                  grenade\n                  1\n                \n                \n                  gun and sword\n                  1\n                \n                \n                  hand torch\n                  1\n                \n                \n                  ice pick\n                  1\n                \n                \n                  incendiary device\n                  1\n                \n                \n                  knife and vehicle\n                  1\n                \n                \n                  machete and gun\n                  1\n                \n                \n                  metal rake\n                  1\n                \n                \n                  microphone\n                  1\n                \n                \n                  motorcycle\n                  1\n                \n                \n                  nail gun\n                  1\n                \n                \n                  oar\n                  1\n                \n                \n                  pen\n                  1\n                \n                \n                  pepper spray\n                  1\n                \n                \n                  railroad spikes\n                  1\n                \n                \n                  stapler\n                  1\n                \n                \n                  vehicle and machete\n                  1\n                \n                \n                  walking stick\n                  1\n                \n                \n                  wasp spray\n                  1\n                \n                \n                  wrench\n                  1\n                \n        \n      \n    \n\n\n# Flee Status\npolice_shootings_mod1 %&gt;%\n  dplyr::count(flee) %&gt;%\n  arrange(desc(n)) %&gt;% \n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                flee\n                n\n              \n        \n        \n        \n                \n                  Not fleeing\n                  3382\n                \n                \n                  Car\n                  775\n                \n                \n                  Foot\n                  754\n                \n                \n                  Other\n                  195\n                \n        \n      \n    \n\n\n# Threat Level\npolice_shootings_mod1 %&gt;%\n  dplyr::count(threat_level) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                threat_level\n                n\n              \n        \n        \n        \n                \n                  attack\n                  3371\n                \n                \n                  other\n                  1622\n                \n                \n                  undetermined\n                  113\n                \n        \n      \n    \n\n\n# Mental Health\npolice_shootings_mod1 %&gt;%\n  dplyr::count(signs_of_mental_illness) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                signs_of_mental_illness\n                n\n              \n        \n        \n        \n                \n                  FALSE\n                  3872\n                \n                \n                  TRUE\n                  1234\n                \n        \n      \n    \n\n\n# Body Camera\npolice_shootings_mod1 %&gt;%\n  dplyr::count(body_camera) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                body_camera\n                n\n              \n        \n        \n        \n                \n                  FALSE\n                  4390\n                \n                \n                  TRUE\n                  716\n                \n        \n      \n    \n\n\n\n\n\n\nManner of death: Most victims are shot. Some had to be tasered, is there a specific reason (like weapon type, threat level or mental illness which led to the outcome?)\nArmed: Most victims were armed with guns, which explains the critical situation leading to being shot. This is followed by knifes and then unarmed\nFlee: The majority of victims were not fleeing when shot\nThreat level: About 2/3 of victims were perceived as attacking when shot\nSigns of mental illness: About 1/4th of the victims have the signs of mental illness\nBody camera: More than 75% of the victims don’t have body cameras.\n\n\n\n\n\n\nsummary(police_shootings_mod1)\n\n      date            manner_of_death       armed                age       \n Min.   :2015-01-02   Length:5106        Length:5106        Min.   : 6.00  \n 1st Qu.:2016-05-31   Class :character   Class :character   1st Qu.:27.00  \n Median :2018-01-11   Mode  :character   Mode  :character   Median :34.00  \n Mean   :2018-01-13                                         Mean   :36.58  \n 3rd Qu.:2019-08-14                                         3rd Qu.:45.00  \n Max.   :2021-06-25                                         Max.   :91.00  \n    gender              race               city              state          \n Length:5106        Length:5106        Length:5106        Length:5106       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n signs_of_mental_illness threat_level           flee           body_camera    \n Mode :logical           Length:5106        Length:5106        Mode :logical  \n FALSE:3872              Class :character   Class :character   FALSE:4390     \n TRUE :1234              Mode  :character   Mode  :character   TRUE :716      \n                                                                              \n                                                                              \n                                                                              \n\n\n\n\n\n\nThe data is logged from the year 2015 to 2021\nThe youngest victim is 6 years and goes up to the age of 91. Average age is 34 years\n\n\n\n\n\n\n\n\npolice_shootings_mod1 %&gt;% \n    count(across(c(\"gender\", \"race\"))) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                gender\n                race\n                n\n              \n        \n        \n        \n                \n                  F\n                  A\n                  4\n                \n                \n                  F\n                  B\n                  48\n                \n                \n                  F\n                  H\n                  29\n                \n                \n                  F\n                  N\n                  5\n                \n                \n                  F\n                  O\n                  3\n                \n                \n                  F\n                  W\n                  157\n                \n                \n                  M\n                  A\n                  89\n                \n                \n                  M\n                  B\n                  1315\n                \n                \n                  M\n                  H\n                  902\n                \n                \n                  M\n                  N\n                  73\n                \n                \n                  M\n                  O\n                  39\n                \n                \n                  M\n                  W\n                  2442\n                \n        \n      \n    \n\n\n\n\npolice_shootings_mod1 %&gt;% \ngf_bar(~ fct_infreq(race), \n       fill = ~gender, \n       position = \"dodge\") %&gt;%\n  gf_labs(\n     x = \"Race\",\n    y = \"Number of vicyims\",\n    title = \"Race distribution of victims by Gender\")\n\n\n\n\n\n\n\n\n\n\n\n\nThe proportion of females are distinctly less, hence there is not much association between the two\nThe data supports sociological patterns where males tend towards confrontational behaviors and are overrepresented in situations likely to escalate to lethal force\n\n\n\n\n\npolice_shootings_mod1 %&gt;% \n  gf_density(~age, color = ~race, fill = ~race, alpha = 0.2) %&gt;%\n  gf_labs(\n    title = \"Age Distribution by Race\",\n    x = \"Age\",\n    y = \"Density\"\n  )%&gt;%\n  gf_refine(\n    scale_x_continuous(breaks = seq(0, 100, 5))\n  )\n\n\n\n\n\n\n\n\n\npolice_shootings_mod1 %&gt;% \n    count(across(c(\"age\", \"race\"))) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                age\n                race\n                n\n              \n        \n        \n        \n                \n                  6\n                  W\n                  2\n                \n                \n                  12\n                  W\n                  1\n                \n                \n                  13\n                  B\n                  1\n                \n                \n                  13\n                  H\n                  1\n                \n                \n                  14\n                  H\n                  2\n                \n                \n                  14\n                  N\n                  1\n                \n                \n                  15\n                  A\n                  1\n                \n                \n                  15\n                  B\n                  5\n                \n                \n                  15\n                  H\n                  3\n                \n                \n                  15\n                  W\n                  3\n                \n                \n                  16\n                  A\n                  2\n                \n                \n                  16\n                  B\n                  11\n                \n                \n                  16\n                  H\n                  6\n                \n                \n                  16\n                  W\n                  10\n                \n                \n                  17\n                  B\n                  23\n                \n                \n                  17\n                  H\n                  12\n                \n                \n                  17\n                  W\n                  16\n                \n                \n                  18\n                  A\n                  3\n                \n                \n                  18\n                  B\n                  48\n                \n                \n                  18\n                  H\n                  23\n                \n                \n                  18\n                  N\n                  1\n                \n                \n                  18\n                  O\n                  3\n                \n                \n                  18\n                  W\n                  22\n                \n                \n                  19\n                  A\n                  2\n                \n                \n                  19\n                  B\n                  39\n                \n                \n                  19\n                  H\n                  14\n                \n                \n                  19\n                  N\n                  2\n                \n                \n                  19\n                  W\n                  27\n                \n                \n                  20\n                  A\n                  2\n                \n                \n                  20\n                  B\n                  32\n                \n                \n                  20\n                  H\n                  14\n                \n                \n                  20\n                  N\n                  2\n                \n                \n                  20\n                  O\n                  2\n                \n                \n                  20\n                  W\n                  29\n                \n                \n                  21\n                  A\n                  2\n                \n                \n                  21\n                  B\n                  48\n                \n                \n                  21\n                  H\n                  26\n                \n                \n                  21\n                  N\n                  2\n                \n                \n                  21\n                  W\n                  27\n                \n                \n                  22\n                  A\n                  2\n                \n                \n                  22\n                  B\n                  43\n                \n                \n                  22\n                  H\n                  37\n                \n                \n                  22\n                  N\n                  1\n                \n                \n                  22\n                  O\n                  2\n                \n                \n                  22\n                  W\n                  35\n                \n                \n                  23\n                  A\n                  1\n                \n                \n                  23\n                  B\n                  50\n                \n                \n                  23\n                  H\n                  24\n                \n                \n                  23\n                  N\n                  2\n                \n                \n                  23\n                  O\n                  1\n                \n                \n                  23\n                  W\n                  48\n                \n                \n                  24\n                  B\n                  61\n                \n                \n                  24\n                  H\n                  30\n                \n                \n                  24\n                  N\n                  4\n                \n                \n                  24\n                  O\n                  1\n                \n                \n                  24\n                  W\n                  57\n                \n                \n                  25\n                  A\n                  2\n                \n                \n                  25\n                  B\n                  66\n                \n                \n                  25\n                  H\n                  31\n                \n                \n                  25\n                  N\n                  5\n                \n                \n                  25\n                  O\n                  3\n                \n                \n                  25\n                  W\n                  75\n                \n                \n                  26\n                  A\n                  4\n                \n                \n                  26\n                  B\n                  36\n                \n                \n                  26\n                  H\n                  33\n                \n                \n                  26\n                  N\n                  1\n                \n                \n                  26\n                  O\n                  1\n                \n                \n                  26\n                  W\n                  70\n                \n                \n                  27\n                  A\n                  3\n                \n                \n                  27\n                  B\n                  65\n                \n                \n                  27\n                  H\n                  41\n                \n                \n                  27\n                  N\n                  7\n                \n                \n                  27\n                  O\n                  3\n                \n                \n                  27\n                  W\n                  64\n                \n                \n                  28\n                  A\n                  4\n                \n                \n                  28\n                  B\n                  58\n                \n                \n                  28\n                  H\n                  41\n                \n                \n                  28\n                  N\n                  3\n                \n                \n                  28\n                  O\n                  1\n                \n                \n                  28\n                  W\n                  57\n                \n                \n                  29\n                  A\n                  1\n                \n                \n                  29\n                  B\n                  50\n                \n                \n                  29\n                  H\n                  38\n                \n                \n                  29\n                  N\n                  2\n                \n                \n                  29\n                  O\n                  3\n                \n                \n                  29\n                  W\n                  74\n                \n                \n                  30\n                  A\n                  1\n                \n                \n                  30\n                  B\n                  47\n                \n                \n                  30\n                  H\n                  28\n                \n                \n                  30\n                  N\n                  2\n                \n                \n                  30\n                  O\n                  3\n                \n                \n                  30\n                  W\n                  81\n                \n                \n                  31\n                  A\n                  2\n                \n                \n                  31\n                  B\n                  60\n                \n                \n                  31\n                  H\n                  26\n                \n                \n                  31\n                  N\n                  2\n                \n                \n                  31\n                  O\n                  1\n                \n                \n                  31\n                  W\n                  87\n                \n                \n                  32\n                  A\n                  4\n                \n                \n                  32\n                  B\n                  49\n                \n                \n                  32\n                  H\n                  28\n                \n                \n                  32\n                  N\n                  6\n                \n                \n                  32\n                  O\n                  1\n                \n                \n                  32\n                  W\n                  81\n                \n                \n                  33\n                  A\n                  2\n                \n                \n                  33\n                  B\n                  49\n                \n                \n                  33\n                  H\n                  35\n                \n                \n                  33\n                  N\n                  3\n                \n                \n                  33\n                  O\n                  1\n                \n                \n                  33\n                  W\n                  78\n                \n                \n                  34\n                  A\n                  3\n                \n                \n                  34\n                  B\n                  39\n                \n                \n                  34\n                  H\n                  35\n                \n                \n                  34\n                  N\n                  3\n                \n                \n                  34\n                  O\n                  2\n                \n                \n                  34\n                  W\n                  95\n                \n                \n                  35\n                  A\n                  6\n                \n                \n                  35\n                  B\n                  39\n                \n                \n                  35\n                  H\n                  39\n                \n                \n                  35\n                  N\n                  3\n                \n                \n                  35\n                  W\n                  72\n                \n                \n                  36\n                  A\n                  3\n                \n                \n                  36\n                  B\n                  29\n                \n                \n                  36\n                  H\n                  31\n                \n                \n                  36\n                  N\n                  4\n                \n                \n                  36\n                  O\n                  2\n                \n                \n                  36\n                  W\n                  87\n                \n                \n                  37\n                  A\n                  2\n                \n                \n                  37\n                  B\n                  41\n                \n                \n                  37\n                  H\n                  41\n                \n                \n                  37\n                  N\n                  2\n                \n                \n                  37\n                  W\n                  66\n                \n                \n                  38\n                  A\n                  3\n                \n                \n                  38\n                  B\n                  28\n                \n                \n                  38\n                  H\n                  34\n                \n                \n                  38\n                  N\n                  1\n                \n                \n                  38\n                  O\n                  1\n                \n                \n                  38\n                  W\n                  60\n                \n                \n                  39\n                  A\n                  2\n                \n                \n                  39\n                  B\n                  43\n                \n                \n                  39\n                  H\n                  26\n                \n                \n                  39\n                  N\n                  2\n                \n                \n                  39\n                  W\n                  62\n                \n                \n                  40\n                  A\n                  1\n                \n                \n                  40\n                  B\n                  21\n                \n                \n                  40\n                  H\n                  21\n                \n                \n                  40\n                  N\n                  1\n                \n                \n                  40\n                  O\n                  1\n                \n                \n                  40\n                  W\n                  69\n                \n                \n                  41\n                  A\n                  2\n                \n                \n                  41\n                  B\n                  27\n                \n                \n                  41\n                  H\n                  19\n                \n                \n                  41\n                  N\n                  1\n                \n                \n                  41\n                  O\n                  1\n                \n                \n                  41\n                  W\n                  67\n                \n                \n                  42\n                  A\n                  2\n                \n                \n                  42\n                  B\n                  16\n                \n                \n                  42\n                  H\n                  18\n                \n                \n                  42\n                  N\n                  1\n                \n                \n                  42\n                  O\n                  1\n                \n                \n                  42\n                  W\n                  57\n                \n                \n                  43\n                  A\n                  1\n                \n                \n                  43\n                  B\n                  19\n                \n                \n                  43\n                  H\n                  9\n                \n                \n                  43\n                  N\n                  4\n                \n                \n                  43\n                  W\n                  56\n                \n                \n                  44\n                  A\n                  3\n                \n                \n                  44\n                  B\n                  13\n                \n                \n                  44\n                  H\n                  17\n                \n                \n                  44\n                  N\n                  2\n                \n                \n                  44\n                  W\n                  48\n                \n                \n                  45\n                  A\n                  2\n                \n                \n                  45\n                  B\n                  18\n                \n                \n                  45\n                  H\n                  21\n                \n                \n                  45\n                  N\n                  1\n                \n                \n                  45\n                  O\n                  1\n                \n                \n                  45\n                  W\n                  69\n                \n                \n                  46\n                  A\n                  1\n                \n                \n                  46\n                  B\n                  18\n                \n                \n                  46\n                  H\n                  17\n                \n                \n                  46\n                  N\n                  1\n                \n                \n                  46\n                  O\n                  1\n                \n                \n                  46\n                  W\n                  50\n                \n                \n                  47\n                  A\n                  2\n                \n                \n                  47\n                  B\n                  22\n                \n                \n                  47\n                  H\n                  13\n                \n                \n                  47\n                  W\n                  60\n                \n                \n                  48\n                  A\n                  2\n                \n                \n                  48\n                  B\n                  18\n                \n                \n                  48\n                  H\n                  8\n                \n                \n                  48\n                  O\n                  2\n                \n                \n                  48\n                  W\n                  53\n                \n                \n                  49\n                  A\n                  2\n                \n                \n                  49\n                  B\n                  13\n                \n                \n                  49\n                  H\n                  9\n                \n                \n                  49\n                  N\n                  1\n                \n                \n                  49\n                  W\n                  54\n                \n                \n                  50\n                  A\n                  2\n                \n                \n                  50\n                  B\n                  11\n                \n                \n                  50\n                  H\n                  12\n                \n                \n                  50\n                  N\n                  1\n                \n                \n                  50\n                  W\n                  53\n                \n                \n                  51\n                  A\n                  1\n                \n                \n                  51\n                  B\n                  9\n                \n                \n                  51\n                  H\n                  9\n                \n                \n                  51\n                  N\n                  1\n                \n                \n                  51\n                  O\n                  1\n                \n                \n                  51\n                  W\n                  51\n                \n                \n                  52\n                  A\n                  2\n                \n                \n                  52\n                  B\n                  11\n                \n                \n                  52\n                  H\n                  11\n                \n                \n                  52\n                  W\n                  41\n                \n                \n                  53\n                  A\n                  3\n                \n                \n                  53\n                  B\n                  6\n                \n                \n                  53\n                  H\n                  2\n                \n                \n                  53\n                  N\n                  1\n                \n                \n                  53\n                  W\n                  48\n                \n                \n                  54\n                  A\n                  1\n                \n                \n                  54\n                  B\n                  6\n                \n                \n                  54\n                  H\n                  3\n                \n                \n                  54\n                  N\n                  1\n                \n                \n                  54\n                  O\n                  1\n                \n                \n                  54\n                  W\n                  38\n                \n                \n                  55\n                  A\n                  2\n                \n                \n                  55\n                  B\n                  11\n                \n                \n                  55\n                  H\n                  9\n                \n                \n                  55\n                  W\n                  29\n                \n                \n                  56\n                  A\n                  1\n                \n                \n                  56\n                  B\n                  5\n                \n                \n                  56\n                  H\n                  3\n                \n                \n                  56\n                  O\n                  1\n                \n                \n                  56\n                  W\n                  50\n                \n                \n                  57\n                  B\n                  10\n                \n                \n                  57\n                  H\n                  6\n                \n                \n                  57\n                  W\n                  31\n                \n                \n                  58\n                  B\n                  3\n                \n                \n                  58\n                  H\n                  4\n                \n                \n                  58\n                  N\n                  1\n                \n                \n                  58\n                  W\n                  42\n                \n                \n                  59\n                  A\n                  1\n                \n                \n                  59\n                  B\n                  2\n                \n                \n                  59\n                  H\n                  4\n                \n                \n                  59\n                  O\n                  1\n                \n                \n                  59\n                  W\n                  44\n                \n                \n                  60\n                  A\n                  3\n                \n                \n                  60\n                  B\n                  6\n                \n                \n                  60\n                  H\n                  1\n                \n                \n                  60\n                  W\n                  25\n                \n                \n                  61\n                  A\n                  1\n                \n                \n                  61\n                  B\n                  9\n                \n                \n                  61\n                  H\n                  1\n                \n                \n                  61\n                  W\n                  24\n                \n                \n                  62\n                  A\n                  1\n                \n                \n                  62\n                  B\n                  4\n                \n                \n                  62\n                  H\n                  3\n                \n                \n                  62\n                  W\n                  24\n                \n                \n                  63\n                  B\n                  6\n                \n                \n                  63\n                  H\n                  1\n                \n                \n                  63\n                  W\n                  17\n                \n                \n                  64\n                  B\n                  2\n                \n                \n                  64\n                  H\n                  1\n                \n                \n                  64\n                  W\n                  15\n                \n                \n                  65\n                  B\n                  2\n                \n                \n                  65\n                  H\n                  3\n                \n                \n                  65\n                  W\n                  16\n                \n                \n                  67\n                  B\n                  5\n                \n                \n                  67\n                  W\n                  12\n                \n                \n                  68\n                  B\n                  5\n                \n                \n                  68\n                  W\n                  8\n                \n                \n                  69\n                  B\n                  1\n                \n                \n                  69\n                  H\n                  3\n                \n                \n                  69\n                  W\n                  10\n                \n                \n                  70\n                  B\n                  1\n                \n                \n                  70\n                  H\n                  1\n                \n                \n                  70\n                  W\n                  7\n                \n                \n                  71\n                  H\n                  1\n                \n                \n                  71\n                  W\n                  6\n                \n                \n                  72\n                  B\n                  1\n                \n                \n                  72\n                  W\n                  4\n                \n                \n                  73\n                  H\n                  1\n                \n                \n                  73\n                  W\n                  3\n                \n                \n                  74\n                  B\n                  2\n                \n                \n                  74\n                  W\n                  3\n                \n                \n                  75\n                  W\n                  4\n                \n                \n                  76\n                  W\n                  8\n                \n                \n                  78\n                  W\n                  1\n                \n                \n                  79\n                  W\n                  4\n                \n                \n                  80\n                  H\n                  1\n                \n                \n                  80\n                  W\n                  1\n                \n                \n                  81\n                  W\n                  2\n                \n                \n                  82\n                  W\n                  1\n                \n                \n                  83\n                  W\n                  2\n                \n                \n                  84\n                  W\n                  4\n                \n                \n                  91\n                  W\n                  2\n                \n        \n      \n    \n\n\n\n\npolice_shootings_mod1 %&gt;% \ngf_boxplot(age ~ race, fill = ~race, orientation = \"x\") %&gt;%\n  gf_labs(\n    x = \"Race\",\n    y = \"Age\",\n    title = \"Age distribution across Races\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nBlack and Others are usually younger in age\nWhite and Asian victims are more spread out and Whites have higher median age\nHispanics have 2 peaks in their age - around 25s and 40s\nBlacks and Natives show a distinct peak at around 25 and 30 respectively\n\n\n\n\n\nBlack & Natives: Young adulthood is the highest danger period, likely linked to street policing and urban violence exposure\nWhite & Asian Pattern: Risk spreads across all adult ages, suggesting more varied incidents like mental health crises, domestic disputes, and elderly situations\nHispanics: Two different risk groups are seen in younger and older people\n\n\n\n\n\n\n# Race vs. Manner of Death\nvcd::structable(race ~ manner_of_death, data = police_shootings_mod1) %&gt;%\n  as.matrix() %&gt;%\n  addmargins() %&gt;%\n  as_tibble(rownames = \"Race\")\n\n# A tibble: 3 × 8\n  Race                 A     B     H     N     O     W   Sum\n  &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 shot                85  1283   878    74    38  2471  4829\n2 shot and Tasered     8    80    53     4     4   128   277\n3 Sum                 93  1363   931    78    42  2599  5106\n\nvcd::structable(race ~ manner_of_death, data = police_shootings_mod1) %&gt;%\n  vcd::mosaic(shade = TRUE, legend = TRUE,\n              main = \"Race vs. Manner of Death\",\n              gp = shading_max)\n\n\n\n\n\n\n\n# Gender vs. Manner of Death\nvcd::structable(gender ~ manner_of_death, data = police_shootings_mod1) %&gt;%\n  as.matrix() %&gt;%\n  addmargins() %&gt;%\n  as_tibble(rownames = \"Gender\")\n\n# A tibble: 3 × 4\n  Gender               F     M   Sum\n  &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 shot               237  4592  4829\n2 shot and Tasered     9   268   277\n3 Sum                246  4860  5106\n\nvcd::structable(gender ~ manner_of_death, data = police_shootings_mod1) %&gt;%\n  vcd::mosaic(shade = TRUE, legend = TRUE,\n              main = \"Gender vs. Manner of Death\",\n              gp = shading_max)\n\n\n\n\n\n\n\n# Manner of Death vs. Weapon type\npolice_shootings_mod1 %&gt;%\n  mutate(armed_top5 = fct_lump_n(armed, 5)) %&gt;%\n  vcd::structable(manner_of_death ~ armed_top5, data = .) %&gt;%\n  as.matrix() %&gt;%\n  addmargins() %&gt;%\n  as_tibble(rownames = \"Manner of Death\")\n\n# A tibble: 7 × 4\n  `Manner of Death`  shot `shot and Tasered`   Sum\n  &lt;chr&gt;             &lt;dbl&gt;              &lt;dbl&gt; &lt;dbl&gt;\n1 gun                2962                 46  3008\n2 knife               665                115   780\n3 toy weapon          190                  3   193\n4 unarmed             346                 44   390\n5 vehicle             167                  1   168\n6 Other               499                 68   567\n7 Sum                4829                277  5106\n\npolice_shootings_mod1 %&gt;%\n  mutate(armed_top5 = fct_lump_n(armed, 5)) %&gt;%\n  vcd::structable(manner_of_death ~ armed_top5, data = .) %&gt;%\n  vcd::mosaic(shade = TRUE, legend = TRUE,\n              main = \"Manner of Death vs. Top 5 Weapon Types\",\n              gp = shading_max)\n\n\n\n\n\n\n\n# Manner of Death vs. Threat level\nvcd::structable(manner_of_death ~ threat_level, data = police_shootings_mod1) %&gt;%\n  vcd::mosaic(shade = TRUE, legend = TRUE,\n              main = \"Manner of Death vs. Threat Level\",\n              gp = shading_max)\n\n\n\n\n\n\n\n# Manner of Death vs. Mental Illness\nvcd::structable(manner_of_death ~ signs_of_mental_illness, data = police_shootings_mod1) %&gt;%\n  vcd::mosaic(shade = TRUE, legend = TRUE,\n              main = \"Manner of Death vs. Mental Illness Signs\",\n              gp = shading_max)\n\n\n\n\n\n\n\n\n\n\n\n\nRace and Gender don’t have any distinct association with the manner of death\nVictims having gun and those perceived as threatening, show a distinct negative correlation with being shot and tasered meaning some distance had to be maintained\nThose who are armed with knife, show positive correlation being shot and tasered\nVictims showing signs of mental illness shows have a positive correlation with being shot and tasered\n\n\n\n\n\nWeapon type and mental state determine police tactics. Guns trigger immediate lethal response, while other weapons/conditions allow for attempted intermediate options.\n\n\n\n\n\npolice_shootings_dates &lt;- police_shootings_mod1 %&gt;%\n  mutate(\n    year = as.numeric(format(date, \"%Y\")),\n    month = as.numeric(format(date, \"%m\"))\n  )\n\n\n# Yearly trend\npolice_shootings_dates %&gt;%\n  count(year) %&gt;%\n  gf_line(n ~ year, color = \"steelblue\", size = 1) %&gt;%\n  gf_point(color = \"steelblue\", size = 2) %&gt;%\n  gf_labs(\n    title = \"Yearly Trend in Police Shootings\",\n    x = \"Year\", \n    y = \"Number of Shootings\"\n  ) %&gt;%\n  gf_refine(\n    scale_x_continuous(breaks = unique(police_shootings_dates$year))\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n# Monthly trend\npolice_shootings_dates %&gt;%\n     mutate(\n    month = format(as.Date(date), \"%b\"),\n    month = factor(month, levels = month.abb)\n  ) %&gt;%\n  count(month) %&gt;%\n  gf_line(n ~ month, group = 1, color = \"dodgerblue\", size = 1) %&gt;%\n  gf_point(color = \"dodgerblue\", size = 2) %&gt;%\n  gf_labs(\n    title = \"Monthly Trend in Police Shootings\",\n    x = \"Month\",\n    y = \"Number of Shootings\"\n  ) %&gt;%\n  gf_theme(axis.text.x = element_text(angle = 0, hjust = 1))\n\n\n\n\n\n\n\n\n\npolice_shootings_mod1 %&gt;%\n  mutate(year = as.numeric(format(date, \"%Y\"))) %&gt;%\n  count(year, race) %&gt;%\n  gf_line(n ~ year, color = ~race) %&gt;%\n  gf_point(n ~ year, color = ~race) %&gt;%\n  gf_labs(title = \"Yearly Shooting Trends by Race\")\n\n\n\n\n\n\n\n\n\n\n\n\nksjeh\nksejrh\nksj\n\n\n\n\n\nsldfkj\nsldkfj\nsjdfh\n\n\n\n\nAssociation of age with fleeing and weapon type\n\npolice_shootings_mod1 %&gt;%\n  mutate(\n    flee = fct_infreq(flee),      \n    armed = fct_lump_n(armed, 5)\n  ) %&gt;%\n  gf_boxplot(age ~ flee,\n             fill = ~armed,\n             orientation = \"x\" ) %&gt;%\n  gf_labs(\n    title = \"Age Distribution by Flee type and Weapon status\",\n    x = \"Flee Type\",\n    y = \"Age of Victim\",\n    fill = \"Weapon Type\"\n  )\n\n\n\n\n\n\n\n\nAge distribution by Flee status\n\npolice_shootings_mod1 %&gt;%\n  gf_density(~age, color = ~flee, fill = ~flee, alpha = 0.3) %&gt;%\n  gf_labs(title = \"Age Distribution by Flee Status\") %&gt;%\n  gf_refine(\n    scale_color_brewer(palette = \"Set1\"),\n    scale_x_continuous(breaks = seq(0, 100, 5))\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nThose “Not fleeing” or fleeing by car appear slightly older on average than those fleeing on foot.\nMedian ages for “Not fleeing” and “Car” are higher, while “Foot” and “Other” categories have lower medians.\nGuns and knives dominate across all flee types.\nUnarmed individuals appear in every flee category, often with similar or slightly lower median ages compared to armed groups.\nThe variation is generally higher for armed individuals, indicating broader age diversity among armed victims.\nA few older individuals (60+) appear across all flee types, particularly in the “Not fleeing” group.\n\n\n\n\n\nThere is no strong age-flee interaction, but the slightly higher median ages among “Not fleeing” cases could indicate that older victims are less likely to attempt escape.\nThe consistent presence of unarmed victims across flee types highlights that weapon possession is not always tied to fleeing behavior.\nThe broad age spread, especially in “Not fleeing” cases, suggests police encounters affect a wide demographic, not limited to younger populations.\n\n\n\n\npolice_shootings_mod1 %&gt;%\n  mutate(year = as.numeric(format(date, \"%Y\"))) %&gt;%\n  gf_point(age ~ year, alpha = 0.5) %&gt;%\n  gf_lm(age ~ year) %&gt;%\n  gf_facet_wrap(~ race) %&gt;%\n  gf_labs(\n    title = \"Age Distribution Over Years by Race\",\n    x = \"Year\",\n    y = \"Age\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nAcross all racial groups , most victims fall in the 25–45 age range, with only slight variations.\nThe median age remains relatively stable over time (2015–2020) with no significant increase or decrease in any group.\nWhite and Black individuals have the highest representation and wider spread in age distribution.\nOther races (Asian, Native, Hispanic, etc.) show smaller sample sizes and thus more variability.\n\n\npolice_shootings_mod1 %&gt;%\n  count(city, state) %&gt;%\n  arrange(desc(n)) %&gt;%\n  head(15) %&gt;%  # Top 15 locations\n  unite(location, city, state, sep = \", \") %&gt;%\n  select(location) %&gt;%\n  inner_join(police_shootings_mod1 %&gt;% \n              unite(location, city, state, sep = \", \"), \n            by = \"location\") %&gt;%\n  gf_boxplot(age ~ fct_reorder(location, age), fill = \"forestgreen\", orientation = \"x\") %&gt;%\n  gf_labs(\n    title = \"Age Distribution by Location (Top 15 Cities)\",\n    x = \"City, State\",\n    y = \"Age\"\n  ) %&gt;%\n  gf_theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\nSome cities like Chicago, Columbus, and St. Louis have younger victims, while Miami and Las Vegas show slightly higher medians.\nThe spread varies, larger in cities like Los Angeles and Jacksonville, suggesting more diverse victim age groups there.\n\n\n\n\n\npolice_shootings_mod1 %&gt;%\n  count(city, state) %&gt;%\n  arrange(desc(n)) %&gt;%\n  head(30) %&gt;%  # Taking top 30 locations\n  unite(location, city, state, sep = \", \") %&gt;%\n  gf_point(n ~ fct_reorder(location, n), size = ~n, color = \"red\") %&gt;%\n  gf_labs(\n    title = \"Police Shootings by Location\",\n    x = \"City, State\",\n    y = \"Number of Shootings\"\n  ) %&gt;%\n  gf_theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\nLos Angeles, CA reports the highest number of police shootings, followed by Phoenix, AZ, Houston, TX, and Las Vegas, NV.\nThe distribution is right-skewed where a few major cities account for a disproportionately large share of total shootings.\nMany smaller or mid-size cities (e.g., Colorado Springs, Charlotte) have fewer than 20 recorded incidents.\n\n\n\n\n\nPolice shootings predominantly involve young to middle-aged individuals (25–40 years old) across most races and cities, with no major age trend changes over time. However, incidents are geographically concentrated, a small number of large urban centers (like Los Angeles and Phoenix) account for the bulk of cases, indicating regional disparities that may be tied to population density, policing intensity, or systemic factors.\n\n\n\n\n\npolice_shootings_mod1 %&gt;%\n  count(city, state, threat_level) %&gt;%\n  group_by(city, state) %&gt;%\n  mutate(total = sum(n)) %&gt;%\n  filter(total &gt;= 10) %&gt;%  # Cities with 10+ incidents\n  ungroup() %&gt;%\n  arrange(desc(total)) %&gt;%\n  head(50) %&gt;%\n  unite(location, city, state, sep = \", \") %&gt;%\n  gf_col(n ~ location, fill = ~threat_level, position = \"fill\") %&gt;%\n  gf_theme(axis.text.x = element_text(angle = 90, hjust = 1)) %&gt;%\n  gf_labs(title = \"Threat Level Distribution by City\")\n\n\n\n\n\n\n\n\n\n\n\n\nAcross most cities, the attack threat level dominates, with smaller proportions of other and undetermined cases.\nCities like Los Angeles, Phoenix, and San Antonio show particularly high instances of attack classified incidents, while places like Columbus and Jacksonville have slightly higher variation across categories.\n\n\n\n\n\nThis suggests that police encounters in many urban centers are predominantly categorized as threats requiring lethal or aggressive response levels.\nThe consistency across locations might indicate uniform policy interpretation rather than contextual variations in local threat assessment.\n\n\n\n\n\npolice_shootings_mod1 %&gt;%\n  mutate(weapon_cat = fct_lump_n(armed, 6)) %&gt;%\n  count(race, weapon_cat) %&gt;%\n  group_by(race) %&gt;%\n  mutate(prop = n / sum(n)) %&gt;%\n  gf_tile(prop ~ race + weapon_cat) %&gt;%\n  gf_labs(\n    title = \"Weapon Type Distribution by Race\",\n    x = \"Race\",\n    y = \"Weapon Type\",\n    fill = \"Proportion\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nThe heatmap shows that guns are the most common weapon type across all racial groups, particularly pronounced among Black and White victims.\nNon-firearm weapons (like knives and toy weapons) appear far less frequently, with a few variations among racial groups.\n\n\n\n\n\nThis pattern could indicate both a systemic emphasis on firearm-related encounters and possible disparities in perceived weapon possession across racial groups.\nThe high prevalence of gun-related cases may also reflect broader accessibility and cultural factors related to weapon ownership.\n\n\npolice_shootings_mod1 %&gt;%\n  mutate(weapon_cat = fct_lump_n(armed, 5)) %&gt;%\n  count(weapon_cat, threat_level) %&gt;%\n  gf_col(n ~ weapon_cat, fill = ~threat_level, position = \"dodge\") %&gt;%\n  gf_labs(\n    title = \"Weapon Type vs Threat Level\",\n    x = \"Weapon Type\",\n    y = \"Count\",\n    fill = \"Threat Level\"\n  ) %&gt;%\n  gf_theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\nIndividuals categorized as notfleeing form the largest proportion across all weapon types, especially for guns, knives, and unarmed cases.\nVehicle-related cases show relatively more instances of fleeing by car, while foot fleeing is modestly present across some categories.\n\n\n\n\n\nThis could suggest that most encounters leading to recorded incidents occur when suspects are stationary or restrained rather than actively escaping. However, the relatively higher “car fleeing” in vehicle-related incidents might point to situational factors influencing pursuit and response dynamics.\n\n\npolice_shootings_mod1 %&gt;%\n  mutate(weapon_cat = fct_lump_n(armed, 8)) %&gt;%\n  count(weapon_cat, flee) %&gt;%\n  group_by(weapon_cat) %&gt;%\n  mutate(prop = n / sum(n)) %&gt;%\n  gf_col(prop ~ weapon_cat, fill = ~flee, position = \"fill\") %&gt;%\n  gf_labs(\n    title = \"Flee Behavior by Weapon Type\",\n    subtitle = \"Proportion of flee status for each weapon category\",\n    x = \"Weapon Type\",\n    y = \"Proportion\",\n    fill = \"Flee Status\"\n  ) %&gt;%\n  gf_theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\nGun-related incidents overwhelmingly fall under the attack threat level, followed by knives and unarmed cases at much lower frequencies.\nToy weapons and vehicles have very few attack classifications, and undetermined cases remain minimal overall.\n\n\n\n\n\nWeapons perceived as more dangerous (like firearms) are strongly associated with escalated threat responses. This pattern could imply that the presence of a gun, regardless of situation, significantly biases threat assessment, leading to higher rates of lethal force justification.\n\n\n\n\n\n\nDemographic Trends: Majority of victims are male (25–40 years); Black individuals face disproportionately higher risk relative to population size.\nSituational Insights: Most victims were armed, often with guns, but a notable share were unarmed or mentally ill, raising questions about threat assessment and escalation.\nBehavioral Patterns: Many were not fleeing, showing that fatal shootings often occur in static encounters, not active chases.\nThreat Perception: “Attack” is the most frequent threat label, especially when firearms are involved — suggesting strong bias toward perceiving high threat.\nGeographic Trends: Incidents cluster in urban hubs like Los Angeles, Houston, and Phoenix, showing concentration in large metro areas.\nThe data suggests that systemic patterns, not isolated incidents, underlie police shootings in the U.S. While armed confrontations explain part of the trend, biases in threat perception, inadequate handling of mental health crises, and regional concentration of incidents all point to the need for deeper structural reform."
  },
  {
    "objectID": "A2/DataSetsVerse/Police_shootings.html#viewing-the-dataset",
    "href": "A2/DataSetsVerse/Police_shootings.html#viewing-the-dataset",
    "title": "Police Shootings Dataset",
    "section": "",
    "text": "library(DataSetsVerse)\n\nLoading required package: timeSeriesDataSets\n\n\nLoading required package: educationR\n\n\nLoading required package: crimedatasets\n\n\nLoading required package: MedDataSets\n\n\nLoading required package: OncoDataSets\n\n\n═══════════════════════════ Welcome to DataSetsVerse ═══════════════════════════\n\n\nA metapackage for thematic and domain-specific datasets in R.\n\n\n✔ timeSeriesDataSets v0.1.0\n\n\n✔ educationR         v0.1.0\n\n\n✔ crimedatasets      v0.1.0\n\n\n✔ MedDataSets        v0.1.0\n\n\n✔ OncoDataSets       v0.1.0\n\nDataSetsVerse()\n\n═══════════════════════════ Welcome to DataSetsVerse ═══════════════════════════ \nA metapackage for thematic and domain-specific datasets in R.\n\n✔ timeSeriesDataSets v0.1.0\n✔ educationR         v0.1.0\n✔ crimedatasets      v0.1.0\n✔ MedDataSets        v0.1.0\n✔ OncoDataSets       v0.1.0 \n\n\n\nlibrary(crimedatasets)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nglimpse(police_shootings_tbl_df)\n\nRows: 6,421\nColumns: 12\n$ date                    &lt;date&gt; 2015-01-02, 2015-01-02, 2015-01-03, 2015-01-0…\n$ manner_of_death         &lt;chr&gt; \"shot\", \"shot\", \"shot and Tasered\", \"shot\", \"s…\n$ armed                   &lt;chr&gt; \"gun\", \"gun\", \"unarmed\", \"toy weapon\", \"nail g…\n$ age                     &lt;dbl&gt; 53, 47, 23, 32, 39, 18, 22, 35, 34, 47, 25, 31…\n$ gender                  &lt;chr&gt; \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"F\", \"…\n$ race                    &lt;chr&gt; \"A\", \"W\", \"H\", \"W\", \"H\", \"W\", \"H\", \"W\", \"W\", \"…\n$ city                    &lt;chr&gt; \"Shelton\", \"Aloha\", \"Wichita\", \"San Francisco\"…\n$ state                   &lt;chr&gt; \"WA\", \"OR\", \"KS\", \"CA\", \"CO\", \"OK\", \"AZ\", \"KS\"…\n$ signs_of_mental_illness &lt;lgl&gt; TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE,…\n$ threat_level            &lt;chr&gt; \"attack\", \"attack\", \"other\", \"attack\", \"attack…\n$ flee                    &lt;chr&gt; \"Not fleeing\", \"Not fleeing\", \"Not fleeing\", \"…\n$ body_camera             &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…"
  },
  {
    "objectID": "A2/DataSetsVerse/Police_shootings.html#data-dictionary",
    "href": "A2/DataSetsVerse/Police_shootings.html#data-dictionary",
    "title": "Police Shootings Dataset",
    "section": "",
    "text": "date: Date when the shooting occurred\nmanner_of_death: How the person died\narmed: What the victim was reportedly armed with\nage: Age of the victim\ngender: Gender of the victim ( M = Male, F = Female)\nrace: Race / ethnicity of the victim (W = White, B = Black, H = Hispanic, A = Asian, N = Native, O = Other)\ncity: City where the shooting took place\nstate: U.S. state abbreviation\nthreat_level: The perceived threat level\nflee: Whether the person was fleeing\nbody_camera: Whether a body camera was in use during the shooting\nsigns_of_mental_illness: Whether there were reported signs of mental illness"
  },
  {
    "objectID": "A2/DataSetsVerse/Police_shootings.html#setting-up-packages",
    "href": "A2/DataSetsVerse/Police_shootings.html#setting-up-packages",
    "title": "Police Shootings Dataset",
    "section": "",
    "text": "Registered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\n\nAttaching package: 'naniar'\n\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\n\n\nAttaching package: 'tinytable'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\n\n\nAttaching package: 'crosstable'\n\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\n\nLoading required package: grid\n\n\n\nAttaching package: 'vcd'\n\n\nThe following object is masked from 'package:mosaic':\n\n    mplot\n\n\nLoading required package: gnm\n\n\n\nAttaching package: 'gnm'\n\n\nThe following object is masked from 'package:lattice':\n\n    barley\n\n\n\nAttaching package: 'vcdExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    summarise\n\n\n\nAttaching package: 'resampledata'\n\n\nThe following object is masked from 'package:vcdExtra':\n\n    TV\n\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n\n\n\nAttaching package: 'ggmosaic'\n\n\nThe following objects are masked from 'package:vcd':\n\n    mosaic, spine\n\n\n\n\nTo analyze patterns in police shootings in the US, including demographic, situational and geographic factors.\nOur analyses might explore:\n\nVariation by race, gender, age\nWhether victims were armed\nThe role of mental health indicators\nThe effect of fleeing behavior and perceived threat levels\nGeographic & state‐level patterns\nYearly and monthly trends\n\n\npolice_shootings &lt;- police_shootings_tbl_df\nglimpse(police_shootings)\n\nRows: 6,421\nColumns: 12\n$ date                    &lt;date&gt; 2015-01-02, 2015-01-02, 2015-01-03, 2015-01-0…\n$ manner_of_death         &lt;chr&gt; \"shot\", \"shot\", \"shot and Tasered\", \"shot\", \"s…\n$ armed                   &lt;chr&gt; \"gun\", \"gun\", \"unarmed\", \"toy weapon\", \"nail g…\n$ age                     &lt;dbl&gt; 53, 47, 23, 32, 39, 18, 22, 35, 34, 47, 25, 31…\n$ gender                  &lt;chr&gt; \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"F\", \"…\n$ race                    &lt;chr&gt; \"A\", \"W\", \"H\", \"W\", \"H\", \"W\", \"H\", \"W\", \"W\", \"…\n$ city                    &lt;chr&gt; \"Shelton\", \"Aloha\", \"Wichita\", \"San Francisco\"…\n$ state                   &lt;chr&gt; \"WA\", \"OR\", \"KS\", \"CA\", \"CO\", \"OK\", \"AZ\", \"KS\"…\n$ signs_of_mental_illness &lt;lgl&gt; TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE,…\n$ threat_level            &lt;chr&gt; \"attack\", \"attack\", \"other\", \"attack\", \"attack…\n$ flee                    &lt;chr&gt; \"Not fleeing\", \"Not fleeing\", \"Not fleeing\", \"…\n$ body_camera             &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n\njanitor::clean_names(police_shootings)\n\n# A tibble: 6,421 × 12\n   date       manner_of_death  armed        age gender race  city          state\n   &lt;date&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt;\n 1 2015-01-02 shot             gun           53 M      A     Shelton       WA   \n 2 2015-01-02 shot             gun           47 M      W     Aloha         OR   \n 3 2015-01-03 shot and Tasered unarmed       23 M      H     Wichita       KS   \n 4 2015-01-04 shot             toy weapon    32 M      W     San Francisco CA   \n 5 2015-01-04 shot             nail gun      39 M      H     Evans         CO   \n 6 2015-01-04 shot             gun           18 M      W     Guthrie       OK   \n 7 2015-01-05 shot             gun           22 M      H     Chandler      AZ   \n 8 2015-01-06 shot             gun           35 M      W     Assaria       KS   \n 9 2015-01-06 shot             unarmed       34 F      W     Burlington    IA   \n10 2015-01-06 shot             toy weapon    47 M      B     Knoxville     PA   \n# ℹ 6,411 more rows\n# ℹ 4 more variables: signs_of_mental_illness &lt;lgl&gt;, threat_level &lt;chr&gt;,\n#   flee &lt;chr&gt;, body_camera &lt;lgl&gt;"
  },
  {
    "objectID": "A2/DataSetsVerse/Police_shootings.html#checking-for-missing-values",
    "href": "A2/DataSetsVerse/Police_shootings.html#checking-for-missing-values",
    "title": "Police Shootings Dataset",
    "section": "",
    "text": "visdat::vis_dat(police_shootings)\n\n\n\n\n\n\n\n\nThere are many missing entries; hence dropping the NA’s\n\npolice_shootings_mod1 &lt;- police_shootings %&gt;% \n  naniar::replace_with_na_all(condition = ~ .x %in% common_na_strings) %&gt;%\n  naniar::replace_with_na_all(condition = ~ .x %in% common_na_numbers) %&gt;% \ndrop_na()\npolice_shootings_mod1\n\n# A tibble: 5,106 × 12\n   date       manner_of_death  armed        age gender race  city          state\n   &lt;date&gt;     &lt;chr&gt;            &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt;\n 1 2015-01-02 shot             gun           53 M      A     Shelton       WA   \n 2 2015-01-02 shot             gun           47 M      W     Aloha         OR   \n 3 2015-01-03 shot and Tasered unarmed       23 M      H     Wichita       KS   \n 4 2015-01-04 shot             toy weapon    32 M      W     San Francisco CA   \n 5 2015-01-04 shot             nail gun      39 M      H     Evans         CO   \n 6 2015-01-04 shot             gun           18 M      W     Guthrie       OK   \n 7 2015-01-05 shot             gun           22 M      H     Chandler      AZ   \n 8 2015-01-06 shot             gun           35 M      W     Assaria       KS   \n 9 2015-01-06 shot             unarmed       34 F      W     Burlington    IA   \n10 2015-01-06 shot             toy weapon    47 M      B     Knoxville     PA   \n# ℹ 5,096 more rows\n# ℹ 4 more variables: signs_of_mental_illness &lt;lgl&gt;, threat_level &lt;chr&gt;,\n#   flee &lt;chr&gt;, body_camera &lt;lgl&gt;"
  },
  {
    "objectID": "A2/DataSetsVerse/Police_shootings.html#data-munging",
    "href": "A2/DataSetsVerse/Police_shootings.html#data-munging",
    "title": "Police Shootings Dataset",
    "section": "",
    "text": "police_shootings_mod1 %&gt;%  \nmutate(\n    manner_of_death = as_factor(manner_of_death),\n    armed = as_factor(armed),\n    gender = as_factor(gender),\n    race = as_factor(race),\n    city = as_factor(city),\n    state = as_factor(state),\n    signs_of_mental_illness = as_factor(signs_of_mental_illness),\n    threat_level = as_factor(threat_level),\n    flee = as_factor(flee),\n    body_camera = as_factor(body_camera)\n )\n\n# A tibble: 5,106 × 12\n   date       manner_of_death  armed        age gender race  city          state\n   &lt;date&gt;     &lt;fct&gt;            &lt;fct&gt;      &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt;         &lt;fct&gt;\n 1 2015-01-02 shot             gun           53 M      A     Shelton       WA   \n 2 2015-01-02 shot             gun           47 M      W     Aloha         OR   \n 3 2015-01-03 shot and Tasered unarmed       23 M      H     Wichita       KS   \n 4 2015-01-04 shot             toy weapon    32 M      W     San Francisco CA   \n 5 2015-01-04 shot             nail gun      39 M      H     Evans         CO   \n 6 2015-01-04 shot             gun           18 M      W     Guthrie       OK   \n 7 2015-01-05 shot             gun           22 M      H     Chandler      AZ   \n 8 2015-01-06 shot             gun           35 M      W     Assaria       KS   \n 9 2015-01-06 shot             unarmed       34 F      W     Burlington    IA   \n10 2015-01-06 shot             toy weapon    47 M      B     Knoxville     PA   \n# ℹ 5,096 more rows\n# ℹ 4 more variables: signs_of_mental_illness &lt;fct&gt;, threat_level &lt;fct&gt;,\n#   flee &lt;fct&gt;, body_camera &lt;fct&gt;"
  },
  {
    "objectID": "A2/DataSetsVerse/Police_shootings.html#examining-the-data",
    "href": "A2/DataSetsVerse/Police_shootings.html#examining-the-data",
    "title": "Police Shootings Dataset",
    "section": "",
    "text": "# Race\npolice_shootings_mod1 %&gt;%\n  dplyr::count(race) %&gt;%\n  arrange(desc(n)) %&gt;% \n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                race\n                n\n              \n        \n        \n        \n                \n                  W\n                  2599\n                \n                \n                  B\n                  1363\n                \n                \n                  H\n                  931\n                \n                \n                  A\n                  93\n                \n                \n                  N\n                  78\n                \n                \n                  O\n                  42\n                \n        \n      \n    \n\n\n# Gender\npolice_shootings_mod1 %&gt;%\n  dplyr::count(gender) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                gender\n                n\n              \n        \n        \n        \n                \n                  F\n                  246\n                \n                \n                  M\n                  4860\n                \n        \n      \n    \n\n\n# Age\npolice_shootings_mod1 %&gt;%\n  dplyr::count(age) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                age\n                n\n              \n        \n        \n        \n                \n                  6\n                  2\n                \n                \n                  12\n                  1\n                \n                \n                  13\n                  2\n                \n                \n                  14\n                  3\n                \n                \n                  15\n                  12\n                \n                \n                  16\n                  29\n                \n                \n                  17\n                  51\n                \n                \n                  18\n                  100\n                \n                \n                  19\n                  84\n                \n                \n                  20\n                  81\n                \n                \n                  21\n                  105\n                \n                \n                  22\n                  120\n                \n                \n                  23\n                  126\n                \n                \n                  24\n                  153\n                \n                \n                  25\n                  182\n                \n                \n                  26\n                  145\n                \n                \n                  27\n                  183\n                \n                \n                  28\n                  164\n                \n                \n                  29\n                  168\n                \n                \n                  30\n                  162\n                \n                \n                  31\n                  178\n                \n                \n                  32\n                  169\n                \n                \n                  33\n                  168\n                \n                \n                  34\n                  177\n                \n                \n                  35\n                  159\n                \n                \n                  36\n                  156\n                \n                \n                  37\n                  152\n                \n                \n                  38\n                  127\n                \n                \n                  39\n                  135\n                \n                \n                  40\n                  114\n                \n                \n                  41\n                  117\n                \n                \n                  42\n                  95\n                \n                \n                  43\n                  89\n                \n                \n                  44\n                  83\n                \n                \n                  45\n                  112\n                \n                \n                  46\n                  88\n                \n                \n                  47\n                  97\n                \n                \n                  48\n                  83\n                \n                \n                  49\n                  79\n                \n                \n                  50\n                  79\n                \n                \n                  51\n                  72\n                \n                \n                  52\n                  65\n                \n                \n                  53\n                  60\n                \n                \n                  54\n                  50\n                \n                \n                  55\n                  51\n                \n                \n                  56\n                  60\n                \n                \n                  57\n                  47\n                \n                \n                  58\n                  50\n                \n                \n                  59\n                  52\n                \n                \n                  60\n                  35\n                \n                \n                  61\n                  35\n                \n                \n                  62\n                  32\n                \n                \n                  63\n                  24\n                \n                \n                  64\n                  18\n                \n                \n                  65\n                  21\n                \n                \n                  67\n                  17\n                \n                \n                  68\n                  13\n                \n                \n                  69\n                  14\n                \n                \n                  70\n                  9\n                \n                \n                  71\n                  7\n                \n                \n                  72\n                  5\n                \n                \n                  73\n                  4\n                \n                \n                  74\n                  5\n                \n                \n                  75\n                  4\n                \n                \n                  76\n                  8\n                \n                \n                  78\n                  1\n                \n                \n                  79\n                  4\n                \n                \n                  80\n                  2\n                \n                \n                  81\n                  2\n                \n                \n                  82\n                  1\n                \n                \n                  83\n                  2\n                \n                \n                  84\n                  4\n                \n                \n                  91\n                  2\n                \n        \n      \n    \n\n\n\n\n\n\n\npolice_shootings_mod1 %&gt;% \ngf_bar(~ fct_infreq(race), fill = \"skyblue\") %&gt;%\n  gf_labs(\n     x = \"Race\",\n    y = \"Number of victims\",\n    title = \"Race distribution of victims\")\n\n\n\n\n\n\n\n\n\n\n\nWhite individuals represent the majority (about half) of police shooting victims\nBlack individuals are the second largest group (about 1/4th), approximately half the frequency of White victims, followed by Hispanics\nAsian, Native, and Other racial groups collectively represent only 4% of total incidents\n\n\n\n\n\nThe data suggests potential racial disparities in police shooting incidents\nThe 2:1 ratio between White and Black victims may indicate either population distribution patterns or systemic factors\nWhen adjusted for population demographics, Black individuals may experience higher per-capita rates of police shootings\n\n\n\n\n\n\npolice_shootings_mod1 %&gt;% \ngf_bar(~ gender, fill = \"steelblue\") %&gt;%\n  gf_labs(\n     x = \"Gender\",\n    y = \"Number of victims\",\n    title = \"Gender distribution of victims\")\n\n\n\n\n\n\n\n\n\n\n\nThe gender disparity is extreme, with males being about 20 time more to be involved in police shootings than females\n\n\n\n\nMales are disproportionately involved in situations that are critical and need the use of deadly force, potentially due to:\n\nHigher rates of violent crime commission\nDifferent patterns of resistance or confrontation with law enforcement\nOccupational exposure (certain professions with police interaction)\n\n\n\n\n\n\npolice_shootings_mod1 %&gt;% \n  count(age) %&gt;% \ngf_line(n ~ age, colour = \"navyblue\") %&gt;%\n  gf_labs(\n     x = \"Age\",\n    y = \"Number of victims\",\n    title = \"Age distribution of victims\") %&gt;% \n  gf_refine(\n    scale_x_continuous(breaks = seq(0, 100, 5)) \n  )\n\n\n\n\n\n\n\n\n\n\n\n\nThere is a strongconcentrationofage between 20-40 years old, with peak incidence at ages 25-35\nThere is a sharpincrease from teenage years, peaking in mid-to-late 20s, then a gradual decline after age 35\nElderly victims are rare but present, with incidents documented up to age 91\n\n\n\n\n\nThe peak in late 20s and 30s aligns with ages of highest criminal offense rates and police encounters\nThis suggests that most incidents occur during police responses to criminal activity\n\n\n\n\n\n# Manner of Death\npolice_shootings_mod1 %&gt;%\n  dplyr::count(manner_of_death) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                manner_of_death\n                n\n              \n        \n        \n        \n                \n                  shot\n                  4829\n                \n                \n                  shot and Tasered\n                  277\n                \n        \n      \n    \n\n\n# Armed status\npolice_shootings_mod1 %&gt;%\n  dplyr::count(armed) %&gt;%\n  arrange(desc(n)) %&gt;% \n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                armed\n                n\n              \n        \n        \n        \n                \n                  gun\n                  3008\n                \n                \n                  knife\n                  780\n                \n                \n                  unarmed\n                  390\n                \n                \n                  toy weapon\n                  193\n                \n                \n                  vehicle\n                  168\n                \n                \n                  undetermined\n                  95\n                \n                \n                  unknown weapon\n                  55\n                \n                \n                  machete\n                  44\n                \n                \n                  Taser\n                  27\n                \n                \n                  sword\n                  22\n                \n                \n                  baseball bat\n                  17\n                \n                \n                  ax\n                  16\n                \n                \n                  hammer\n                  16\n                \n                \n                  gun and vehicle\n                  15\n                \n                \n                  gun and knife\n                  14\n                \n                \n                  metal pipe\n                  14\n                \n                \n                  screwdriver\n                  13\n                \n                \n                  box cutter\n                  12\n                \n                \n                  sharp object\n                  12\n                \n                \n                  hatchet\n                  11\n                \n                \n                  BB gun\n                  9\n                \n                \n                  gun and car\n                  9\n                \n                \n                  scissors\n                  8\n                \n                \n                  piece of wood\n                  7\n                \n                \n                  pipe\n                  6\n                \n                \n                  rock\n                  6\n                \n                \n                  shovel\n                  6\n                \n                \n                  blunt object\n                  5\n                \n                \n                  crossbow\n                  5\n                \n                \n                  meat cleaver\n                  5\n                \n                \n                  straight edge razor\n                  5\n                \n                \n                  vehicle and gun\n                  5\n                \n                \n                  baton\n                  4\n                \n                \n                  chair\n                  4\n                \n                \n                  crowbar\n                  4\n                \n                \n                  metal pole\n                  4\n                \n                \n                  pick-axe\n                  4\n                \n                \n                  samurai sword\n                  4\n                \n                \n                  chain\n                  3\n                \n                \n                  guns and explosives\n                  3\n                \n                \n                  metal object\n                  3\n                \n                \n                  metal stick\n                  3\n                \n                \n                  pellet gun\n                  3\n                \n                \n                  pole\n                  3\n                \n                \n                  Airsoft pistol\n                  2\n                \n                \n                  beer bottle\n                  2\n                \n                \n                  brick\n                  2\n                \n                \n                  flashlight\n                  2\n                \n                \n                  glass shard\n                  2\n                \n                \n                  gun and machete\n                  2\n                \n                \n                  hatchet and gun\n                  2\n                \n                \n                  lawn mower blade\n                  2\n                \n                \n                  metal hand tool\n                  2\n                \n                \n                  pitchfork\n                  2\n                \n                \n                  pole and knife\n                  2\n                \n                \n                  spear\n                  2\n                \n                \n                  tire iron\n                  2\n                \n                \n                  BB gun and vehicle\n                  1\n                \n                \n                  air conditioner\n                  1\n                \n                \n                  air pistol\n                  1\n                \n                \n                  barstool\n                  1\n                \n                \n                  baseball bat and bottle\n                  1\n                \n                \n                  baseball bat and fireplace poker\n                  1\n                \n                \n                  baseball bat and knife\n                  1\n                \n                \n                  bean-bag gun\n                  1\n                \n                \n                  binoculars\n                  1\n                \n                \n                  bottle\n                  1\n                \n                \n                  bow and arrow\n                  1\n                \n                \n                  car, knife and mace\n                  1\n                \n                \n                  carjack\n                  1\n                \n                \n                  chain saw\n                  1\n                \n                \n                  chainsaw\n                  1\n                \n                \n                  contractor's level\n                  1\n                \n                \n                  cordless drill\n                  1\n                \n                \n                  fireworks\n                  1\n                \n                \n                  flagpole\n                  1\n                \n                \n                  garden tool\n                  1\n                \n                \n                  grenade\n                  1\n                \n                \n                  gun and sword\n                  1\n                \n                \n                  hand torch\n                  1\n                \n                \n                  ice pick\n                  1\n                \n                \n                  incendiary device\n                  1\n                \n                \n                  knife and vehicle\n                  1\n                \n                \n                  machete and gun\n                  1\n                \n                \n                  metal rake\n                  1\n                \n                \n                  microphone\n                  1\n                \n                \n                  motorcycle\n                  1\n                \n                \n                  nail gun\n                  1\n                \n                \n                  oar\n                  1\n                \n                \n                  pen\n                  1\n                \n                \n                  pepper spray\n                  1\n                \n                \n                  railroad spikes\n                  1\n                \n                \n                  stapler\n                  1\n                \n                \n                  vehicle and machete\n                  1\n                \n                \n                  walking stick\n                  1\n                \n                \n                  wasp spray\n                  1\n                \n                \n                  wrench\n                  1\n                \n        \n      \n    \n\n\n# Flee Status\npolice_shootings_mod1 %&gt;%\n  dplyr::count(flee) %&gt;%\n  arrange(desc(n)) %&gt;% \n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                flee\n                n\n              \n        \n        \n        \n                \n                  Not fleeing\n                  3382\n                \n                \n                  Car\n                  775\n                \n                \n                  Foot\n                  754\n                \n                \n                  Other\n                  195\n                \n        \n      \n    \n\n\n# Threat Level\npolice_shootings_mod1 %&gt;%\n  dplyr::count(threat_level) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                threat_level\n                n\n              \n        \n        \n        \n                \n                  attack\n                  3371\n                \n                \n                  other\n                  1622\n                \n                \n                  undetermined\n                  113\n                \n        \n      \n    \n\n\n# Mental Health\npolice_shootings_mod1 %&gt;%\n  dplyr::count(signs_of_mental_illness) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                signs_of_mental_illness\n                n\n              \n        \n        \n        \n                \n                  FALSE\n                  3872\n                \n                \n                  TRUE\n                  1234\n                \n        \n      \n    \n\n\n# Body Camera\npolice_shootings_mod1 %&gt;%\n  dplyr::count(body_camera) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                body_camera\n                n\n              \n        \n        \n        \n                \n                  FALSE\n                  4390\n                \n                \n                  TRUE\n                  716\n                \n        \n      \n    \n\n\n\n\n\n\nManner of death: Most victims are shot. Some had to be tasered, is there a specific reason (like weapon type, threat level or mental illness which led to the outcome?)\nArmed: Most victims were armed with guns, which explains the critical situation leading to being shot. This is followed by knifes and then unarmed\nFlee: The majority of victims were not fleeing when shot\nThreat level: About 2/3 of victims were perceived as attacking when shot\nSigns of mental illness: About 1/4th of the victims have the signs of mental illness\nBody camera: More than 75% of the victims don’t have body cameras.\n\n\n\n\n\n\nsummary(police_shootings_mod1)\n\n      date            manner_of_death       armed                age       \n Min.   :2015-01-02   Length:5106        Length:5106        Min.   : 6.00  \n 1st Qu.:2016-05-31   Class :character   Class :character   1st Qu.:27.00  \n Median :2018-01-11   Mode  :character   Mode  :character   Median :34.00  \n Mean   :2018-01-13                                         Mean   :36.58  \n 3rd Qu.:2019-08-14                                         3rd Qu.:45.00  \n Max.   :2021-06-25                                         Max.   :91.00  \n    gender              race               city              state          \n Length:5106        Length:5106        Length:5106        Length:5106       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n signs_of_mental_illness threat_level           flee           body_camera    \n Mode :logical           Length:5106        Length:5106        Mode :logical  \n FALSE:3872              Class :character   Class :character   FALSE:4390     \n TRUE :1234              Mode  :character   Mode  :character   TRUE :716      \n                                                                              \n                                                                              \n                                                                              \n\n\n\n\n\n\nThe data is logged from the year 2015 to 2021\nThe youngest victim is 6 years and goes up to the age of 91. Average age is 34 years"
  },
  {
    "objectID": "A2/DataSetsVerse/Police_shootings.html#building-hypothesis",
    "href": "A2/DataSetsVerse/Police_shootings.html#building-hypothesis",
    "title": "Police Shootings Dataset",
    "section": "",
    "text": "police_shootings_mod1 %&gt;% \n    count(across(c(\"gender\", \"race\"))) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                gender\n                race\n                n\n              \n        \n        \n        \n                \n                  F\n                  A\n                  4\n                \n                \n                  F\n                  B\n                  48\n                \n                \n                  F\n                  H\n                  29\n                \n                \n                  F\n                  N\n                  5\n                \n                \n                  F\n                  O\n                  3\n                \n                \n                  F\n                  W\n                  157\n                \n                \n                  M\n                  A\n                  89\n                \n                \n                  M\n                  B\n                  1315\n                \n                \n                  M\n                  H\n                  902\n                \n                \n                  M\n                  N\n                  73\n                \n                \n                  M\n                  O\n                  39\n                \n                \n                  M\n                  W\n                  2442\n                \n        \n      \n    \n\n\n\n\npolice_shootings_mod1 %&gt;% \ngf_bar(~ fct_infreq(race), \n       fill = ~gender, \n       position = \"dodge\") %&gt;%\n  gf_labs(\n     x = \"Race\",\n    y = \"Number of vicyims\",\n    title = \"Race distribution of victims by Gender\")\n\n\n\n\n\n\n\n\n\n\n\n\nThe proportion of females are distinctly less, hence there is not much association between the two\nThe data supports sociological patterns where males tend towards confrontational behaviors and are overrepresented in situations likely to escalate to lethal force\n\n\n\n\n\npolice_shootings_mod1 %&gt;% \n  gf_density(~age, color = ~race, fill = ~race, alpha = 0.2) %&gt;%\n  gf_labs(\n    title = \"Age Distribution by Race\",\n    x = \"Age\",\n    y = \"Density\"\n  )%&gt;%\n  gf_refine(\n    scale_x_continuous(breaks = seq(0, 100, 5))\n  )\n\n\n\n\n\n\n\n\n\npolice_shootings_mod1 %&gt;% \n    count(across(c(\"age\", \"race\"))) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                age\n                race\n                n\n              \n        \n        \n        \n                \n                  6\n                  W\n                  2\n                \n                \n                  12\n                  W\n                  1\n                \n                \n                  13\n                  B\n                  1\n                \n                \n                  13\n                  H\n                  1\n                \n                \n                  14\n                  H\n                  2\n                \n                \n                  14\n                  N\n                  1\n                \n                \n                  15\n                  A\n                  1\n                \n                \n                  15\n                  B\n                  5\n                \n                \n                  15\n                  H\n                  3\n                \n                \n                  15\n                  W\n                  3\n                \n                \n                  16\n                  A\n                  2\n                \n                \n                  16\n                  B\n                  11\n                \n                \n                  16\n                  H\n                  6\n                \n                \n                  16\n                  W\n                  10\n                \n                \n                  17\n                  B\n                  23\n                \n                \n                  17\n                  H\n                  12\n                \n                \n                  17\n                  W\n                  16\n                \n                \n                  18\n                  A\n                  3\n                \n                \n                  18\n                  B\n                  48\n                \n                \n                  18\n                  H\n                  23\n                \n                \n                  18\n                  N\n                  1\n                \n                \n                  18\n                  O\n                  3\n                \n                \n                  18\n                  W\n                  22\n                \n                \n                  19\n                  A\n                  2\n                \n                \n                  19\n                  B\n                  39\n                \n                \n                  19\n                  H\n                  14\n                \n                \n                  19\n                  N\n                  2\n                \n                \n                  19\n                  W\n                  27\n                \n                \n                  20\n                  A\n                  2\n                \n                \n                  20\n                  B\n                  32\n                \n                \n                  20\n                  H\n                  14\n                \n                \n                  20\n                  N\n                  2\n                \n                \n                  20\n                  O\n                  2\n                \n                \n                  20\n                  W\n                  29\n                \n                \n                  21\n                  A\n                  2\n                \n                \n                  21\n                  B\n                  48\n                \n                \n                  21\n                  H\n                  26\n                \n                \n                  21\n                  N\n                  2\n                \n                \n                  21\n                  W\n                  27\n                \n                \n                  22\n                  A\n                  2\n                \n                \n                  22\n                  B\n                  43\n                \n                \n                  22\n                  H\n                  37\n                \n                \n                  22\n                  N\n                  1\n                \n                \n                  22\n                  O\n                  2\n                \n                \n                  22\n                  W\n                  35\n                \n                \n                  23\n                  A\n                  1\n                \n                \n                  23\n                  B\n                  50\n                \n                \n                  23\n                  H\n                  24\n                \n                \n                  23\n                  N\n                  2\n                \n                \n                  23\n                  O\n                  1\n                \n                \n                  23\n                  W\n                  48\n                \n                \n                  24\n                  B\n                  61\n                \n                \n                  24\n                  H\n                  30\n                \n                \n                  24\n                  N\n                  4\n                \n                \n                  24\n                  O\n                  1\n                \n                \n                  24\n                  W\n                  57\n                \n                \n                  25\n                  A\n                  2\n                \n                \n                  25\n                  B\n                  66\n                \n                \n                  25\n                  H\n                  31\n                \n                \n                  25\n                  N\n                  5\n                \n                \n                  25\n                  O\n                  3\n                \n                \n                  25\n                  W\n                  75\n                \n                \n                  26\n                  A\n                  4\n                \n                \n                  26\n                  B\n                  36\n                \n                \n                  26\n                  H\n                  33\n                \n                \n                  26\n                  N\n                  1\n                \n                \n                  26\n                  O\n                  1\n                \n                \n                  26\n                  W\n                  70\n                \n                \n                  27\n                  A\n                  3\n                \n                \n                  27\n                  B\n                  65\n                \n                \n                  27\n                  H\n                  41\n                \n                \n                  27\n                  N\n                  7\n                \n                \n                  27\n                  O\n                  3\n                \n                \n                  27\n                  W\n                  64\n                \n                \n                  28\n                  A\n                  4\n                \n                \n                  28\n                  B\n                  58\n                \n                \n                  28\n                  H\n                  41\n                \n                \n                  28\n                  N\n                  3\n                \n                \n                  28\n                  O\n                  1\n                \n                \n                  28\n                  W\n                  57\n                \n                \n                  29\n                  A\n                  1\n                \n                \n                  29\n                  B\n                  50\n                \n                \n                  29\n                  H\n                  38\n                \n                \n                  29\n                  N\n                  2\n                \n                \n                  29\n                  O\n                  3\n                \n                \n                  29\n                  W\n                  74\n                \n                \n                  30\n                  A\n                  1\n                \n                \n                  30\n                  B\n                  47\n                \n                \n                  30\n                  H\n                  28\n                \n                \n                  30\n                  N\n                  2\n                \n                \n                  30\n                  O\n                  3\n                \n                \n                  30\n                  W\n                  81\n                \n                \n                  31\n                  A\n                  2\n                \n                \n                  31\n                  B\n                  60\n                \n                \n                  31\n                  H\n                  26\n                \n                \n                  31\n                  N\n                  2\n                \n                \n                  31\n                  O\n                  1\n                \n                \n                  31\n                  W\n                  87\n                \n                \n                  32\n                  A\n                  4\n                \n                \n                  32\n                  B\n                  49\n                \n                \n                  32\n                  H\n                  28\n                \n                \n                  32\n                  N\n                  6\n                \n                \n                  32\n                  O\n                  1\n                \n                \n                  32\n                  W\n                  81\n                \n                \n                  33\n                  A\n                  2\n                \n                \n                  33\n                  B\n                  49\n                \n                \n                  33\n                  H\n                  35\n                \n                \n                  33\n                  N\n                  3\n                \n                \n                  33\n                  O\n                  1\n                \n                \n                  33\n                  W\n                  78\n                \n                \n                  34\n                  A\n                  3\n                \n                \n                  34\n                  B\n                  39\n                \n                \n                  34\n                  H\n                  35\n                \n                \n                  34\n                  N\n                  3\n                \n                \n                  34\n                  O\n                  2\n                \n                \n                  34\n                  W\n                  95\n                \n                \n                  35\n                  A\n                  6\n                \n                \n                  35\n                  B\n                  39\n                \n                \n                  35\n                  H\n                  39\n                \n                \n                  35\n                  N\n                  3\n                \n                \n                  35\n                  W\n                  72\n                \n                \n                  36\n                  A\n                  3\n                \n                \n                  36\n                  B\n                  29\n                \n                \n                  36\n                  H\n                  31\n                \n                \n                  36\n                  N\n                  4\n                \n                \n                  36\n                  O\n                  2\n                \n                \n                  36\n                  W\n                  87\n                \n                \n                  37\n                  A\n                  2\n                \n                \n                  37\n                  B\n                  41\n                \n                \n                  37\n                  H\n                  41\n                \n                \n                  37\n                  N\n                  2\n                \n                \n                  37\n                  W\n                  66\n                \n                \n                  38\n                  A\n                  3\n                \n                \n                  38\n                  B\n                  28\n                \n                \n                  38\n                  H\n                  34\n                \n                \n                  38\n                  N\n                  1\n                \n                \n                  38\n                  O\n                  1\n                \n                \n                  38\n                  W\n                  60\n                \n                \n                  39\n                  A\n                  2\n                \n                \n                  39\n                  B\n                  43\n                \n                \n                  39\n                  H\n                  26\n                \n                \n                  39\n                  N\n                  2\n                \n                \n                  39\n                  W\n                  62\n                \n                \n                  40\n                  A\n                  1\n                \n                \n                  40\n                  B\n                  21\n                \n                \n                  40\n                  H\n                  21\n                \n                \n                  40\n                  N\n                  1\n                \n                \n                  40\n                  O\n                  1\n                \n                \n                  40\n                  W\n                  69\n                \n                \n                  41\n                  A\n                  2\n                \n                \n                  41\n                  B\n                  27\n                \n                \n                  41\n                  H\n                  19\n                \n                \n                  41\n                  N\n                  1\n                \n                \n                  41\n                  O\n                  1\n                \n                \n                  41\n                  W\n                  67\n                \n                \n                  42\n                  A\n                  2\n                \n                \n                  42\n                  B\n                  16\n                \n                \n                  42\n                  H\n                  18\n                \n                \n                  42\n                  N\n                  1\n                \n                \n                  42\n                  O\n                  1\n                \n                \n                  42\n                  W\n                  57\n                \n                \n                  43\n                  A\n                  1\n                \n                \n                  43\n                  B\n                  19\n                \n                \n                  43\n                  H\n                  9\n                \n                \n                  43\n                  N\n                  4\n                \n                \n                  43\n                  W\n                  56\n                \n                \n                  44\n                  A\n                  3\n                \n                \n                  44\n                  B\n                  13\n                \n                \n                  44\n                  H\n                  17\n                \n                \n                  44\n                  N\n                  2\n                \n                \n                  44\n                  W\n                  48\n                \n                \n                  45\n                  A\n                  2\n                \n                \n                  45\n                  B\n                  18\n                \n                \n                  45\n                  H\n                  21\n                \n                \n                  45\n                  N\n                  1\n                \n                \n                  45\n                  O\n                  1\n                \n                \n                  45\n                  W\n                  69\n                \n                \n                  46\n                  A\n                  1\n                \n                \n                  46\n                  B\n                  18\n                \n                \n                  46\n                  H\n                  17\n                \n                \n                  46\n                  N\n                  1\n                \n                \n                  46\n                  O\n                  1\n                \n                \n                  46\n                  W\n                  50\n                \n                \n                  47\n                  A\n                  2\n                \n                \n                  47\n                  B\n                  22\n                \n                \n                  47\n                  H\n                  13\n                \n                \n                  47\n                  W\n                  60\n                \n                \n                  48\n                  A\n                  2\n                \n                \n                  48\n                  B\n                  18\n                \n                \n                  48\n                  H\n                  8\n                \n                \n                  48\n                  O\n                  2\n                \n                \n                  48\n                  W\n                  53\n                \n                \n                  49\n                  A\n                  2\n                \n                \n                  49\n                  B\n                  13\n                \n                \n                  49\n                  H\n                  9\n                \n                \n                  49\n                  N\n                  1\n                \n                \n                  49\n                  W\n                  54\n                \n                \n                  50\n                  A\n                  2\n                \n                \n                  50\n                  B\n                  11\n                \n                \n                  50\n                  H\n                  12\n                \n                \n                  50\n                  N\n                  1\n                \n                \n                  50\n                  W\n                  53\n                \n                \n                  51\n                  A\n                  1\n                \n                \n                  51\n                  B\n                  9\n                \n                \n                  51\n                  H\n                  9\n                \n                \n                  51\n                  N\n                  1\n                \n                \n                  51\n                  O\n                  1\n                \n                \n                  51\n                  W\n                  51\n                \n                \n                  52\n                  A\n                  2\n                \n                \n                  52\n                  B\n                  11\n                \n                \n                  52\n                  H\n                  11\n                \n                \n                  52\n                  W\n                  41\n                \n                \n                  53\n                  A\n                  3\n                \n                \n                  53\n                  B\n                  6\n                \n                \n                  53\n                  H\n                  2\n                \n                \n                  53\n                  N\n                  1\n                \n                \n                  53\n                  W\n                  48\n                \n                \n                  54\n                  A\n                  1\n                \n                \n                  54\n                  B\n                  6\n                \n                \n                  54\n                  H\n                  3\n                \n                \n                  54\n                  N\n                  1\n                \n                \n                  54\n                  O\n                  1\n                \n                \n                  54\n                  W\n                  38\n                \n                \n                  55\n                  A\n                  2\n                \n                \n                  55\n                  B\n                  11\n                \n                \n                  55\n                  H\n                  9\n                \n                \n                  55\n                  W\n                  29\n                \n                \n                  56\n                  A\n                  1\n                \n                \n                  56\n                  B\n                  5\n                \n                \n                  56\n                  H\n                  3\n                \n                \n                  56\n                  O\n                  1\n                \n                \n                  56\n                  W\n                  50\n                \n                \n                  57\n                  B\n                  10\n                \n                \n                  57\n                  H\n                  6\n                \n                \n                  57\n                  W\n                  31\n                \n                \n                  58\n                  B\n                  3\n                \n                \n                  58\n                  H\n                  4\n                \n                \n                  58\n                  N\n                  1\n                \n                \n                  58\n                  W\n                  42\n                \n                \n                  59\n                  A\n                  1\n                \n                \n                  59\n                  B\n                  2\n                \n                \n                  59\n                  H\n                  4\n                \n                \n                  59\n                  O\n                  1\n                \n                \n                  59\n                  W\n                  44\n                \n                \n                  60\n                  A\n                  3\n                \n                \n                  60\n                  B\n                  6\n                \n                \n                  60\n                  H\n                  1\n                \n                \n                  60\n                  W\n                  25\n                \n                \n                  61\n                  A\n                  1\n                \n                \n                  61\n                  B\n                  9\n                \n                \n                  61\n                  H\n                  1\n                \n                \n                  61\n                  W\n                  24\n                \n                \n                  62\n                  A\n                  1\n                \n                \n                  62\n                  B\n                  4\n                \n                \n                  62\n                  H\n                  3\n                \n                \n                  62\n                  W\n                  24\n                \n                \n                  63\n                  B\n                  6\n                \n                \n                  63\n                  H\n                  1\n                \n                \n                  63\n                  W\n                  17\n                \n                \n                  64\n                  B\n                  2\n                \n                \n                  64\n                  H\n                  1\n                \n                \n                  64\n                  W\n                  15\n                \n                \n                  65\n                  B\n                  2\n                \n                \n                  65\n                  H\n                  3\n                \n                \n                  65\n                  W\n                  16\n                \n                \n                  67\n                  B\n                  5\n                \n                \n                  67\n                  W\n                  12\n                \n                \n                  68\n                  B\n                  5\n                \n                \n                  68\n                  W\n                  8\n                \n                \n                  69\n                  B\n                  1\n                \n                \n                  69\n                  H\n                  3\n                \n                \n                  69\n                  W\n                  10\n                \n                \n                  70\n                  B\n                  1\n                \n                \n                  70\n                  H\n                  1\n                \n                \n                  70\n                  W\n                  7\n                \n                \n                  71\n                  H\n                  1\n                \n                \n                  71\n                  W\n                  6\n                \n                \n                  72\n                  B\n                  1\n                \n                \n                  72\n                  W\n                  4\n                \n                \n                  73\n                  H\n                  1\n                \n                \n                  73\n                  W\n                  3\n                \n                \n                  74\n                  B\n                  2\n                \n                \n                  74\n                  W\n                  3\n                \n                \n                  75\n                  W\n                  4\n                \n                \n                  76\n                  W\n                  8\n                \n                \n                  78\n                  W\n                  1\n                \n                \n                  79\n                  W\n                  4\n                \n                \n                  80\n                  H\n                  1\n                \n                \n                  80\n                  W\n                  1\n                \n                \n                  81\n                  W\n                  2\n                \n                \n                  82\n                  W\n                  1\n                \n                \n                  83\n                  W\n                  2\n                \n                \n                  84\n                  W\n                  4\n                \n                \n                  91\n                  W\n                  2\n                \n        \n      \n    \n\n\n\n\npolice_shootings_mod1 %&gt;% \ngf_boxplot(age ~ race, fill = ~race, orientation = \"x\") %&gt;%\n  gf_labs(\n    x = \"Race\",\n    y = \"Age\",\n    title = \"Age distribution across Races\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nBlack and Others are usually younger in age\nWhite and Asian victims are more spread out and Whites have higher median age\nHispanics have 2 peaks in their age - around 25s and 40s\nBlacks and Natives show a distinct peak at around 25 and 30 respectively\n\n\n\n\n\nBlack & Natives: Young adulthood is the highest danger period, likely linked to street policing and urban violence exposure\nWhite & Asian Pattern: Risk spreads across all adult ages, suggesting more varied incidents like mental health crises, domestic disputes, and elderly situations\nHispanics: Two different risk groups are seen in younger and older people\n\n\n\n\n\n\n# Race vs. Manner of Death\nvcd::structable(race ~ manner_of_death, data = police_shootings_mod1) %&gt;%\n  as.matrix() %&gt;%\n  addmargins() %&gt;%\n  as_tibble(rownames = \"Race\")\n\n# A tibble: 3 × 8\n  Race                 A     B     H     N     O     W   Sum\n  &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 shot                85  1283   878    74    38  2471  4829\n2 shot and Tasered     8    80    53     4     4   128   277\n3 Sum                 93  1363   931    78    42  2599  5106\n\nvcd::structable(race ~ manner_of_death, data = police_shootings_mod1) %&gt;%\n  vcd::mosaic(shade = TRUE, legend = TRUE,\n              main = \"Race vs. Manner of Death\",\n              gp = shading_max)\n\n\n\n\n\n\n\n# Gender vs. Manner of Death\nvcd::structable(gender ~ manner_of_death, data = police_shootings_mod1) %&gt;%\n  as.matrix() %&gt;%\n  addmargins() %&gt;%\n  as_tibble(rownames = \"Gender\")\n\n# A tibble: 3 × 4\n  Gender               F     M   Sum\n  &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 shot               237  4592  4829\n2 shot and Tasered     9   268   277\n3 Sum                246  4860  5106\n\nvcd::structable(gender ~ manner_of_death, data = police_shootings_mod1) %&gt;%\n  vcd::mosaic(shade = TRUE, legend = TRUE,\n              main = \"Gender vs. Manner of Death\",\n              gp = shading_max)\n\n\n\n\n\n\n\n# Manner of Death vs. Weapon type\npolice_shootings_mod1 %&gt;%\n  mutate(armed_top5 = fct_lump_n(armed, 5)) %&gt;%\n  vcd::structable(manner_of_death ~ armed_top5, data = .) %&gt;%\n  as.matrix() %&gt;%\n  addmargins() %&gt;%\n  as_tibble(rownames = \"Manner of Death\")\n\n# A tibble: 7 × 4\n  `Manner of Death`  shot `shot and Tasered`   Sum\n  &lt;chr&gt;             &lt;dbl&gt;              &lt;dbl&gt; &lt;dbl&gt;\n1 gun                2962                 46  3008\n2 knife               665                115   780\n3 toy weapon          190                  3   193\n4 unarmed             346                 44   390\n5 vehicle             167                  1   168\n6 Other               499                 68   567\n7 Sum                4829                277  5106\n\npolice_shootings_mod1 %&gt;%\n  mutate(armed_top5 = fct_lump_n(armed, 5)) %&gt;%\n  vcd::structable(manner_of_death ~ armed_top5, data = .) %&gt;%\n  vcd::mosaic(shade = TRUE, legend = TRUE,\n              main = \"Manner of Death vs. Top 5 Weapon Types\",\n              gp = shading_max)\n\n\n\n\n\n\n\n# Manner of Death vs. Threat level\nvcd::structable(manner_of_death ~ threat_level, data = police_shootings_mod1) %&gt;%\n  vcd::mosaic(shade = TRUE, legend = TRUE,\n              main = \"Manner of Death vs. Threat Level\",\n              gp = shading_max)\n\n\n\n\n\n\n\n# Manner of Death vs. Mental Illness\nvcd::structable(manner_of_death ~ signs_of_mental_illness, data = police_shootings_mod1) %&gt;%\n  vcd::mosaic(shade = TRUE, legend = TRUE,\n              main = \"Manner of Death vs. Mental Illness Signs\",\n              gp = shading_max)\n\n\n\n\n\n\n\n\n\n\n\n\nRace and Gender don’t have any distinct association with the manner of death\nVictims having gun and those perceived as threatening, show a distinct negative correlation with being shot and tasered meaning some distance had to be maintained\nThose who are armed with knife, show positive correlation being shot and tasered\nVictims showing signs of mental illness shows have a positive correlation with being shot and tasered\n\n\n\n\n\nWeapon type and mental state determine police tactics. Guns trigger immediate lethal response, while other weapons/conditions allow for attempted intermediate options.\n\n\n\n\n\npolice_shootings_dates &lt;- police_shootings_mod1 %&gt;%\n  mutate(\n    year = as.numeric(format(date, \"%Y\")),\n    month = as.numeric(format(date, \"%m\"))\n  )\n\n\n# Yearly trend\npolice_shootings_dates %&gt;%\n  count(year) %&gt;%\n  gf_line(n ~ year, color = \"steelblue\", size = 1) %&gt;%\n  gf_point(color = \"steelblue\", size = 2) %&gt;%\n  gf_labs(\n    title = \"Yearly Trend in Police Shootings\",\n    x = \"Year\", \n    y = \"Number of Shootings\"\n  ) %&gt;%\n  gf_refine(\n    scale_x_continuous(breaks = unique(police_shootings_dates$year))\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n# Monthly trend\npolice_shootings_dates %&gt;%\n     mutate(\n    month = format(as.Date(date), \"%b\"),\n    month = factor(month, levels = month.abb)\n  ) %&gt;%\n  count(month) %&gt;%\n  gf_line(n ~ month, group = 1, color = \"dodgerblue\", size = 1) %&gt;%\n  gf_point(color = \"dodgerblue\", size = 2) %&gt;%\n  gf_labs(\n    title = \"Monthly Trend in Police Shootings\",\n    x = \"Month\",\n    y = \"Number of Shootings\"\n  ) %&gt;%\n  gf_theme(axis.text.x = element_text(angle = 0, hjust = 1))\n\n\n\n\n\n\n\n\n\npolice_shootings_mod1 %&gt;%\n  mutate(year = as.numeric(format(date, \"%Y\"))) %&gt;%\n  count(year, race) %&gt;%\n  gf_line(n ~ year, color = ~race) %&gt;%\n  gf_point(n ~ year, color = ~race) %&gt;%\n  gf_labs(title = \"Yearly Shooting Trends by Race\")\n\n\n\n\n\n\n\n\n\n\n\n\nksjeh\nksejrh\nksj\n\n\n\n\n\nsldfkj\nsldkfj\nsjdfh\n\n\n\n\nAssociation of age with fleeing and weapon type\n\npolice_shootings_mod1 %&gt;%\n  mutate(\n    flee = fct_infreq(flee),      \n    armed = fct_lump_n(armed, 5)\n  ) %&gt;%\n  gf_boxplot(age ~ flee,\n             fill = ~armed,\n             orientation = \"x\" ) %&gt;%\n  gf_labs(\n    title = \"Age Distribution by Flee type and Weapon status\",\n    x = \"Flee Type\",\n    y = \"Age of Victim\",\n    fill = \"Weapon Type\"\n  )\n\n\n\n\n\n\n\n\nAge distribution by Flee status\n\npolice_shootings_mod1 %&gt;%\n  gf_density(~age, color = ~flee, fill = ~flee, alpha = 0.3) %&gt;%\n  gf_labs(title = \"Age Distribution by Flee Status\") %&gt;%\n  gf_refine(\n    scale_color_brewer(palette = \"Set1\"),\n    scale_x_continuous(breaks = seq(0, 100, 5))\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nThose “Not fleeing” or fleeing by car appear slightly older on average than those fleeing on foot.\nMedian ages for “Not fleeing” and “Car” are higher, while “Foot” and “Other” categories have lower medians.\nGuns and knives dominate across all flee types.\nUnarmed individuals appear in every flee category, often with similar or slightly lower median ages compared to armed groups.\nThe variation is generally higher for armed individuals, indicating broader age diversity among armed victims.\nA few older individuals (60+) appear across all flee types, particularly in the “Not fleeing” group.\n\n\n\n\n\nThere is no strong age-flee interaction, but the slightly higher median ages among “Not fleeing” cases could indicate that older victims are less likely to attempt escape.\nThe consistent presence of unarmed victims across flee types highlights that weapon possession is not always tied to fleeing behavior.\nThe broad age spread, especially in “Not fleeing” cases, suggests police encounters affect a wide demographic, not limited to younger populations.\n\n\n\n\npolice_shootings_mod1 %&gt;%\n  mutate(year = as.numeric(format(date, \"%Y\"))) %&gt;%\n  gf_point(age ~ year, alpha = 0.5) %&gt;%\n  gf_lm(age ~ year) %&gt;%\n  gf_facet_wrap(~ race) %&gt;%\n  gf_labs(\n    title = \"Age Distribution Over Years by Race\",\n    x = \"Year\",\n    y = \"Age\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nAcross all racial groups , most victims fall in the 25–45 age range, with only slight variations.\nThe median age remains relatively stable over time (2015–2020) with no significant increase or decrease in any group.\nWhite and Black individuals have the highest representation and wider spread in age distribution.\nOther races (Asian, Native, Hispanic, etc.) show smaller sample sizes and thus more variability.\n\n\npolice_shootings_mod1 %&gt;%\n  count(city, state) %&gt;%\n  arrange(desc(n)) %&gt;%\n  head(15) %&gt;%  # Top 15 locations\n  unite(location, city, state, sep = \", \") %&gt;%\n  select(location) %&gt;%\n  inner_join(police_shootings_mod1 %&gt;% \n              unite(location, city, state, sep = \", \"), \n            by = \"location\") %&gt;%\n  gf_boxplot(age ~ fct_reorder(location, age), fill = \"forestgreen\", orientation = \"x\") %&gt;%\n  gf_labs(\n    title = \"Age Distribution by Location (Top 15 Cities)\",\n    x = \"City, State\",\n    y = \"Age\"\n  ) %&gt;%\n  gf_theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\nSome cities like Chicago, Columbus, and St. Louis have younger victims, while Miami and Las Vegas show slightly higher medians.\nThe spread varies, larger in cities like Los Angeles and Jacksonville, suggesting more diverse victim age groups there.\n\n\n\n\n\npolice_shootings_mod1 %&gt;%\n  count(city, state) %&gt;%\n  arrange(desc(n)) %&gt;%\n  head(30) %&gt;%  # Taking top 30 locations\n  unite(location, city, state, sep = \", \") %&gt;%\n  gf_point(n ~ fct_reorder(location, n), size = ~n, color = \"red\") %&gt;%\n  gf_labs(\n    title = \"Police Shootings by Location\",\n    x = \"City, State\",\n    y = \"Number of Shootings\"\n  ) %&gt;%\n  gf_theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\nLos Angeles, CA reports the highest number of police shootings, followed by Phoenix, AZ, Houston, TX, and Las Vegas, NV.\nThe distribution is right-skewed where a few major cities account for a disproportionately large share of total shootings.\nMany smaller or mid-size cities (e.g., Colorado Springs, Charlotte) have fewer than 20 recorded incidents.\n\n\n\n\n\nPolice shootings predominantly involve young to middle-aged individuals (25–40 years old) across most races and cities, with no major age trend changes over time. However, incidents are geographically concentrated, a small number of large urban centers (like Los Angeles and Phoenix) account for the bulk of cases, indicating regional disparities that may be tied to population density, policing intensity, or systemic factors.\n\n\n\n\n\npolice_shootings_mod1 %&gt;%\n  count(city, state, threat_level) %&gt;%\n  group_by(city, state) %&gt;%\n  mutate(total = sum(n)) %&gt;%\n  filter(total &gt;= 10) %&gt;%  # Cities with 10+ incidents\n  ungroup() %&gt;%\n  arrange(desc(total)) %&gt;%\n  head(50) %&gt;%\n  unite(location, city, state, sep = \", \") %&gt;%\n  gf_col(n ~ location, fill = ~threat_level, position = \"fill\") %&gt;%\n  gf_theme(axis.text.x = element_text(angle = 90, hjust = 1)) %&gt;%\n  gf_labs(title = \"Threat Level Distribution by City\")\n\n\n\n\n\n\n\n\n\n\n\n\nAcross most cities, the attack threat level dominates, with smaller proportions of other and undetermined cases.\nCities like Los Angeles, Phoenix, and San Antonio show particularly high instances of attack classified incidents, while places like Columbus and Jacksonville have slightly higher variation across categories.\n\n\n\n\n\nThis suggests that police encounters in many urban centers are predominantly categorized as threats requiring lethal or aggressive response levels.\nThe consistency across locations might indicate uniform policy interpretation rather than contextual variations in local threat assessment.\n\n\n\n\n\npolice_shootings_mod1 %&gt;%\n  mutate(weapon_cat = fct_lump_n(armed, 6)) %&gt;%\n  count(race, weapon_cat) %&gt;%\n  group_by(race) %&gt;%\n  mutate(prop = n / sum(n)) %&gt;%\n  gf_tile(prop ~ race + weapon_cat) %&gt;%\n  gf_labs(\n    title = \"Weapon Type Distribution by Race\",\n    x = \"Race\",\n    y = \"Weapon Type\",\n    fill = \"Proportion\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nThe heatmap shows that guns are the most common weapon type across all racial groups, particularly pronounced among Black and White victims.\nNon-firearm weapons (like knives and toy weapons) appear far less frequently, with a few variations among racial groups.\n\n\n\n\n\nThis pattern could indicate both a systemic emphasis on firearm-related encounters and possible disparities in perceived weapon possession across racial groups.\nThe high prevalence of gun-related cases may also reflect broader accessibility and cultural factors related to weapon ownership.\n\n\npolice_shootings_mod1 %&gt;%\n  mutate(weapon_cat = fct_lump_n(armed, 5)) %&gt;%\n  count(weapon_cat, threat_level) %&gt;%\n  gf_col(n ~ weapon_cat, fill = ~threat_level, position = \"dodge\") %&gt;%\n  gf_labs(\n    title = \"Weapon Type vs Threat Level\",\n    x = \"Weapon Type\",\n    y = \"Count\",\n    fill = \"Threat Level\"\n  ) %&gt;%\n  gf_theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\nIndividuals categorized as notfleeing form the largest proportion across all weapon types, especially for guns, knives, and unarmed cases.\nVehicle-related cases show relatively more instances of fleeing by car, while foot fleeing is modestly present across some categories.\n\n\n\n\n\nThis could suggest that most encounters leading to recorded incidents occur when suspects are stationary or restrained rather than actively escaping. However, the relatively higher “car fleeing” in vehicle-related incidents might point to situational factors influencing pursuit and response dynamics.\n\n\npolice_shootings_mod1 %&gt;%\n  mutate(weapon_cat = fct_lump_n(armed, 8)) %&gt;%\n  count(weapon_cat, flee) %&gt;%\n  group_by(weapon_cat) %&gt;%\n  mutate(prop = n / sum(n)) %&gt;%\n  gf_col(prop ~ weapon_cat, fill = ~flee, position = \"fill\") %&gt;%\n  gf_labs(\n    title = \"Flee Behavior by Weapon Type\",\n    subtitle = \"Proportion of flee status for each weapon category\",\n    x = \"Weapon Type\",\n    y = \"Proportion\",\n    fill = \"Flee Status\"\n  ) %&gt;%\n  gf_theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\nGun-related incidents overwhelmingly fall under the attack threat level, followed by knives and unarmed cases at much lower frequencies.\nToy weapons and vehicles have very few attack classifications, and undetermined cases remain minimal overall.\n\n\n\n\n\nWeapons perceived as more dangerous (like firearms) are strongly associated with escalated threat responses. This pattern could imply that the presence of a gun, regardless of situation, significantly biases threat assessment, leading to higher rates of lethal force justification."
  },
  {
    "objectID": "A2/DataSetsVerse/Police_shootings.html#conclusion",
    "href": "A2/DataSetsVerse/Police_shootings.html#conclusion",
    "title": "Police Shootings Dataset",
    "section": "",
    "text": "Demographic Trends: Majority of victims are male (25–40 years); Black individuals face disproportionately higher risk relative to population size.\nSituational Insights: Most victims were armed, often with guns, but a notable share were unarmed or mentally ill, raising questions about threat assessment and escalation.\nBehavioral Patterns: Many were not fleeing, showing that fatal shootings often occur in static encounters, not active chases.\nThreat Perception: “Attack” is the most frequent threat label, especially when firearms are involved — suggesting strong bias toward perceiving high threat.\nGeographic Trends: Incidents cluster in urban hubs like Los Angeles, Houston, and Phoenix, showing concentration in large metro areas.\nThe data suggests that systemic patterns, not isolated incidents, underlie police shootings in the U.S. While armed confrontations explain part of the trend, biases in threat perception, inadequate handling of mental health crises, and regional concentration of incidents all point to the need for deeper structural reform."
  },
  {
    "objectID": "A2/Mongolia-Demoiselle-cranes/final.html",
    "href": "A2/Mongolia-Demoiselle-cranes/final.html",
    "title": "Demoiselle Crane Migration Route",
    "section": "",
    "text": "Mapping out the migration route of the Demoiselle Crane\nThe Demoiselle Crane (aka Anthropoides virgo) has the most remarkable migration pattern. Every year, it travels around thousands of kilometers between its breeding grounds in Central Eurasia (from Ukraine and Mongolia to China) and its wintering areas in India and Africa. It’s known for its elegance and graceful movements among the crane species. (Fun fact: Its also the smallest among the crane species!)"
  },
  {
    "objectID": "A2/Mongolia-Demoiselle-cranes/final.html#setup",
    "href": "A2/Mongolia-Demoiselle-cranes/final.html#setup",
    "title": "Demoiselle Crane Migration Route",
    "section": "Setup",
    "text": "Setup\n\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\n\n\nAttaching package: 'rnaturalearthdata'\n\n\nThe following object is masked from 'package:rnaturalearth':\n\n    countries110\n\n# Run this in your console first\n# devtools::install_github(\"ropensci/rnaturalearthhires\")\nlibrary(rnaturalearthhires)\n\n# Plotting Maps\nlibrary(tidyverse) # Maps using ggplot() + geom_sf()\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggformula) # Maps using gf_sf()\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(tmap) # Thematic Maps, static and interactive\nlibrary(tmaptools)\nlibrary(tmap.mapgl)\nlibrary(osmdata) # Fetch map data from osmdata.org\n\nData (c) OpenStreetMap contributors, ODbL 1.0. https://www.openstreetmap.org/copyright\n\nlibrary(sfheaders) # Handcrafted Map data\n## Interactive Maps\nlibrary(leaflet) # interactive Maps\nlibrary(leaflet)\nlibrary(leaflet.providers)\nlibrary(leaflet.extras)\nlibrary(threejs) # Globe maps in R. Part of the htmlwidgets family of packages\n\nLoading required package: igraph\n\nAttaching package: 'igraph'\n\nThe following objects are masked from 'package:lubridate':\n\n    %--%, union\n\nThe following objects are masked from 'package:dplyr':\n\n    as_data_frame, groups, union\n\nThe following objects are masked from 'package:purrr':\n\n    compose, simplify\n\nThe following object is masked from 'package:tidyr':\n\n    crossing\n\nThe following object is masked from 'package:tibble':\n\n    as_data_frame\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\nThe following object is masked from 'package:base':\n\n    union\n\n# For Spatial Data Frame Processing\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE"
  },
  {
    "objectID": "A2/Mongolia-Demoiselle-cranes/final.html#loading-world",
    "href": "A2/Mongolia-Demoiselle-cranes/final.html#loading-world",
    "title": "Demoiselle Crane Migration Route",
    "section": "Loading World",
    "text": "Loading World\n\ndata(World, package = \"tmap\")\nWorld %&gt;% filter(name == \"India\" | name ==\"Siberia\" | name ==\"Pakistan\" | name ==\"Kazakhstan\" | name == \"Mongolia\" | name == \"Uzbekistan\" | name == \"Kyrgyzstan\" | name == \"China\" | name == \"Afghanistan\") -&gt; bird_route\nbird_route\n\nSimple feature collection with 8 features and 17 fields\nAttribute-geometry relationships: constant (12), aggregate (3), identity (2)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 46.466 ymin: 7.966 xmax: 135.026 ymax: 55.385\nGeodetic CRS:  WGS 84\n  iso_a3        name  sovereignt continent             area    pop_est\n1    AFG Afghanistan Afghanistan      Asia  642393.2 [km^2]   38041754\n2    CHN       China       China      Asia 9373438.5 [km^2] 1397715000\n3    IND       India       India      Asia 3158320.3 [km^2] 1366417754\n4    KAZ  Kazakhstan  Kazakhstan      Asia 2706355.2 [km^2]   18513930\n5    KGZ  Kyrgyzstan  Kyrgyzstan      Asia  198713.1 [km^2]    6456900\n6    MNG    Mongolia    Mongolia      Asia 1560539.0 [km^2]    3225167\n7    PAK    Pakistan    Pakistan      Asia  873936.6 [km^2]  216565318\n8    UZB  Uzbekistan  Uzbekistan      Asia  447178.8 [km^2]   33580650\n  pop_est_dens                   economy             income_grp gdp_cap_est\n1    59.218799 7. Least developed region          5. Low income    507.1007\n2   149.114436  3. Emerging region: BRIC 3. Upper middle income  10261.6792\n3   432.640658  3. Emerging region: BRIC 4. Lower middle income   2099.5987\n4     6.840909      6. Developing region 3. Upper middle income   9812.3413\n5    32.493580      6. Developing region          5. Low income   1309.2970\n6     2.066701      6. Developing region 4. Lower middle income   4339.6202\n7   247.804372   5. Emerging region: G20 4. Lower middle income   1284.6979\n8    75.094467      6. Developing region 4. Lower middle income   1724.8326\n  life_exp well_being footprint      HPI inequality gender press\n1   61.982   2.436034  1.139635 16.21067         NA  0.665 19.09\n2   78.211   5.862864  8.382514 41.91819       35.7  0.186 23.36\n3   67.240   3.558254  2.097628 27.84994       32.8  0.437 31.28\n4   69.362   6.259634 14.219707 29.37862       29.2  0.177 41.11\n5   69.977   5.563700  4.090139 41.38047       26.4  0.345 49.11\n6   70.975   5.721034 24.674600 20.39398       31.4  0.297 51.34\n7   66.098   4.486835  2.234078 33.69527       29.6  0.522 33.90\n8   70.862   6.185308  5.686355 43.00974       31.2  0.242 37.27\n                        geometry\n1 MULTIPOLYGON (((66.217 37.3...\n2 MULTIPOLYGON (((109.475 18....\n3 MULTIPOLYGON (((96.249 28.4...\n4 MULTIPOLYGON (((86.829 49.8...\n5 MULTIPOLYGON (((71.259 42.1...\n6 MULTIPOLYGON (((88.014 48.5...\n7 MULTIPOLYGON (((76.193 35.8...\n8 MULTIPOLYGON (((57.096 41.3...\n\nst_crs(bird_route) -&gt; crs_bird_route\ncrs_bird_route\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]"
  },
  {
    "objectID": "A2/Mongolia-Demoiselle-cranes/final.html#reading-the-shape-files",
    "href": "A2/Mongolia-Demoiselle-cranes/final.html#reading-the-shape-files",
    "title": "Demoiselle Crane Migration Route",
    "section": "Reading the shape files",
    "text": "Reading the shape files\n\nlines &lt;- st_read(\"C:/Users/diyab/OneDrive/Documents/DiyaData/A2/Mongolia-Demoiselle-cranes/files/lines.shp\")\n\nReading layer `lines' from data source \n  `C:\\Users\\diyab\\OneDrive\\Documents\\DiyaData\\A2\\Mongolia-Demoiselle-cranes\\files\\lines.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 19 features and 1 field\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 65.32627 ymin: 20.73 xmax: 116.9764 ymax: 53.8847\nGeodetic CRS:  WGS 84\n\n\n\npoints &lt;- st_read(\"C:/Users/diyab/OneDrive/Documents/DiyaData/A2/Mongolia-Demoiselle-cranes/files/points.shp\")\n\nReading layer `points' from data source \n  `C:\\Users\\diyab\\OneDrive\\Documents\\DiyaData\\A2\\Mongolia-Demoiselle-cranes\\files\\points.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 74380 features and 0 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 65.32627 ymin: 20.73 xmax: 116.9764 ymax: 53.8847\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "A2/Mongolia-Demoiselle-cranes/final.html#plotting",
    "href": "A2/Mongolia-Demoiselle-cranes/final.html#plotting",
    "title": "Demoiselle Crane Migration Route",
    "section": "Plotting",
    "text": "Plotting\n\nPoints\n\ngf_sf(data = bird_route, geometry = ~geometry, fill = \"white\", color = \"grey\") %&gt;%\n  gf_sf(data = points, geometry = ~geometry, size = 0.01, color = \"pink\") %&gt;% \n  gf_labs(title = \"Demoiselle Crane Migration Routes\")\n\n\n\n\n\n\n\n\n\n\nLines\n\ngf_sf(data = bird_route, geometry = ~geometry, fill = \"white\", color = \"grey\") %&gt;%\n  gf_sf(data = lines, geometry = ~geometry, size = 0.25, color = \"darkblue\") %&gt;%\n  gf_labs(title = \"Demoiselle Crane Migration Routes\")\n\n\n\n\n\n\n\n\n\n\nFinal Plot\n\ngf_sf(data = bird_route, geometry = ~geometry, fill = \"white\", color = \"grey\") %&gt;%\n  gf_sf(data = lines, geometry = ~geometry, size = 0.25, color = \"darkblue\") %&gt;%\n  gf_sf(data = points, geometry = ~geometry, size = 0.01, color = \"pink\") %&gt;% \n  gf_labs(title = \"Demoiselle Crane Migration Routes\")"
  },
  {
    "objectID": "A3/belief_in_god/god.html",
    "href": "A3/belief_in_god/god.html",
    "title": "What’s the proportion of people who believe in god?",
    "section": "",
    "text": "library(ggformula)\n\nLoading required package: ggplot2\n\n\nLoading required package: scales\n\n\nLoading required package: ggridges\n\n\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(naniar)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:naniar':\n\n    n_complete\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.1.0     ✔ tidyr     1.3.1\n✔ readr     2.1.5     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ mosaic::count()     masks dplyr::count()\n✖ purrr::cross()      masks mosaic::cross()\n✖ purrr::discard()    masks scales::discard()\n✖ mosaic::do()        masks dplyr::do()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ mosaic::stat()      masks ggplot2::stat()\n✖ mosaic::tally()     masks dplyr::tally()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tinytable)\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(visdat)\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(RColorBrewer)\nlibrary(naniar)\nlibrary(GGally)\nlibrary(ggplot2)\nlibrary(correlation)\n\n\nAttaching package: 'correlation'\n\nThe following object is masked from 'package:mosaic':\n\n    cor_test\n\nlibrary(dplyr)\nlibrary(RColorBrewer)\nlibrary(DT)\nlibrary(infer)\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(resampledata)\n\n\nAttaching package: 'resampledata'\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n\nlibrary(openintro)\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:GGally':\n\n    tips\n\nThe following object is masked from 'package:mosaic':\n\n    dotPlot\n\nThe following objects are masked from 'package:lattice':\n\n    ethanol, lsegments\n\nlibrary(vcd)\n\nLoading required package: grid\n\nAttaching package: 'vcd'\n\nThe following object is masked from 'package:mosaic':\n\n    mplot\n\nlibrary(visStatistics)"
  },
  {
    "objectID": "A3/belief_in_god/god.html#r-packages-setup",
    "href": "A3/belief_in_god/god.html#r-packages-setup",
    "title": "What’s the proportion of people who believe in god?",
    "section": "",
    "text": "library(ggformula)\n\nLoading required package: ggplot2\n\n\nLoading required package: scales\n\n\nLoading required package: ggridges\n\n\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(naniar)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:naniar':\n\n    n_complete\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.1.0     ✔ tidyr     1.3.1\n✔ readr     2.1.5     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ mosaic::count()     masks dplyr::count()\n✖ purrr::cross()      masks mosaic::cross()\n✖ purrr::discard()    masks scales::discard()\n✖ mosaic::do()        masks dplyr::do()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ mosaic::stat()      masks ggplot2::stat()\n✖ mosaic::tally()     masks dplyr::tally()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tinytable)\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(visdat)\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(RColorBrewer)\nlibrary(naniar)\nlibrary(GGally)\nlibrary(ggplot2)\nlibrary(correlation)\n\n\nAttaching package: 'correlation'\n\nThe following object is masked from 'package:mosaic':\n\n    cor_test\n\nlibrary(dplyr)\nlibrary(RColorBrewer)\nlibrary(DT)\nlibrary(infer)\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(resampledata)\n\n\nAttaching package: 'resampledata'\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n\nlibrary(openintro)\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:GGally':\n\n    tips\n\nThe following object is masked from 'package:mosaic':\n\n    dotPlot\n\nThe following objects are masked from 'package:lattice':\n\n    ethanol, lsegments\n\nlibrary(vcd)\n\nLoading required package: grid\n\nAttaching package: 'vcd'\n\nThe following object is masked from 'package:mosaic':\n\n    mplot\n\nlibrary(visStatistics)"
  },
  {
    "objectID": "A3/belief_in_god/god.html#reading-the-file",
    "href": "A3/belief_in_god/god.html#reading-the-file",
    "title": "What’s the proportion of people who believe in god?",
    "section": "Reading the file",
    "text": "Reading the file\n\nbelief &lt;- read.csv(\"5-believe_in_god.csv\")\nglimpse(belief)\n\nRows: 47\nColumns: 3\n$ Name           &lt;chr&gt; \"Sanjana\", \"Tathasthu\", \"Vaibhav\", \"Siddharth\", \"Ashik\"…\n$ Gender         &lt;chr&gt; \"Female\", \"Male\", \"Male\", \"Male\", \"Male\", \"Female\", \"Fe…\n$ Believe_in_God &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"…"
  },
  {
    "objectID": "A3/belief_in_god/god.html#munging",
    "href": "A3/belief_in_god/god.html#munging",
    "title": "What’s the proportion of people who believe in god?",
    "section": "Munging",
    "text": "Munging\n\nbelief_modified &lt;- belief %&gt;%\n  mutate(across(where(is.character), as.factor))%&gt;%\n  dplyr::relocate(where(is.factor), .after = Name)\nglimpse(belief_modified)\n\nRows: 47\nColumns: 3\n$ Name           &lt;fct&gt; Sanjana, Tathasthu, Vaibhav, Siddharth, Ashik, Kshirab,…\n$ Gender         &lt;fct&gt; Female, Male, Male, Male, Male, Female, Female, Female,…\n$ Believe_in_God &lt;fct&gt; Yes, Yes, Yes, Yes, No, Yes, Yes, No, Yes, No, NA, No, …"
  },
  {
    "objectID": "A3/belief_in_god/god.html#removing-missing-data",
    "href": "A3/belief_in_god/god.html#removing-missing-data",
    "title": "What’s the proportion of people who believe in god?",
    "section": "Removing Missing Data",
    "text": "Removing Missing Data\n\nbelief_modified2 &lt;- belief_modified %&gt;% drop_na()\nbelief_modified2\n\n                                   Name Gender Believe_in_God\n1                               Sanjana Female            Yes\n2                             Tathasthu   Male            Yes\n3                               Vaibhav   Male            Yes\n4                             Siddharth   Male            Yes\n5                                 Ashik   Male             No\n6                               Kshirab Female            Yes\n7                               Niyosha Female            Yes\n8                                Charvi Female             No\n9                                 Anoti Female            Yes\n10                                Dhruv   Male             No\n11                               Maanya Female             No\n12                               Aaksha Female            Yes\n13                                Adhil   Male             No\n14                              Aradhya   Male            Yes\n15                             Prathana Female            Yes\n16                              Ashmita Female            Yes\n17                               Ishita Female             No\n18                                Rishi   Male             No\n19 Arnav Kodhandapani  Anupama Srikanth   Male             No\n20                               Nitish   Male            Yes\n21                             Avanilka Female            Yes\n22                             Lakshita Female            Yes\n23                              Nandana Female            Yes\n24                              Mridula Female            Yes\n25                                Shiva   Male             No\n26                                 Diya Female            Yes\n27                              Kanishk   Male             No\n28                              Samaraj   Male            Yes\n29                                Nipun   Male            Yes\n30                            Vasudhara Female             No\n31                               Aditya   Male             No\n32                                Risha Female            Yes\n33                              Jashith   Male             No\n34                               Swetha Female            Yes\n35                                Rishi   Male            Yes\n36                                Manal Female            Yes\n37                              Shruthi Female            Yes\n38                               Aditya   Male             No\n39                              Ashmita Female             No\n40                             Krithika Female            Yes\n41                                 Diya Female            Yes"
  },
  {
    "objectID": "A3/belief_in_god/god.html#examining-the-data",
    "href": "A3/belief_in_god/god.html#examining-the-data",
    "title": "What’s the proportion of people who believe in god?",
    "section": "Examining the Data",
    "text": "Examining the Data\n\nbelief_modified2 %&gt;%\n  count(Believe_in_God)\n\n  Believe_in_God  n\n1             No 15\n2            Yes 26\n\n\n\nbelief_modified2 %&gt;%\n  group_by(Gender) %&gt;% \n  count(Believe_in_God)\n\n# A tibble: 4 × 3\n# Groups:   Gender [2]\n  Gender Believe_in_God     n\n  &lt;fct&gt;  &lt;fct&gt;          &lt;int&gt;\n1 Female No                 5\n2 Female Yes               18\n3 Male   No                10\n4 Male   Yes                8"
  },
  {
    "objectID": "A3/belief_in_god/god.html#visualising-data",
    "href": "A3/belief_in_god/god.html#visualising-data",
    "title": "What’s the proportion of people who believe in god?",
    "section": "Visualising Data",
    "text": "Visualising Data\n\nbelief_modified2 %&gt;%\n  gf_bar(~Believe_in_God, fill = ~ Believe_in_God) %&gt;%\n  gf_labs(\n    x = \"Do you believe in god?\",\n    y = \"Count\",\n    title = \"Proportion of yes & no\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set2\"))\n\n\n\n\n\n\n\n\n\nbelief_modified2 %&gt;%\n  gf_bar(~Believe_in_God | Gender, fill = ~ Believe_in_God) %&gt;%\n  gf_labs(\n    x = \"Do you believe in god?\",\n    y = \"Count\",\n    title = \"Proportion of Yes or No\",\n    subtitle = \"Faceted by Gender\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\nbelief_modified2 %&gt;%\n  gf_bar(~Gender, fill = ~ Believe_in_God, position = \"stack\") %&gt;%\n  gf_labs(\n    x = \"Gender\",\n    y = \"Count\",\n    title = \"Count of Belief in God\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\nbelief_modified2 %&gt;%\n  gf_bar(~Gender, fill = ~ Believe_in_God, position = \"fill\") %&gt;%\n  gf_labs(\n    x = \"Gender\",\n    y = \"Count\",\n    title = \"Count of Belief in God\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))"
  },
  {
    "objectID": "A3/belief_in_god/god.html#prop-test-do-a-majority-of-the-people-believe-in-god",
    "href": "A3/belief_in_god/god.html#prop-test-do-a-majority-of-the-people-believe-in-god",
    "title": "What’s the proportion of people who believe in god?",
    "section": "Prop Test: Do a majority of the people believe in god?",
    "text": "Prop Test: Do a majority of the people believe in god?\nH0: Half of the people believe in God (p = 0.5)\nH1: The proportion of people who believe in God is not equal to 0.5.\n\nmosaic::binom.test(~Believe_in_God, data = belief_modified2, success = \"Yes\") %&gt;% \n  broom::tidy()\n\n# A tibble: 1 × 7\n  estimate statistic p.value parameter conf.low conf.high alternative\n     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      \n1    0.634        26   0.117        41    0.469     0.779 two.sided  \n\n\n\nInference:-\n\nThe p value &gt; 0.05, which means we fail to reject the Null Hypothesis.\nThere isn’t enough evidence to say that the proportion of people who believe in God is different from 50%.\nBelief in God is roughly balanced - half the people believe and half don’t."
  },
  {
    "objectID": "A3/belief_in_god/god.html#chisq.test-is-there-a-difference-in-the-proportion-of-males-and-females-who-believe-in-god",
    "href": "A3/belief_in_god/god.html#chisq.test-is-there-a-difference-in-the-proportion-of-males-and-females-who-believe-in-god",
    "title": "What’s the proportion of people who believe in god?",
    "section": "Chisq.test: Is there a difference in the proportion of males and females who believe in god?",
    "text": "Chisq.test: Is there a difference in the proportion of males and females who believe in god?\nH0: Proportion of males who believe in god is equal to the true proportion of females who believe in god.\nH1: There is a difference between the proportion of males and females who believe in god.\n\ncontingency_table &lt;- vcd::structable(Believe_in_God~ Gender,\n  data = belief_modified2\n)\ncontingency_table\n\n       Believe_in_God No Yes\nGender                      \nFemale                 5  18\nMale                  10   8\n\n\n\ngss_vcd_table &lt;- vcd::structable(Gender ~ Believe_in_God,\n  data = belief_modified2)\n\ngss_vcd_table %&gt;%\n  vcd::mosaic(\n    gp = shading_max, direction = \"v\", # Changed shading function\n    main = \"Gender vs Belief\",\n    legend = TRUE,\n    labeling = labeling_border(\n      varnames = c(\"F\", \"F\"),\n      rot_labels = c(90, 0, 0, 0),\n      just_labels = c(\"left\", \"left\", \"left\", \"right\")\n    )\n  )\n\n\n\n\n\n\n\n\n\nxq_test_object &lt;- chisq.test(contingency_table)\nxq_test_object\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  contingency_table\nX-squared = 3.6262, df = 1, p-value = 0.05688\n\n\n\nxq_test_object %&gt;%\n  broom::tidy() %&gt;%\n  select(statistic) %&gt;%\n  as.numeric() -&gt; X_squared_observed\nX_squared_observed\n\n[1] 3.626225\n\n\n\nX_squared_critical &lt;- qchisq(\n  p = .05,\n  df = (2 - 1) * (2 - 1), # (nrows-1) * (ncols-1)\n  lower.tail = FALSE\n)\nX_squared_critical\n\n[1] 3.841459\n\n\n\nmosaic::xqchisq(\n  p = 0.95, df = 1,\n  return = c(\"plot\"), verbose = F,\n  system = \"gg\"\n) %&gt;%\n  gf_labs(\n    x = \"Chi-Square Value\", \n    title = \"Critical and Observed Chi-Square Values\"\n  ) %&gt;%\n  gf_vline(\n    xintercept = X_squared_observed,\n    color = \"red\", linewidth = 1\n  ) %&gt;%\n  gf_vline(\n    xintercept = X_squared_critical,\n    color = \"dodgerblue\", linewidth = 1\n  ) %&gt;%\n  gf_annotate(\n    x = X_squared_observed + 0.2, y = 0.05,\n    geom = \"label\", label = \"Observed\\nChi-Square\",\n    fill = \"red\", alpha = 0.3\n  ) %&gt;%\n  gf_annotate(\n    x = X_squared_critical - 0.5, y = 0.05,\n    geom = \"label\", label = \"Critical\\nChi-Square\",\n    fill = \"lightblue\"\n  )\n\n\n\n\n\n\n\n\n\nInference:\n\nThe p value = 0.056, so we fail to reject the Null Hypothesis.\nThis means belief in God does not differ between males and females — both genders showed similar levels of belief."
  },
  {
    "objectID": "A3/belief_in_god/god.html#conclusion",
    "href": "A3/belief_in_god/god.html#conclusion",
    "title": "What’s the proportion of people who believe in god?",
    "section": "Conclusion:",
    "text": "Conclusion:\nTo sum up, there is an equal proportion of people who believe in god. A chi-square test was conducted to see if opinions differ from men to women. The test showed no significant difference as both males and females. Overall, we see that belief in god between males and females does not differ significantly, both genders show similar levels of belief."
  },
  {
    "objectID": "A3/TV_Series/tv.html",
    "href": "A3/TV_Series/tv.html",
    "title": "Is the Average Opinion Score for Modern Family, Friends & Big Bang Theory equal?",
    "section": "",
    "text": "library(tidyverse) # Tidy data processing\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggformula) # Formula based plots\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(mosaic) # Data inspection and Statistical Inference\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(broom) # Tidy outputs from Statistical Analyses\nlibrary(infer) # Statistical Inference, Permutation/Bootstrap\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(supernova) # Beginner-Friendly ANOVA Tables\n\n\nAttaching package: 'supernova'\n\nThe following object is masked from 'package:scales':\n\n    number\n\nlibrary(ggstatsplot) # Statistical Plots\n\nYou can cite this package as:\n     Patil, I. (2021). Visualizations with statistical details: The 'ggstatsplot' approach.\n     Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167\n\nlibrary(ggcompare) # Improved p.value brackets on graphs\nlibrary(patchwork) # Arranging Plots\nlibrary(ggprism) # Interesting Categorical Axes\nlibrary(paletteer) # Color Palettes"
  },
  {
    "objectID": "A3/TV_Series/tv.html#r-packages-setup",
    "href": "A3/TV_Series/tv.html#r-packages-setup",
    "title": "Is the Average Opinion Score for Modern Family, Friends & Big Bang Theory equal?",
    "section": "",
    "text": "library(tidyverse) # Tidy data processing\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggformula) # Formula based plots\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(mosaic) # Data inspection and Statistical Inference\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(broom) # Tidy outputs from Statistical Analyses\nlibrary(infer) # Statistical Inference, Permutation/Bootstrap\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(supernova) # Beginner-Friendly ANOVA Tables\n\n\nAttaching package: 'supernova'\n\nThe following object is masked from 'package:scales':\n\n    number\n\nlibrary(ggstatsplot) # Statistical Plots\n\nYou can cite this package as:\n     Patil, I. (2021). Visualizations with statistical details: The 'ggstatsplot' approach.\n     Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167\n\nlibrary(ggcompare) # Improved p.value brackets on graphs\nlibrary(patchwork) # Arranging Plots\nlibrary(ggprism) # Interesting Categorical Axes\nlibrary(paletteer) # Color Palettes"
  },
  {
    "objectID": "A3/TV_Series/tv.html#reading-the-file",
    "href": "A3/TV_Series/tv.html#reading-the-file",
    "title": "Is the Average Opinion Score for Modern Family, Friends & Big Bang Theory equal?",
    "section": "Reading the file",
    "text": "Reading the file\n\ntvshows &lt;- read.csv(\"2-tv_series.csv\")\nglimpse(tvshows)\n\nRows: 52\nColumns: 5\n$ Name            &lt;chr&gt; \"Diya\", \"Ihina\", \"Abhinav\", \"Nikhita\", \"Rishi\", \"Charv…\n$ Gender          &lt;chr&gt; \"Female\", \"Female\", \"Male\", \"Female\", \"Male\", \"Female\"…\n$ Friends         &lt;dbl&gt; 8.0, 7.0, 8.0, 7.0, 8.0, 6.0, 8.0, 4.0, 9.0, 7.0, NA, …\n$ Modern.Family   &lt;dbl&gt; 9.0, 9.0, 10.0, 9.0, 6.0, 9.0, 7.5, 8.0, 8.0, 9.0, 9.5…\n$ Big.Bang.Theory &lt;dbl&gt; 9.0, 6.0, 7.0, 6.0, 5.0, 5.5, 9.0, 6.0, 5.0, 3.0, 6.0,…"
  },
  {
    "objectID": "A3/TV_Series/tv.html#cleaning-the-data",
    "href": "A3/TV_Series/tv.html#cleaning-the-data",
    "title": "Is the Average Opinion Score for Modern Family, Friends & Big Bang Theory equal?",
    "section": "Cleaning the Data",
    "text": "Cleaning the Data\n\ntvshows_modified &lt;- tvshows %&gt;% drop_na()\ntvshows_modified\n\n       Name Gender Friends Modern.Family Big.Bang.Theory\n1      Diya Female     8.0           9.0             9.0\n2     Ihina Female     7.0           9.0             6.0\n3   Abhinav   Male     8.0          10.0             7.0\n4   Nikhita Female     7.0           9.0             6.0\n5     Rishi   Male     8.0           6.0             5.0\n6    Charvi Female     6.0           9.0             5.5\n7      Maya Female     8.0           7.5             9.0\n8     Anuva Female     4.0           8.0             6.0\n9   Shourya   Male     9.0           8.0             5.0\n10  sarthak   Male     7.0           9.0             3.0\n11  Niyosha Female     8.0           8.0             7.0\n12  Alekhya Female     5.0           8.0             7.0\n13 Shalmali Female     7.0           9.0             9.0\n14   Riddhi Female     8.5          10.0             8.0\n15   Aryaan   Male     7.0           9.0             8.0\n16  Jeffery   Male     6.0           8.0            10.0\n17    Ishaa Female     9.0          10.0             7.0\n18     Paru Female     5.0           9.0             8.0\n19  Krushna Female     2.0           3.0             4.0\n20     Neil   Male     6.5           8.0             4.0\n21 Avantika Female     8.0          10.0             2.0\n22 prakruti Female     7.0           9.0             7.5\n23    Aditi Female     5.0          10.0             3.0\n24    Kavya Female     7.0           8.0             3.0\n25   Mitali Female     5.0           8.0             7.0\n26   Ananya Female     8.0          10.0             8.0\n27    Dhruv   Male     6.5           7.5             9.0\n28  Prithvi   Male     6.0           8.0             7.0\n29     Arya   Male     1.0           6.0             3.0\n30 Tathastu   Male    10.0           9.0             9.0\n31  Vaibhav   Male     8.0          10.0             6.0\n32   Akarsh   Male     7.0           8.0             8.0\n33    Arnav   Male     8.0           3.0             5.0\n34    Aarav   Male     9.0           8.0             7.0\n35   Kreesh   Male     8.0           9.0             7.0\n36 Niranjan   Male     4.0           9.0             4.0\n37   Vishal   Male     5.0           9.0             5.0\n38   Saachi Female     7.0          10.0             7.0\n39     Diya Female     8.0          10.0             7.0\n40    Rahul   Male     9.0           9.0             7.0\n41    Nipun   Male     9.5           8.0             7.0\n42  Akshaya   Male     7.5           9.0             9.0\n43     Anay   Male     7.0           8.0             5.0\n44     Amit   Male     2.0           7.0             4.0\n45    Aryan   Male    10.0           6.0             8.0\n46  Drishti Female     8.5           7.0             8.5\n\n\n\ntvshows_pivot &lt;- tvshows_modified %&gt;%\n  pivot_longer(\n    cols = c(Friends, Modern.Family, Big.Bang.Theory),\n    names_to = \"Series\",\n    values_to = \"Opinion_Score\"\n  ) %&gt;%\n  drop_na() %&gt;%\n  mutate(\n    Series = factor(\n      Series,\n      levels = c(\"Friends\", \"Modern.Family\", \"Big.Bang.Theory\"),\n      labels = c(\"Friends\", \"Modern Family\", \"Big Bang Theory\")\n    )\n  ) %&gt;%\n  rename(\"Id\" = 1) -&gt; tv_long\n\ntv_long\n\n# A tibble: 138 × 4\n   Id      Gender Series          Opinion_Score\n   &lt;chr&gt;   &lt;chr&gt;  &lt;fct&gt;                   &lt;dbl&gt;\n 1 Diya    Female Friends                     8\n 2 Diya    Female Modern Family               9\n 3 Diya    Female Big Bang Theory             9\n 4 Ihina   Female Friends                     7\n 5 Ihina   Female Modern Family               9\n 6 Ihina   Female Big Bang Theory             6\n 7 Abhinav Male   Friends                     8\n 8 Abhinav Male   Modern Family              10\n 9 Abhinav Male   Big Bang Theory             7\n10 Nikhita Female Friends                     7\n# ℹ 128 more rows"
  },
  {
    "objectID": "A3/TV_Series/tv.html#visualising-the-data",
    "href": "A3/TV_Series/tv.html#visualising-the-data",
    "title": "Is the Average Opinion Score for Modern Family, Friends & Big Bang Theory equal?",
    "section": "Visualising the Data",
    "text": "Visualising the Data\n\ntv_long %&gt;% gf_boxplot(Opinion_Score~Series, orientation = \"x\", fill = ~ Series) %&gt;% \n  gf_labs(\n    title = \"Opinion Score vs Series\",\n    x = \"TV shows\",\n    y = \"Opinion Scores\"\n  ) %&gt;% \n  gf_hline(yintercept = ~ mean(Opinion_Score), color = \"grey\") %&gt;% \n  gf_annotate(geom = \"text\", label = \"Overall Mean\", x = 2, y = mean(tv_long$Opinion_Score) + -0.5, size = 4)\n\n\n\n\n\n\n\n  gf_theme(theme_minimal)\n\nNULL\n\n\n\nBetween the three groups, we see a lot of variance from the overall mean.\nFriends & Big Bang Theory are closer while Modern Family has a lot of variance.\n\n\ngf_jitter(Opinion_Score ~ Series,\n  color = ~Series, width = 0.2,\n  data = tv_long, size = 3, alpha = 0.5\n) %&gt;%\n  gf_labs(\n    title = \"Opinion Scores across TV Series\",\n    x = \"TV Series\", y = \"Opinion Score\"\n  ) %&gt;%\n  gf_hline(yintercept = ~ mean(Opinion_Score), color = \"grey\") %&gt;%\n  gf_annotate(\n    geom = \"text\",\n    label = \"Overall Mean\",\n    x = 2,\n    y = mean(tv_long$Opinion_Score) + 0.5,\n    size = 4\n  ) \n\n\n\n\n\n\n\n\nFrom the above jitter plot, we see that there is a lot of variance within each group (height of each plot is long)."
  },
  {
    "objectID": "A3/TV_Series/tv.html#anova",
    "href": "A3/TV_Series/tv.html#anova",
    "title": "Is the Average Opinion Score for Modern Family, Friends & Big Bang Theory equal?",
    "section": "ANOVA",
    "text": "ANOVA\n\nH0: All three series have equal mean opinion scores\nH1: All three series have different mean opinion scores\n\n\ntvshows_anova &lt;- aov(Opinion_Score~Series, data = tv_long)\ntvshows_anova\n\nCall:\n   aov(formula = Opinion_Score ~ Series, data = tv_long)\n\nTerms:\n                  Series Residuals\nSum of Squares   86.6341  472.8098\nDeg. of Freedom        2       135\n\nResidual standard error: 1.871442\nEstimated effects may be unbalanced\n\n\n\ntvshows_supernova &lt;-\n  supernova::pairwise(tvshows_anova,\n    correction = \"Bonferroni\", # Try \"Tukey\"\n    alpha = 0.05, # 95% CI calculation\n    var_equal = TRUE, # We'll see\n    plot = T\n  )\n\n\n\n\n\n\n\n\n\ntvshows_supernova$Series\n\nSeries\n\n\nLevels: 3\n\n\nFamily-wise error-rate: 0.049\n\n\n\n  group_1         group_2        diff pooled_se      t    df  lower  upper p_adj\n  &lt;chr&gt;           &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Modern Family   Friends       1.413     0.276  5.121   135  0.820  2.006 .0000\n2 Big Bang Theory Friends      -0.446     0.276 -1.615   135 -1.039  0.148 .3259\n3 Big Bang Theory Modern Fami… -1.859     0.276 -6.736   135 -2.452 -1.265 .0000\n\n\n\nsupernova::supernova(tvshows_anova)\n\n Analysis of Variance Table (Type III SS)\n Model: Opinion_Score ~ Series\n\n                              SS  df     MS      F   PRE     p\n ----- --------------- | ------- --- ------ ------ ----- -----\n Model (error reduced) |  86.634   2 43.317 12.368 .1549 .0000\n Error (from model)    | 472.810 135  3.502                   \n ----- --------------- | ------- --- ------ ------ ----- -----\n Total (empty model)   | 559.444 137  4.084                   \n\n\n\nsupernova::equation(tvshows_anova)\n\nFitted equation:\nOpinion_Score = 6.891304 + 1.413043*SeriesModern Family + -0.4456522*SeriesBig Bang Theory + e\n\n\n\ntv_long %&gt;%\n  mutate(fitted = fitted(tvshows_anova)) %&gt;%\n  gf_jitter(Opinion_Score ~ Series,\n    width = 0.2, alpha = 0.6,\n    color = ~Series,\n    data = .\n  ) %&gt;%\n  gf_summary(\n    group = ~1, \n    fun = \"mean\", geom = \"line\", colour = \"lightblue\",\n    lty = 1, linewidth = 2\n  ) %&gt;%\n  gf_point(fitted ~ Series,\n    color = ~Series,\n    shape = 2,\n    size = 6\n  ) %&gt;%\n  gf_segment(fitted + fitted ~ 0 + Series, linetype = 2, color = ~Series) %&gt;%\n  gf_labs(\n    title = \"Fitted ANOVA Model Equation\",\n    x = \"Series\", y = \"Opinion Score\"\n  ) %&gt;%\n  gf_refine(\n    scale_x_discrete(guide = \"prism_bracket\"),\n    scale_y_continuous(breaks = c(10, 15, (26.3 - 10.1), 20, (26.3 - 5.3), 25, 26.3, 30, 35))\n  )\n\nWarning: The S3 guide system was deprecated in ggplot2 3.5.0.\nℹ It has been replaced by a ggproto system that can be extended.\n\n\n\n\n\n\n\n\n\n\nInference:-\n\nThe test gave an F-value of 14.24 and a p-value &lt; 0.001 which means the result is statistically significant. This suggests that at least one show’s average opinion score is different from the others.\nWe reject the null hypothesis that all three shows have the same average opinion score. At least one show’s rating differs significantly from the others."
  },
  {
    "objectID": "A3/TV_Series/tv.html#check-for-normality",
    "href": "A3/TV_Series/tv.html#check-for-normality",
    "title": "Is the Average Opinion Score for Modern Family, Friends & Big Bang Theory equal?",
    "section": "1. Check for Normality",
    "text": "1. Check for Normality\n\nshapiro.test(x = tv_long$Opinion_Score)\n\n\n    Shapiro-Wilk normality test\n\ndata:  tv_long$Opinion_Score\nW = 0.91645, p-value = 3.301e-07\n\n\n\ntv_long %&gt;%\n  group_by(Series) %&gt;%\n  group_modify(~ .x %&gt;%\n    select(Opinion_Score) %&gt;%\n    as_vector() %&gt;%\n    shapiro.test() %&gt;%\n    broom::tidy())\n\n# A tibble: 3 × 4\n# Groups:   Series [3]\n  Series          statistic    p.value method                     \n  &lt;fct&gt;               &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                      \n1 Friends             0.909 0.00161    Shapiro-Wilk normality test\n2 Modern Family       0.808 0.00000294 Shapiro-Wilk normality test\n3 Big Bang Theory     0.946 0.0320     Shapiro-Wilk normality test\n\n\nThe p value at each level is very low so we reject the Null Hypothesis that its normally distributed.\n\ntvshows_anova$residuals %&gt;%\n  as_tibble() %&gt;%\n  gf_dhistogram(~value, data = .) %&gt;%\n  gf_labs(\n    title = \"Residuals Histogram\",\n    x = \"Residuals\", y = \"Count\"\n  ) %&gt;%\n  gf_fitdistr()\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n##\ntvshows_anova$residuals %&gt;%\n  as_tibble() %&gt;%\n  gf_qq(~value, data = .) %&gt;%\n  gf_qqstep() %&gt;%\n  gf_labs(\n    title = \"Residuals Q-Q Plot\",\n    x = \"Theoretical Quantiles\", y = \"Sample Quantiles\"\n  ) %&gt;%\n  gf_qqline()\n\n\n\n\n\n\n\n\n\nshapiro.test(tvshows_anova$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  tvshows_anova$residuals\nW = 0.93715, p-value = 7.456e-06\n\n\nThe residual p value is also very small."
  },
  {
    "objectID": "A3/TV_Series/tv.html#check-for-similar-variance",
    "href": "A3/TV_Series/tv.html#check-for-similar-variance",
    "title": "Is the Average Opinion Score for Modern Family, Friends & Big Bang Theory equal?",
    "section": "2. Check for Similar Variance",
    "text": "2. Check for Similar Variance\n\ntv_long %&gt;%\n  group_by(Series) %&gt;%\n  summarise(variance = var(Opinion_Score))\n\n# A tibble: 3 × 2\n  Series          variance\n  &lt;fct&gt;              &lt;dbl&gt;\n1 Friends             4.07\n2 Modern Family       2.47\n3 Big Bang Theory     3.97\n\n\n\nDescTools::LeveneTest(Opinion_Score ~ Series, data = tv_long)\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(&gt;F)\ngroup   2  1.5298 0.2203\n      135               \n\n\n\nfligner.test(Opinion_Score ~ Series, data = tv_long)\n\n\n    Fligner-Killeen test of homogeneity of variances\n\ndata:  Opinion_Score by Series\nFligner-Killeen:med chi-squared = 4.0885, df = 2, p-value = 0.1295\n\n\nFrom both tests, we see that p&gt;0.05. Therefore, variances are not significantly different.\n\nInference:-\n\nThe Variables are not normally distributed\nThe Variables are not significantly different"
  },
  {
    "objectID": "A3/TV_Series/tv.html#effect-size",
    "href": "A3/TV_Series/tv.html#effect-size",
    "title": "Is the Average Opinion Score for Modern Family, Friends & Big Bang Theory equal?",
    "section": "Effect Size",
    "text": "Effect Size\nTo see how how strong or big the difference is.\n\ntvshows_supernova &lt;-\n  supernova::pairwise(tvshows_anova,\n    plot = TRUE,\n    alpha = 0.05,\n    correction = \"Bonferroni\"\n  )\n\n\n\n\n\n\n\n\n\ntvshows_supernova$Series\n\nSeries\n\n\nLevels: 3\n\n\nFamily-wise error-rate: 0.049\n\n\n\n  group_1         group_2        diff pooled_se      t    df  lower  upper p_adj\n  &lt;chr&gt;           &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Modern Family   Friends       1.413     0.276  5.121   135  0.820  2.006 .0000\n2 Big Bang Theory Friends      -0.446     0.276 -1.615   135 -1.039  0.148 .3259\n3 Big Bang Theory Modern Fami… -1.859     0.276 -6.736   135 -2.452 -1.265 .0000\n\n\n\nModern Family has the highest on average.\nFriends was rated moderately.\nBig Bang Theory received the lowest scores.\nThere is no significant difference between Friends and Big Bang Theory.\n\n\nVisualizing ANOVA using ggstatsplot\n\nlibrary(ggstatsplot)\ntv_long %&gt;%\n  ggstatsplot::ggbetweenstats(\n    x = Series, y = Opinion_Score,\n    colour = Series, alpha = 0.8,\n    type = \"parametric\",\n    p.adjust.method = \"bonferroni\",\n    conf.level = 0.95,\n\n    violin.args = list(width = 0.0)\n  ) +\n\n  scale_colour_paletteer_d(\"ggthemes::colorblind\") +\n  labs(\n    title = \"ANOVA : Series vs Opinion Scores\",\n    x = \"Series\", y = \"Opinion Score\"\n  )\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n\n\n\n\n\n\n\n\n\nF stat value is 14.24 - which is a very large variance.\nP value is 4.32 * 10^-06 is really small, and such a large F value is very unlikely to happen by chance.\nSo we reject the Null Hypothesis that all three means are equal.\nThe graph shows the means for each series:\n\nFriends: 6.89\nModern Family: 8.30\nBig Bang Theory: 6.45\n\nModern Family was rated significantly higher than both Friends and Big Bang Theory."
  },
  {
    "objectID": "A3/TV_Series/tv.html#permutation-test",
    "href": "A3/TV_Series/tv.html#permutation-test",
    "title": "Is the Average Opinion Score for Modern Family, Friends & Big Bang Theory equal?",
    "section": "Permutation Test",
    "text": "Permutation Test\n\nobserved_infer &lt;-\n  tv_long %&gt;%\n  specify(Opinion_Score ~ Series) %&gt;%\n  hypothesise(null = \"independence\") %&gt;%\n  calculate(stat = \"F\")\nobserved_infer\n\nResponse: Opinion_Score (numeric)\nExplanatory: Series (factor)\nNull Hypothesi...\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1  12.4\n\n\n\nnull_dist_infer &lt;- tv_long %&gt;%\n  specify(Opinion_Score ~ Series) %&gt;%\n  hypothesise(null = \"independence\") %&gt;%\n  generate(reps = 4999, type = \"permute\") %&gt;%\n  calculate(stat = \"F\")\nnull_dist_infer\n\nResponse: Opinion_Score (numeric)\nExplanatory: Series (factor)\nNull Hypothesi...\n# A tibble: 4,999 × 2\n   replicate  stat\n       &lt;int&gt; &lt;dbl&gt;\n 1         1 0.536\n 2         2 0.574\n 3         3 0.652\n 4         4 2.96 \n 5         5 2.73 \n 6         6 0.643\n 7         7 1.12 \n 8         8 1.16 \n 9         9 0.428\n10        10 0.625\n# ℹ 4,989 more rows\n\n\n\nnull_dist_infer %&gt;%\n  visualize() +\n  shade_p_value(observed_infer, direction = \"greater\") +\n  labs(\n    title = \"Permutation Test: Distribution of F-statistic\",\n    x = \"F-statistic\",\n    y = \"Count\"\n  )\n\n\n\n\n\n\n\n\n\nnull_dist_infer %&gt;%\n  get_p_value(obs_stat = observed_infer, direction = \"two-sided\")\n\nWarning: Please be cautious in reporting a p-value of 0. This result is an approximation\nbased on the number of `reps` chosen in the `generate()` step.\nℹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\n\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1       0\n\n\n\nInference:-\n\nThe observed F-statistic was 12.37, shown by the red line on the graph. The red line lies far to the right of the null distribution which represents what we would expect if there were no real differences between shows.\nThe p-value = 0 which indicates none of the 4,999 random permutations produced an F value as large as the observed one.\nWe reject the null hypothesis which confirms that at least one show’s average opinion score is significantly different from the others."
  },
  {
    "objectID": "A3/TV_Series/tv.html#conclusion",
    "href": "A3/TV_Series/tv.html#conclusion",
    "title": "Is the Average Opinion Score for Modern Family, Friends & Big Bang Theory equal?",
    "section": "Conclusion",
    "text": "Conclusion\nThe ANOVA test showed a significant difference in average opinion scores (F = 12.37, p &lt; 0.001), indicating that not all shows were rated the same.\nBecause the data was not perfectly normal, a permutation test was also conducted. The observed F-statistic lay far beyond the null distribution with a p-value of 0, confirming that the differences are statistically significant and not due to random variation.\nAmong the three shows, Modern Family received the highest average rating (8.3), followed by Friends (6.9) and The Big Bang Theory (6.4). This shows that viewers clearly preferred Modern Family, while Friends and The Big Bang Theory received comparatively lower and similar scores.\nOverall, both tests lead to the same conclusion - there is a real and significant difference in how audiences rated the three shows, with Modern Family being the most favorite."
  },
  {
    "objectID": "A3/Weird_dads/dad.html",
    "href": "A3/Weird_dads/dad.html",
    "title": "Are Srishti Dads weird?",
    "section": "",
    "text": "library(ggformula)\n\nLoading required package: ggplot2\n\n\nLoading required package: scales\n\n\nLoading required package: ggridges\n\n\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(naniar)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:naniar':\n\n    n_complete\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.1.0     ✔ tidyr     1.3.1\n✔ readr     2.1.5     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ mosaic::count()     masks dplyr::count()\n✖ purrr::cross()      masks mosaic::cross()\n✖ purrr::discard()    masks scales::discard()\n✖ mosaic::do()        masks dplyr::do()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ mosaic::stat()      masks ggplot2::stat()\n✖ mosaic::tally()     masks dplyr::tally()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tinytable)\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(visdat)\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(RColorBrewer)\nlibrary(naniar)\nlibrary(GGally)\nlibrary(ggplot2)\nlibrary(correlation)\n\n\nAttaching package: 'correlation'\n\nThe following object is masked from 'package:mosaic':\n\n    cor_test\n\nlibrary(dplyr)\nlibrary(RColorBrewer)\nlibrary(DT)\nlibrary(infer)\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(resampledata)\n\n\nAttaching package: 'resampledata'\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n\nlibrary(openintro)\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:GGally':\n\n    tips\n\nThe following object is masked from 'package:mosaic':\n\n    dotPlot\n\nThe following objects are masked from 'package:lattice':\n\n    ethanol, lsegments\n\nlibrary(vcd)\n\nLoading required package: grid\n\nAttaching package: 'vcd'\n\nThe following object is masked from 'package:mosaic':\n\n    mplot\n\nlibrary(visStatistics)"
  },
  {
    "objectID": "A3/Weird_dads/dad.html#r-packages-setup",
    "href": "A3/Weird_dads/dad.html#r-packages-setup",
    "title": "Are Srishti Dads weird?",
    "section": "",
    "text": "library(ggformula)\n\nLoading required package: ggplot2\n\n\nLoading required package: scales\n\n\nLoading required package: ggridges\n\n\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(naniar)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:naniar':\n\n    n_complete\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.1.0     ✔ tidyr     1.3.1\n✔ readr     2.1.5     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ mosaic::count()     masks dplyr::count()\n✖ purrr::cross()      masks mosaic::cross()\n✖ purrr::discard()    masks scales::discard()\n✖ mosaic::do()        masks dplyr::do()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ mosaic::stat()      masks ggplot2::stat()\n✖ mosaic::tally()     masks dplyr::tally()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tinytable)\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(visdat)\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(RColorBrewer)\nlibrary(naniar)\nlibrary(GGally)\nlibrary(ggplot2)\nlibrary(correlation)\n\n\nAttaching package: 'correlation'\n\nThe following object is masked from 'package:mosaic':\n\n    cor_test\n\nlibrary(dplyr)\nlibrary(RColorBrewer)\nlibrary(DT)\nlibrary(infer)\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(resampledata)\n\n\nAttaching package: 'resampledata'\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n\nlibrary(openintro)\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:GGally':\n\n    tips\n\nThe following object is masked from 'package:mosaic':\n\n    dotPlot\n\nThe following objects are masked from 'package:lattice':\n\n    ethanol, lsegments\n\nlibrary(vcd)\n\nLoading required package: grid\n\nAttaching package: 'vcd'\n\nThe following object is masked from 'package:mosaic':\n\n    mplot\n\nlibrary(visStatistics)"
  },
  {
    "objectID": "A3/Weird_dads/dad.html#reading-the-file",
    "href": "A3/Weird_dads/dad.html#reading-the-file",
    "title": "Are Srishti Dads weird?",
    "section": "Reading the file",
    "text": "Reading the file\n\nweird_dads &lt;- read.csv(\"3-weird_dads.csv\")\nglimpse(weird_dads)\n\nRows: 65\nColumns: 4\n$ gender       &lt;chr&gt; \"F\", \"F\", \"M\", \"F\", \"M\", \"M\", \"M\", \"M\", \"F\", \"M\", \"F\", \"M…\n$ college      &lt;chr&gt; \"SMI\", \"SMI\", \"SMI\", \"SMI\", \"MIT\", \"MIT\", \"MIT\", \"SMI\", \"…\n$ is_dad_weird &lt;chr&gt; \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"…\n$ name         &lt;chr&gt; \"Manya\", \"Sradha\", \"Arun\", \"Nidhi\", \"Shaurya\", \"Pratham\",…"
  },
  {
    "objectID": "A3/Weird_dads/dad.html#munging",
    "href": "A3/Weird_dads/dad.html#munging",
    "title": "Are Srishti Dads weird?",
    "section": "Munging",
    "text": "Munging\n\nweird_dads_modified &lt;- weird_dads %&gt;% \n  mutate(across(where(is.character), as.factor))%&gt;%\n  dplyr::relocate(\"gender\", \"college\", \"is_dad_weird\", .after = name)\nglimpse(weird_dads_modified)\n\nRows: 65\nColumns: 4\n$ name         &lt;fct&gt; Manya, Sradha, Arun, Nidhi, Shaurya, Pratham, Jeevan, Dhr…\n$ gender       &lt;fct&gt; F, F, M, F, M, M, M, M, F, M, F, M, F, F, M, M, F, M, M, …\n$ college      &lt;fct&gt; SMI, SMI, SMI, SMI, MIT, MIT, MIT, SMI, SMI, SMI, SMI, SM…\n$ is_dad_weird &lt;fct&gt; No, No, No, Yes, No, No, No, No, Yes, Yes, Yes, Yes, No, …"
  },
  {
    "objectID": "A3/Weird_dads/dad.html#removing-na-values",
    "href": "A3/Weird_dads/dad.html#removing-na-values",
    "title": "Are Srishti Dads weird?",
    "section": "Removing NA Values",
    "text": "Removing NA Values\n\nweird_dads_modified2 &lt;- weird_dads_modified %&gt;% drop_na()"
  },
  {
    "objectID": "A3/Weird_dads/dad.html#examining-the-data",
    "href": "A3/Weird_dads/dad.html#examining-the-data",
    "title": "Are Srishti Dads weird?",
    "section": "Examining the Data",
    "text": "Examining the Data\n\nweird_dads_modified2 %&gt;% \n  group_by(college) %&gt;% \n  count(is_dad_weird)\n\n# A tibble: 4 × 3\n# Groups:   college [2]\n  college is_dad_weird     n\n  &lt;fct&gt;   &lt;fct&gt;        &lt;int&gt;\n1 MIT     No              28\n2 MIT     Yes              5\n3 SMI     No              19\n4 SMI     Yes             12\n\n\n\nweird_dads_modified2 %&gt;% \n  count(is_dad_weird)\n\n  is_dad_weird  n\n1           No 47\n2          Yes 17\n\n\n\nweird_dads_modified2 %&gt;% \n  group_by(gender) %&gt;% \n  count(is_dad_weird)\n\n# A tibble: 5 × 3\n# Groups:   gender [3]\n  gender is_dad_weird     n\n  &lt;fct&gt;  &lt;fct&gt;        &lt;int&gt;\n1 F      No              23\n2 F      Yes              9\n3 M      No              24\n4 M      Yes              7\n5 NB     Yes              1"
  },
  {
    "objectID": "A3/Weird_dads/dad.html#visualising-the-data",
    "href": "A3/Weird_dads/dad.html#visualising-the-data",
    "title": "Are Srishti Dads weird?",
    "section": "Visualising the Data",
    "text": "Visualising the Data\n\nweird_dads_modified2 %&gt;% \n  gf_bar(~is_dad_weird | college, fill = ~ is_dad_weird) %&gt;% \n  gf_labs(\n    title = \"Count of Yes or No to whether dad is weird or not\",\n    subtitle = \"Faceted by College\",\n    x = \"Is your dad weird?\",\n    y = \"Count\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set2\")) %&gt;% \n  gf_theme(theme_minimal)\n\n\n\n\n\n\n\n\n\nweird_dads_modified2 %&gt;% \n  gf_bar(~is_dad_weird, fill = ~ college, position = \"fill\") %&gt;% \n  gf_labs(\n    title = \"Count of Yes or No to whether dad is weird or not\",\n    subtitle = \"Filled by college\",\n    x = \"Is your dad weird?\",\n    y = \"Proportion\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\")) %&gt;% \n  gf_theme(theme_minimal)\n\n\n\n\n\n\n\n\n\nweird_dads_modified2 %&gt;% \n  gf_bar(~is_dad_weird | college, fill = ~ gender, position = \"dodge\") %&gt;% \n  gf_labs(\n    title = \"Count of Yes or No to whether dad is weird or not\",\n    subtitle = \"Faceted by college\",\n    x = \"Is your dad weird?\",\n    y = \"Count\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\")) %&gt;% \n  gf_theme(theme_minimal)"
  },
  {
    "objectID": "A3/Weird_dads/dad.html#chisq.test",
    "href": "A3/Weird_dads/dad.html#chisq.test",
    "title": "Are Srishti Dads weird?",
    "section": "Chisq.test:",
    "text": "Chisq.test:\n\nHunch: Are Srishti Dads weird?\n\n\nTest 1: Dad Weirdness & College\n\nH0: Weirdness of dads does not depend on college\nH1: Weirdness of dads depends on college\n\n\ncontingency_table_college &lt;- vcd::structable(is_dad_weird~ college,\n  data = weird_dads_modified2\n)\ncontingency_table_college\n\n        is_dad_weird No Yes\ncollege                    \nMIT                  28   5\nSMI                  19  12\n\n\n\ngss_vcd_table_college &lt;- vcd::structable(college~is_dad_weird,\n  data = weird_dads_modified2)\n\ngss_vcd_table_college %&gt;%\n  vcd::mosaic(\n    gp = shading_max, direction = \"v\", # Changed shading function\n    main = \"Dad Weirdness vs College\",\n    legend = TRUE,\n    labeling = labeling_border(\n      varnames = c(\"F\", \"F\"),\n      rot_labels = c(90, 0, 0, 0),\n      just_labels = c(\"left\", \"left\", \"left\", \"right\")\n    )\n  )\n\n\n\n\n\n\n\n\n\nxq_test_object_college &lt;- chisq.test(contingency_table_college)\nxq_test_object_college\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  contingency_table_college\nX-squared = 3.4202, df = 1, p-value = 0.0644\n\n\n\nP=0.06 which is &gt;0.05, we fail to reject the Null Hypothesis.\nTherefore, weirdness of dads do not depend on college. Srishti dads are not significantly weirder or less weird than dads from other colleges\n\n\nxq_test_object_college %&gt;%\n  broom::tidy() %&gt;%\n  select(statistic) %&gt;%\n  as.numeric() -&gt; X_squared_observed_college\nX_squared_observed_college\n\n[1] 3.420189\n\n\n\n# Determine the Chi-Square critical value\nX_squared_critical_college &lt;- qchisq(\n  p = .05,\n  df = (2 - 1) * (2 - 1), # (nrows-1) * (ncols-1)\n  lower.tail = FALSE\n)\nX_squared_critical_college\n\n[1] 3.841459\n\n\n\nmosaic::xqchisq(\n  p = 0.95, df = 1,\n  return = c(\"plot\"), verbose = F,\n  system = \"gg\"\n) %&gt;%\n  gf_labs(\n    x = \"Chi-Square Value\", \n    title = \"Critical and Observed Chi-Square Values\"\n  ) %&gt;%\n  gf_vline(\n    xintercept = X_squared_observed_college,\n    color = \"red\", linewidth = 1\n  ) %&gt;%\n  gf_vline(\n    xintercept = X_squared_critical_college,\n    color = \"dodgerblue\", linewidth = 1\n  ) %&gt;%\n  gf_annotate(\n    x = X_squared_observed_college + 0.2, y = 0.05,\n    geom = \"label\", label = \"Observed\\nChi-Square\",\n    fill = \"red\", alpha = 0.3\n  ) %&gt;%\n  gf_annotate(\n    x = X_squared_critical_college - 0.5, y = 0.05,\n    geom = \"label\", label = \"Critical\\nChi-Square\",\n    fill = \"lightblue\"\n  )\n\n\n\n\n\n\n\n\n\n\nTest 2: Dad Weirdness & Gender\n\nH0: Perception of dad weirdness is the same for all genders\nH1: Perception of dad weirdness differs by gender.\n\n\ncontingency_table_gender&lt;- vcd::structable(is_dad_weird~ gender,\n  data = weird_dads_modified2\n)\ncontingency_table_gender\n\n       is_dad_weird No Yes\ngender                    \nF                   23   9\nM                   24   7\nNB                   0   1\n\n\n\ngss_vcd_table_gender &lt;- vcd::structable(gender~is_dad_weird,\n  data = weird_dads_modified2)\n\ngss_vcd_table_gender %&gt;%\n  vcd::mosaic(\n    gp = shading_max, direction = \"v\", # Changed shading function\n    main = \"Dad Weirdness vs Gender\",\n    legend = TRUE,\n    labeling = labeling_border(\n      varnames = c(\"F\", \"F\"),\n      rot_labels = c(90, 0, 0, 0),\n      just_labels = c(\"left\", \"left\", \"left\", \"right\")\n    )\n  )\n\n\n\n\n\n\n\n\n\nxq_test_object_gender&lt;- chisq.test(contingency_table_gender)\n\nWarning in stats::chisq.test(x, y, ...): Chi-squared approximation may be\nincorrect\n\nxq_test_object_gender\n\n\n    Pearson's Chi-squared test\n\ndata:  contingency_table_gender\nX-squared = 3.0567, df = 2, p-value = 0.2169\n\n\n\n\nInference\n\nP=0.21 which is &gt;0.05, we fail to reject the Null Hypothesis. Therefore, weirdness of dads do not depend on gender.\nThis shows that gender does not influence perceptions of dad weirdness, both males and females responded similarly when asked if their dads are weird.\n\n\nxq_test_object_gender %&gt;%\n  broom::tidy() %&gt;%\n  select(statistic) %&gt;%\n  as.numeric() -&gt; X_squared_observed_gender\nX_squared_observed_gender\n\n[1] 3.056724\n\n\n\n# Determine the Chi-Square critical value\nX_squared_critical_gender &lt;- qchisq(\n  p = .05,\n  df = (2 - 1) * (2 - 1), # (nrows-1) * (ncols-1)\n  lower.tail = FALSE\n)\nX_squared_critical_gender\n\n[1] 3.841459\n\n\n\nmosaic::xqchisq(\n  p = 0.95, df = 1,\n  return = c(\"plot\"), verbose = F,\n  system = \"gg\"\n) %&gt;%\n  gf_labs(\n    x = \"Chi-Square Value\", \n    title = \"Critical and Observed Chi-Square Values\"\n  ) %&gt;%\n  gf_vline(\n    xintercept = X_squared_observed_gender,\n    color = \"red\", linewidth = 1\n  ) %&gt;%\n  gf_vline(\n    xintercept = X_squared_critical_gender,\n    color = \"dodgerblue\", linewidth = 1\n  ) %&gt;%\n  gf_annotate(\n    x = X_squared_observed_gender + 0.2, y = 0.05,\n    geom = \"label\", label = \"Observed\\nChi-Square\",\n    fill = \"red\", alpha = 0.3\n  ) %&gt;%\n  gf_annotate(\n    x = X_squared_critical_gender - 0.5, y = 0.05,\n    geom = \"label\", label = \"Critical\\nChi-Square\",\n    fill = \"lightblue\"\n  )"
  },
  {
    "objectID": "A3/Weird_dads/dad.html#conclusion",
    "href": "A3/Weird_dads/dad.html#conclusion",
    "title": "Are Srishti Dads weird?",
    "section": "Conclusion:",
    "text": "Conclusion:\nTo conclude, chi-square tests indicate that neither college nor gender significantly affect perceptions of dad weirdness. Overall, the hunch that “Srishti dads are weird” is not statistically supported - dads in MIT & SMI seem to have a similar level of weirdness."
  },
  {
    "objectID": "classwork/classwork1/index.html",
    "href": "classwork/classwork1/index.html",
    "title": "Classwork 1",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(babynames)\nlibrary(ggformula)\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\n\n\nbabynames\n\n# A tibble: 1,924,665 × 5\n    year sex   name          n   prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt;\n 1  1880 F     Mary       7065 0.0724\n 2  1880 F     Anna       2604 0.0267\n 3  1880 F     Emma       2003 0.0205\n 4  1880 F     Elizabeth  1939 0.0199\n 5  1880 F     Minnie     1746 0.0179\n 6  1880 F     Margaret   1578 0.0162\n 7  1880 F     Ida        1472 0.0151\n 8  1880 F     Alice      1414 0.0145\n 9  1880 F     Bertha     1320 0.0135\n10  1880 F     Sarah      1288 0.0132\n# ℹ 1,924,655 more rows\n\n\n\n\n\n\nbabynames %&gt;% filter(name==\"Diya\")\n\n# A tibble: 27 × 5\n    year sex   name      n       prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt;      &lt;dbl&gt;\n 1  1991 F     Diya      5 0.00000246\n 2  1992 F     Diya      5 0.00000249\n 3  1995 F     Diya      6 0.00000312\n 4  1996 F     Diya      7 0.00000365\n 5  1997 F     Diya     12 0.00000629\n 6  1998 F     Diya     12 0.00000619\n 7  1999 F     Diya     14 0.00000719\n 8  2000 F     Diya     18 0.00000902\n 9  2001 F     Diya     54 0.0000273 \n10  2002 F     Diya     92 0.0000466 \n# ℹ 17 more rows\n\n\n\n\n\nbabynames %&gt;% filter(name == \"Diya\" | name == \"Dia\" | name == \"Deeya\") %&gt;%\n  gf_area(n ~ year, color = ~ name) %&gt;% \n  gf_labs(title = \"Number of babies named Diya or Dia or Diyaa in the USA\",\n         x = \"Year\",\n         y = \"Number of babies\") %&gt;% gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\n\nbabynames %&gt;% filter(name == \"Diya\" | name == \"Dia\" | name == \"Deeya\") %&gt;%\n  gf_point(n ~ year, color = ~ name) %&gt;% \n  gf_labs(title = \"Number of babies named Diya or Dia or Diyaa in the USA\",\n         x = \"Year\",\n         y = \"Number of babies\") %&gt;% gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\n\nbabynames %&gt;% filter(name == \"Diya\" | name == \"Dia\" | name == \"Deeya\") %&gt;%\n  gf_bar(n ~ year, color = ~ name) %&gt;% \n  gf_labs(title = \"Number of babies named Diya or Dia or Diyaa in the USA\",\n         x = \"Year\",\n         y = \"Number of babies\") %&gt;% gf_theme(theme_light())\n\nWarning: Ignoring unknown aesthetics: .\n\n\nWarning: The following aesthetics were dropped during statistical transformation: ..\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\n\n\nbabynames %&gt;% filter(name == \"Diya\" | name == \"Dia\" | name == \"Deeya\") %&gt;% filter(year == \"1989\" | year == \"2010\") %&gt;%\n  gf_point(n ~ year, color = ~ name) %&gt;% \n  gf_labs(title = \"Number of babies named Diya or Dia or Diyaa in the USA\",\n         x = \"Year\",\n         y = \"Number of babies\") %&gt;% gf_theme(theme_light())"
  },
  {
    "objectID": "classwork/classwork1/index.html#this-is-my-first-quarto-document",
    "href": "classwork/classwork1/index.html#this-is-my-first-quarto-document",
    "title": "Classwork 1",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(babynames)\nlibrary(ggformula)\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\n\n\nbabynames\n\n# A tibble: 1,924,665 × 5\n    year sex   name          n   prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt;\n 1  1880 F     Mary       7065 0.0724\n 2  1880 F     Anna       2604 0.0267\n 3  1880 F     Emma       2003 0.0205\n 4  1880 F     Elizabeth  1939 0.0199\n 5  1880 F     Minnie     1746 0.0179\n 6  1880 F     Margaret   1578 0.0162\n 7  1880 F     Ida        1472 0.0151\n 8  1880 F     Alice      1414 0.0145\n 9  1880 F     Bertha     1320 0.0135\n10  1880 F     Sarah      1288 0.0132\n# ℹ 1,924,655 more rows\n\n\n\n\n\n\nbabynames %&gt;% filter(name==\"Diya\")\n\n# A tibble: 27 × 5\n    year sex   name      n       prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt;      &lt;dbl&gt;\n 1  1991 F     Diya      5 0.00000246\n 2  1992 F     Diya      5 0.00000249\n 3  1995 F     Diya      6 0.00000312\n 4  1996 F     Diya      7 0.00000365\n 5  1997 F     Diya     12 0.00000629\n 6  1998 F     Diya     12 0.00000619\n 7  1999 F     Diya     14 0.00000719\n 8  2000 F     Diya     18 0.00000902\n 9  2001 F     Diya     54 0.0000273 \n10  2002 F     Diya     92 0.0000466 \n# ℹ 17 more rows\n\n\n\n\n\nbabynames %&gt;% filter(name == \"Diya\" | name == \"Dia\" | name == \"Deeya\") %&gt;%\n  gf_area(n ~ year, color = ~ name) %&gt;% \n  gf_labs(title = \"Number of babies named Diya or Dia or Diyaa in the USA\",\n         x = \"Year\",\n         y = \"Number of babies\") %&gt;% gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\n\nbabynames %&gt;% filter(name == \"Diya\" | name == \"Dia\" | name == \"Deeya\") %&gt;%\n  gf_point(n ~ year, color = ~ name) %&gt;% \n  gf_labs(title = \"Number of babies named Diya or Dia or Diyaa in the USA\",\n         x = \"Year\",\n         y = \"Number of babies\") %&gt;% gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\n\nbabynames %&gt;% filter(name == \"Diya\" | name == \"Dia\" | name == \"Deeya\") %&gt;%\n  gf_bar(n ~ year, color = ~ name) %&gt;% \n  gf_labs(title = \"Number of babies named Diya or Dia or Diyaa in the USA\",\n         x = \"Year\",\n         y = \"Number of babies\") %&gt;% gf_theme(theme_light())\n\nWarning: Ignoring unknown aesthetics: .\n\n\nWarning: The following aesthetics were dropped during statistical transformation: ..\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\n\n\nbabynames %&gt;% filter(name == \"Diya\" | name == \"Dia\" | name == \"Deeya\") %&gt;% filter(year == \"1989\" | year == \"2010\") %&gt;%\n  gf_point(n ~ year, color = ~ name) %&gt;% \n  gf_labs(title = \"Number of babies named Diya or Dia or Diyaa in the USA\",\n         x = \"Year\",\n         y = \"Number of babies\") %&gt;% gf_theme(theme_light())"
  },
  {
    "objectID": "classwork/classwork2/index.html",
    "href": "classwork/classwork2/index.html",
    "title": "Classwork 2",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\nAttaching package: 'mosaic'\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\n\n\nAttaching package: 'naniar'\n\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\n\nAttaching package: 'tinytable'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void"
  },
  {
    "objectID": "classwork/classwork2/index.html#setup-r-packages",
    "href": "classwork/classwork2/index.html#setup-r-packages",
    "title": "Classwork 2",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\nAttaching package: 'mosaic'\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\n\n\nAttaching package: 'naniar'\n\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\n\nAttaching package: 'tinytable'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void"
  },
  {
    "objectID": "classwork/classwork2/index.html#reading-csv-file",
    "href": "classwork/classwork2/index.html#reading-csv-file",
    "title": "Classwork 2",
    "section": "Reading csv file",
    "text": "Reading csv file\n\nfastfood &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/fastfood.csv\") %&gt;% \nclean_names(case=\"snake\")\n\nRows: 515 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): restaurant, item, salad\ndbl (15): rownames, calories, cal_fat, total_fat, sat_fat, trans_fat, choles...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nfastfood\n\n# A tibble: 515 × 18\n   rownames restaurant item         calories cal_fat total_fat sat_fat trans_fat\n      &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n 1        1 Mcdonalds  Artisan Gri…      380      60         7       2       0  \n 2        2 Mcdonalds  Single Baco…      840     410        45      17       1.5\n 3        3 Mcdonalds  Double Baco…     1130     600        67      27       3  \n 4        4 Mcdonalds  Grilled Bac…      750     280        31      10       0.5\n 5        5 Mcdonalds  Crispy Baco…      920     410        45      12       0.5\n 6        6 Mcdonalds  Big Mac           540     250        28      10       1  \n 7        7 Mcdonalds  Cheeseburger      300     100        12       5       0.5\n 8        8 Mcdonalds  Classic Chi…      510     210        24       4       0  \n 9        9 Mcdonalds  Double Chee…      430     190        21      11       1  \n10       10 Mcdonalds  Double Quar…      770     400        45      21       2.5\n# ℹ 505 more rows\n# ℹ 10 more variables: cholesterol &lt;dbl&gt;, sodium &lt;dbl&gt;, total_carb &lt;dbl&gt;,\n#   fiber &lt;dbl&gt;, sugar &lt;dbl&gt;, protein &lt;dbl&gt;, vit_a &lt;dbl&gt;, vit_c &lt;dbl&gt;,\n#   calcium &lt;dbl&gt;, salad &lt;chr&gt;"
  },
  {
    "objectID": "classwork/classwork2/index.html#names-function",
    "href": "classwork/classwork2/index.html#names-function",
    "title": "Classwork 2",
    "section": "Names function",
    "text": "Names function\n\nnames(fastfood)\n\n [1] \"rownames\"    \"restaurant\"  \"item\"        \"calories\"    \"cal_fat\"    \n [6] \"total_fat\"   \"sat_fat\"     \"trans_fat\"   \"cholesterol\" \"sodium\"     \n[11] \"total_carb\"  \"fiber\"       \"sugar\"       \"protein\"     \"vit_a\"      \n[16] \"vit_c\"       \"calcium\"     \"salad\""
  },
  {
    "objectID": "classwork/classwork2/index.html#glimpse-dim-str",
    "href": "classwork/classwork2/index.html#glimpse-dim-str",
    "title": "Classwork 2",
    "section": "Glimpse, Dim, str",
    "text": "Glimpse, Dim, str\n\ndplyr::glimpse(fastfood)\n\nRows: 515\nColumns: 18\n$ rownames    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ restaurant  &lt;chr&gt; \"Mcdonalds\", \"Mcdonalds\", \"Mcdonalds\", \"Mcdonalds\", \"Mcdon…\n$ item        &lt;chr&gt; \"Artisan Grilled Chicken Sandwich\", \"Single Bacon Smokehou…\n$ calories    &lt;dbl&gt; 380, 840, 1130, 750, 920, 540, 300, 510, 430, 770, 380, 62…\n$ cal_fat     &lt;dbl&gt; 60, 410, 600, 280, 410, 250, 100, 210, 190, 400, 170, 300,…\n$ total_fat   &lt;dbl&gt; 7, 45, 67, 31, 45, 28, 12, 24, 21, 45, 18, 34, 20, 34, 8, …\n$ sat_fat     &lt;dbl&gt; 2.0, 17.0, 27.0, 10.0, 12.0, 10.0, 5.0, 4.0, 11.0, 21.0, 4…\n$ trans_fat   &lt;dbl&gt; 0.0, 1.5, 3.0, 0.5, 0.5, 1.0, 0.5, 0.0, 1.0, 2.5, 0.0, 1.5…\n$ cholesterol &lt;dbl&gt; 95, 130, 220, 155, 120, 80, 40, 65, 85, 175, 40, 95, 125, …\n$ sodium      &lt;dbl&gt; 1110, 1580, 1920, 1940, 1980, 950, 680, 1040, 1040, 1290, …\n$ total_carb  &lt;dbl&gt; 44, 62, 63, 62, 81, 46, 33, 49, 35, 42, 38, 48, 48, 67, 31…\n$ fiber       &lt;dbl&gt; 3, 2, 3, 2, 4, 3, 2, 3, 2, 3, 2, 3, 3, 5, 2, 2, 3, 3, 5, 2…\n$ sugar       &lt;dbl&gt; 11, 18, 18, 18, 18, 9, 7, 6, 7, 10, 5, 11, 11, 11, 6, 3, 1…\n$ protein     &lt;dbl&gt; 37, 46, 70, 55, 46, 25, 15, 25, 25, 51, 15, 32, 42, 33, 13…\n$ vit_a       &lt;dbl&gt; 4, 6, 10, 6, 6, 10, 10, 0, 20, 20, 2, 10, 10, 10, 2, 4, 6,…\n$ vit_c       &lt;dbl&gt; 20, 20, 20, 25, 20, 2, 2, 4, 4, 6, 0, 10, 20, 15, 2, 6, 15…\n$ calcium     &lt;dbl&gt; 20, 20, 50, 20, 20, 15, 10, 2, 15, 20, 15, 35, 35, 35, 4, …\n$ salad       &lt;chr&gt; \"Other\", \"Other\", \"Other\", \"Other\", \"Other\", \"Other\", \"Oth…\n\n\n\nbase::dim(fastfood)\n\n[1] 515  18\n\n\n\nutils::str(fastfood)\n\nspc_tbl_ [515 × 18] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ rownames   : num [1:515] 1 2 3 4 5 6 7 8 9 10 ...\n $ restaurant : chr [1:515] \"Mcdonalds\" \"Mcdonalds\" \"Mcdonalds\" \"Mcdonalds\" ...\n $ item       : chr [1:515] \"Artisan Grilled Chicken Sandwich\" \"Single Bacon Smokehouse Burger\" \"Double Bacon Smokehouse Burger\" \"Grilled Bacon Smokehouse Chicken Sandwich\" ...\n $ calories   : num [1:515] 380 840 1130 750 920 540 300 510 430 770 ...\n $ cal_fat    : num [1:515] 60 410 600 280 410 250 100 210 190 400 ...\n $ total_fat  : num [1:515] 7 45 67 31 45 28 12 24 21 45 ...\n $ sat_fat    : num [1:515] 2 17 27 10 12 10 5 4 11 21 ...\n $ trans_fat  : num [1:515] 0 1.5 3 0.5 0.5 1 0.5 0 1 2.5 ...\n $ cholesterol: num [1:515] 95 130 220 155 120 80 40 65 85 175 ...\n $ sodium     : num [1:515] 1110 1580 1920 1940 1980 950 680 1040 1040 1290 ...\n $ total_carb : num [1:515] 44 62 63 62 81 46 33 49 35 42 ...\n $ fiber      : num [1:515] 3 2 3 2 4 3 2 3 2 3 ...\n $ sugar      : num [1:515] 11 18 18 18 18 9 7 6 7 10 ...\n $ protein    : num [1:515] 37 46 70 55 46 25 15 25 25 51 ...\n $ vit_a      : num [1:515] 4 6 10 6 6 10 10 0 20 20 ...\n $ vit_c      : num [1:515] 20 20 20 25 20 2 2 4 4 6 ...\n $ calcium    : num [1:515] 20 20 50 20 20 15 10 2 15 20 ...\n $ salad      : chr [1:515] \"Other\" \"Other\" \"Other\" \"Other\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   rownames = col_double(),\n  ..   restaurant = col_character(),\n  ..   item = col_character(),\n  ..   calories = col_double(),\n  ..   cal_fat = col_double(),\n  ..   total_fat = col_double(),\n  ..   sat_fat = col_double(),\n  ..   trans_fat = col_double(),\n  ..   cholesterol = col_double(),\n  ..   sodium = col_double(),\n  ..   total_carb = col_double(),\n  ..   fiber = col_double(),\n  ..   sugar = col_double(),\n  ..   protein = col_double(),\n  ..   vit_a = col_double(),\n  ..   vit_c = col_double(),\n  ..   calcium = col_double(),\n  ..   salad = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "classwork/classwork2/index.html#finding-missing-values",
    "href": "classwork/classwork2/index.html#finding-missing-values",
    "title": "Classwork 2",
    "section": "Finding Missing values",
    "text": "Finding Missing values\n\nvisdat::vis_dat(fastfood) +\n  labs(title = \"Missing Data\", subtitle = \"Showing variable types\") + \n  theme(plot.title = element_text(size = 20), plot.subtitle = element_text(size = 14))\n\n\n\n\n\n\n\n\n\nvis_miss(fastfood) +\n  labs(title =\"Missing Data in the FastFood Dataset\", subtitle = \"Showing missing & present data\") +\n  theme(plot.title = element_text(size = 20), plot.subtitle = element_text(size = 14))"
  },
  {
    "objectID": "classwork/classwork2/index.html#removing-missing-data",
    "href": "classwork/classwork2/index.html#removing-missing-data",
    "title": "Classwork 2",
    "section": "Removing missing data",
    "text": "Removing missing data\n\nfastfood_modified &lt;- fastfood %&gt;% tidyr::drop_na()"
  },
  {
    "objectID": "classwork/classwork2/index.html#displaying-modified-data-table",
    "href": "classwork/classwork2/index.html#displaying-modified-data-table",
    "title": "Classwork 2",
    "section": "Displaying modified data table",
    "text": "Displaying modified data table\n\nfastfood_modified\n\n# A tibble: 301 × 18\n   rownames restaurant item         calories cal_fat total_fat sat_fat trans_fat\n      &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n 1        1 Mcdonalds  Artisan Gri…      380      60         7       2       0  \n 2        2 Mcdonalds  Single Baco…      840     410        45      17       1.5\n 3        3 Mcdonalds  Double Baco…     1130     600        67      27       3  \n 4        4 Mcdonalds  Grilled Bac…      750     280        31      10       0.5\n 5        5 Mcdonalds  Crispy Baco…      920     410        45      12       0.5\n 6        6 Mcdonalds  Big Mac           540     250        28      10       1  \n 7        7 Mcdonalds  Cheeseburger      300     100        12       5       0.5\n 8        8 Mcdonalds  Classic Chi…      510     210        24       4       0  \n 9        9 Mcdonalds  Double Chee…      430     190        21      11       1  \n10       10 Mcdonalds  Double Quar…      770     400        45      21       2.5\n# ℹ 291 more rows\n# ℹ 10 more variables: cholesterol &lt;dbl&gt;, sodium &lt;dbl&gt;, total_carb &lt;dbl&gt;,\n#   fiber &lt;dbl&gt;, sugar &lt;dbl&gt;, protein &lt;dbl&gt;, vit_a &lt;dbl&gt;, vit_c &lt;dbl&gt;,\n#   calcium &lt;dbl&gt;, salad &lt;chr&gt;"
  },
  {
    "objectID": "classwork/classwork2/index.html#removing-the-column-entirely",
    "href": "classwork/classwork2/index.html#removing-the-column-entirely",
    "title": "Classwork 2",
    "section": "Removing the column entirely",
    "text": "Removing the column entirely\n\nfastfood_modified2 &lt;- fastfood %&gt;%\n  dplyr::select(-vit_a)\n\nfastfood_modified2 &lt;- fastfood %&gt;%\n  dplyr::select(-c(vit_a, vit_c))"
  },
  {
    "objectID": "classwork/classwork2/index.html#converting-into-factors",
    "href": "classwork/classwork2/index.html#converting-into-factors",
    "title": "Classwork 2",
    "section": "Converting into Factors",
    "text": "Converting into Factors\n\nfastfood_modified1 &lt;- fastfood %&gt;%\n  mutate(\n    restaurant = as.factor(restaurant),\n    salad = as.factor(salad),\n    item = as.factor(item))\ndplyr::glimpse(fastfood_modified1)\n\nRows: 515\nColumns: 18\n$ rownames    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ restaurant  &lt;fct&gt; Mcdonalds, Mcdonalds, Mcdonalds, Mcdonalds, Mcdonalds, Mcd…\n$ item        &lt;fct&gt; \"Artisan Grilled Chicken Sandwich\", \"Single Bacon Smokehou…\n$ calories    &lt;dbl&gt; 380, 840, 1130, 750, 920, 540, 300, 510, 430, 770, 380, 62…\n$ cal_fat     &lt;dbl&gt; 60, 410, 600, 280, 410, 250, 100, 210, 190, 400, 170, 300,…\n$ total_fat   &lt;dbl&gt; 7, 45, 67, 31, 45, 28, 12, 24, 21, 45, 18, 34, 20, 34, 8, …\n$ sat_fat     &lt;dbl&gt; 2.0, 17.0, 27.0, 10.0, 12.0, 10.0, 5.0, 4.0, 11.0, 21.0, 4…\n$ trans_fat   &lt;dbl&gt; 0.0, 1.5, 3.0, 0.5, 0.5, 1.0, 0.5, 0.0, 1.0, 2.5, 0.0, 1.5…\n$ cholesterol &lt;dbl&gt; 95, 130, 220, 155, 120, 80, 40, 65, 85, 175, 40, 95, 125, …\n$ sodium      &lt;dbl&gt; 1110, 1580, 1920, 1940, 1980, 950, 680, 1040, 1040, 1290, …\n$ total_carb  &lt;dbl&gt; 44, 62, 63, 62, 81, 46, 33, 49, 35, 42, 38, 48, 48, 67, 31…\n$ fiber       &lt;dbl&gt; 3, 2, 3, 2, 4, 3, 2, 3, 2, 3, 2, 3, 3, 5, 2, 2, 3, 3, 5, 2…\n$ sugar       &lt;dbl&gt; 11, 18, 18, 18, 18, 9, 7, 6, 7, 10, 5, 11, 11, 11, 6, 3, 1…\n$ protein     &lt;dbl&gt; 37, 46, 70, 55, 46, 25, 15, 25, 25, 51, 15, 32, 42, 33, 13…\n$ vit_a       &lt;dbl&gt; 4, 6, 10, 6, 6, 10, 10, 0, 20, 20, 2, 10, 10, 10, 2, 4, 6,…\n$ vit_c       &lt;dbl&gt; 20, 20, 20, 25, 20, 2, 2, 4, 4, 6, 0, 10, 20, 15, 2, 6, 15…\n$ calcium     &lt;dbl&gt; 20, 20, 50, 20, 20, 15, 10, 2, 15, 20, 15, 35, 35, 35, 4, …\n$ salad       &lt;fct&gt; Other, Other, Other, Other, Other, Other, Other, Other, Ot…"
  },
  {
    "objectID": "classwork/classwork2/index.html#relocate",
    "href": "classwork/classwork2/index.html#relocate",
    "title": "Classwork 2",
    "section": "Relocate",
    "text": "Relocate\n\nfast_food_modified &lt;- fastfood_modified %&gt;%\n  mutate(\n    restaurant = as.factor(restaurant),\n    salad = as.factor(salad),\n    item = as.factor(item)\n  ) %&gt;%\n  rename(\"dish\" = item) %&gt;% # rename item to dish\n\n  # arrange the Qual variables first, Quant next\n  dplyr::relocate(where(is.factor), .after = rownames)\n\nglimpse(fast_food_modified)\n\nRows: 301\nColumns: 18\n$ rownames    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ restaurant  &lt;fct&gt; Mcdonalds, Mcdonalds, Mcdonalds, Mcdonalds, Mcdonalds, Mcd…\n$ dish        &lt;fct&gt; \"Artisan Grilled Chicken Sandwich\", \"Single Bacon Smokehou…\n$ salad       &lt;fct&gt; Other, Other, Other, Other, Other, Other, Other, Other, Ot…\n$ calories    &lt;dbl&gt; 380, 840, 1130, 750, 920, 540, 300, 510, 430, 770, 380, 62…\n$ cal_fat     &lt;dbl&gt; 60, 410, 600, 280, 410, 250, 100, 210, 190, 400, 170, 300,…\n$ total_fat   &lt;dbl&gt; 7, 45, 67, 31, 45, 28, 12, 24, 21, 45, 18, 34, 20, 34, 8, …\n$ sat_fat     &lt;dbl&gt; 2.0, 17.0, 27.0, 10.0, 12.0, 10.0, 5.0, 4.0, 11.0, 21.0, 4…\n$ trans_fat   &lt;dbl&gt; 0.0, 1.5, 3.0, 0.5, 0.5, 1.0, 0.5, 0.0, 1.0, 2.5, 0.0, 1.5…\n$ cholesterol &lt;dbl&gt; 95, 130, 220, 155, 120, 80, 40, 65, 85, 175, 40, 95, 125, …\n$ sodium      &lt;dbl&gt; 1110, 1580, 1920, 1940, 1980, 950, 680, 1040, 1040, 1290, …\n$ total_carb  &lt;dbl&gt; 44, 62, 63, 62, 81, 46, 33, 49, 35, 42, 38, 48, 48, 67, 31…\n$ fiber       &lt;dbl&gt; 3, 2, 3, 2, 4, 3, 2, 3, 2, 3, 2, 3, 3, 5, 2, 2, 3, 3, 5, 2…\n$ sugar       &lt;dbl&gt; 11, 18, 18, 18, 18, 9, 7, 6, 7, 10, 5, 11, 11, 11, 6, 3, 1…\n$ protein     &lt;dbl&gt; 37, 46, 70, 55, 46, 25, 15, 25, 25, 51, 15, 32, 42, 33, 13…\n$ vit_a       &lt;dbl&gt; 4, 6, 10, 6, 6, 10, 10, 0, 20, 20, 2, 10, 10, 10, 2, 4, 6,…\n$ vit_c       &lt;dbl&gt; 20, 20, 20, 25, 20, 2, 2, 4, 4, 6, 0, 10, 20, 15, 2, 6, 15…\n$ calcium     &lt;dbl&gt; 20, 20, 50, 20, 20, 15, 10, 2, 15, 20, 15, 35, 35, 35, 4, …"
  },
  {
    "objectID": "classwork/classwork2/index.html#displaying-data",
    "href": "classwork/classwork2/index.html#displaying-data",
    "title": "Classwork 2",
    "section": "Displaying Data",
    "text": "Displaying Data\n\nfast_food_modified %&gt;%\n  head(10) %&gt;%\n  tinytable::tt(caption = \"Fast Food Dataset (Clean)\")\n\n\n\n    \n\n    \n    \n      \n        \n        Fast Food Dataset (Clean)\n              \n                rownames\n                restaurant\n                dish\n                salad\n                calories\n                cal_fat\n                total_fat\n                sat_fat\n                trans_fat\n                cholesterol\n                sodium\n                total_carb\n                fiber\n                sugar\n                protein\n                vit_a\n                vit_c\n                calcium\n              \n        \n        \n        \n                \n                  1\n                  Mcdonalds\n                  Artisan Grilled Chicken Sandwich\n                  Other\n                  380\n                  60\n                  7\n                  2\n                  0.0\n                  95\n                  1110\n                  44\n                  3\n                  11\n                  37\n                  4\n                  20\n                  20\n                \n                \n                  2\n                  Mcdonalds\n                  Single Bacon Smokehouse Burger\n                  Other\n                  840\n                  410\n                  45\n                  17\n                  1.5\n                  130\n                  1580\n                  62\n                  2\n                  18\n                  46\n                  6\n                  20\n                  20\n                \n                \n                  3\n                  Mcdonalds\n                  Double Bacon Smokehouse Burger\n                  Other\n                  1130\n                  600\n                  67\n                  27\n                  3.0\n                  220\n                  1920\n                  63\n                  3\n                  18\n                  70\n                  10\n                  20\n                  50\n                \n                \n                  4\n                  Mcdonalds\n                  Grilled Bacon Smokehouse Chicken Sandwich\n                  Other\n                  750\n                  280\n                  31\n                  10\n                  0.5\n                  155\n                  1940\n                  62\n                  2\n                  18\n                  55\n                  6\n                  25\n                  20\n                \n                \n                  5\n                  Mcdonalds\n                  Crispy Bacon Smokehouse Chicken Sandwich\n                  Other\n                  920\n                  410\n                  45\n                  12\n                  0.5\n                  120\n                  1980\n                  81\n                  4\n                  18\n                  46\n                  6\n                  20\n                  20\n                \n                \n                  6\n                  Mcdonalds\n                  Big Mac\n                  Other\n                  540\n                  250\n                  28\n                  10\n                  1.0\n                  80\n                  950\n                  46\n                  3\n                  9\n                  25\n                  10\n                  2\n                  15\n                \n                \n                  7\n                  Mcdonalds\n                  Cheeseburger\n                  Other\n                  300\n                  100\n                  12\n                  5\n                  0.5\n                  40\n                  680\n                  33\n                  2\n                  7\n                  15\n                  10\n                  2\n                  10\n                \n                \n                  8\n                  Mcdonalds\n                  Classic Chicken Sandwich\n                  Other\n                  510\n                  210\n                  24\n                  4\n                  0.0\n                  65\n                  1040\n                  49\n                  3\n                  6\n                  25\n                  0\n                  4\n                  2\n                \n                \n                  9\n                  Mcdonalds\n                  Double Cheeseburger\n                  Other\n                  430\n                  190\n                  21\n                  11\n                  1.0\n                  85\n                  1040\n                  35\n                  2\n                  7\n                  25\n                  20\n                  4\n                  15\n                \n                \n                  10\n                  Mcdonalds\n                  Double Quarter Pounder® with Cheese\n                  Other\n                  770\n                  400\n                  45\n                  21\n                  2.5\n                  175\n                  1290\n                  42\n                  3\n                  10\n                  51\n                  20\n                  6\n                  20"
  },
  {
    "objectID": "classwork/classwork4/index.html",
    "href": "classwork/classwork4/index.html",
    "title": "Classwork 4",
    "section": "",
    "text": "Setup\n\nlibrary(tidyverse) # Sine qua non\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic) # Out all-in-one package\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula) # Graphing package\nlibrary(skimr) # Looking at Data\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(janitor) # Clean the data\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(naniar) # Handle missing data\n\n\nAttaching package: 'naniar'\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\nlibrary(visdat) # Visualise missing data\nlibrary(tinytable) # Printing Static Tables for our data\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(DT) # Interactive Tables for our data\nlibrary(crosstable) # Multiple variable summaries\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\n\n\n\nReading csv file\n\ntaxi &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/taxi.csv\")\n\nRows: 10000 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): tip, company, local, dow, month\ndbl (3): rownames, distance, hour\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntaxi_modified &lt;- taxi %&gt;%\n  naniar::replace_with_na_all(condition = ~ .x %in% common_na_strings) %&gt;%\n  naniar::replace_with_na_all(condition = ~ .x %in% common_na_numbers) %&gt;%\n  janitor::clean_names(case = \"snake\") %&gt;%\n  janitor::remove_empty()\n\nvalue for \"which\" not specified, defaulting to c(\"rows\", \"cols\")\n\ntaxi_modified\n\n# A tibble: 10,000 × 8\n   rownames tip   distance company                      local dow   month  hour\n      &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;                        &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1        1 yes      17.2  Chicago Independents         no    Thu   Feb      16\n 2        2 yes       0.88 City Service                 yes   Thu   Mar       8\n 3        3 yes      18.1  other                        no    Mon   Feb      18\n 4        4 yes      20.7  Chicago Independents         no    Mon   Apr       8\n 5        5 yes      12.2  Chicago Independents         no    Sun   Mar      21\n 6        6 yes       0.94 Sun Taxi                     yes   Sat   Apr      23\n 7        7 yes      17.5  Flash Cab                    no    Fri   Mar      12\n 8        8 yes      17.7  other                        no    Sun   Jan       6\n 9        9 yes       1.85 Taxicab Insurance Agency Llc no    Fri   Apr      12\n10       10 yes       1.47 City Service                 no    Tue   Mar      14\n# ℹ 9,990 more rows\n\n\n\n\nTheme chosing\n\nRColorBrewer::display.brewer.all()\n\n\n\n\n\n\n\n\n\n\nData Munging\n\n## Convert `dow`, `local`, `month`, and `hour` into ordered factors\ntaxi_modified &lt;- taxi_modified %&gt;%\n  dplyr::mutate(\n\n    ## Variable \"tip\"\n    tip = base::factor(tip,\n      levels = c(\"yes\", \"no\"),\n      labels = c(\"yes\", \"no\"),\n      ordered = TRUE\n    ),\n\n    ## Variable \"company\"\n    company = base::factor(company), # Any order is OK.\n\n    ## Variable \"dow\"\n    dow = base::factor(dow,\n      levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"),\n      labels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"),\n      ordered = TRUE\n    ),\n\n    ## Variable \"local\"\n    local = base::factor(local,\n      levels = c(\"yes\", \"no\"),\n      labels = c(\"yes\", \"no\"),\n      ordered = TRUE\n    ),\n\n    ## Variable \"month\"\n    month = base::factor(month,\n      levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\"),\n      labels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\"),\n      ordered = TRUE\n    ),\n\n    ## Variable \"hour\"\n    hour = base::factor(hour,\n      levels = c(0:23), labels = c(0:23),\n      ordered = TRUE\n    )\n  ) %&gt;%\n  dplyr::relocate(where(is.factor), .after = rownames) # Move all factors to the left\n\ntaxi_modified %&gt;% glimpse()\n\nRows: 10,000\nColumns: 8\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ tip      &lt;ord&gt; yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, y…\n$ company  &lt;fct&gt; Chicago Independents, City Service, other, Chicago Independen…\n$ local    &lt;ord&gt; no, yes, no, no, no, yes, no, no, no, no, no, no, no, yes, no…\n$ dow      &lt;ord&gt; Thu, Thu, Mon, Mon, Sun, Sat, Fri, Sun, Fri, Tue, Tue, Sun, W…\n$ month    &lt;ord&gt; Feb, Mar, Feb, Apr, Mar, Apr, Mar, Jan, Apr, Mar, Mar, Apr, A…\n$ hour     &lt;ord&gt; 16, 8, 18, 8, 21, 23, 12, 6, 12, 14, 18, 11, 12, 19, 17, 13, …\n$ distance &lt;dbl&gt; 17.19, 0.88, 18.11, 20.70, 12.23, 0.94, 17.47, 17.67, 1.85, 1…\n\n\n\n\nPosition dodge\n\ntaxi_modified %&gt;%\n  gf_bar(~local,\n    fill = ~tip,\n    position = \"dodge\"\n  ) %&gt;%\n  gf_labs(title = \"Plot 2A: Dodged Bar Chart\") %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\nPosition stack\n\ntaxi_modified %&gt;%\n  gf_bar(~local,\n    fill = ~tip,\n    position = \"stack\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Plot 2B: Stacked Bar Chart\",\n    subtitle = \"Can we spot per group differences in proportions??\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\nPosition fill\n\ntaxi_modified %&gt;%\n  gf_bar(~local,\n    fill = ~tip,\n    position = \"fill\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Plot 2C: Filled Bar Chart\",\n    subtitle = \"Shows Per group differences in Proportions!\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\nHistogram\n\ndata(\"diamonds\", package = \"ggplot2\")\nglimpse(diamonds)\n\nRows: 53,940\nColumns: 10\n$ carat   &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…\n\n\n\ndiamonds_modified &lt;- diamonds %&gt;%\n  janitor::clean_names(case = \"snake\") %&gt;%\n  janitor::remove_empty(which = c(\"rows\", \"cols\")) # Empty columns and rows if any\ndiamonds_modified %&gt;% glimpse()\n\nRows: 53,940\nColumns: 10\n$ carat   &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…\n\n\n\ngf_histogram(~price, data = diamonds_modified, fill=~cut, color=\"black\") %&gt;%\n  gf_labs(\n    title = \"Plot 1A: Diamond Prices\",\n    caption = \"ggformula\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_histogram(~price | cut, data = diamonds_modified, fill=~cut, color=\"black\") %&gt;%\n  gf_labs(\n    title = \"Plot 1A: Diamond Prices\",\n    caption = \"ggformula\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set8\"))\n\nWarning: Unknown palette: \"Set8\"\n\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_histogram(~price | color, data = diamonds_modified, fill=~color, color=\"black\") %&gt;%\n  gf_labs(\n    title = \"Plot 1A: Diamond Prices\",\n    caption = \"ggformula\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\nglimpse(diamonds_modified)\n\nRows: 53,940\nColumns: 10\n$ carat   &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…\n\n\n\ndiamonds_modified %&gt;%\n  gf_boxplot(cut ~ carat | clarity, orientation = \"y\") %&gt;%\n  gf_labs(y = \"Gender\", x = \"Income\", title = \"Plot 2A: Income by Gender\")\n\n\n\n\n\n\n\n\n\ndiamonds_modified %&gt;%\n  gf_boxplot(clarity ~ depth, orientation = \"y\") %&gt;%\n  gf_labs(y = \"Gender\", x = \"Income\", title = \"Plot 2A: Income by Gender\")\n\n\n\n\n\n\n\n\n\ndiamonds_modified %&gt;%\n  gf_boxplot(color ~ price, orientation = \"y\", fill = \"pink\", color = \"black\") %&gt;%\n  gf_labs(y = \"Gender\", x = \"Income\", title = \"Plot 2A: Income by Gender\")\n\n\n\n\n\n\n\n\n\ndiamonds_modified %&gt;%\n  gf_boxplot(clarity ~ price, orientation = \"y\") %&gt;%\n  gf_labs(y = \"Clarity\", x = \"Price\", title = \"Plot 2A: Income by Gender\")\n\n\n\n\n\n\n\n\n\ndiamonds_modified %&gt;%\n  gf_boxplot(cut ~ carat, orientation = \"y\") %&gt;%\n  gf_labs(y = \"Clarity\", x = \"Price\", title = \"Plot 2A: Income by Gender\")"
  },
  {
    "objectID": "classwork/classwork6/index.html",
    "href": "classwork/classwork6/index.html",
    "title": "Classwork 6",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic) # Our trusted friend\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(ggformula) # Formula interface to ggplot2\nlibrary(vcd) # Michael Friendly's package, Visualizing Categorical\n\nLoading required package: grid\n\nAttaching package: 'vcd'\n\nThe following object is masked from 'package:mosaic':\n\n    mplot\n\nlibrary(vcdExtra) # Categorical Data Sets\n\nLoading required package: gnm\n\nAttaching package: 'gnm'\n\nThe following object is masked from 'package:lattice':\n\n    barley\n\n\nAttaching package: 'vcdExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    summarise\n\nlibrary(resampledata) # More datasets\n\n\nAttaching package: 'resampledata'\n\nThe following object is masked from 'package:vcdExtra':\n\n    TV\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n\nlibrary(visStatistics) # Comprehensive all-in-one stats viz/test package\nlibrary(ggmosaic) # Tidy Mosaic Plots\n\n\nAttaching package: 'ggmosaic'\n\nThe following objects are masked from 'package:vcd':\n\n    mosaic, spine\n\nlibrary(ggpubr) # Colours, Themes and new geometries in ggplot\n##\nlibrary(janitor) # Data Cleaning and Tidying\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(visdat) # Visualize whole dataframes for missing data\nlibrary(naniar) # Clean missing data\n\n\nAttaching package: 'naniar'\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\nlibrary(DT) # Interactive Tables for our data\nlibrary(tinytable) # Elegant Tables for our data\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(ggrepel) # Repelling Text Labels in ggplot\nlibrary(marquee) # Marquee Text in ggplot\n\n\nArthritis %&gt;% class()\n\n[1] \"data.frame\"\n\nvcd::structable(data = Arthritis, Improved ~ Treatment)\n\n          Improved None Some Marked\nTreatment                          \nPlacebo              29    7      7\nTreated              13    7     21\n\nvcd::structable(data = Arthritis, Improved ~ Treatment) %&gt;% \n  as.matrix() %&gt;% # Convert to matrix; \n  addmargins() %&gt;% # Add margins to the table; matrix output\n  class() \n\n[1] \"matrix\" \"array\" \n\nvcd::structable(data = Arthritis, Improved ~ Treatment) %&gt;% \n  as.matrix() %&gt;% # Convert to matrix;\n  addmargins() %&gt;% # Add margins to the table; matrix output\n  as_tibble(rownames = \"Treatment\") # Convert to tibble; ensure row names!\n\n# A tibble: 3 × 5\n  Treatment  None  Some Marked   Sum\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Placebo      29     7      7    43\n2 Treated      13     7     21    41\n3 Sum          42    14     28    84\n\n\n\narthritis_table &lt;- vcd::structable(Improved ~ Treatment,\n                                   data = Arthritis)\narthritis_table\n\n          Improved None Some Marked\nTreatment                          \nPlacebo              29    7      7\nTreated              13    7     21\n\nvcd::mosaic(arthritis_table)\n\n\n\n\n\n\n\n\n\nvcd::mosaic(arthritis_table, \n            gp = shading_max, direction = \"v\",\n            main = \"Arthritis Treatment Dataset\",\nlabeling = labeling_border(\n                varnames = c(\"F\", \"F\"), # Remove variable name labels\n                rot_labels = c(90,0,0,0), #t,r,b,l\n                just_labels = c(\"left\", \n                                \"left\", \n                                \"left\", \n                                \"right\"))) # How?\n\n\n\n\n\n\n\n\n\n# library(ggmosaic)\ndata(\"titanic\", package = \"ggmosaic\")\ntitanic\n\n     Class    Sex   Age Survived\n1      3rd   Male Child       No\n2      3rd   Male Child       No\n3      3rd   Male Child       No\n4      3rd   Male Child       No\n5      3rd   Male Child       No\n6      3rd   Male Child       No\n7      3rd   Male Child       No\n8      3rd   Male Child       No\n9      3rd   Male Child       No\n10     3rd   Male Child       No\n11     3rd   Male Child       No\n12     3rd   Male Child       No\n13     3rd   Male Child       No\n14     3rd   Male Child       No\n15     3rd   Male Child       No\n16     3rd   Male Child       No\n17     3rd   Male Child       No\n18     3rd   Male Child       No\n19     3rd   Male Child       No\n20     3rd   Male Child       No\n21     3rd   Male Child       No\n22     3rd   Male Child       No\n23     3rd   Male Child       No\n24     3rd   Male Child       No\n25     3rd   Male Child       No\n26     3rd   Male Child       No\n27     3rd   Male Child       No\n28     3rd   Male Child       No\n29     3rd   Male Child       No\n30     3rd   Male Child       No\n31     3rd   Male Child       No\n32     3rd   Male Child       No\n33     3rd   Male Child       No\n34     3rd   Male Child       No\n35     3rd   Male Child       No\n36     3rd Female Child       No\n37     3rd Female Child       No\n38     3rd Female Child       No\n39     3rd Female Child       No\n40     3rd Female Child       No\n41     3rd Female Child       No\n42     3rd Female Child       No\n43     3rd Female Child       No\n44     3rd Female Child       No\n45     3rd Female Child       No\n46     3rd Female Child       No\n47     3rd Female Child       No\n48     3rd Female Child       No\n49     3rd Female Child       No\n50     3rd Female Child       No\n51     3rd Female Child       No\n52     3rd Female Child       No\n53     1st   Male Adult       No\n54     1st   Male Adult       No\n55     1st   Male Adult       No\n56     1st   Male Adult       No\n57     1st   Male Adult       No\n58     1st   Male Adult       No\n59     1st   Male Adult       No\n60     1st   Male Adult       No\n61     1st   Male Adult       No\n62     1st   Male Adult       No\n63     1st   Male Adult       No\n64     1st   Male Adult       No\n65     1st   Male Adult       No\n66     1st   Male Adult       No\n67     1st   Male Adult       No\n68     1st   Male Adult       No\n69     1st   Male Adult       No\n70     1st   Male Adult       No\n71     1st   Male Adult       No\n72     1st   Male Adult       No\n73     1st   Male Adult       No\n74     1st   Male Adult       No\n75     1st   Male Adult       No\n76     1st   Male Adult       No\n77     1st   Male Adult       No\n78     1st   Male Adult       No\n79     1st   Male Adult       No\n80     1st   Male Adult       No\n81     1st   Male Adult       No\n82     1st   Male Adult       No\n83     1st   Male Adult       No\n84     1st   Male Adult       No\n85     1st   Male Adult       No\n86     1st   Male Adult       No\n87     1st   Male Adult       No\n88     1st   Male Adult       No\n89     1st   Male Adult       No\n90     1st   Male Adult       No\n91     1st   Male Adult       No\n92     1st   Male Adult       No\n93     1st   Male Adult       No\n94     1st   Male Adult       No\n95     1st   Male Adult       No\n96     1st   Male Adult       No\n97     1st   Male Adult       No\n98     1st   Male Adult       No\n99     1st   Male Adult       No\n100    1st   Male Adult       No\n101    1st   Male Adult       No\n102    1st   Male Adult       No\n103    1st   Male Adult       No\n104    1st   Male Adult       No\n105    1st   Male Adult       No\n106    1st   Male Adult       No\n107    1st   Male Adult       No\n108    1st   Male Adult       No\n109    1st   Male Adult       No\n110    1st   Male Adult       No\n111    1st   Male Adult       No\n112    1st   Male Adult       No\n113    1st   Male Adult       No\n114    1st   Male Adult       No\n115    1st   Male Adult       No\n116    1st   Male Adult       No\n117    1st   Male Adult       No\n118    1st   Male Adult       No\n119    1st   Male Adult       No\n120    1st   Male Adult       No\n121    1st   Male Adult       No\n122    1st   Male Adult       No\n123    1st   Male Adult       No\n124    1st   Male Adult       No\n125    1st   Male Adult       No\n126    1st   Male Adult       No\n127    1st   Male Adult       No\n128    1st   Male Adult       No\n129    1st   Male Adult       No\n130    1st   Male Adult       No\n131    1st   Male Adult       No\n132    1st   Male Adult       No\n133    1st   Male Adult       No\n134    1st   Male Adult       No\n135    1st   Male Adult       No\n136    1st   Male Adult       No\n137    1st   Male Adult       No\n138    1st   Male Adult       No\n139    1st   Male Adult       No\n140    1st   Male Adult       No\n141    1st   Male Adult       No\n142    1st   Male Adult       No\n143    1st   Male Adult       No\n144    1st   Male Adult       No\n145    1st   Male Adult       No\n146    1st   Male Adult       No\n147    1st   Male Adult       No\n148    1st   Male Adult       No\n149    1st   Male Adult       No\n150    1st   Male Adult       No\n151    1st   Male Adult       No\n152    1st   Male Adult       No\n153    1st   Male Adult       No\n154    1st   Male Adult       No\n155    1st   Male Adult       No\n156    1st   Male Adult       No\n157    1st   Male Adult       No\n158    1st   Male Adult       No\n159    1st   Male Adult       No\n160    1st   Male Adult       No\n161    1st   Male Adult       No\n162    1st   Male Adult       No\n163    1st   Male Adult       No\n164    1st   Male Adult       No\n165    1st   Male Adult       No\n166    1st   Male Adult       No\n167    1st   Male Adult       No\n168    1st   Male Adult       No\n169    1st   Male Adult       No\n170    1st   Male Adult       No\n171    2nd   Male Adult       No\n172    2nd   Male Adult       No\n173    2nd   Male Adult       No\n174    2nd   Male Adult       No\n175    2nd   Male Adult       No\n176    2nd   Male Adult       No\n177    2nd   Male Adult       No\n178    2nd   Male Adult       No\n179    2nd   Male Adult       No\n180    2nd   Male Adult       No\n181    2nd   Male Adult       No\n182    2nd   Male Adult       No\n183    2nd   Male Adult       No\n184    2nd   Male Adult       No\n185    2nd   Male Adult       No\n186    2nd   Male Adult       No\n187    2nd   Male Adult       No\n188    2nd   Male Adult       No\n189    2nd   Male Adult       No\n190    2nd   Male Adult       No\n191    2nd   Male Adult       No\n192    2nd   Male Adult       No\n193    2nd   Male Adult       No\n194    2nd   Male Adult       No\n195    2nd   Male Adult       No\n196    2nd   Male Adult       No\n197    2nd   Male Adult       No\n198    2nd   Male Adult       No\n199    2nd   Male Adult       No\n200    2nd   Male Adult       No\n201    2nd   Male Adult       No\n202    2nd   Male Adult       No\n203    2nd   Male Adult       No\n204    2nd   Male Adult       No\n205    2nd   Male Adult       No\n206    2nd   Male Adult       No\n207    2nd   Male Adult       No\n208    2nd   Male Adult       No\n209    2nd   Male Adult       No\n210    2nd   Male Adult       No\n211    2nd   Male Adult       No\n212    2nd   Male Adult       No\n213    2nd   Male Adult       No\n214    2nd   Male Adult       No\n215    2nd   Male Adult       No\n216    2nd   Male Adult       No\n217    2nd   Male Adult       No\n218    2nd   Male Adult       No\n219    2nd   Male Adult       No\n220    2nd   Male Adult       No\n221    2nd   Male Adult       No\n222    2nd   Male Adult       No\n223    2nd   Male Adult       No\n224    2nd   Male Adult       No\n225    2nd   Male Adult       No\n226    2nd   Male Adult       No\n227    2nd   Male Adult       No\n228    2nd   Male Adult       No\n229    2nd   Male Adult       No\n230    2nd   Male Adult       No\n231    2nd   Male Adult       No\n232    2nd   Male Adult       No\n233    2nd   Male Adult       No\n234    2nd   Male Adult       No\n235    2nd   Male Adult       No\n236    2nd   Male Adult       No\n237    2nd   Male Adult       No\n238    2nd   Male Adult       No\n239    2nd   Male Adult       No\n240    2nd   Male Adult       No\n241    2nd   Male Adult       No\n242    2nd   Male Adult       No\n243    2nd   Male Adult       No\n244    2nd   Male Adult       No\n245    2nd   Male Adult       No\n246    2nd   Male Adult       No\n247    2nd   Male Adult       No\n248    2nd   Male Adult       No\n249    2nd   Male Adult       No\n250    2nd   Male Adult       No\n251    2nd   Male Adult       No\n252    2nd   Male Adult       No\n253    2nd   Male Adult       No\n254    2nd   Male Adult       No\n255    2nd   Male Adult       No\n256    2nd   Male Adult       No\n257    2nd   Male Adult       No\n258    2nd   Male Adult       No\n259    2nd   Male Adult       No\n260    2nd   Male Adult       No\n261    2nd   Male Adult       No\n262    2nd   Male Adult       No\n263    2nd   Male Adult       No\n264    2nd   Male Adult       No\n265    2nd   Male Adult       No\n266    2nd   Male Adult       No\n267    2nd   Male Adult       No\n268    2nd   Male Adult       No\n269    2nd   Male Adult       No\n270    2nd   Male Adult       No\n271    2nd   Male Adult       No\n272    2nd   Male Adult       No\n273    2nd   Male Adult       No\n274    2nd   Male Adult       No\n275    2nd   Male Adult       No\n276    2nd   Male Adult       No\n277    2nd   Male Adult       No\n278    2nd   Male Adult       No\n279    2nd   Male Adult       No\n280    2nd   Male Adult       No\n281    2nd   Male Adult       No\n282    2nd   Male Adult       No\n283    2nd   Male Adult       No\n284    2nd   Male Adult       No\n285    2nd   Male Adult       No\n286    2nd   Male Adult       No\n287    2nd   Male Adult       No\n288    2nd   Male Adult       No\n289    2nd   Male Adult       No\n290    2nd   Male Adult       No\n291    2nd   Male Adult       No\n292    2nd   Male Adult       No\n293    2nd   Male Adult       No\n294    2nd   Male Adult       No\n295    2nd   Male Adult       No\n296    2nd   Male Adult       No\n297    2nd   Male Adult       No\n298    2nd   Male Adult       No\n299    2nd   Male Adult       No\n300    2nd   Male Adult       No\n301    2nd   Male Adult       No\n302    2nd   Male Adult       No\n303    2nd   Male Adult       No\n304    2nd   Male Adult       No\n305    2nd   Male Adult       No\n306    2nd   Male Adult       No\n307    2nd   Male Adult       No\n308    2nd   Male Adult       No\n309    2nd   Male Adult       No\n310    2nd   Male Adult       No\n311    2nd   Male Adult       No\n312    2nd   Male Adult       No\n313    2nd   Male Adult       No\n314    2nd   Male Adult       No\n315    2nd   Male Adult       No\n316    2nd   Male Adult       No\n317    2nd   Male Adult       No\n318    2nd   Male Adult       No\n319    2nd   Male Adult       No\n320    2nd   Male Adult       No\n321    2nd   Male Adult       No\n322    2nd   Male Adult       No\n323    2nd   Male Adult       No\n324    2nd   Male Adult       No\n325    3rd   Male Adult       No\n326    3rd   Male Adult       No\n327    3rd   Male Adult       No\n328    3rd   Male Adult       No\n329    3rd   Male Adult       No\n330    3rd   Male Adult       No\n331    3rd   Male Adult       No\n332    3rd   Male Adult       No\n333    3rd   Male Adult       No\n334    3rd   Male Adult       No\n335    3rd   Male Adult       No\n336    3rd   Male Adult       No\n337    3rd   Male Adult       No\n338    3rd   Male Adult       No\n339    3rd   Male Adult       No\n340    3rd   Male Adult       No\n341    3rd   Male Adult       No\n342    3rd   Male Adult       No\n343    3rd   Male Adult       No\n344    3rd   Male Adult       No\n345    3rd   Male Adult       No\n346    3rd   Male Adult       No\n347    3rd   Male Adult       No\n348    3rd   Male Adult       No\n349    3rd   Male Adult       No\n350    3rd   Male Adult       No\n351    3rd   Male Adult       No\n352    3rd   Male Adult       No\n353    3rd   Male Adult       No\n354    3rd   Male Adult       No\n355    3rd   Male Adult       No\n356    3rd   Male Adult       No\n357    3rd   Male Adult       No\n358    3rd   Male Adult       No\n359    3rd   Male Adult       No\n360    3rd   Male Adult       No\n361    3rd   Male Adult       No\n362    3rd   Male Adult       No\n363    3rd   Male Adult       No\n364    3rd   Male Adult       No\n365    3rd   Male Adult       No\n366    3rd   Male Adult       No\n367    3rd   Male Adult       No\n368    3rd   Male Adult       No\n369    3rd   Male Adult       No\n370    3rd   Male Adult       No\n371    3rd   Male Adult       No\n372    3rd   Male Adult       No\n373    3rd   Male Adult       No\n374    3rd   Male Adult       No\n375    3rd   Male Adult       No\n376    3rd   Male Adult       No\n377    3rd   Male Adult       No\n378    3rd   Male Adult       No\n379    3rd   Male Adult       No\n380    3rd   Male Adult       No\n381    3rd   Male Adult       No\n382    3rd   Male Adult       No\n383    3rd   Male Adult       No\n384    3rd   Male Adult       No\n385    3rd   Male Adult       No\n386    3rd   Male Adult       No\n387    3rd   Male Adult       No\n388    3rd   Male Adult       No\n389    3rd   Male Adult       No\n390    3rd   Male Adult       No\n391    3rd   Male Adult       No\n392    3rd   Male Adult       No\n393    3rd   Male Adult       No\n394    3rd   Male Adult       No\n395    3rd   Male Adult       No\n396    3rd   Male Adult       No\n397    3rd   Male Adult       No\n398    3rd   Male Adult       No\n399    3rd   Male Adult       No\n400    3rd   Male Adult       No\n401    3rd   Male Adult       No\n402    3rd   Male Adult       No\n403    3rd   Male Adult       No\n404    3rd   Male Adult       No\n405    3rd   Male Adult       No\n406    3rd   Male Adult       No\n407    3rd   Male Adult       No\n408    3rd   Male Adult       No\n409    3rd   Male Adult       No\n410    3rd   Male Adult       No\n411    3rd   Male Adult       No\n412    3rd   Male Adult       No\n413    3rd   Male Adult       No\n414    3rd   Male Adult       No\n415    3rd   Male Adult       No\n416    3rd   Male Adult       No\n417    3rd   Male Adult       No\n418    3rd   Male Adult       No\n419    3rd   Male Adult       No\n420    3rd   Male Adult       No\n421    3rd   Male Adult       No\n422    3rd   Male Adult       No\n423    3rd   Male Adult       No\n424    3rd   Male Adult       No\n425    3rd   Male Adult       No\n426    3rd   Male Adult       No\n427    3rd   Male Adult       No\n428    3rd   Male Adult       No\n429    3rd   Male Adult       No\n430    3rd   Male Adult       No\n431    3rd   Male Adult       No\n432    3rd   Male Adult       No\n433    3rd   Male Adult       No\n434    3rd   Male Adult       No\n435    3rd   Male Adult       No\n436    3rd   Male Adult       No\n437    3rd   Male Adult       No\n438    3rd   Male Adult       No\n439    3rd   Male Adult       No\n440    3rd   Male Adult       No\n441    3rd   Male Adult       No\n442    3rd   Male Adult       No\n443    3rd   Male Adult       No\n444    3rd   Male Adult       No\n445    3rd   Male Adult       No\n446    3rd   Male Adult       No\n447    3rd   Male Adult       No\n448    3rd   Male Adult       No\n449    3rd   Male Adult       No\n450    3rd   Male Adult       No\n451    3rd   Male Adult       No\n452    3rd   Male Adult       No\n453    3rd   Male Adult       No\n454    3rd   Male Adult       No\n455    3rd   Male Adult       No\n456    3rd   Male Adult       No\n457    3rd   Male Adult       No\n458    3rd   Male Adult       No\n459    3rd   Male Adult       No\n460    3rd   Male Adult       No\n461    3rd   Male Adult       No\n462    3rd   Male Adult       No\n463    3rd   Male Adult       No\n464    3rd   Male Adult       No\n465    3rd   Male Adult       No\n466    3rd   Male Adult       No\n467    3rd   Male Adult       No\n468    3rd   Male Adult       No\n469    3rd   Male Adult       No\n470    3rd   Male Adult       No\n471    3rd   Male Adult       No\n472    3rd   Male Adult       No\n473    3rd   Male Adult       No\n474    3rd   Male Adult       No\n475    3rd   Male Adult       No\n476    3rd   Male Adult       No\n477    3rd   Male Adult       No\n478    3rd   Male Adult       No\n479    3rd   Male Adult       No\n480    3rd   Male Adult       No\n481    3rd   Male Adult       No\n482    3rd   Male Adult       No\n483    3rd   Male Adult       No\n484    3rd   Male Adult       No\n485    3rd   Male Adult       No\n486    3rd   Male Adult       No\n487    3rd   Male Adult       No\n488    3rd   Male Adult       No\n489    3rd   Male Adult       No\n490    3rd   Male Adult       No\n491    3rd   Male Adult       No\n492    3rd   Male Adult       No\n493    3rd   Male Adult       No\n494    3rd   Male Adult       No\n495    3rd   Male Adult       No\n496    3rd   Male Adult       No\n497    3rd   Male Adult       No\n498    3rd   Male Adult       No\n499    3rd   Male Adult       No\n500    3rd   Male Adult       No\n501    3rd   Male Adult       No\n502    3rd   Male Adult       No\n503    3rd   Male Adult       No\n504    3rd   Male Adult       No\n505    3rd   Male Adult       No\n506    3rd   Male Adult       No\n507    3rd   Male Adult       No\n508    3rd   Male Adult       No\n509    3rd   Male Adult       No\n510    3rd   Male Adult       No\n511    3rd   Male Adult       No\n512    3rd   Male Adult       No\n513    3rd   Male Adult       No\n514    3rd   Male Adult       No\n515    3rd   Male Adult       No\n516    3rd   Male Adult       No\n517    3rd   Male Adult       No\n518    3rd   Male Adult       No\n519    3rd   Male Adult       No\n520    3rd   Male Adult       No\n521    3rd   Male Adult       No\n522    3rd   Male Adult       No\n523    3rd   Male Adult       No\n524    3rd   Male Adult       No\n525    3rd   Male Adult       No\n526    3rd   Male Adult       No\n527    3rd   Male Adult       No\n528    3rd   Male Adult       No\n529    3rd   Male Adult       No\n530    3rd   Male Adult       No\n531    3rd   Male Adult       No\n532    3rd   Male Adult       No\n533    3rd   Male Adult       No\n534    3rd   Male Adult       No\n535    3rd   Male Adult       No\n536    3rd   Male Adult       No\n537    3rd   Male Adult       No\n538    3rd   Male Adult       No\n539    3rd   Male Adult       No\n540    3rd   Male Adult       No\n541    3rd   Male Adult       No\n542    3rd   Male Adult       No\n543    3rd   Male Adult       No\n544    3rd   Male Adult       No\n545    3rd   Male Adult       No\n546    3rd   Male Adult       No\n547    3rd   Male Adult       No\n548    3rd   Male Adult       No\n549    3rd   Male Adult       No\n550    3rd   Male Adult       No\n551    3rd   Male Adult       No\n552    3rd   Male Adult       No\n553    3rd   Male Adult       No\n554    3rd   Male Adult       No\n555    3rd   Male Adult       No\n556    3rd   Male Adult       No\n557    3rd   Male Adult       No\n558    3rd   Male Adult       No\n559    3rd   Male Adult       No\n560    3rd   Male Adult       No\n561    3rd   Male Adult       No\n562    3rd   Male Adult       No\n563    3rd   Male Adult       No\n564    3rd   Male Adult       No\n565    3rd   Male Adult       No\n566    3rd   Male Adult       No\n567    3rd   Male Adult       No\n568    3rd   Male Adult       No\n569    3rd   Male Adult       No\n570    3rd   Male Adult       No\n571    3rd   Male Adult       No\n572    3rd   Male Adult       No\n573    3rd   Male Adult       No\n574    3rd   Male Adult       No\n575    3rd   Male Adult       No\n576    3rd   Male Adult       No\n577    3rd   Male Adult       No\n578    3rd   Male Adult       No\n579    3rd   Male Adult       No\n580    3rd   Male Adult       No\n581    3rd   Male Adult       No\n582    3rd   Male Adult       No\n583    3rd   Male Adult       No\n584    3rd   Male Adult       No\n585    3rd   Male Adult       No\n586    3rd   Male Adult       No\n587    3rd   Male Adult       No\n588    3rd   Male Adult       No\n589    3rd   Male Adult       No\n590    3rd   Male Adult       No\n591    3rd   Male Adult       No\n592    3rd   Male Adult       No\n593    3rd   Male Adult       No\n594    3rd   Male Adult       No\n595    3rd   Male Adult       No\n596    3rd   Male Adult       No\n597    3rd   Male Adult       No\n598    3rd   Male Adult       No\n599    3rd   Male Adult       No\n600    3rd   Male Adult       No\n601    3rd   Male Adult       No\n602    3rd   Male Adult       No\n603    3rd   Male Adult       No\n604    3rd   Male Adult       No\n605    3rd   Male Adult       No\n606    3rd   Male Adult       No\n607    3rd   Male Adult       No\n608    3rd   Male Adult       No\n609    3rd   Male Adult       No\n610    3rd   Male Adult       No\n611    3rd   Male Adult       No\n612    3rd   Male Adult       No\n613    3rd   Male Adult       No\n614    3rd   Male Adult       No\n615    3rd   Male Adult       No\n616    3rd   Male Adult       No\n617    3rd   Male Adult       No\n618    3rd   Male Adult       No\n619    3rd   Male Adult       No\n620    3rd   Male Adult       No\n621    3rd   Male Adult       No\n622    3rd   Male Adult       No\n623    3rd   Male Adult       No\n624    3rd   Male Adult       No\n625    3rd   Male Adult       No\n626    3rd   Male Adult       No\n627    3rd   Male Adult       No\n628    3rd   Male Adult       No\n629    3rd   Male Adult       No\n630    3rd   Male Adult       No\n631    3rd   Male Adult       No\n632    3rd   Male Adult       No\n633    3rd   Male Adult       No\n634    3rd   Male Adult       No\n635    3rd   Male Adult       No\n636    3rd   Male Adult       No\n637    3rd   Male Adult       No\n638    3rd   Male Adult       No\n639    3rd   Male Adult       No\n640    3rd   Male Adult       No\n641    3rd   Male Adult       No\n642    3rd   Male Adult       No\n643    3rd   Male Adult       No\n644    3rd   Male Adult       No\n645    3rd   Male Adult       No\n646    3rd   Male Adult       No\n647    3rd   Male Adult       No\n648    3rd   Male Adult       No\n649    3rd   Male Adult       No\n650    3rd   Male Adult       No\n651    3rd   Male Adult       No\n652    3rd   Male Adult       No\n653    3rd   Male Adult       No\n654    3rd   Male Adult       No\n655    3rd   Male Adult       No\n656    3rd   Male Adult       No\n657    3rd   Male Adult       No\n658    3rd   Male Adult       No\n659    3rd   Male Adult       No\n660    3rd   Male Adult       No\n661    3rd   Male Adult       No\n662    3rd   Male Adult       No\n663    3rd   Male Adult       No\n664    3rd   Male Adult       No\n665    3rd   Male Adult       No\n666    3rd   Male Adult       No\n667    3rd   Male Adult       No\n668    3rd   Male Adult       No\n669    3rd   Male Adult       No\n670    3rd   Male Adult       No\n671    3rd   Male Adult       No\n672    3rd   Male Adult       No\n673    3rd   Male Adult       No\n674    3rd   Male Adult       No\n675    3rd   Male Adult       No\n676    3rd   Male Adult       No\n677    3rd   Male Adult       No\n678    3rd   Male Adult       No\n679    3rd   Male Adult       No\n680    3rd   Male Adult       No\n681    3rd   Male Adult       No\n682    3rd   Male Adult       No\n683    3rd   Male Adult       No\n684    3rd   Male Adult       No\n685    3rd   Male Adult       No\n686    3rd   Male Adult       No\n687    3rd   Male Adult       No\n688    3rd   Male Adult       No\n689    3rd   Male Adult       No\n690    3rd   Male Adult       No\n691    3rd   Male Adult       No\n692    3rd   Male Adult       No\n693    3rd   Male Adult       No\n694    3rd   Male Adult       No\n695    3rd   Male Adult       No\n696    3rd   Male Adult       No\n697    3rd   Male Adult       No\n698    3rd   Male Adult       No\n699    3rd   Male Adult       No\n700    3rd   Male Adult       No\n701    3rd   Male Adult       No\n702    3rd   Male Adult       No\n703    3rd   Male Adult       No\n704    3rd   Male Adult       No\n705    3rd   Male Adult       No\n706    3rd   Male Adult       No\n707    3rd   Male Adult       No\n708    3rd   Male Adult       No\n709    3rd   Male Adult       No\n710    3rd   Male Adult       No\n711    3rd   Male Adult       No\n712   Crew   Male Adult       No\n713   Crew   Male Adult       No\n714   Crew   Male Adult       No\n715   Crew   Male Adult       No\n716   Crew   Male Adult       No\n717   Crew   Male Adult       No\n718   Crew   Male Adult       No\n719   Crew   Male Adult       No\n720   Crew   Male Adult       No\n721   Crew   Male Adult       No\n722   Crew   Male Adult       No\n723   Crew   Male Adult       No\n724   Crew   Male Adult       No\n725   Crew   Male Adult       No\n726   Crew   Male Adult       No\n727   Crew   Male Adult       No\n728   Crew   Male Adult       No\n729   Crew   Male Adult       No\n730   Crew   Male Adult       No\n731   Crew   Male Adult       No\n732   Crew   Male Adult       No\n733   Crew   Male Adult       No\n734   Crew   Male Adult       No\n735   Crew   Male Adult       No\n736   Crew   Male Adult       No\n737   Crew   Male Adult       No\n738   Crew   Male Adult       No\n739   Crew   Male Adult       No\n740   Crew   Male Adult       No\n741   Crew   Male Adult       No\n742   Crew   Male Adult       No\n743   Crew   Male Adult       No\n744   Crew   Male Adult       No\n745   Crew   Male Adult       No\n746   Crew   Male Adult       No\n747   Crew   Male Adult       No\n748   Crew   Male Adult       No\n749   Crew   Male Adult       No\n750   Crew   Male Adult       No\n751   Crew   Male Adult       No\n752   Crew   Male Adult       No\n753   Crew   Male Adult       No\n754   Crew   Male Adult       No\n755   Crew   Male Adult       No\n756   Crew   Male Adult       No\n757   Crew   Male Adult       No\n758   Crew   Male Adult       No\n759   Crew   Male Adult       No\n760   Crew   Male Adult       No\n761   Crew   Male Adult       No\n762   Crew   Male Adult       No\n763   Crew   Male Adult       No\n764   Crew   Male Adult       No\n765   Crew   Male Adult       No\n766   Crew   Male Adult       No\n767   Crew   Male Adult       No\n768   Crew   Male Adult       No\n769   Crew   Male Adult       No\n770   Crew   Male Adult       No\n771   Crew   Male Adult       No\n772   Crew   Male Adult       No\n773   Crew   Male Adult       No\n774   Crew   Male Adult       No\n775   Crew   Male Adult       No\n776   Crew   Male Adult       No\n777   Crew   Male Adult       No\n778   Crew   Male Adult       No\n779   Crew   Male Adult       No\n780   Crew   Male Adult       No\n781   Crew   Male Adult       No\n782   Crew   Male Adult       No\n783   Crew   Male Adult       No\n784   Crew   Male Adult       No\n785   Crew   Male Adult       No\n786   Crew   Male Adult       No\n787   Crew   Male Adult       No\n788   Crew   Male Adult       No\n789   Crew   Male Adult       No\n790   Crew   Male Adult       No\n791   Crew   Male Adult       No\n792   Crew   Male Adult       No\n793   Crew   Male Adult       No\n794   Crew   Male Adult       No\n795   Crew   Male Adult       No\n796   Crew   Male Adult       No\n797   Crew   Male Adult       No\n798   Crew   Male Adult       No\n799   Crew   Male Adult       No\n800   Crew   Male Adult       No\n801   Crew   Male Adult       No\n802   Crew   Male Adult       No\n803   Crew   Male Adult       No\n804   Crew   Male Adult       No\n805   Crew   Male Adult       No\n806   Crew   Male Adult       No\n807   Crew   Male Adult       No\n808   Crew   Male Adult       No\n809   Crew   Male Adult       No\n810   Crew   Male Adult       No\n811   Crew   Male Adult       No\n812   Crew   Male Adult       No\n813   Crew   Male Adult       No\n814   Crew   Male Adult       No\n815   Crew   Male Adult       No\n816   Crew   Male Adult       No\n817   Crew   Male Adult       No\n818   Crew   Male Adult       No\n819   Crew   Male Adult       No\n820   Crew   Male Adult       No\n821   Crew   Male Adult       No\n822   Crew   Male Adult       No\n823   Crew   Male Adult       No\n824   Crew   Male Adult       No\n825   Crew   Male Adult       No\n826   Crew   Male Adult       No\n827   Crew   Male Adult       No\n828   Crew   Male Adult       No\n829   Crew   Male Adult       No\n830   Crew   Male Adult       No\n831   Crew   Male Adult       No\n832   Crew   Male Adult       No\n833   Crew   Male Adult       No\n834   Crew   Male Adult       No\n835   Crew   Male Adult       No\n836   Crew   Male Adult       No\n837   Crew   Male Adult       No\n838   Crew   Male Adult       No\n839   Crew   Male Adult       No\n840   Crew   Male Adult       No\n841   Crew   Male Adult       No\n842   Crew   Male Adult       No\n843   Crew   Male Adult       No\n844   Crew   Male Adult       No\n845   Crew   Male Adult       No\n846   Crew   Male Adult       No\n847   Crew   Male Adult       No\n848   Crew   Male Adult       No\n849   Crew   Male Adult       No\n850   Crew   Male Adult       No\n851   Crew   Male Adult       No\n852   Crew   Male Adult       No\n853   Crew   Male Adult       No\n854   Crew   Male Adult       No\n855   Crew   Male Adult       No\n856   Crew   Male Adult       No\n857   Crew   Male Adult       No\n858   Crew   Male Adult       No\n859   Crew   Male Adult       No\n860   Crew   Male Adult       No\n861   Crew   Male Adult       No\n862   Crew   Male Adult       No\n863   Crew   Male Adult       No\n864   Crew   Male Adult       No\n865   Crew   Male Adult       No\n866   Crew   Male Adult       No\n867   Crew   Male Adult       No\n868   Crew   Male Adult       No\n869   Crew   Male Adult       No\n870   Crew   Male Adult       No\n871   Crew   Male Adult       No\n872   Crew   Male Adult       No\n873   Crew   Male Adult       No\n874   Crew   Male Adult       No\n875   Crew   Male Adult       No\n876   Crew   Male Adult       No\n877   Crew   Male Adult       No\n878   Crew   Male Adult       No\n879   Crew   Male Adult       No\n880   Crew   Male Adult       No\n881   Crew   Male Adult       No\n882   Crew   Male Adult       No\n883   Crew   Male Adult       No\n884   Crew   Male Adult       No\n885   Crew   Male Adult       No\n886   Crew   Male Adult       No\n887   Crew   Male Adult       No\n888   Crew   Male Adult       No\n889   Crew   Male Adult       No\n890   Crew   Male Adult       No\n891   Crew   Male Adult       No\n892   Crew   Male Adult       No\n893   Crew   Male Adult       No\n894   Crew   Male Adult       No\n895   Crew   Male Adult       No\n896   Crew   Male Adult       No\n897   Crew   Male Adult       No\n898   Crew   Male Adult       No\n899   Crew   Male Adult       No\n900   Crew   Male Adult       No\n901   Crew   Male Adult       No\n902   Crew   Male Adult       No\n903   Crew   Male Adult       No\n904   Crew   Male Adult       No\n905   Crew   Male Adult       No\n906   Crew   Male Adult       No\n907   Crew   Male Adult       No\n908   Crew   Male Adult       No\n909   Crew   Male Adult       No\n910   Crew   Male Adult       No\n911   Crew   Male Adult       No\n912   Crew   Male Adult       No\n913   Crew   Male Adult       No\n914   Crew   Male Adult       No\n915   Crew   Male Adult       No\n916   Crew   Male Adult       No\n917   Crew   Male Adult       No\n918   Crew   Male Adult       No\n919   Crew   Male Adult       No\n920   Crew   Male Adult       No\n921   Crew   Male Adult       No\n922   Crew   Male Adult       No\n923   Crew   Male Adult       No\n924   Crew   Male Adult       No\n925   Crew   Male Adult       No\n926   Crew   Male Adult       No\n927   Crew   Male Adult       No\n928   Crew   Male Adult       No\n929   Crew   Male Adult       No\n930   Crew   Male Adult       No\n931   Crew   Male Adult       No\n932   Crew   Male Adult       No\n933   Crew   Male Adult       No\n934   Crew   Male Adult       No\n935   Crew   Male Adult       No\n936   Crew   Male Adult       No\n937   Crew   Male Adult       No\n938   Crew   Male Adult       No\n939   Crew   Male Adult       No\n940   Crew   Male Adult       No\n941   Crew   Male Adult       No\n942   Crew   Male Adult       No\n943   Crew   Male Adult       No\n944   Crew   Male Adult       No\n945   Crew   Male Adult       No\n946   Crew   Male Adult       No\n947   Crew   Male Adult       No\n948   Crew   Male Adult       No\n949   Crew   Male Adult       No\n950   Crew   Male Adult       No\n951   Crew   Male Adult       No\n952   Crew   Male Adult       No\n953   Crew   Male Adult       No\n954   Crew   Male Adult       No\n955   Crew   Male Adult       No\n956   Crew   Male Adult       No\n957   Crew   Male Adult       No\n958   Crew   Male Adult       No\n959   Crew   Male Adult       No\n960   Crew   Male Adult       No\n961   Crew   Male Adult       No\n962   Crew   Male Adult       No\n963   Crew   Male Adult       No\n964   Crew   Male Adult       No\n965   Crew   Male Adult       No\n966   Crew   Male Adult       No\n967   Crew   Male Adult       No\n968   Crew   Male Adult       No\n969   Crew   Male Adult       No\n970   Crew   Male Adult       No\n971   Crew   Male Adult       No\n972   Crew   Male Adult       No\n973   Crew   Male Adult       No\n974   Crew   Male Adult       No\n975   Crew   Male Adult       No\n976   Crew   Male Adult       No\n977   Crew   Male Adult       No\n978   Crew   Male Adult       No\n979   Crew   Male Adult       No\n980   Crew   Male Adult       No\n981   Crew   Male Adult       No\n982   Crew   Male Adult       No\n983   Crew   Male Adult       No\n984   Crew   Male Adult       No\n985   Crew   Male Adult       No\n986   Crew   Male Adult       No\n987   Crew   Male Adult       No\n988   Crew   Male Adult       No\n989   Crew   Male Adult       No\n990   Crew   Male Adult       No\n991   Crew   Male Adult       No\n992   Crew   Male Adult       No\n993   Crew   Male Adult       No\n994   Crew   Male Adult       No\n995   Crew   Male Adult       No\n996   Crew   Male Adult       No\n997   Crew   Male Adult       No\n998   Crew   Male Adult       No\n999   Crew   Male Adult       No\n1000  Crew   Male Adult       No\n1001  Crew   Male Adult       No\n1002  Crew   Male Adult       No\n1003  Crew   Male Adult       No\n1004  Crew   Male Adult       No\n1005  Crew   Male Adult       No\n1006  Crew   Male Adult       No\n1007  Crew   Male Adult       No\n1008  Crew   Male Adult       No\n1009  Crew   Male Adult       No\n1010  Crew   Male Adult       No\n1011  Crew   Male Adult       No\n1012  Crew   Male Adult       No\n1013  Crew   Male Adult       No\n1014  Crew   Male Adult       No\n1015  Crew   Male Adult       No\n1016  Crew   Male Adult       No\n1017  Crew   Male Adult       No\n1018  Crew   Male Adult       No\n1019  Crew   Male Adult       No\n1020  Crew   Male Adult       No\n1021  Crew   Male Adult       No\n1022  Crew   Male Adult       No\n1023  Crew   Male Adult       No\n1024  Crew   Male Adult       No\n1025  Crew   Male Adult       No\n1026  Crew   Male Adult       No\n1027  Crew   Male Adult       No\n1028  Crew   Male Adult       No\n1029  Crew   Male Adult       No\n1030  Crew   Male Adult       No\n1031  Crew   Male Adult       No\n1032  Crew   Male Adult       No\n1033  Crew   Male Adult       No\n1034  Crew   Male Adult       No\n1035  Crew   Male Adult       No\n1036  Crew   Male Adult       No\n1037  Crew   Male Adult       No\n1038  Crew   Male Adult       No\n1039  Crew   Male Adult       No\n1040  Crew   Male Adult       No\n1041  Crew   Male Adult       No\n1042  Crew   Male Adult       No\n1043  Crew   Male Adult       No\n1044  Crew   Male Adult       No\n1045  Crew   Male Adult       No\n1046  Crew   Male Adult       No\n1047  Crew   Male Adult       No\n1048  Crew   Male Adult       No\n1049  Crew   Male Adult       No\n1050  Crew   Male Adult       No\n1051  Crew   Male Adult       No\n1052  Crew   Male Adult       No\n1053  Crew   Male Adult       No\n1054  Crew   Male Adult       No\n1055  Crew   Male Adult       No\n1056  Crew   Male Adult       No\n1057  Crew   Male Adult       No\n1058  Crew   Male Adult       No\n1059  Crew   Male Adult       No\n1060  Crew   Male Adult       No\n1061  Crew   Male Adult       No\n1062  Crew   Male Adult       No\n1063  Crew   Male Adult       No\n1064  Crew   Male Adult       No\n1065  Crew   Male Adult       No\n1066  Crew   Male Adult       No\n1067  Crew   Male Adult       No\n1068  Crew   Male Adult       No\n1069  Crew   Male Adult       No\n1070  Crew   Male Adult       No\n1071  Crew   Male Adult       No\n1072  Crew   Male Adult       No\n1073  Crew   Male Adult       No\n1074  Crew   Male Adult       No\n1075  Crew   Male Adult       No\n1076  Crew   Male Adult       No\n1077  Crew   Male Adult       No\n1078  Crew   Male Adult       No\n1079  Crew   Male Adult       No\n1080  Crew   Male Adult       No\n1081  Crew   Male Adult       No\n1082  Crew   Male Adult       No\n1083  Crew   Male Adult       No\n1084  Crew   Male Adult       No\n1085  Crew   Male Adult       No\n1086  Crew   Male Adult       No\n1087  Crew   Male Adult       No\n1088  Crew   Male Adult       No\n1089  Crew   Male Adult       No\n1090  Crew   Male Adult       No\n1091  Crew   Male Adult       No\n1092  Crew   Male Adult       No\n1093  Crew   Male Adult       No\n1094  Crew   Male Adult       No\n1095  Crew   Male Adult       No\n1096  Crew   Male Adult       No\n1097  Crew   Male Adult       No\n1098  Crew   Male Adult       No\n1099  Crew   Male Adult       No\n1100  Crew   Male Adult       No\n1101  Crew   Male Adult       No\n1102  Crew   Male Adult       No\n1103  Crew   Male Adult       No\n1104  Crew   Male Adult       No\n1105  Crew   Male Adult       No\n1106  Crew   Male Adult       No\n1107  Crew   Male Adult       No\n1108  Crew   Male Adult       No\n1109  Crew   Male Adult       No\n1110  Crew   Male Adult       No\n1111  Crew   Male Adult       No\n1112  Crew   Male Adult       No\n1113  Crew   Male Adult       No\n1114  Crew   Male Adult       No\n1115  Crew   Male Adult       No\n1116  Crew   Male Adult       No\n1117  Crew   Male Adult       No\n1118  Crew   Male Adult       No\n1119  Crew   Male Adult       No\n1120  Crew   Male Adult       No\n1121  Crew   Male Adult       No\n1122  Crew   Male Adult       No\n1123  Crew   Male Adult       No\n1124  Crew   Male Adult       No\n1125  Crew   Male Adult       No\n1126  Crew   Male Adult       No\n1127  Crew   Male Adult       No\n1128  Crew   Male Adult       No\n1129  Crew   Male Adult       No\n1130  Crew   Male Adult       No\n1131  Crew   Male Adult       No\n1132  Crew   Male Adult       No\n1133  Crew   Male Adult       No\n1134  Crew   Male Adult       No\n1135  Crew   Male Adult       No\n1136  Crew   Male Adult       No\n1137  Crew   Male Adult       No\n1138  Crew   Male Adult       No\n1139  Crew   Male Adult       No\n1140  Crew   Male Adult       No\n1141  Crew   Male Adult       No\n1142  Crew   Male Adult       No\n1143  Crew   Male Adult       No\n1144  Crew   Male Adult       No\n1145  Crew   Male Adult       No\n1146  Crew   Male Adult       No\n1147  Crew   Male Adult       No\n1148  Crew   Male Adult       No\n1149  Crew   Male Adult       No\n1150  Crew   Male Adult       No\n1151  Crew   Male Adult       No\n1152  Crew   Male Adult       No\n1153  Crew   Male Adult       No\n1154  Crew   Male Adult       No\n1155  Crew   Male Adult       No\n1156  Crew   Male Adult       No\n1157  Crew   Male Adult       No\n1158  Crew   Male Adult       No\n1159  Crew   Male Adult       No\n1160  Crew   Male Adult       No\n1161  Crew   Male Adult       No\n1162  Crew   Male Adult       No\n1163  Crew   Male Adult       No\n1164  Crew   Male Adult       No\n1165  Crew   Male Adult       No\n1166  Crew   Male Adult       No\n1167  Crew   Male Adult       No\n1168  Crew   Male Adult       No\n1169  Crew   Male Adult       No\n1170  Crew   Male Adult       No\n1171  Crew   Male Adult       No\n1172  Crew   Male Adult       No\n1173  Crew   Male Adult       No\n1174  Crew   Male Adult       No\n1175  Crew   Male Adult       No\n1176  Crew   Male Adult       No\n1177  Crew   Male Adult       No\n1178  Crew   Male Adult       No\n1179  Crew   Male Adult       No\n1180  Crew   Male Adult       No\n1181  Crew   Male Adult       No\n1182  Crew   Male Adult       No\n1183  Crew   Male Adult       No\n1184  Crew   Male Adult       No\n1185  Crew   Male Adult       No\n1186  Crew   Male Adult       No\n1187  Crew   Male Adult       No\n1188  Crew   Male Adult       No\n1189  Crew   Male Adult       No\n1190  Crew   Male Adult       No\n1191  Crew   Male Adult       No\n1192  Crew   Male Adult       No\n1193  Crew   Male Adult       No\n1194  Crew   Male Adult       No\n1195  Crew   Male Adult       No\n1196  Crew   Male Adult       No\n1197  Crew   Male Adult       No\n1198  Crew   Male Adult       No\n1199  Crew   Male Adult       No\n1200  Crew   Male Adult       No\n1201  Crew   Male Adult       No\n1202  Crew   Male Adult       No\n1203  Crew   Male Adult       No\n1204  Crew   Male Adult       No\n1205  Crew   Male Adult       No\n1206  Crew   Male Adult       No\n1207  Crew   Male Adult       No\n1208  Crew   Male Adult       No\n1209  Crew   Male Adult       No\n1210  Crew   Male Adult       No\n1211  Crew   Male Adult       No\n1212  Crew   Male Adult       No\n1213  Crew   Male Adult       No\n1214  Crew   Male Adult       No\n1215  Crew   Male Adult       No\n1216  Crew   Male Adult       No\n1217  Crew   Male Adult       No\n1218  Crew   Male Adult       No\n1219  Crew   Male Adult       No\n1220  Crew   Male Adult       No\n1221  Crew   Male Adult       No\n1222  Crew   Male Adult       No\n1223  Crew   Male Adult       No\n1224  Crew   Male Adult       No\n1225  Crew   Male Adult       No\n1226  Crew   Male Adult       No\n1227  Crew   Male Adult       No\n1228  Crew   Male Adult       No\n1229  Crew   Male Adult       No\n1230  Crew   Male Adult       No\n1231  Crew   Male Adult       No\n1232  Crew   Male Adult       No\n1233  Crew   Male Adult       No\n1234  Crew   Male Adult       No\n1235  Crew   Male Adult       No\n1236  Crew   Male Adult       No\n1237  Crew   Male Adult       No\n1238  Crew   Male Adult       No\n1239  Crew   Male Adult       No\n1240  Crew   Male Adult       No\n1241  Crew   Male Adult       No\n1242  Crew   Male Adult       No\n1243  Crew   Male Adult       No\n1244  Crew   Male Adult       No\n1245  Crew   Male Adult       No\n1246  Crew   Male Adult       No\n1247  Crew   Male Adult       No\n1248  Crew   Male Adult       No\n1249  Crew   Male Adult       No\n1250  Crew   Male Adult       No\n1251  Crew   Male Adult       No\n1252  Crew   Male Adult       No\n1253  Crew   Male Adult       No\n1254  Crew   Male Adult       No\n1255  Crew   Male Adult       No\n1256  Crew   Male Adult       No\n1257  Crew   Male Adult       No\n1258  Crew   Male Adult       No\n1259  Crew   Male Adult       No\n1260  Crew   Male Adult       No\n1261  Crew   Male Adult       No\n1262  Crew   Male Adult       No\n1263  Crew   Male Adult       No\n1264  Crew   Male Adult       No\n1265  Crew   Male Adult       No\n1266  Crew   Male Adult       No\n1267  Crew   Male Adult       No\n1268  Crew   Male Adult       No\n1269  Crew   Male Adult       No\n1270  Crew   Male Adult       No\n1271  Crew   Male Adult       No\n1272  Crew   Male Adult       No\n1273  Crew   Male Adult       No\n1274  Crew   Male Adult       No\n1275  Crew   Male Adult       No\n1276  Crew   Male Adult       No\n1277  Crew   Male Adult       No\n1278  Crew   Male Adult       No\n1279  Crew   Male Adult       No\n1280  Crew   Male Adult       No\n1281  Crew   Male Adult       No\n1282  Crew   Male Adult       No\n1283  Crew   Male Adult       No\n1284  Crew   Male Adult       No\n1285  Crew   Male Adult       No\n1286  Crew   Male Adult       No\n1287  Crew   Male Adult       No\n1288  Crew   Male Adult       No\n1289  Crew   Male Adult       No\n1290  Crew   Male Adult       No\n1291  Crew   Male Adult       No\n1292  Crew   Male Adult       No\n1293  Crew   Male Adult       No\n1294  Crew   Male Adult       No\n1295  Crew   Male Adult       No\n1296  Crew   Male Adult       No\n1297  Crew   Male Adult       No\n1298  Crew   Male Adult       No\n1299  Crew   Male Adult       No\n1300  Crew   Male Adult       No\n1301  Crew   Male Adult       No\n1302  Crew   Male Adult       No\n1303  Crew   Male Adult       No\n1304  Crew   Male Adult       No\n1305  Crew   Male Adult       No\n1306  Crew   Male Adult       No\n1307  Crew   Male Adult       No\n1308  Crew   Male Adult       No\n1309  Crew   Male Adult       No\n1310  Crew   Male Adult       No\n1311  Crew   Male Adult       No\n1312  Crew   Male Adult       No\n1313  Crew   Male Adult       No\n1314  Crew   Male Adult       No\n1315  Crew   Male Adult       No\n1316  Crew   Male Adult       No\n1317  Crew   Male Adult       No\n1318  Crew   Male Adult       No\n1319  Crew   Male Adult       No\n1320  Crew   Male Adult       No\n1321  Crew   Male Adult       No\n1322  Crew   Male Adult       No\n1323  Crew   Male Adult       No\n1324  Crew   Male Adult       No\n1325  Crew   Male Adult       No\n1326  Crew   Male Adult       No\n1327  Crew   Male Adult       No\n1328  Crew   Male Adult       No\n1329  Crew   Male Adult       No\n1330  Crew   Male Adult       No\n1331  Crew   Male Adult       No\n1332  Crew   Male Adult       No\n1333  Crew   Male Adult       No\n1334  Crew   Male Adult       No\n1335  Crew   Male Adult       No\n1336  Crew   Male Adult       No\n1337  Crew   Male Adult       No\n1338  Crew   Male Adult       No\n1339  Crew   Male Adult       No\n1340  Crew   Male Adult       No\n1341  Crew   Male Adult       No\n1342  Crew   Male Adult       No\n1343  Crew   Male Adult       No\n1344  Crew   Male Adult       No\n1345  Crew   Male Adult       No\n1346  Crew   Male Adult       No\n1347  Crew   Male Adult       No\n1348  Crew   Male Adult       No\n1349  Crew   Male Adult       No\n1350  Crew   Male Adult       No\n1351  Crew   Male Adult       No\n1352  Crew   Male Adult       No\n1353  Crew   Male Adult       No\n1354  Crew   Male Adult       No\n1355  Crew   Male Adult       No\n1356  Crew   Male Adult       No\n1357  Crew   Male Adult       No\n1358  Crew   Male Adult       No\n1359  Crew   Male Adult       No\n1360  Crew   Male Adult       No\n1361  Crew   Male Adult       No\n1362  Crew   Male Adult       No\n1363  Crew   Male Adult       No\n1364  Crew   Male Adult       No\n1365  Crew   Male Adult       No\n1366  Crew   Male Adult       No\n1367  Crew   Male Adult       No\n1368  Crew   Male Adult       No\n1369  Crew   Male Adult       No\n1370  Crew   Male Adult       No\n1371  Crew   Male Adult       No\n1372  Crew   Male Adult       No\n1373  Crew   Male Adult       No\n1374  Crew   Male Adult       No\n1375  Crew   Male Adult       No\n1376  Crew   Male Adult       No\n1377  Crew   Male Adult       No\n1378  Crew   Male Adult       No\n1379  Crew   Male Adult       No\n1380  Crew   Male Adult       No\n1381  Crew   Male Adult       No\n1382   1st Female Adult       No\n1383   1st Female Adult       No\n1384   1st Female Adult       No\n1385   1st Female Adult       No\n1386   2nd Female Adult       No\n1387   2nd Female Adult       No\n1388   2nd Female Adult       No\n1389   2nd Female Adult       No\n1390   2nd Female Adult       No\n1391   2nd Female Adult       No\n1392   2nd Female Adult       No\n1393   2nd Female Adult       No\n1394   2nd Female Adult       No\n1395   2nd Female Adult       No\n1396   2nd Female Adult       No\n1397   2nd Female Adult       No\n1398   2nd Female Adult       No\n1399   3rd Female Adult       No\n1400   3rd Female Adult       No\n1401   3rd Female Adult       No\n1402   3rd Female Adult       No\n1403   3rd Female Adult       No\n1404   3rd Female Adult       No\n1405   3rd Female Adult       No\n1406   3rd Female Adult       No\n1407   3rd Female Adult       No\n1408   3rd Female Adult       No\n1409   3rd Female Adult       No\n1410   3rd Female Adult       No\n1411   3rd Female Adult       No\n1412   3rd Female Adult       No\n1413   3rd Female Adult       No\n1414   3rd Female Adult       No\n1415   3rd Female Adult       No\n1416   3rd Female Adult       No\n1417   3rd Female Adult       No\n1418   3rd Female Adult       No\n1419   3rd Female Adult       No\n1420   3rd Female Adult       No\n1421   3rd Female Adult       No\n1422   3rd Female Adult       No\n1423   3rd Female Adult       No\n1424   3rd Female Adult       No\n1425   3rd Female Adult       No\n1426   3rd Female Adult       No\n1427   3rd Female Adult       No\n1428   3rd Female Adult       No\n1429   3rd Female Adult       No\n1430   3rd Female Adult       No\n1431   3rd Female Adult       No\n1432   3rd Female Adult       No\n1433   3rd Female Adult       No\n1434   3rd Female Adult       No\n1435   3rd Female Adult       No\n1436   3rd Female Adult       No\n1437   3rd Female Adult       No\n1438   3rd Female Adult       No\n1439   3rd Female Adult       No\n1440   3rd Female Adult       No\n1441   3rd Female Adult       No\n1442   3rd Female Adult       No\n1443   3rd Female Adult       No\n1444   3rd Female Adult       No\n1445   3rd Female Adult       No\n1446   3rd Female Adult       No\n1447   3rd Female Adult       No\n1448   3rd Female Adult       No\n1449   3rd Female Adult       No\n1450   3rd Female Adult       No\n1451   3rd Female Adult       No\n1452   3rd Female Adult       No\n1453   3rd Female Adult       No\n1454   3rd Female Adult       No\n1455   3rd Female Adult       No\n1456   3rd Female Adult       No\n1457   3rd Female Adult       No\n1458   3rd Female Adult       No\n1459   3rd Female Adult       No\n1460   3rd Female Adult       No\n1461   3rd Female Adult       No\n1462   3rd Female Adult       No\n1463   3rd Female Adult       No\n1464   3rd Female Adult       No\n1465   3rd Female Adult       No\n1466   3rd Female Adult       No\n1467   3rd Female Adult       No\n1468   3rd Female Adult       No\n1469   3rd Female Adult       No\n1470   3rd Female Adult       No\n1471   3rd Female Adult       No\n1472   3rd Female Adult       No\n1473   3rd Female Adult       No\n1474   3rd Female Adult       No\n1475   3rd Female Adult       No\n1476   3rd Female Adult       No\n1477   3rd Female Adult       No\n1478   3rd Female Adult       No\n1479   3rd Female Adult       No\n1480   3rd Female Adult       No\n1481   3rd Female Adult       No\n1482   3rd Female Adult       No\n1483   3rd Female Adult       No\n1484   3rd Female Adult       No\n1485   3rd Female Adult       No\n1486   3rd Female Adult       No\n1487   3rd Female Adult       No\n1488  Crew Female Adult       No\n1489  Crew Female Adult       No\n1490  Crew Female Adult       No\n1491   1st   Male Child      Yes\n1492   1st   Male Child      Yes\n1493   1st   Male Child      Yes\n1494   1st   Male Child      Yes\n1495   1st   Male Child      Yes\n1496   2nd   Male Child      Yes\n1497   2nd   Male Child      Yes\n1498   2nd   Male Child      Yes\n1499   2nd   Male Child      Yes\n1500   2nd   Male Child      Yes\n1501   2nd   Male Child      Yes\n1502   2nd   Male Child      Yes\n1503   2nd   Male Child      Yes\n1504   2nd   Male Child      Yes\n1505   2nd   Male Child      Yes\n1506   2nd   Male Child      Yes\n1507   3rd   Male Child      Yes\n1508   3rd   Male Child      Yes\n1509   3rd   Male Child      Yes\n1510   3rd   Male Child      Yes\n1511   3rd   Male Child      Yes\n1512   3rd   Male Child      Yes\n1513   3rd   Male Child      Yes\n1514   3rd   Male Child      Yes\n1515   3rd   Male Child      Yes\n1516   3rd   Male Child      Yes\n1517   3rd   Male Child      Yes\n1518   3rd   Male Child      Yes\n1519   3rd   Male Child      Yes\n1520   1st Female Child      Yes\n1521   2nd Female Child      Yes\n1522   2nd Female Child      Yes\n1523   2nd Female Child      Yes\n1524   2nd Female Child      Yes\n1525   2nd Female Child      Yes\n1526   2nd Female Child      Yes\n1527   2nd Female Child      Yes\n1528   2nd Female Child      Yes\n1529   2nd Female Child      Yes\n1530   2nd Female Child      Yes\n1531   2nd Female Child      Yes\n1532   2nd Female Child      Yes\n1533   2nd Female Child      Yes\n1534   3rd Female Child      Yes\n1535   3rd Female Child      Yes\n1536   3rd Female Child      Yes\n1537   3rd Female Child      Yes\n1538   3rd Female Child      Yes\n1539   3rd Female Child      Yes\n1540   3rd Female Child      Yes\n1541   3rd Female Child      Yes\n1542   3rd Female Child      Yes\n1543   3rd Female Child      Yes\n1544   3rd Female Child      Yes\n1545   3rd Female Child      Yes\n1546   3rd Female Child      Yes\n1547   3rd Female Child      Yes\n1548   1st   Male Adult      Yes\n1549   1st   Male Adult      Yes\n1550   1st   Male Adult      Yes\n1551   1st   Male Adult      Yes\n1552   1st   Male Adult      Yes\n1553   1st   Male Adult      Yes\n1554   1st   Male Adult      Yes\n1555   1st   Male Adult      Yes\n1556   1st   Male Adult      Yes\n1557   1st   Male Adult      Yes\n1558   1st   Male Adult      Yes\n1559   1st   Male Adult      Yes\n1560   1st   Male Adult      Yes\n1561   1st   Male Adult      Yes\n1562   1st   Male Adult      Yes\n1563   1st   Male Adult      Yes\n1564   1st   Male Adult      Yes\n1565   1st   Male Adult      Yes\n1566   1st   Male Adult      Yes\n1567   1st   Male Adult      Yes\n1568   1st   Male Adult      Yes\n1569   1st   Male Adult      Yes\n1570   1st   Male Adult      Yes\n1571   1st   Male Adult      Yes\n1572   1st   Male Adult      Yes\n1573   1st   Male Adult      Yes\n1574   1st   Male Adult      Yes\n1575   1st   Male Adult      Yes\n1576   1st   Male Adult      Yes\n1577   1st   Male Adult      Yes\n1578   1st   Male Adult      Yes\n1579   1st   Male Adult      Yes\n1580   1st   Male Adult      Yes\n1581   1st   Male Adult      Yes\n1582   1st   Male Adult      Yes\n1583   1st   Male Adult      Yes\n1584   1st   Male Adult      Yes\n1585   1st   Male Adult      Yes\n1586   1st   Male Adult      Yes\n1587   1st   Male Adult      Yes\n1588   1st   Male Adult      Yes\n1589   1st   Male Adult      Yes\n1590   1st   Male Adult      Yes\n1591   1st   Male Adult      Yes\n1592   1st   Male Adult      Yes\n1593   1st   Male Adult      Yes\n1594   1st   Male Adult      Yes\n1595   1st   Male Adult      Yes\n1596   1st   Male Adult      Yes\n1597   1st   Male Adult      Yes\n1598   1st   Male Adult      Yes\n1599   1st   Male Adult      Yes\n1600   1st   Male Adult      Yes\n1601   1st   Male Adult      Yes\n1602   1st   Male Adult      Yes\n1603   1st   Male Adult      Yes\n1604   1st   Male Adult      Yes\n1605   2nd   Male Adult      Yes\n1606   2nd   Male Adult      Yes\n1607   2nd   Male Adult      Yes\n1608   2nd   Male Adult      Yes\n1609   2nd   Male Adult      Yes\n1610   2nd   Male Adult      Yes\n1611   2nd   Male Adult      Yes\n1612   2nd   Male Adult      Yes\n1613   2nd   Male Adult      Yes\n1614   2nd   Male Adult      Yes\n1615   2nd   Male Adult      Yes\n1616   2nd   Male Adult      Yes\n1617   2nd   Male Adult      Yes\n1618   2nd   Male Adult      Yes\n1619   3rd   Male Adult      Yes\n1620   3rd   Male Adult      Yes\n1621   3rd   Male Adult      Yes\n1622   3rd   Male Adult      Yes\n1623   3rd   Male Adult      Yes\n1624   3rd   Male Adult      Yes\n1625   3rd   Male Adult      Yes\n1626   3rd   Male Adult      Yes\n1627   3rd   Male Adult      Yes\n1628   3rd   Male Adult      Yes\n1629   3rd   Male Adult      Yes\n1630   3rd   Male Adult      Yes\n1631   3rd   Male Adult      Yes\n1632   3rd   Male Adult      Yes\n1633   3rd   Male Adult      Yes\n1634   3rd   Male Adult      Yes\n1635   3rd   Male Adult      Yes\n1636   3rd   Male Adult      Yes\n1637   3rd   Male Adult      Yes\n1638   3rd   Male Adult      Yes\n1639   3rd   Male Adult      Yes\n1640   3rd   Male Adult      Yes\n1641   3rd   Male Adult      Yes\n1642   3rd   Male Adult      Yes\n1643   3rd   Male Adult      Yes\n1644   3rd   Male Adult      Yes\n1645   3rd   Male Adult      Yes\n1646   3rd   Male Adult      Yes\n1647   3rd   Male Adult      Yes\n1648   3rd   Male Adult      Yes\n1649   3rd   Male Adult      Yes\n1650   3rd   Male Adult      Yes\n1651   3rd   Male Adult      Yes\n1652   3rd   Male Adult      Yes\n1653   3rd   Male Adult      Yes\n1654   3rd   Male Adult      Yes\n1655   3rd   Male Adult      Yes\n1656   3rd   Male Adult      Yes\n1657   3rd   Male Adult      Yes\n1658   3rd   Male Adult      Yes\n1659   3rd   Male Adult      Yes\n1660   3rd   Male Adult      Yes\n1661   3rd   Male Adult      Yes\n1662   3rd   Male Adult      Yes\n1663   3rd   Male Adult      Yes\n1664   3rd   Male Adult      Yes\n1665   3rd   Male Adult      Yes\n1666   3rd   Male Adult      Yes\n1667   3rd   Male Adult      Yes\n1668   3rd   Male Adult      Yes\n1669   3rd   Male Adult      Yes\n1670   3rd   Male Adult      Yes\n1671   3rd   Male Adult      Yes\n1672   3rd   Male Adult      Yes\n1673   3rd   Male Adult      Yes\n1674   3rd   Male Adult      Yes\n1675   3rd   Male Adult      Yes\n1676   3rd   Male Adult      Yes\n1677   3rd   Male Adult      Yes\n1678   3rd   Male Adult      Yes\n1679   3rd   Male Adult      Yes\n1680   3rd   Male Adult      Yes\n1681   3rd   Male Adult      Yes\n1682   3rd   Male Adult      Yes\n1683   3rd   Male Adult      Yes\n1684   3rd   Male Adult      Yes\n1685   3rd   Male Adult      Yes\n1686   3rd   Male Adult      Yes\n1687   3rd   Male Adult      Yes\n1688   3rd   Male Adult      Yes\n1689   3rd   Male Adult      Yes\n1690   3rd   Male Adult      Yes\n1691   3rd   Male Adult      Yes\n1692   3rd   Male Adult      Yes\n1693   3rd   Male Adult      Yes\n1694  Crew   Male Adult      Yes\n1695  Crew   Male Adult      Yes\n1696  Crew   Male Adult      Yes\n1697  Crew   Male Adult      Yes\n1698  Crew   Male Adult      Yes\n1699  Crew   Male Adult      Yes\n1700  Crew   Male Adult      Yes\n1701  Crew   Male Adult      Yes\n1702  Crew   Male Adult      Yes\n1703  Crew   Male Adult      Yes\n1704  Crew   Male Adult      Yes\n1705  Crew   Male Adult      Yes\n1706  Crew   Male Adult      Yes\n1707  Crew   Male Adult      Yes\n1708  Crew   Male Adult      Yes\n1709  Crew   Male Adult      Yes\n1710  Crew   Male Adult      Yes\n1711  Crew   Male Adult      Yes\n1712  Crew   Male Adult      Yes\n1713  Crew   Male Adult      Yes\n1714  Crew   Male Adult      Yes\n1715  Crew   Male Adult      Yes\n1716  Crew   Male Adult      Yes\n1717  Crew   Male Adult      Yes\n1718  Crew   Male Adult      Yes\n1719  Crew   Male Adult      Yes\n1720  Crew   Male Adult      Yes\n1721  Crew   Male Adult      Yes\n1722  Crew   Male Adult      Yes\n1723  Crew   Male Adult      Yes\n1724  Crew   Male Adult      Yes\n1725  Crew   Male Adult      Yes\n1726  Crew   Male Adult      Yes\n1727  Crew   Male Adult      Yes\n1728  Crew   Male Adult      Yes\n1729  Crew   Male Adult      Yes\n1730  Crew   Male Adult      Yes\n1731  Crew   Male Adult      Yes\n1732  Crew   Male Adult      Yes\n1733  Crew   Male Adult      Yes\n1734  Crew   Male Adult      Yes\n1735  Crew   Male Adult      Yes\n1736  Crew   Male Adult      Yes\n1737  Crew   Male Adult      Yes\n1738  Crew   Male Adult      Yes\n1739  Crew   Male Adult      Yes\n1740  Crew   Male Adult      Yes\n1741  Crew   Male Adult      Yes\n1742  Crew   Male Adult      Yes\n1743  Crew   Male Adult      Yes\n1744  Crew   Male Adult      Yes\n1745  Crew   Male Adult      Yes\n1746  Crew   Male Adult      Yes\n1747  Crew   Male Adult      Yes\n1748  Crew   Male Adult      Yes\n1749  Crew   Male Adult      Yes\n1750  Crew   Male Adult      Yes\n1751  Crew   Male Adult      Yes\n1752  Crew   Male Adult      Yes\n1753  Crew   Male Adult      Yes\n1754  Crew   Male Adult      Yes\n1755  Crew   Male Adult      Yes\n1756  Crew   Male Adult      Yes\n1757  Crew   Male Adult      Yes\n1758  Crew   Male Adult      Yes\n1759  Crew   Male Adult      Yes\n1760  Crew   Male Adult      Yes\n1761  Crew   Male Adult      Yes\n1762  Crew   Male Adult      Yes\n1763  Crew   Male Adult      Yes\n1764  Crew   Male Adult      Yes\n1765  Crew   Male Adult      Yes\n1766  Crew   Male Adult      Yes\n1767  Crew   Male Adult      Yes\n1768  Crew   Male Adult      Yes\n1769  Crew   Male Adult      Yes\n1770  Crew   Male Adult      Yes\n1771  Crew   Male Adult      Yes\n1772  Crew   Male Adult      Yes\n1773  Crew   Male Adult      Yes\n1774  Crew   Male Adult      Yes\n1775  Crew   Male Adult      Yes\n1776  Crew   Male Adult      Yes\n1777  Crew   Male Adult      Yes\n1778  Crew   Male Adult      Yes\n1779  Crew   Male Adult      Yes\n1780  Crew   Male Adult      Yes\n1781  Crew   Male Adult      Yes\n1782  Crew   Male Adult      Yes\n1783  Crew   Male Adult      Yes\n1784  Crew   Male Adult      Yes\n1785  Crew   Male Adult      Yes\n1786  Crew   Male Adult      Yes\n1787  Crew   Male Adult      Yes\n1788  Crew   Male Adult      Yes\n1789  Crew   Male Adult      Yes\n1790  Crew   Male Adult      Yes\n1791  Crew   Male Adult      Yes\n1792  Crew   Male Adult      Yes\n1793  Crew   Male Adult      Yes\n1794  Crew   Male Adult      Yes\n1795  Crew   Male Adult      Yes\n1796  Crew   Male Adult      Yes\n1797  Crew   Male Adult      Yes\n1798  Crew   Male Adult      Yes\n1799  Crew   Male Adult      Yes\n1800  Crew   Male Adult      Yes\n1801  Crew   Male Adult      Yes\n1802  Crew   Male Adult      Yes\n1803  Crew   Male Adult      Yes\n1804  Crew   Male Adult      Yes\n1805  Crew   Male Adult      Yes\n1806  Crew   Male Adult      Yes\n1807  Crew   Male Adult      Yes\n1808  Crew   Male Adult      Yes\n1809  Crew   Male Adult      Yes\n1810  Crew   Male Adult      Yes\n1811  Crew   Male Adult      Yes\n1812  Crew   Male Adult      Yes\n1813  Crew   Male Adult      Yes\n1814  Crew   Male Adult      Yes\n1815  Crew   Male Adult      Yes\n1816  Crew   Male Adult      Yes\n1817  Crew   Male Adult      Yes\n1818  Crew   Male Adult      Yes\n1819  Crew   Male Adult      Yes\n1820  Crew   Male Adult      Yes\n1821  Crew   Male Adult      Yes\n1822  Crew   Male Adult      Yes\n1823  Crew   Male Adult      Yes\n1824  Crew   Male Adult      Yes\n1825  Crew   Male Adult      Yes\n1826  Crew   Male Adult      Yes\n1827  Crew   Male Adult      Yes\n1828  Crew   Male Adult      Yes\n1829  Crew   Male Adult      Yes\n1830  Crew   Male Adult      Yes\n1831  Crew   Male Adult      Yes\n1832  Crew   Male Adult      Yes\n1833  Crew   Male Adult      Yes\n1834  Crew   Male Adult      Yes\n1835  Crew   Male Adult      Yes\n1836  Crew   Male Adult      Yes\n1837  Crew   Male Adult      Yes\n1838  Crew   Male Adult      Yes\n1839  Crew   Male Adult      Yes\n1840  Crew   Male Adult      Yes\n1841  Crew   Male Adult      Yes\n1842  Crew   Male Adult      Yes\n1843  Crew   Male Adult      Yes\n1844  Crew   Male Adult      Yes\n1845  Crew   Male Adult      Yes\n1846  Crew   Male Adult      Yes\n1847  Crew   Male Adult      Yes\n1848  Crew   Male Adult      Yes\n1849  Crew   Male Adult      Yes\n1850  Crew   Male Adult      Yes\n1851  Crew   Male Adult      Yes\n1852  Crew   Male Adult      Yes\n1853  Crew   Male Adult      Yes\n1854  Crew   Male Adult      Yes\n1855  Crew   Male Adult      Yes\n1856  Crew   Male Adult      Yes\n1857  Crew   Male Adult      Yes\n1858  Crew   Male Adult      Yes\n1859  Crew   Male Adult      Yes\n1860  Crew   Male Adult      Yes\n1861  Crew   Male Adult      Yes\n1862  Crew   Male Adult      Yes\n1863  Crew   Male Adult      Yes\n1864  Crew   Male Adult      Yes\n1865  Crew   Male Adult      Yes\n1866  Crew   Male Adult      Yes\n1867  Crew   Male Adult      Yes\n1868  Crew   Male Adult      Yes\n1869  Crew   Male Adult      Yes\n1870  Crew   Male Adult      Yes\n1871  Crew   Male Adult      Yes\n1872  Crew   Male Adult      Yes\n1873  Crew   Male Adult      Yes\n1874  Crew   Male Adult      Yes\n1875  Crew   Male Adult      Yes\n1876  Crew   Male Adult      Yes\n1877  Crew   Male Adult      Yes\n1878  Crew   Male Adult      Yes\n1879  Crew   Male Adult      Yes\n1880  Crew   Male Adult      Yes\n1881  Crew   Male Adult      Yes\n1882  Crew   Male Adult      Yes\n1883  Crew   Male Adult      Yes\n1884  Crew   Male Adult      Yes\n1885  Crew   Male Adult      Yes\n1886   1st Female Adult      Yes\n1887   1st Female Adult      Yes\n1888   1st Female Adult      Yes\n1889   1st Female Adult      Yes\n1890   1st Female Adult      Yes\n1891   1st Female Adult      Yes\n1892   1st Female Adult      Yes\n1893   1st Female Adult      Yes\n1894   1st Female Adult      Yes\n1895   1st Female Adult      Yes\n1896   1st Female Adult      Yes\n1897   1st Female Adult      Yes\n1898   1st Female Adult      Yes\n1899   1st Female Adult      Yes\n1900   1st Female Adult      Yes\n1901   1st Female Adult      Yes\n1902   1st Female Adult      Yes\n1903   1st Female Adult      Yes\n1904   1st Female Adult      Yes\n1905   1st Female Adult      Yes\n1906   1st Female Adult      Yes\n1907   1st Female Adult      Yes\n1908   1st Female Adult      Yes\n1909   1st Female Adult      Yes\n1910   1st Female Adult      Yes\n1911   1st Female Adult      Yes\n1912   1st Female Adult      Yes\n1913   1st Female Adult      Yes\n1914   1st Female Adult      Yes\n1915   1st Female Adult      Yes\n1916   1st Female Adult      Yes\n1917   1st Female Adult      Yes\n1918   1st Female Adult      Yes\n1919   1st Female Adult      Yes\n1920   1st Female Adult      Yes\n1921   1st Female Adult      Yes\n1922   1st Female Adult      Yes\n1923   1st Female Adult      Yes\n1924   1st Female Adult      Yes\n1925   1st Female Adult      Yes\n1926   1st Female Adult      Yes\n1927   1st Female Adult      Yes\n1928   1st Female Adult      Yes\n1929   1st Female Adult      Yes\n1930   1st Female Adult      Yes\n1931   1st Female Adult      Yes\n1932   1st Female Adult      Yes\n1933   1st Female Adult      Yes\n1934   1st Female Adult      Yes\n1935   1st Female Adult      Yes\n1936   1st Female Adult      Yes\n1937   1st Female Adult      Yes\n1938   1st Female Adult      Yes\n1939   1st Female Adult      Yes\n1940   1st Female Adult      Yes\n1941   1st Female Adult      Yes\n1942   1st Female Adult      Yes\n1943   1st Female Adult      Yes\n1944   1st Female Adult      Yes\n1945   1st Female Adult      Yes\n1946   1st Female Adult      Yes\n1947   1st Female Adult      Yes\n1948   1st Female Adult      Yes\n1949   1st Female Adult      Yes\n1950   1st Female Adult      Yes\n1951   1st Female Adult      Yes\n1952   1st Female Adult      Yes\n1953   1st Female Adult      Yes\n1954   1st Female Adult      Yes\n1955   1st Female Adult      Yes\n1956   1st Female Adult      Yes\n1957   1st Female Adult      Yes\n1958   1st Female Adult      Yes\n1959   1st Female Adult      Yes\n1960   1st Female Adult      Yes\n1961   1st Female Adult      Yes\n1962   1st Female Adult      Yes\n1963   1st Female Adult      Yes\n1964   1st Female Adult      Yes\n1965   1st Female Adult      Yes\n1966   1st Female Adult      Yes\n1967   1st Female Adult      Yes\n1968   1st Female Adult      Yes\n1969   1st Female Adult      Yes\n1970   1st Female Adult      Yes\n1971   1st Female Adult      Yes\n1972   1st Female Adult      Yes\n1973   1st Female Adult      Yes\n1974   1st Female Adult      Yes\n1975   1st Female Adult      Yes\n1976   1st Female Adult      Yes\n1977   1st Female Adult      Yes\n1978   1st Female Adult      Yes\n1979   1st Female Adult      Yes\n1980   1st Female Adult      Yes\n1981   1st Female Adult      Yes\n1982   1st Female Adult      Yes\n1983   1st Female Adult      Yes\n1984   1st Female Adult      Yes\n1985   1st Female Adult      Yes\n1986   1st Female Adult      Yes\n1987   1st Female Adult      Yes\n1988   1st Female Adult      Yes\n1989   1st Female Adult      Yes\n1990   1st Female Adult      Yes\n1991   1st Female Adult      Yes\n1992   1st Female Adult      Yes\n1993   1st Female Adult      Yes\n1994   1st Female Adult      Yes\n1995   1st Female Adult      Yes\n1996   1st Female Adult      Yes\n1997   1st Female Adult      Yes\n1998   1st Female Adult      Yes\n1999   1st Female Adult      Yes\n2000   1st Female Adult      Yes\n2001   1st Female Adult      Yes\n2002   1st Female Adult      Yes\n2003   1st Female Adult      Yes\n2004   1st Female Adult      Yes\n2005   1st Female Adult      Yes\n2006   1st Female Adult      Yes\n2007   1st Female Adult      Yes\n2008   1st Female Adult      Yes\n2009   1st Female Adult      Yes\n2010   1st Female Adult      Yes\n2011   1st Female Adult      Yes\n2012   1st Female Adult      Yes\n2013   1st Female Adult      Yes\n2014   1st Female Adult      Yes\n2015   1st Female Adult      Yes\n2016   1st Female Adult      Yes\n2017   1st Female Adult      Yes\n2018   1st Female Adult      Yes\n2019   1st Female Adult      Yes\n2020   1st Female Adult      Yes\n2021   1st Female Adult      Yes\n2022   1st Female Adult      Yes\n2023   1st Female Adult      Yes\n2024   1st Female Adult      Yes\n2025   1st Female Adult      Yes\n2026   2nd Female Adult      Yes\n2027   2nd Female Adult      Yes\n2028   2nd Female Adult      Yes\n2029   2nd Female Adult      Yes\n2030   2nd Female Adult      Yes\n2031   2nd Female Adult      Yes\n2032   2nd Female Adult      Yes\n2033   2nd Female Adult      Yes\n2034   2nd Female Adult      Yes\n2035   2nd Female Adult      Yes\n2036   2nd Female Adult      Yes\n2037   2nd Female Adult      Yes\n2038   2nd Female Adult      Yes\n2039   2nd Female Adult      Yes\n2040   2nd Female Adult      Yes\n2041   2nd Female Adult      Yes\n2042   2nd Female Adult      Yes\n2043   2nd Female Adult      Yes\n2044   2nd Female Adult      Yes\n2045   2nd Female Adult      Yes\n2046   2nd Female Adult      Yes\n2047   2nd Female Adult      Yes\n2048   2nd Female Adult      Yes\n2049   2nd Female Adult      Yes\n2050   2nd Female Adult      Yes\n2051   2nd Female Adult      Yes\n2052   2nd Female Adult      Yes\n2053   2nd Female Adult      Yes\n2054   2nd Female Adult      Yes\n2055   2nd Female Adult      Yes\n2056   2nd Female Adult      Yes\n2057   2nd Female Adult      Yes\n2058   2nd Female Adult      Yes\n2059   2nd Female Adult      Yes\n2060   2nd Female Adult      Yes\n2061   2nd Female Adult      Yes\n2062   2nd Female Adult      Yes\n2063   2nd Female Adult      Yes\n2064   2nd Female Adult      Yes\n2065   2nd Female Adult      Yes\n2066   2nd Female Adult      Yes\n2067   2nd Female Adult      Yes\n2068   2nd Female Adult      Yes\n2069   2nd Female Adult      Yes\n2070   2nd Female Adult      Yes\n2071   2nd Female Adult      Yes\n2072   2nd Female Adult      Yes\n2073   2nd Female Adult      Yes\n2074   2nd Female Adult      Yes\n2075   2nd Female Adult      Yes\n2076   2nd Female Adult      Yes\n2077   2nd Female Adult      Yes\n2078   2nd Female Adult      Yes\n2079   2nd Female Adult      Yes\n2080   2nd Female Adult      Yes\n2081   2nd Female Adult      Yes\n2082   2nd Female Adult      Yes\n2083   2nd Female Adult      Yes\n2084   2nd Female Adult      Yes\n2085   2nd Female Adult      Yes\n2086   2nd Female Adult      Yes\n2087   2nd Female Adult      Yes\n2088   2nd Female Adult      Yes\n2089   2nd Female Adult      Yes\n2090   2nd Female Adult      Yes\n2091   2nd Female Adult      Yes\n2092   2nd Female Adult      Yes\n2093   2nd Female Adult      Yes\n2094   2nd Female Adult      Yes\n2095   2nd Female Adult      Yes\n2096   2nd Female Adult      Yes\n2097   2nd Female Adult      Yes\n2098   2nd Female Adult      Yes\n2099   2nd Female Adult      Yes\n2100   2nd Female Adult      Yes\n2101   2nd Female Adult      Yes\n2102   2nd Female Adult      Yes\n2103   2nd Female Adult      Yes\n2104   2nd Female Adult      Yes\n2105   2nd Female Adult      Yes\n2106   3rd Female Adult      Yes\n2107   3rd Female Adult      Yes\n2108   3rd Female Adult      Yes\n2109   3rd Female Adult      Yes\n2110   3rd Female Adult      Yes\n2111   3rd Female Adult      Yes\n2112   3rd Female Adult      Yes\n2113   3rd Female Adult      Yes\n2114   3rd Female Adult      Yes\n2115   3rd Female Adult      Yes\n2116   3rd Female Adult      Yes\n2117   3rd Female Adult      Yes\n2118   3rd Female Adult      Yes\n2119   3rd Female Adult      Yes\n2120   3rd Female Adult      Yes\n2121   3rd Female Adult      Yes\n2122   3rd Female Adult      Yes\n2123   3rd Female Adult      Yes\n2124   3rd Female Adult      Yes\n2125   3rd Female Adult      Yes\n2126   3rd Female Adult      Yes\n2127   3rd Female Adult      Yes\n2128   3rd Female Adult      Yes\n2129   3rd Female Adult      Yes\n2130   3rd Female Adult      Yes\n2131   3rd Female Adult      Yes\n2132   3rd Female Adult      Yes\n2133   3rd Female Adult      Yes\n2134   3rd Female Adult      Yes\n2135   3rd Female Adult      Yes\n2136   3rd Female Adult      Yes\n2137   3rd Female Adult      Yes\n2138   3rd Female Adult      Yes\n2139   3rd Female Adult      Yes\n2140   3rd Female Adult      Yes\n2141   3rd Female Adult      Yes\n2142   3rd Female Adult      Yes\n2143   3rd Female Adult      Yes\n2144   3rd Female Adult      Yes\n2145   3rd Female Adult      Yes\n2146   3rd Female Adult      Yes\n2147   3rd Female Adult      Yes\n2148   3rd Female Adult      Yes\n2149   3rd Female Adult      Yes\n2150   3rd Female Adult      Yes\n2151   3rd Female Adult      Yes\n2152   3rd Female Adult      Yes\n2153   3rd Female Adult      Yes\n2154   3rd Female Adult      Yes\n2155   3rd Female Adult      Yes\n2156   3rd Female Adult      Yes\n2157   3rd Female Adult      Yes\n2158   3rd Female Adult      Yes\n2159   3rd Female Adult      Yes\n2160   3rd Female Adult      Yes\n2161   3rd Female Adult      Yes\n2162   3rd Female Adult      Yes\n2163   3rd Female Adult      Yes\n2164   3rd Female Adult      Yes\n2165   3rd Female Adult      Yes\n2166   3rd Female Adult      Yes\n2167   3rd Female Adult      Yes\n2168   3rd Female Adult      Yes\n2169   3rd Female Adult      Yes\n2170   3rd Female Adult      Yes\n2171   3rd Female Adult      Yes\n2172   3rd Female Adult      Yes\n2173   3rd Female Adult      Yes\n2174   3rd Female Adult      Yes\n2175   3rd Female Adult      Yes\n2176   3rd Female Adult      Yes\n2177   3rd Female Adult      Yes\n2178   3rd Female Adult      Yes\n2179   3rd Female Adult      Yes\n2180   3rd Female Adult      Yes\n2181   3rd Female Adult      Yes\n2182  Crew Female Adult      Yes\n2183  Crew Female Adult      Yes\n2184  Crew Female Adult      Yes\n2185  Crew Female Adult      Yes\n2186  Crew Female Adult      Yes\n2187  Crew Female Adult      Yes\n2188  Crew Female Adult      Yes\n2189  Crew Female Adult      Yes\n2190  Crew Female Adult      Yes\n2191  Crew Female Adult      Yes\n2192  Crew Female Adult      Yes\n2193  Crew Female Adult      Yes\n2194  Crew Female Adult      Yes\n2195  Crew Female Adult      Yes\n2196  Crew Female Adult      Yes\n2197  Crew Female Adult      Yes\n2198  Crew Female Adult      Yes\n2199  Crew Female Adult      Yes\n2200  Crew Female Adult      Yes\n2201  Crew Female Adult      Yes\n\n\n\ntitanic_table &lt;- vcd::structable(Survived ~ Sex, data = titanic)\nvcd::mosaic(titanic_table,\n            gp = shading_max, direction = \"v\",\n            main = \"Arthritis Treatment Dataset\",\nlabeling = labeling_border(\n                varnames = c(\"F\", \"F\"), # Remove variable name labels\n                rot_labels = c(90,0,0,0), #t,r,b,l\n                just_labels = c(\"left\", \n                                \"left\", \n                                \"left\", \n                                \"right\")))\n\n\n\n\n\n\n\n\n\ntitanic_table &lt;- vcd::structable(Sex ~ Survived, data = titanic)\nvcd::mosaic(titanic_table,\n            gp = shading_max, direction = \"v\",\n            main = \"Arthritis Treatment Dataset\",\nlabeling = labeling_border(\n                varnames = c(\"F\", \"F\"), # Remove variable name labels\n                rot_labels = c(90,0,0,0), #t,r,b,l\n                just_labels = c(\"left\", \n                                \"left\", \n                                \"left\", \n                                \"right\"))) \n\n\n\n\n\n\n\n\n\nvcd::mosaic(Improved ~ Treatment, data = Arthritis, \n            direction = \"v\", gp = shading_max)\n\n\n\n\n\n\n\n\n\nvcd::mosaic(Improved ~ Treatment, data = Arthritis, \n            type = \"expected\", direction = \"v\", gp = shading_max)\n\n\n\n\n\n\n\n\n\nvcd::assoc(Improved ~ Treatment, # Note formula direction!\n           data = Arthritis, \n           gp = shading_max, \n           legend = FALSE) \n\n\n\n\n\n\n\n\n\nvcd::assoc(Treatment ~ Improved, # Note formula direction!\n           data = Arthritis, \n           gp = shading_max, \n           legend = FALSE) \n\n\n\n\n\n\n\n\n\nFertility &lt;- readr::read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Fertility.csv\") %&gt;% \njanitor::clean_names(case=\"snake\")\n\nRows: 254654 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): morekids, gender1, gender2, afam, hispanic, other\ndbl (3): rownames, age, work\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(Fertility)\n\nRows: 254,654\nColumns: 9\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ morekids &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ gender1  &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"female\",…\n$ gender2  &lt;chr&gt; \"female\", \"male\", \"female\", \"female\", \"female\", \"female\", \"ma…\n$ age      &lt;dbl&gt; 27, 30, 27, 35, 30, 26, 29, 33, 29, 27, 28, 28, 35, 34, 32, 2…\n$ afam     &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ hispanic &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ other    &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ work     &lt;dbl&gt; 0, 30, 0, 0, 22, 40, 0, 52, 0, 0, 0, 52, 52, 52, 8, 7, 0, 40,…\n\n\n\nFertility_ethnicity &lt;- Fertility %&gt;%\n  mutate(ethnicity = case_when(\n    afam == \"yes\" & hispanic == \"no\" & other == \"no\" ~ \"Afam\",\n    afam == \"no\" & hispanic == \"yes\" & other == \"no\" ~ \"Hispanic\",\n    afam == \"no\" & hispanic == \"no\" & other == \"yes\" ~ \"Other\",\n    afam == \"no\" & hispanic == \"no\" & other == \"no\" ~ \"Caucasian\",\n    afam == \"yes\" & hispanic == \"yes\" & other == \"no\" ~ \"AfamHispanic\",\n    afam == \"yes\" & hispanic == \"no\" & other == \"yes\" ~ \"AfamOther\",\n    afam == \"no\" & hispanic == \"yes\" & other == \"yes\" ~ \"HispanicOther\"\n  ))\n  \nFertility_ethnicity\n\n# A tibble: 254,654 × 10\n   rownames morekids gender1 gender2   age afam  hispanic other  work ethnicity\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    \n 1        1 no       male    female     27 no    no       no        0 Caucasian\n 2        2 no       female  male       30 no    no       no       30 Caucasian\n 3        3 no       male    female     27 no    no       no        0 Caucasian\n 4        4 no       male    female     35 yes   no       no        0 Afam     \n 5        5 no       female  female     30 no    no       no       22 Caucasian\n 6        6 no       male    female     26 no    no       no       40 Caucasian\n 7        7 no       female  male       29 no    no       no        0 Caucasian\n 8        8 no       male    male       33 no    no       no       52 Caucasian\n 9        9 no       female  male       29 no    no       no        0 Caucasian\n10       10 no       male    female     27 no    no       no        0 Caucasian\n# ℹ 254,644 more rows\n\n\n\nvcd::mosaic(morekids ~ ethnicity, data = Fertility_ethnicity, \n            direction = \"v\", gp = shading_max)"
  },
  {
    "objectID": "classwork/classwork9/index.html",
    "href": "classwork/classwork9/index.html",
    "title": "Classwork 9",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(infer)\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(broom) # Clean test results in tibble form\nlibrary(resampledata) # Datasets from Chihara and Hesterberg's book\n\n\nAttaching package: 'resampledata'\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n\nlibrary(openintro) # More datasets\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:mosaic':\n\n    dotPlot\n\nThe following objects are masked from 'package:lattice':\n\n    ethanol, lsegments\n\nlibrary(visStatistics) # One package to rule them all\nlibrary(ggstatsplot)\n\nYou can cite this package as:\n     Patil, I. (2021). Visualizations with statistical details: The 'ggstatsplot' approach.\n     Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167\n\n\n\ndata(\"exam_grades\", package = \"openintro\")\nexam_grades\n\n# A tibble: 233 × 6\n   semester sex   exam1 exam2 exam3 course_grade\n   &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;\n 1 2000-1   Man    84.5  69.5  86.5         76.3\n 2 2000-1   Man    80    74    67           75.4\n 3 2000-1   Man    56    70    71.5         67.1\n 4 2000-1   Man    64    61    67.5         63.5\n 5 2000-1   Man    90.5  72.5  75           72.4\n 6 2000-1   Man    74    78.5  84.5         71.4\n 7 2000-1   Man    60.5  44    58           56.1\n 8 2000-1   Man    89    82    88           78.0\n 9 2000-1   Woman  87.5  86.5  95           82.9\n10 2000-1   Man    91    98    88           89.1\n# ℹ 223 more rows\n\n\n\nlibrary(nortest)\n# Especially when we have &gt;= 5000 observations\nnortest::ad.test(x = exam_grades$course_grade) %&gt;%\n  broom::tidy()\n\n# A tibble: 1 × 3\n  statistic p.value method                         \n      &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                          \n1     0.331   0.512 Anderson-Darling normality test\n\n\n\n# t-test\nt4 &lt;- mosaic::t_test(\n  exam_grades$course_grade, # Name of variable\n  mu = 80, # belief\n  alternative = \"two.sided\"\n) %&gt;% # Check both sides\n  broom::tidy()\nt4\n\n# A tibble: 1 × 8\n  estimate statistic  p.value parameter conf.low conf.high method    alternative\n     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;      \n1     72.2     -12.1 2.19e-26       232     71.0      73.5 One Samp… two.sided  \n\n\n\nANOVA\n\nfrogs_orig &lt;- read_csv(\"frogs.csv\")\n\nRows: 60 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (4): Frogspawn sample id, Temperature13, Temperature18, Temperature25\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nfrogs_orig\n\n# A tibble: 60 × 4\n   `Frogspawn sample id` Temperature13 Temperature18 Temperature25\n                   &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n 1                     1            24            NA            NA\n 2                     2            NA            21            NA\n 3                     3            NA            NA            18\n 4                     4            26            NA            NA\n 5                     5            NA            22            NA\n 6                     6            NA            NA            14\n 7                     7            27            NA            NA\n 8                     8            NA            22            NA\n 9                     9            NA            NA            15\n10                    10            27            NA            NA\n# ℹ 50 more rows\n\n\nCONVERTING TO LONG FROM FROM LONG FORM\n\nfrogs_orig %&gt;%\n  pivot_longer(\n    .,\n    cols = starts_with(\"Temperature\"),\n    cols_vary = \"fastest\",\n    # new in pivot_longer\n    names_to = \"Temp\",\n    values_to = \"Time\"\n  ) %&gt;%\n  drop_na() %&gt;%\n  ##\n  separate_wider_regex(\n    cols = Temp,\n    # knock off the unnecessary \"Temperature\" word\n    # Just keep the digits thereafter\n    patterns = c(\"Temperature\", TempFac = \"\\\\d+\"),\n    cols_remove = TRUE\n  ) %&gt;%\n  # Convert Temp into TempFac, a 3-level factor\n  mutate(TempFac = factor(\n    x = TempFac,\n    levels = c(13, 18, 25),\n    labels = c(\"13\", \"18\", \"25\")\n  )) %&gt;%\n  rename(\"Id\" = `Frogspawn sample id`) -&gt; frogs_long\nfrogs_long\n\n# A tibble: 60 × 3\n      Id TempFac  Time\n   &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;\n 1     1 13         24\n 2     2 18         21\n 3     3 25         18\n 4     4 13         26\n 5     5 18         22\n 6     6 25         14\n 7     7 13         27\n 8     8 18         22\n 9     9 25         15\n10    10 13         27\n# ℹ 50 more rows\n\n##\nfrogs_long %&gt;% count(TempFac)\n\n# A tibble: 3 × 2\n  TempFac     n\n  &lt;fct&gt;   &lt;int&gt;\n1 13         20\n2 18         20\n3 25         20"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fundamentals of Statistics and Exploratory Data Analysis",
    "section": "",
    "text": "Sep 28, 2025\n\n\nDiya Bijoy, Swetha KV, Abhinav, Aanya Pandith\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2025\n\n\nDiya Bijoy, Swetha KV, Abhinav R, Aanya Pandith\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2025\n\n\nDiya Bijoy, Swetha KV, Abhinav, Aanya Pandith\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#a1-basics-of-eda-1",
    "href": "index.html#a1-basics-of-eda-1",
    "title": "Fundamentals of Statistics and Exploratory Data Analysis",
    "section": "",
    "text": "Sep 28, 2025\n\n\nDiya Bijoy, Swetha KV, Abhinav, Aanya Pandith\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2025\n\n\nDiya Bijoy, Swetha KV, Abhinav R, Aanya Pandith\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2025\n\n\nDiya Bijoy, Swetha KV, Abhinav, Aanya Pandith\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#a2-basics-of-eda-2",
    "href": "index.html#a2-basics-of-eda-2",
    "title": "Fundamentals of Statistics and Exploratory Data Analysis",
    "section": "A2: Basics of EDA #2",
    "text": "A2: Basics of EDA #2\n\n\n\n\n\n\n\n\n\n\nCardioDataSets HeartDisease\n\n\n\n\n\n\n\n\n\n\n\nOct 20, 2025\n\n\nKrithika, Ashmita, Krithika, Arnav\n\n\n\n\n\n\n\n\n\n\n\n\nPolice Shootings Dataset\n\n\n\n\n\n\n\n\n\n\n\nOct 20, 2025\n\n\nAshmita, Diya, Krithika, Arnav\n\n\n\n\n\n\n\n\n\n\n\n\nDemoiselle Crane Migration Route\n\n\n\n\n\n\n\n\n\n\n\nOct 20, 2025\n\n\nDiya, Ashmita, Krithika, Arnav\n\n\n\n\n\n\n\n\n\n\n\n\nCuisines Dataset\n\n\n\n\n\n\n\n\n\n\n\nOct 20, 2025\n\n\nDiya, Ashmita, Krithika, Arnav\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#experiments",
    "href": "index.html#experiments",
    "title": "Fundamentals of Statistics and Exploratory Data Analysis",
    "section": "Experiments",
    "text": "Experiments\n\n\n\n\n\n\n\n\n\n\nIs the Average Opinion Score for Modern Family, Friends & Big Bang Theory equal?\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2025\n\n\nDiya Bijoy\n\n\n\n\n\n\n\n\n\n\n\n\nDo tattoos make people look attractive or not?\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2025\n\n\nDiya Bijoy\n\n\n\n\n\n\n\n\n\n\n\n\nIs the average weekly expenditure for boys equal to girls?\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2025\n\n\nDiya Bijoy\n\n\n\n\n\n\n\n\n\n\n\n\nAre Srishti Dads weird?\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2025\n\n\nDiya Bijoy\n\n\n\n\n\n\n\n\n\n\n\n\nWhat’s the proportion of people who believe in god?\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2025\n\n\nDiya Bijoy\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#classwork",
    "href": "index.html#classwork",
    "title": "Fundamentals of Statistics and Exploratory Data Analysis",
    "section": "Classwork",
    "text": "Classwork\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n \n\n\nclasswork8\n\n\n \n\n\n\n\n \n\n\nClasswork 7\n\n\n \n\n\n\n\nOct 27, 2025\n\n\nClasswork 9\n\n\nDiya Bijoy\n\n\n\n\nOct 21, 2025\n\n\nClasswork 9\n\n\nDiya Bijoy\n\n\n\n\nOct 7, 2025\n\n\nClasswork 6\n\n\nDiya Bijoy\n\n\n\n\nOct 6, 2025\n\n\nClasswork 5\n\n\nDiya Bijoy\n\n\n\n\nSep 23, 2025\n\n\nClasswork 4\n\n\nDiya Bijoy\n\n\n\n\nSep 22, 2025\n\n\nClasswork 3\n\n\nDiya Bijoy\n\n\n\n\nSep 16, 2025\n\n\nClasswork 2\n\n\nDiya Bijoy\n\n\n\n\nSep 15, 2025\n\n\nClasswork 1\n\n\nDiya Bijoy\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "Math, math, math… for some an absolute nightmare for others the holy grail of existence. Let’s break it down\n\n\n\nThis section handles loading the dataset, cleaning missing values, and initial transformations like converting variables to factors.\nLoad necessary libraries for data manipulation, visualization, and interactive elements.\n\n\n\nlibrary(ggformula)\n\nLoading required package: ggplot2\n\n\nLoading required package: scales\n\n\nLoading required package: ggridges\n\n\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(naniar)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:naniar':\n\n    n_complete\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.0.4     ✔ tidyr     1.3.1\n✔ readr     2.1.5     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ mosaic::count()     masks dplyr::count()\n✖ purrr::cross()      masks mosaic::cross()\n✖ purrr::discard()    masks scales::discard()\n✖ mosaic::do()        masks dplyr::do()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ mosaic::stat()      masks ggplot2::stat()\n✖ mosaic::tally()     masks dplyr::tally()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tinytable)\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(visdat)\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(RColorBrewer)\n\n\n\n\n\n\nmeth &lt;- readr::read_delim(\"MathAnxiety.csv\",\n                          delim = \";\",\n                          locale = locale(decimal_mark = \",\")) %&gt;% \n  janitor::clean_names(\"snake\")\n\nRows: 599 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (2): Gender, Grade\ndbl (4): Age, AMAS, RCMAS, Arith\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmeth\n\n# A tibble: 599 × 6\n     age gender grade      amas rcmas arith\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  138. Boy    Secondary     9    20     6\n 2  141. Boy    Secondary    18     8     6\n 3  138. Girl   Secondary    23    26     5\n 4  143. Girl   Secondary    19    18     7\n 5  136. Boy    Secondary    23    20     1\n 6  135  Girl   Secondary    27    33     1\n 7  134. Boy    Secondary    22    23     4\n 8  139. Boy    Secondary    17    11     7\n 9  132. Girl   Secondary    28    32     2\n10  135. Boy    Secondary    20    30     6\n# ℹ 589 more rows\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nAge\nThe age of the child in months.\n\n\nGender\nThe gender of the child (Boy or Girl).\n\n\nGrade\nThe educational level of the child (Primary or Secondary).\n\n\nAMAS\nThe score on the Abbreviated Math Anxiety Scale, where a higher score indicates greater math anxiety.\n\n\nRCMAS\nThe score on the Revised Children’s Manifest Anxiety Scale, measuring general anxiety\n\n\nArith\nThe score on an arithmetic test.\n\n\n\n\n\n\nThis section inspects the dataset structure, summaries, counts, and missing values through various diagnostic functions.\n\nsummary(meth)\n\n      age           gender             grade                amas      \n Min.   :  3.7   Length:599         Length:599         Min.   : 4.00  \n 1st Qu.:106.2   Class :character   Class :character   1st Qu.:18.00  \n Median :120.8   Mode  :character   Mode  :character   Median :22.00  \n Mean   :124.6                                         Mean   :21.98  \n 3rd Qu.:141.8                                         3rd Qu.:26.50  \n Max.   :187.5                                         Max.   :45.00  \n     rcmas           arith      \n Min.   : 1.00   Min.   :0.000  \n 1st Qu.:14.00   1st Qu.:4.000  \n Median :19.00   Median :6.000  \n Mean   :19.24   Mean   :5.302  \n 3rd Qu.:25.00   3rd Qu.:7.000  \n Max.   :41.00   Max.   :8.000  \n\n\n\nskimr::skim(meth)\n\n\nData summary\n\n\nName\nmeth\n\n\nNumber of rows\n599\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ngender\n0\n1\n3\n4\n0\n2\n0\n\n\ngrade\n0\n1\n7\n9\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nage\n0\n1\n124.65\n22.31\n3.7\n106.15\n120.8\n141.85\n187.5\n▁▁▇▇▃\n\n\namas\n0\n1\n21.98\n6.60\n4.0\n18.00\n22.0\n26.50\n45.0\n▂▆▇▃▁\n\n\nrcmas\n0\n1\n19.24\n7.57\n1.0\n14.00\n19.0\n25.00\n41.0\n▂▇▇▅▁\n\n\narith\n0\n1\n5.30\n2.11\n0.0\n4.00\n6.0\n7.00\n8.0\n▂▃▃▇▇\n\n\n\n\n\nShow the structure of the dataset including data types.\n\nstr(meth)\n\nspc_tbl_ [599 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ age   : num [1:599] 138 141 138 143 136 ...\n $ gender: chr [1:599] \"Boy\" \"Boy\" \"Girl\" \"Girl\" ...\n $ grade : chr [1:599] \"Secondary\" \"Secondary\" \"Secondary\" \"Secondary\" ...\n $ amas  : num [1:599] 9 18 23 19 23 27 22 17 28 20 ...\n $ rcmas : num [1:599] 20 8 26 18 20 33 23 11 32 30 ...\n $ arith : num [1:599] 6 6 5 7 1 1 4 7 2 6 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Age = col_double(),\n  ..   Gender = col_character(),\n  ..   Grade = col_character(),\n  ..   AMAS = col_double(),\n  ..   RCMAS = col_double(),\n  ..   Arith = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nCount occurrences by gender.\n\ncount(meth, gender)\n\n# A tibble: 2 × 2\n  gender     n\n  &lt;chr&gt;  &lt;int&gt;\n1 Boy      323\n2 Girl     276\n\n\nReturn the dimensions of the dataset.\n\ndim(meth)\n\n[1] 599   6\n\n\nList the column names of the dataset.\n\nbase::names(meth)\n\n[1] \"age\"    \"gender\" \"grade\"  \"amas\"   \"rcmas\"  \"arith\" \n\n\nProvide a glimpse of the dataset showing types and sample value\n\ndplyr::glimpse(meth)\n\nRows: 599\nColumns: 6\n$ age    &lt;dbl&gt; 137.8, 140.7, 137.9, 142.8, 135.6, 135.0, 133.6, 139.3, 131.7, …\n$ gender &lt;chr&gt; \"Boy\", \"Boy\", \"Girl\", \"Girl\", \"Boy\", \"Girl\", \"Boy\", \"Boy\", \"Gir…\n$ grade  &lt;chr&gt; \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\"…\n$ amas   &lt;dbl&gt; 9, 18, 23, 19, 23, 27, 22, 17, 28, 20, 16, 20, 21, 36, 16, 27, …\n$ rcmas  &lt;dbl&gt; 20, 8, 26, 18, 20, 33, 23, 11, 32, 30, 10, 4, 23, 26, 24, 21, 3…\n$ arith  &lt;dbl&gt; 6, 6, 5, 7, 1, 1, 4, 7, 2, 6, 2, 5, 2, 6, 2, 7, 2, 4, 7, 3, 8, …\n\n\nReplace common NA representations with actual NA values in the dataset.\n\nmeth_modified &lt;- meth %&gt;%\n  naniar::replace_with_na_all(data = ., condition = ~ .x %in% common_na_numbers) %&gt;%\n  naniar::replace_with_na_all(data = ., condition = ~ .x %in% common_na_strings)\nglimpse(meth_modified)\n\nRows: 599\nColumns: 6\n$ age    &lt;dbl&gt; 137.8, 140.7, 137.9, 142.8, 135.6, 135.0, 133.6, 139.3, 131.7, …\n$ gender &lt;chr&gt; \"Boy\", \"Boy\", \"Girl\", \"Girl\", \"Boy\", \"Girl\", \"Boy\", \"Boy\", \"Gir…\n$ grade  &lt;chr&gt; \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\"…\n$ amas   &lt;dbl&gt; 9, 18, 23, 19, 23, 27, 22, 17, 28, 20, 16, 20, 21, 36, 16, 27, …\n$ rcmas  &lt;dbl&gt; 20, 8, 26, 18, 20, 33, 23, 11, 32, 30, 10, 4, 23, 26, 24, 21, 3…\n$ arith  &lt;dbl&gt; 6, 6, 5, 7, 1, 1, 4, 7, 2, 6, 2, 5, 2, 6, 2, 7, 2, 4, 7, 3, 8, …\n\n\n\n\n\n\nvisdat::vis_miss(meth_modified)\n\n\n\n\n\n\n\nvisdat::vis_dat(meth_modified)\n\n\n\n\n\n\n\n\n\n\n\nThis section performs further data wrangling, such as binning age and factoring variables.\nConvert gender and grade to factors and relocate them before age for better organization.\n\nmeth_modified &lt;- meth_modified %&gt;%\n  mutate(\n    gender = as.factor(gender),\n    grade = as.factor(grade),\n  ) %&gt;%\n  dplyr::relocate(where(is.factor), .before = age)\nglimpse(meth_modified)\n\nRows: 599\nColumns: 6\n$ gender &lt;fct&gt; Boy, Boy, Girl, Girl, Boy, Girl, Boy, Boy, Girl, Boy, Boy, Boy,…\n$ grade  &lt;fct&gt; Secondary, Secondary, Secondary, Secondary, Secondary, Secondar…\n$ age    &lt;dbl&gt; 137.8, 140.7, 137.9, 142.8, 135.6, 135.0, 133.6, 139.3, 131.7, …\n$ amas   &lt;dbl&gt; 9, 18, 23, 19, 23, 27, 22, 17, 28, 20, 16, 20, 21, 36, 16, 27, …\n$ rcmas  &lt;dbl&gt; 20, 8, 26, 18, 20, 33, 23, 11, 32, 30, 10, 4, 23, 26, 24, 21, 3…\n$ arith  &lt;dbl&gt; 6, 6, 5, 7, 1, 1, 4, 7, 2, 6, 2, 5, 2, 6, 2, 7, 2, 4, 7, 3, 8, …\n\n\n\nmeth_modified %&gt;%\n  head(10) %&gt;%\n  dplyr::rename(\n    \"Gender\" = gender,\n    \"Grade\" = grade,\n    \"Age (months)\" = age,\n    \"AMAS (Math Anxiety)\" = amas,\n    \"RCMAS (General Anxiety)\" = rcmas,\n    \"Arithmetic Score\" = arith\n  ) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Gender\n                Grade\n                Age (months)\n                AMAS (Math Anxiety)\n                RCMAS (General Anxiety)\n                Arithmetic Score\n              \n        \n        \n        \n                \n                  Boy\n                  Secondary\n                  137.8\n                  9\n                  20\n                  6\n                \n                \n                  Boy\n                  Secondary\n                  140.7\n                  18\n                  8\n                  6\n                \n                \n                  Girl\n                  Secondary\n                  137.9\n                  23\n                  26\n                  5\n                \n                \n                  Girl\n                  Secondary\n                  142.8\n                  19\n                  18\n                  7\n                \n                \n                  Boy\n                  Secondary\n                  135.6\n                  23\n                  20\n                  1\n                \n                \n                  Girl\n                  Secondary\n                  135.0\n                  27\n                  33\n                  1\n                \n                \n                  Boy\n                  Secondary\n                  133.6\n                  22\n                  23\n                  4\n                \n                \n                  Boy\n                  Secondary\n                  139.3\n                  17\n                  11\n                  7\n                \n                \n                  Girl\n                  Secondary\n                  131.7\n                  28\n                  32\n                  2\n                \n                \n                  Boy\n                  Secondary\n                  134.8\n                  20\n                  30\n                  6\n                \n        \n      \n    \n\n\n\n\n\n\n\nmeth_modified %&gt;% dplyr::count(across(.cols = c(gender, grade)))\n\n# A tibble: 4 × 3\n  gender grade         n\n  &lt;fct&gt;  &lt;fct&gt;     &lt;int&gt;\n1 Boy    Primary     199\n2 Boy    Secondary   124\n3 Girl   Primary     202\n4 Girl   Secondary    74\n\n\n\nmeth_modified %&gt;%\n  dplyr::summarise(\n    mean_amas = mean(amas, na.rm = T),\n    sd_amas = sd(amas, na.rm = T),\n    min_amas = min(amas, na.rm = T),\n    max_amas = max(amas, na.rm = T)\n  )\n\n# A tibble: 1 × 4\n  mean_amas sd_amas min_amas max_amas\n      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1      22.0    6.60        4       45\n\n\n\nmeth_modified %&gt;%\n  dplyr::summarise(across(\n    .cols = c(amas, rcmas), \n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 1 × 8\n  amas_mean amas_sd amas_min amas_max rcmas_mean rcmas_sd rcmas_min rcmas_max\n      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1      22.0    6.60        4       45       19.2     7.57         1        41\n\n\n\nmeth_modified %&gt;%\n  dplyr::summarise(\n    mean_arith = mean(arith, na.rm = T),\n    sd_arith = sd(arith, na.rm = T),\n    min_arith = min(arith, na.rm = T),\n    max_arith = max(arith, na.rm = T)\n  )\n\n# A tibble: 1 × 4\n  mean_arith sd_arith min_arith max_arith\n       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1       5.30     2.11         0         8\n\n\n\nmeth_modified %&gt;%\n  dplyr::summarise(\n    mean_age = mean(age, na.rm = T),\n    sd_age = sd(age, na.rm = T),\n    min_age = min(age, na.rm = T),\n    max_age = max(age, na.rm = T)\n  )\n\n# A tibble: 1 × 4\n  mean_age sd_age min_age max_age\n     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     125.   22.3     3.7    188.\n\n\n\nmeth_modified %&gt;%\n  group_by(gender) %&gt;%\n  dplyr::summarise(across(\n    .cols = c(age, amas, rcmas, arith),\n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 2 × 17\n  gender age_mean age_sd age_min age_max amas_mean amas_sd amas_min amas_max\n  &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Boy        128.   22.9    93.1    188.      21.2    6.51        4       45\n2 Girl       121.   21.1     3.7    180.      22.9    6.59        9       40\n# ℹ 8 more variables: rcmas_mean &lt;dbl&gt;, rcmas_sd &lt;dbl&gt;, rcmas_min &lt;dbl&gt;,\n#   rcmas_max &lt;dbl&gt;, arith_mean &lt;dbl&gt;, arith_sd &lt;dbl&gt;, arith_min &lt;dbl&gt;,\n#   arith_max &lt;dbl&gt;\n\n\n\ncrosstable(age + rcmas + amas + arith ~ gender,\n  data = meth_modified\n) %&gt;%\n  crosstable::as_flextable()\n\nlabelvariablegenderBoyGirlageMin / Max93.1 / 187.53.7 / 180.3Med [IQR]124.9 [107.4;147.2]117.8 [105.8;133.4]Mean (std)127.6 (22.9)121.1 (21.1)N (NA)323 (0)276 (0)rcmasMin / Max1.0 / 41.03.0 / 38.0Med [IQR]18.0 [13.0;23.0]20.0 [15.0;26.0]Mean (std)18.1 (7.5)20.6 (7.4)N (NA)323 (0)276 (0)amasMin / Max4.0 / 45.09.0 / 40.0Med [IQR]21.0 [17.0;26.0]23.0 [19.0;28.0]Mean (std)21.2 (6.5)22.9 (6.6)N (NA)323 (0)276 (0)arithMin / Max0 / 8.00 / 8.0Med [IQR]6.0 [4.0;7.0]6.0 [4.0;7.0]Mean (std)5.3 (2.1)5.3 (2.1)N (NA)323 (0)276 (0)\n\n\n\nmeth_modified %&gt;%\n  group_by(gender) %&gt;%\n  dplyr::summarise(across(\n    .cols = c(age, amas, rcmas, arith),\n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 2 × 17\n  gender age_mean age_sd age_min age_max amas_mean amas_sd amas_min amas_max\n  &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Boy        128.   22.9    93.1    188.      21.2    6.51        4       45\n2 Girl       121.   21.1     3.7    180.      22.9    6.59        9       40\n# ℹ 8 more variables: rcmas_mean &lt;dbl&gt;, rcmas_sd &lt;dbl&gt;, rcmas_min &lt;dbl&gt;,\n#   rcmas_max &lt;dbl&gt;, arith_mean &lt;dbl&gt;, arith_sd &lt;dbl&gt;, arith_min &lt;dbl&gt;,\n#   arith_max &lt;dbl&gt;\n\n\n\nmeth_modified %&gt;%\n  group_by(grade) %&gt;%\n  dplyr::summarise(across(\n    .cols = c(age, amas, rcmas, arith),\n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 2 × 17\n  grade     age_mean age_sd age_min age_max amas_mean amas_sd amas_min amas_max\n  &lt;fct&gt;        &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Primary       111.   12.1     3.7    135.      21.8    6.53        4       38\n2 Secondary     151.   12.1   132.     188.      22.3    6.75        9       45\n# ℹ 8 more variables: rcmas_mean &lt;dbl&gt;, rcmas_sd &lt;dbl&gt;, rcmas_min &lt;dbl&gt;,\n#   rcmas_max &lt;dbl&gt;, arith_mean &lt;dbl&gt;, arith_sd &lt;dbl&gt;, arith_min &lt;dbl&gt;,\n#   arith_max &lt;dbl&gt;\n\n\n\ngf_histogram(~age, data = meth_modified) %&gt;%\n  gf_labs(title = \"Histogram of Age\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_histogram(~amas, data = meth_modified) %&gt;%\n  gf_labs(title = \"Histogram of AMAS\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_histogram(~rcmas, data = meth_modified) %&gt;%\n  gf_labs(title = \"Histogram of RCMAS\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_bar(~grade, data = meth_modified) %&gt;%\n  gf_labs(title = \"Bar Plot of Grade\")\n\n\n\n\n\n\n\n\n\ngf_bar(~gender, data = meth_modified) %&gt;%\n  gf_labs(title = \"Bar Plot of Gender\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_bar(~grade,\n         fill=~gender,\n         position = \"dodge\") +\n  labs(title= \"Grade count for both genders\", subtitle = \"Dodged Bar Chart\", x =\"Grade\", y =\"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\nWhy is the count reducing in secondary grade? Assuming lesser students have enrolled for Secondary grade compared to Primary grade.\n\nmeth_modified %&gt;%\n  gf_bar(~grade,\n         fill=~gender,\n         position = \"stack\") +\n  labs(title= \"Grade count for both genders\", subtitle = \"Stacked Bar Chart\", x =\"Grade\", y =\"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\nComparing Count of Girl’s Grade\n\nmeth_modified %&gt;%\n  gf_bar(~grade,\n         fill=~gender,\n         position = \"fill\") +\n  labs(title= \"Comparing count of both gender's grade\", subtitle = \"Filled Bar Chart\", x =\"Grade\", y =\"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_bar(~age,\n         fill=~gender,\n         position = \"stack\") +\n  labs(title= \"Age count for both genders\", subtitle = \"Stacked Bar Chart\", x =\"Age\", y =\"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\n\n\nAfter age 150 months (12.5 years), there’s a significant drop, which confirms that as students get older, fewer people enroll in math.\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_histogram(~amas| grade~gender,\n               bins = 5,\n               fill = \"steelblue\",\n               color=\"white\") %&gt;% \n  gf_labs(title=\"Histogram of AMAS Scores\",\n          subtitle =\"Faceted by Grade and Gender\",\n          x=\"AMAS Score\",\n          y=\"Count\")\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_histogram(~amas | grade,\n               fill=~gender,\n               colour=\"black\") %&gt;%\n  gf_labs(\n    title = \"AMAS by Filled and Faceted by Grade\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_boxplot(amas~gender | grade,\n             fill=~gender,\n             orientation = \"x\") %&gt;% \n  gf_labs(title = \"Boxplots of AMAS Scores by Grade\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Gender\",\n       y = \"AMAS Score\")\n\n\n\n\n\n\n\n\n\n\n\nGirls face more math anxiety: Box plots show higher medians, wider ranges. For girls, means are higher in both Primary & Secondary Grades.\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_histogram(~rcmas| grade~gender,\n               bins = 5,\n               fill = \"steelblue\",\n               color=\"white\") %&gt;% \n  gf_labs(title=\"Histogram of RCMAS Scores\",\n          subtitle =\"Faceted by Grade and Gender\",\n          x=\"RCMAS Score\",\n          y=\"Count\")\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_histogram(~rcmas | grade,\n               fill=~gender,\n               colour=\"black\") %&gt;%\n  gf_labs(\n    title = \"RCMAS by Filled and Faceted by Grade\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_boxplot(rcmas~gender | grade,\n             fill=~gender,\n             orientation = \"x\") %&gt;% \n  gf_labs(title = \"Boxplots of RCMAS Scores by Grade\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Gender\",\n       y = \"RCMAS Score\")\n\n\n\n\n\n\n\n\n\n\n\nAnxiety appears to be higher for Girls than for Boys\nAnxiety appears to be highest in Primary Girls\nAnxiety appears to be lowest in Secondary Boys\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_bar(~arith | grade,\n               fill = ~gender,\n               position=\"dodge\",\n               color=\"black\") %&gt;% \n  gf_labs(title = \"Dodged Bar Graph of Arith Scores\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Arith Score\",\n       y = \"Count\") %&gt;% \n  gf_refine(scale_color_brewer(palette = \"Set 2\"))\n\nWarning: Unknown palette: \"Set 2\"\n\n\n\n\n\n\n\n\n\n\n\n\nIn general, girls have a lower arith score than boys.\nIn Primary Grade, it is seen that the difference between girls and boys score is less when compared to Secondary grade where the gap is bigger.\n\n\nmeth_modified %&gt;%\n  gf_bar(~arith | grade,\n               fill = ~gender,\n               position=\"fill\",\n               color=\"black\") %&gt;% \n  gf_labs(title = \"Filled Bar Graph of Arith Scores\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Arith Score\",\n       y = \"Count\") %&gt;% \n  gf_refine(scale_color_brewer(palette = \"Set 2\"))\n\nWarning: Unknown palette: \"Set 2\"\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_bar(~arith | grade,\n               fill=~grade,\n               colour=\"black\") %&gt;%\n  gf_labs(\n    title = \"Arith by Filled and Faceted by Grade\",\n    x=\"Arith Scores\",\n    y=\"Count\")\n\n\n\n\n\n\n\n\n\n\n\nPrimary Grade have higher arith scores than Secondary Grade.\n\nmeth_modified %&gt;% \n  gf_boxplot(arith ~gender | grade,\n             fill=~gender,\n             orientation = \"x\") %&gt;% \n  gf_labs(title = \"Boxplots of Arith Scores by Grade\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Gender\",\n       y = \"Arith Score\")\n\n\n\n\n\n\n\n\n\n\n\n\nPrimary grades ranges from 5 to 7 & Median is 6, while Secondary grades ranges from 3 to 6 & median is 4.\nSecondary students lag in arithmetic: Box plots shows lower medians and wider ranges for Secondary Grade.\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_point(arith ~ age | gender, color = ~ grade) %&gt;%\n  gf_labs(\n    title = \"Scatter Plot of Age vs Arithmetic Score\",\n    subtitle = \"Faceted by Gender, Colored by Grade\",\n    x = \"Age\",\n    y = \"Arithmetic Score\",\n    color = \"Grade\"\n  ) %&gt;%\n  gf_refine(scale_color_brewer(palette = \"Spectral\")) %&gt;% \n  gf_theme(theme_dark())\n\n\n\n\n\n\n\n\n\n\n\nScatter plots shows similar Arith trends across both genders, but primary tend to have higher Arith scores.\n\n\nmeth_modified %&gt;% \n  gf_boxplot(arith ~ grade | gender, orientation = \"x\", fill=~grade, color = \"black\") %&gt;%\n gf_labs(\n    x = \"Grade\",\n    y = \"Arithmetic Score\",\n    title = \"Arithmetic Scores by Grade\",\n    subtitle = \"Faceted by Gender\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set3\")) %&gt;%\n  gf_theme(theme_dark())\n\n\n\n\n\n\n\n\n\n\n\n\nPrimary grade students (both genders) have higher arithmetic scores compared to secondary grade.\nSecondary grade students have wider range for arithmetic scores compared to Primary grade.\nAmong genders within each grade there’s no difference in score .\n\n\n\n\n\n\nHypothesis: From previous visualization we think that Math Anxiety (AMAS) is affects Arithmetic scores.\n\n\nmeth_modified %&gt;%\n  gf_boxplot(arith ~ amas | gender ~ grade, fill = ~ gender, orientation = \"x\") %&gt;%\n  gf_labs(\n    title = \"Relationship between Math Anxiety and Arithmetic Performance\",\n    subtitle = \"Across Gender and Grade\",\n    x = \"Math Anxiety (AMAS)\",\n    y = \"Arithmetic Performance (Arith)\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set2\")) %&gt;%\n  gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\nAs math anxiety (AMAS) increases, arithmetic performance tends to go down for both genders.\nIn both primary and secondary grade, Boys perform better than girls.\nPrimary Grade students have higher math score than Secondary.\nThe Secondary grade has more Math anxeity and this affects their Arithmatic scores.\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_density(~ age | gender, fill = ~ grade, color=\"black\") %&gt;%\n  gf_labs(\n    title = \"Density Plots of Age\",\n    subtitle = \"Faceted by Gender, Filled by Grade\",\n    x = \"Age\",\n    y = \"Density\",\n    color = \"Grade\"\n  ) %&gt;% \n  gf_refine(scale_color_brewer(palette = \"Set 3\")) %&gt;% \n  gf_theme(theme_light())\n\nWarning: Unknown palette: \"Set 3\"\n\n\nIgnoring unknown labels:\n• colour : \"Grade\"\n\n\n\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_point(rcmas ~ amas, color = ~ gender, shape = ~ gender) %&gt;%\n  gf_labs(\n    title = \"Scatter Plot of Amas vs Rcmas\",\n    subtitle = \"Colored by Gender\",\n    x = \"Amas Score\",\n    y = \"Rcmas Score\"\n  ) %&gt;%\n  gf_refine(scale_color_brewer(palette = \"Set1\")) %&gt;% \n  gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\nIn general, both Genders have higher amas and lower rcmas\n\n\nmeth_modified %&gt;%\n  gf_boxplot(rcmas ~ amas | gender~grade, fill =~gender, orientation = \"y\") %&gt;%\n  gf_labs(\n    title = \"Box Plot of Amas vs Rcmas\",\n    subtitle = \"Colored by Grade\",\n    x = \"Amas Score\",\n    y = \"Rcmas Score\"\n  ) %&gt;%\n  gf_refine(scale_color_brewer(palette = \"Set2\")) %&gt;% \n  gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\n\nAs seen in the boxplot graphs, Boys tend to have a wider range of RCMAS than girls.\nComparing Primary and Secondary Boys -\n\nPrimary Boys have lower general anxiety (rcmas) and higher math anxiety (amas).\nSecondary Boys have higher general anxiety (rcmas) and lower math anxiety (amas).\n\nComparing Primary and Secondary Girls -\n\nPrimary Girls have higher general anxiety(rcmas) and lower math anxiety (amas)\nSecondary Girls have lower general anxiety (rcmas) and higher math anxiety (amas)\n\nComparing Primary Boys and Girls -\n\nBoys have lesser median but wider range for math anxiety (amas)\nGirls have higher median but narrower range for math anxiety (amas)\nBoys & Girls have same range for general anxiety (rcmas)\n\nComparing Secondary Boys & Girls -\n\nBoys have lesser median and narrower range for math anxiety (amas)\nGirls have higher median and wider range for math anxiety (amas)\nBoys have wider range of general anxiety compared to girls (rcmas)\n\n\n\n\n\n\n\n\nMost visualizations show that girls have higher anxieties (both math and general), while boys have higher arithmetic scores. This could be due to boys possibly having a better support system.\nMany visualizations confirm: primary grade students do better in Math,"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#data-cleaning",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#data-cleaning",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "This section handles loading the dataset, cleaning missing values, and initial transformations like converting variables to factors.\nLoad necessary libraries for data manipulation, visualization, and interactive elements.\n\n\n\nlibrary(ggformula)\n\nLoading required package: ggplot2\n\n\nLoading required package: scales\n\n\nLoading required package: ggridges\n\n\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(naniar)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:naniar':\n\n    n_complete\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.0.4     ✔ tidyr     1.3.1\n✔ readr     2.1.5     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ mosaic::count()     masks dplyr::count()\n✖ purrr::cross()      masks mosaic::cross()\n✖ purrr::discard()    masks scales::discard()\n✖ mosaic::do()        masks dplyr::do()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ mosaic::stat()      masks ggplot2::stat()\n✖ mosaic::tally()     masks dplyr::tally()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tinytable)\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(visdat)\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(RColorBrewer)"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#read-data",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#read-data",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "meth &lt;- readr::read_delim(\"MathAnxiety.csv\",\n                          delim = \";\",\n                          locale = locale(decimal_mark = \",\")) %&gt;% \n  janitor::clean_names(\"snake\")\n\nRows: 599 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (2): Gender, Grade\ndbl (4): Age, AMAS, RCMAS, Arith\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmeth\n\n# A tibble: 599 × 6\n     age gender grade      amas rcmas arith\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  138. Boy    Secondary     9    20     6\n 2  141. Boy    Secondary    18     8     6\n 3  138. Girl   Secondary    23    26     5\n 4  143. Girl   Secondary    19    18     7\n 5  136. Boy    Secondary    23    20     1\n 6  135  Girl   Secondary    27    33     1\n 7  134. Boy    Secondary    22    23     4\n 8  139. Boy    Secondary    17    11     7\n 9  132. Girl   Secondary    28    32     2\n10  135. Boy    Secondary    20    30     6\n# ℹ 589 more rows"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#data-dictionary",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#data-dictionary",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "Variable\nDescription\n\n\n\n\nAge\nThe age of the child in months.\n\n\nGender\nThe gender of the child (Boy or Girl).\n\n\nGrade\nThe educational level of the child (Primary or Secondary).\n\n\nAMAS\nThe score on the Abbreviated Math Anxiety Scale, where a higher score indicates greater math anxiety.\n\n\nRCMAS\nThe score on the Revised Children’s Manifest Anxiety Scale, measuring general anxiety\n\n\nArith\nThe score on an arithmetic test."
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#examine-data",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#examine-data",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "This section inspects the dataset structure, summaries, counts, and missing values through various diagnostic functions.\n\nsummary(meth)\n\n      age           gender             grade                amas      \n Min.   :  3.7   Length:599         Length:599         Min.   : 4.00  \n 1st Qu.:106.2   Class :character   Class :character   1st Qu.:18.00  \n Median :120.8   Mode  :character   Mode  :character   Median :22.00  \n Mean   :124.6                                         Mean   :21.98  \n 3rd Qu.:141.8                                         3rd Qu.:26.50  \n Max.   :187.5                                         Max.   :45.00  \n     rcmas           arith      \n Min.   : 1.00   Min.   :0.000  \n 1st Qu.:14.00   1st Qu.:4.000  \n Median :19.00   Median :6.000  \n Mean   :19.24   Mean   :5.302  \n 3rd Qu.:25.00   3rd Qu.:7.000  \n Max.   :41.00   Max.   :8.000  \n\n\n\nskimr::skim(meth)\n\n\nData summary\n\n\nName\nmeth\n\n\nNumber of rows\n599\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ngender\n0\n1\n3\n4\n0\n2\n0\n\n\ngrade\n0\n1\n7\n9\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nage\n0\n1\n124.65\n22.31\n3.7\n106.15\n120.8\n141.85\n187.5\n▁▁▇▇▃\n\n\namas\n0\n1\n21.98\n6.60\n4.0\n18.00\n22.0\n26.50\n45.0\n▂▆▇▃▁\n\n\nrcmas\n0\n1\n19.24\n7.57\n1.0\n14.00\n19.0\n25.00\n41.0\n▂▇▇▅▁\n\n\narith\n0\n1\n5.30\n2.11\n0.0\n4.00\n6.0\n7.00\n8.0\n▂▃▃▇▇\n\n\n\n\n\nShow the structure of the dataset including data types.\n\nstr(meth)\n\nspc_tbl_ [599 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ age   : num [1:599] 138 141 138 143 136 ...\n $ gender: chr [1:599] \"Boy\" \"Boy\" \"Girl\" \"Girl\" ...\n $ grade : chr [1:599] \"Secondary\" \"Secondary\" \"Secondary\" \"Secondary\" ...\n $ amas  : num [1:599] 9 18 23 19 23 27 22 17 28 20 ...\n $ rcmas : num [1:599] 20 8 26 18 20 33 23 11 32 30 ...\n $ arith : num [1:599] 6 6 5 7 1 1 4 7 2 6 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Age = col_double(),\n  ..   Gender = col_character(),\n  ..   Grade = col_character(),\n  ..   AMAS = col_double(),\n  ..   RCMAS = col_double(),\n  ..   Arith = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nCount occurrences by gender.\n\ncount(meth, gender)\n\n# A tibble: 2 × 2\n  gender     n\n  &lt;chr&gt;  &lt;int&gt;\n1 Boy      323\n2 Girl     276\n\n\nReturn the dimensions of the dataset.\n\ndim(meth)\n\n[1] 599   6\n\n\nList the column names of the dataset.\n\nbase::names(meth)\n\n[1] \"age\"    \"gender\" \"grade\"  \"amas\"   \"rcmas\"  \"arith\" \n\n\nProvide a glimpse of the dataset showing types and sample value\n\ndplyr::glimpse(meth)\n\nRows: 599\nColumns: 6\n$ age    &lt;dbl&gt; 137.8, 140.7, 137.9, 142.8, 135.6, 135.0, 133.6, 139.3, 131.7, …\n$ gender &lt;chr&gt; \"Boy\", \"Boy\", \"Girl\", \"Girl\", \"Boy\", \"Girl\", \"Boy\", \"Boy\", \"Gir…\n$ grade  &lt;chr&gt; \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\"…\n$ amas   &lt;dbl&gt; 9, 18, 23, 19, 23, 27, 22, 17, 28, 20, 16, 20, 21, 36, 16, 27, …\n$ rcmas  &lt;dbl&gt; 20, 8, 26, 18, 20, 33, 23, 11, 32, 30, 10, 4, 23, 26, 24, 21, 3…\n$ arith  &lt;dbl&gt; 6, 6, 5, 7, 1, 1, 4, 7, 2, 6, 2, 5, 2, 6, 2, 7, 2, 4, 7, 3, 8, …\n\n\nReplace common NA representations with actual NA values in the dataset.\n\nmeth_modified &lt;- meth %&gt;%\n  naniar::replace_with_na_all(data = ., condition = ~ .x %in% common_na_numbers) %&gt;%\n  naniar::replace_with_na_all(data = ., condition = ~ .x %in% common_na_strings)\nglimpse(meth_modified)\n\nRows: 599\nColumns: 6\n$ age    &lt;dbl&gt; 137.8, 140.7, 137.9, 142.8, 135.6, 135.0, 133.6, 139.3, 131.7, …\n$ gender &lt;chr&gt; \"Boy\", \"Boy\", \"Girl\", \"Girl\", \"Boy\", \"Girl\", \"Boy\", \"Boy\", \"Gir…\n$ grade  &lt;chr&gt; \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\"…\n$ amas   &lt;dbl&gt; 9, 18, 23, 19, 23, 27, 22, 17, 28, 20, 16, 20, 21, 36, 16, 27, …\n$ rcmas  &lt;dbl&gt; 20, 8, 26, 18, 20, 33, 23, 11, 32, 30, 10, 4, 23, 26, 24, 21, 3…\n$ arith  &lt;dbl&gt; 6, 6, 5, 7, 1, 1, 4, 7, 2, 6, 2, 5, 2, 6, 2, 7, 2, 4, 7, 3, 8, …"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#viewing-missing-data",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#viewing-missing-data",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "visdat::vis_miss(meth_modified)\n\n\n\n\n\n\n\nvisdat::vis_dat(meth_modified)"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#munging",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#munging",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "This section performs further data wrangling, such as binning age and factoring variables.\nConvert gender and grade to factors and relocate them before age for better organization.\n\nmeth_modified &lt;- meth_modified %&gt;%\n  mutate(\n    gender = as.factor(gender),\n    grade = as.factor(grade),\n  ) %&gt;%\n  dplyr::relocate(where(is.factor), .before = age)\nglimpse(meth_modified)\n\nRows: 599\nColumns: 6\n$ gender &lt;fct&gt; Boy, Boy, Girl, Girl, Boy, Girl, Boy, Boy, Girl, Boy, Boy, Boy,…\n$ grade  &lt;fct&gt; Secondary, Secondary, Secondary, Secondary, Secondary, Secondar…\n$ age    &lt;dbl&gt; 137.8, 140.7, 137.9, 142.8, 135.6, 135.0, 133.6, 139.3, 131.7, …\n$ amas   &lt;dbl&gt; 9, 18, 23, 19, 23, 27, 22, 17, 28, 20, 16, 20, 21, 36, 16, 27, …\n$ rcmas  &lt;dbl&gt; 20, 8, 26, 18, 20, 33, 23, 11, 32, 30, 10, 4, 23, 26, 24, 21, 3…\n$ arith  &lt;dbl&gt; 6, 6, 5, 7, 1, 1, 4, 7, 2, 6, 2, 5, 2, 6, 2, 7, 2, 4, 7, 3, 8, …\n\n\n\nmeth_modified %&gt;%\n  head(10) %&gt;%\n  dplyr::rename(\n    \"Gender\" = gender,\n    \"Grade\" = grade,\n    \"Age (months)\" = age,\n    \"AMAS (Math Anxiety)\" = amas,\n    \"RCMAS (General Anxiety)\" = rcmas,\n    \"Arithmetic Score\" = arith\n  ) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Gender\n                Grade\n                Age (months)\n                AMAS (Math Anxiety)\n                RCMAS (General Anxiety)\n                Arithmetic Score\n              \n        \n        \n        \n                \n                  Boy\n                  Secondary\n                  137.8\n                  9\n                  20\n                  6\n                \n                \n                  Boy\n                  Secondary\n                  140.7\n                  18\n                  8\n                  6\n                \n                \n                  Girl\n                  Secondary\n                  137.9\n                  23\n                  26\n                  5\n                \n                \n                  Girl\n                  Secondary\n                  142.8\n                  19\n                  18\n                  7\n                \n                \n                  Boy\n                  Secondary\n                  135.6\n                  23\n                  20\n                  1\n                \n                \n                  Girl\n                  Secondary\n                  135.0\n                  27\n                  33\n                  1\n                \n                \n                  Boy\n                  Secondary\n                  133.6\n                  22\n                  23\n                  4\n                \n                \n                  Boy\n                  Secondary\n                  139.3\n                  17\n                  11\n                  7\n                \n                \n                  Girl\n                  Secondary\n                  131.7\n                  28\n                  32\n                  2\n                \n                \n                  Boy\n                  Secondary\n                  134.8\n                  20\n                  30\n                  6"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#summaries-examining-the-data",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#summaries-examining-the-data",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "meth_modified %&gt;% dplyr::count(across(.cols = c(gender, grade)))\n\n# A tibble: 4 × 3\n  gender grade         n\n  &lt;fct&gt;  &lt;fct&gt;     &lt;int&gt;\n1 Boy    Primary     199\n2 Boy    Secondary   124\n3 Girl   Primary     202\n4 Girl   Secondary    74\n\n\n\nmeth_modified %&gt;%\n  dplyr::summarise(\n    mean_amas = mean(amas, na.rm = T),\n    sd_amas = sd(amas, na.rm = T),\n    min_amas = min(amas, na.rm = T),\n    max_amas = max(amas, na.rm = T)\n  )\n\n# A tibble: 1 × 4\n  mean_amas sd_amas min_amas max_amas\n      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1      22.0    6.60        4       45\n\n\n\nmeth_modified %&gt;%\n  dplyr::summarise(across(\n    .cols = c(amas, rcmas), \n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 1 × 8\n  amas_mean amas_sd amas_min amas_max rcmas_mean rcmas_sd rcmas_min rcmas_max\n      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1      22.0    6.60        4       45       19.2     7.57         1        41\n\n\n\nmeth_modified %&gt;%\n  dplyr::summarise(\n    mean_arith = mean(arith, na.rm = T),\n    sd_arith = sd(arith, na.rm = T),\n    min_arith = min(arith, na.rm = T),\n    max_arith = max(arith, na.rm = T)\n  )\n\n# A tibble: 1 × 4\n  mean_arith sd_arith min_arith max_arith\n       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1       5.30     2.11         0         8\n\n\n\nmeth_modified %&gt;%\n  dplyr::summarise(\n    mean_age = mean(age, na.rm = T),\n    sd_age = sd(age, na.rm = T),\n    min_age = min(age, na.rm = T),\n    max_age = max(age, na.rm = T)\n  )\n\n# A tibble: 1 × 4\n  mean_age sd_age min_age max_age\n     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     125.   22.3     3.7    188.\n\n\n\nmeth_modified %&gt;%\n  group_by(gender) %&gt;%\n  dplyr::summarise(across(\n    .cols = c(age, amas, rcmas, arith),\n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 2 × 17\n  gender age_mean age_sd age_min age_max amas_mean amas_sd amas_min amas_max\n  &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Boy        128.   22.9    93.1    188.      21.2    6.51        4       45\n2 Girl       121.   21.1     3.7    180.      22.9    6.59        9       40\n# ℹ 8 more variables: rcmas_mean &lt;dbl&gt;, rcmas_sd &lt;dbl&gt;, rcmas_min &lt;dbl&gt;,\n#   rcmas_max &lt;dbl&gt;, arith_mean &lt;dbl&gt;, arith_sd &lt;dbl&gt;, arith_min &lt;dbl&gt;,\n#   arith_max &lt;dbl&gt;\n\n\n\ncrosstable(age + rcmas + amas + arith ~ gender,\n  data = meth_modified\n) %&gt;%\n  crosstable::as_flextable()\n\nlabelvariablegenderBoyGirlageMin / Max93.1 / 187.53.7 / 180.3Med [IQR]124.9 [107.4;147.2]117.8 [105.8;133.4]Mean (std)127.6 (22.9)121.1 (21.1)N (NA)323 (0)276 (0)rcmasMin / Max1.0 / 41.03.0 / 38.0Med [IQR]18.0 [13.0;23.0]20.0 [15.0;26.0]Mean (std)18.1 (7.5)20.6 (7.4)N (NA)323 (0)276 (0)amasMin / Max4.0 / 45.09.0 / 40.0Med [IQR]21.0 [17.0;26.0]23.0 [19.0;28.0]Mean (std)21.2 (6.5)22.9 (6.6)N (NA)323 (0)276 (0)arithMin / Max0 / 8.00 / 8.0Med [IQR]6.0 [4.0;7.0]6.0 [4.0;7.0]Mean (std)5.3 (2.1)5.3 (2.1)N (NA)323 (0)276 (0)\n\n\n\nmeth_modified %&gt;%\n  group_by(gender) %&gt;%\n  dplyr::summarise(across(\n    .cols = c(age, amas, rcmas, arith),\n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 2 × 17\n  gender age_mean age_sd age_min age_max amas_mean amas_sd amas_min amas_max\n  &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Boy        128.   22.9    93.1    188.      21.2    6.51        4       45\n2 Girl       121.   21.1     3.7    180.      22.9    6.59        9       40\n# ℹ 8 more variables: rcmas_mean &lt;dbl&gt;, rcmas_sd &lt;dbl&gt;, rcmas_min &lt;dbl&gt;,\n#   rcmas_max &lt;dbl&gt;, arith_mean &lt;dbl&gt;, arith_sd &lt;dbl&gt;, arith_min &lt;dbl&gt;,\n#   arith_max &lt;dbl&gt;\n\n\n\nmeth_modified %&gt;%\n  group_by(grade) %&gt;%\n  dplyr::summarise(across(\n    .cols = c(age, amas, rcmas, arith),\n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 2 × 17\n  grade     age_mean age_sd age_min age_max amas_mean amas_sd amas_min amas_max\n  &lt;fct&gt;        &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Primary       111.   12.1     3.7    135.      21.8    6.53        4       38\n2 Secondary     151.   12.1   132.     188.      22.3    6.75        9       45\n# ℹ 8 more variables: rcmas_mean &lt;dbl&gt;, rcmas_sd &lt;dbl&gt;, rcmas_min &lt;dbl&gt;,\n#   rcmas_max &lt;dbl&gt;, arith_mean &lt;dbl&gt;, arith_sd &lt;dbl&gt;, arith_min &lt;dbl&gt;,\n#   arith_max &lt;dbl&gt;\n\n\n\ngf_histogram(~age, data = meth_modified) %&gt;%\n  gf_labs(title = \"Histogram of Age\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_histogram(~amas, data = meth_modified) %&gt;%\n  gf_labs(title = \"Histogram of AMAS\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_histogram(~rcmas, data = meth_modified) %&gt;%\n  gf_labs(title = \"Histogram of RCMAS\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_bar(~grade, data = meth_modified) %&gt;%\n  gf_labs(title = \"Bar Plot of Grade\")\n\n\n\n\n\n\n\n\n\ngf_bar(~gender, data = meth_modified) %&gt;%\n  gf_labs(title = \"Bar Plot of Gender\")"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#visualizing-the-data",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#visualizing-the-data",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "meth_modified %&gt;%\n  gf_bar(~grade,\n         fill=~gender,\n         position = \"dodge\") +\n  labs(title= \"Grade count for both genders\", subtitle = \"Dodged Bar Chart\", x =\"Grade\", y =\"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\nWhy is the count reducing in secondary grade? Assuming lesser students have enrolled for Secondary grade compared to Primary grade.\n\nmeth_modified %&gt;%\n  gf_bar(~grade,\n         fill=~gender,\n         position = \"stack\") +\n  labs(title= \"Grade count for both genders\", subtitle = \"Stacked Bar Chart\", x =\"Grade\", y =\"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\nComparing Count of Girl’s Grade\n\nmeth_modified %&gt;%\n  gf_bar(~grade,\n         fill=~gender,\n         position = \"fill\") +\n  labs(title= \"Comparing count of both gender's grade\", subtitle = \"Filled Bar Chart\", x =\"Grade\", y =\"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_bar(~age,\n         fill=~gender,\n         position = \"stack\") +\n  labs(title= \"Age count for both genders\", subtitle = \"Stacked Bar Chart\", x =\"Age\", y =\"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\n\n\nAfter age 150 months (12.5 years), there’s a significant drop, which confirms that as students get older, fewer people enroll in math.\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_histogram(~amas| grade~gender,\n               bins = 5,\n               fill = \"steelblue\",\n               color=\"white\") %&gt;% \n  gf_labs(title=\"Histogram of AMAS Scores\",\n          subtitle =\"Faceted by Grade and Gender\",\n          x=\"AMAS Score\",\n          y=\"Count\")\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_histogram(~amas | grade,\n               fill=~gender,\n               colour=\"black\") %&gt;%\n  gf_labs(\n    title = \"AMAS by Filled and Faceted by Grade\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_boxplot(amas~gender | grade,\n             fill=~gender,\n             orientation = \"x\") %&gt;% \n  gf_labs(title = \"Boxplots of AMAS Scores by Grade\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Gender\",\n       y = \"AMAS Score\")\n\n\n\n\n\n\n\n\n\n\n\nGirls face more math anxiety: Box plots show higher medians, wider ranges. For girls, means are higher in both Primary & Secondary Grades.\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_histogram(~rcmas| grade~gender,\n               bins = 5,\n               fill = \"steelblue\",\n               color=\"white\") %&gt;% \n  gf_labs(title=\"Histogram of RCMAS Scores\",\n          subtitle =\"Faceted by Grade and Gender\",\n          x=\"RCMAS Score\",\n          y=\"Count\")\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_histogram(~rcmas | grade,\n               fill=~gender,\n               colour=\"black\") %&gt;%\n  gf_labs(\n    title = \"RCMAS by Filled and Faceted by Grade\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_boxplot(rcmas~gender | grade,\n             fill=~gender,\n             orientation = \"x\") %&gt;% \n  gf_labs(title = \"Boxplots of RCMAS Scores by Grade\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Gender\",\n       y = \"RCMAS Score\")\n\n\n\n\n\n\n\n\n\n\n\nAnxiety appears to be higher for Girls than for Boys\nAnxiety appears to be highest in Primary Girls\nAnxiety appears to be lowest in Secondary Boys\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_bar(~arith | grade,\n               fill = ~gender,\n               position=\"dodge\",\n               color=\"black\") %&gt;% \n  gf_labs(title = \"Dodged Bar Graph of Arith Scores\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Arith Score\",\n       y = \"Count\") %&gt;% \n  gf_refine(scale_color_brewer(palette = \"Set 2\"))\n\nWarning: Unknown palette: \"Set 2\"\n\n\n\n\n\n\n\n\n\n\n\n\nIn general, girls have a lower arith score than boys.\nIn Primary Grade, it is seen that the difference between girls and boys score is less when compared to Secondary grade where the gap is bigger.\n\n\nmeth_modified %&gt;%\n  gf_bar(~arith | grade,\n               fill = ~gender,\n               position=\"fill\",\n               color=\"black\") %&gt;% \n  gf_labs(title = \"Filled Bar Graph of Arith Scores\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Arith Score\",\n       y = \"Count\") %&gt;% \n  gf_refine(scale_color_brewer(palette = \"Set 2\"))\n\nWarning: Unknown palette: \"Set 2\"\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_bar(~arith | grade,\n               fill=~grade,\n               colour=\"black\") %&gt;%\n  gf_labs(\n    title = \"Arith by Filled and Faceted by Grade\",\n    x=\"Arith Scores\",\n    y=\"Count\")\n\n\n\n\n\n\n\n\n\n\n\nPrimary Grade have higher arith scores than Secondary Grade.\n\nmeth_modified %&gt;% \n  gf_boxplot(arith ~gender | grade,\n             fill=~gender,\n             orientation = \"x\") %&gt;% \n  gf_labs(title = \"Boxplots of Arith Scores by Grade\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Gender\",\n       y = \"Arith Score\")\n\n\n\n\n\n\n\n\n\n\n\n\nPrimary grades ranges from 5 to 7 & Median is 6, while Secondary grades ranges from 3 to 6 & median is 4.\nSecondary students lag in arithmetic: Box plots shows lower medians and wider ranges for Secondary Grade.\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_point(arith ~ age | gender, color = ~ grade) %&gt;%\n  gf_labs(\n    title = \"Scatter Plot of Age vs Arithmetic Score\",\n    subtitle = \"Faceted by Gender, Colored by Grade\",\n    x = \"Age\",\n    y = \"Arithmetic Score\",\n    color = \"Grade\"\n  ) %&gt;%\n  gf_refine(scale_color_brewer(palette = \"Spectral\")) %&gt;% \n  gf_theme(theme_dark())\n\n\n\n\n\n\n\n\n\n\n\nScatter plots shows similar Arith trends across both genders, but primary tend to have higher Arith scores.\n\n\nmeth_modified %&gt;% \n  gf_boxplot(arith ~ grade | gender, orientation = \"x\", fill=~grade, color = \"black\") %&gt;%\n gf_labs(\n    x = \"Grade\",\n    y = \"Arithmetic Score\",\n    title = \"Arithmetic Scores by Grade\",\n    subtitle = \"Faceted by Gender\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set3\")) %&gt;%\n  gf_theme(theme_dark())\n\n\n\n\n\n\n\n\n\n\n\n\nPrimary grade students (both genders) have higher arithmetic scores compared to secondary grade.\nSecondary grade students have wider range for arithmetic scores compared to Primary grade.\nAmong genders within each grade there’s no difference in score .\n\n\n\n\n\n\nHypothesis: From previous visualization we think that Math Anxiety (AMAS) is affects Arithmetic scores.\n\n\nmeth_modified %&gt;%\n  gf_boxplot(arith ~ amas | gender ~ grade, fill = ~ gender, orientation = \"x\") %&gt;%\n  gf_labs(\n    title = \"Relationship between Math Anxiety and Arithmetic Performance\",\n    subtitle = \"Across Gender and Grade\",\n    x = \"Math Anxiety (AMAS)\",\n    y = \"Arithmetic Performance (Arith)\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set2\")) %&gt;%\n  gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\nAs math anxiety (AMAS) increases, arithmetic performance tends to go down for both genders.\nIn both primary and secondary grade, Boys perform better than girls.\nPrimary Grade students have higher math score than Secondary.\nThe Secondary grade has more Math anxeity and this affects their Arithmatic scores.\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_density(~ age | gender, fill = ~ grade, color=\"black\") %&gt;%\n  gf_labs(\n    title = \"Density Plots of Age\",\n    subtitle = \"Faceted by Gender, Filled by Grade\",\n    x = \"Age\",\n    y = \"Density\",\n    color = \"Grade\"\n  ) %&gt;% \n  gf_refine(scale_color_brewer(palette = \"Set 3\")) %&gt;% \n  gf_theme(theme_light())\n\nWarning: Unknown palette: \"Set 3\"\n\n\nIgnoring unknown labels:\n• colour : \"Grade\"\n\n\n\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_point(rcmas ~ amas, color = ~ gender, shape = ~ gender) %&gt;%\n  gf_labs(\n    title = \"Scatter Plot of Amas vs Rcmas\",\n    subtitle = \"Colored by Gender\",\n    x = \"Amas Score\",\n    y = \"Rcmas Score\"\n  ) %&gt;%\n  gf_refine(scale_color_brewer(palette = \"Set1\")) %&gt;% \n  gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\nIn general, both Genders have higher amas and lower rcmas\n\n\nmeth_modified %&gt;%\n  gf_boxplot(rcmas ~ amas | gender~grade, fill =~gender, orientation = \"y\") %&gt;%\n  gf_labs(\n    title = \"Box Plot of Amas vs Rcmas\",\n    subtitle = \"Colored by Grade\",\n    x = \"Amas Score\",\n    y = \"Rcmas Score\"\n  ) %&gt;%\n  gf_refine(scale_color_brewer(palette = \"Set2\")) %&gt;% \n  gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\n\nAs seen in the boxplot graphs, Boys tend to have a wider range of RCMAS than girls.\nComparing Primary and Secondary Boys -\n\nPrimary Boys have lower general anxiety (rcmas) and higher math anxiety (amas).\nSecondary Boys have higher general anxiety (rcmas) and lower math anxiety (amas).\n\nComparing Primary and Secondary Girls -\n\nPrimary Girls have higher general anxiety(rcmas) and lower math anxiety (amas)\nSecondary Girls have lower general anxiety (rcmas) and higher math anxiety (amas)\n\nComparing Primary Boys and Girls -\n\nBoys have lesser median but wider range for math anxiety (amas)\nGirls have higher median but narrower range for math anxiety (amas)\nBoys & Girls have same range for general anxiety (rcmas)\n\nComparing Secondary Boys & Girls -\n\nBoys have lesser median and narrower range for math anxiety (amas)\nGirls have higher median and wider range for math anxiety (amas)\nBoys have wider range of general anxiety compared to girls (rcmas)"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#conclusion",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#conclusion",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "Most visualizations show that girls have higher anxieties (both math and general), while boys have higher arithmetic scores. This could be due to boys possibly having a better support system.\nMany visualizations confirm: primary grade students do better in Math,"
  }
]