[
  {
    "objectID": "posts/UFO/UFO.html",
    "href": "posts/UFO/UFO.html",
    "title": "UFO Dataset",
    "section": "",
    "text": "People keep spotting “UFOs” in different shapes, at random places on Earth, for weird amounts of time…and we analysed the patterns of when, where and how.\n\n\n\n\nlibrary(tidyverse) \n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic) \n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula) \nlibrary(skimr) \n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(janitor) \n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(naniar) \n\n\nAttaching package: 'naniar'\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\nlibrary(visdat) \nlibrary(tinytable) \n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(DT) \nlibrary(crosstable) \n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(RColorBrewer)\nlibrary(naniar)\nlibrary(tidyr)\nlibrary(dplyr)      \n\n\n\n\n\nufo_sightings &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2019/2019-06-25/ufo_sightings.csv\") %&gt;% \n  janitor::clean_names(case = \"snake\")\n\nRows: 80332 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): date_time, city_area, state, country, ufo_shape, described_encounte...\ndbl (3): encounter_length, latitude, longitude\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ndate_time\nDate time sighting occurred\n\n\ncity_area\nCity or area of sighting\n\n\nstate\nstate/region of sighting\n\n\ncountry\nCountry of sighting\n\n\nufo_shape\nUFO Shape\n\n\nencounter_length\nEncounter length in seconds\n\n\ndescribed_encounter_length\nEncounter length as described (eg 1 hour, etc\n\n\ndescription\nDescription of encounter\n\n\ndate_documented\nDate documented\n\n\nlatitude\nLatitude\n\n\nlongitude\nLongitude\n\n\n\n\n\n\n\nbase::names(ufo_sightings)\n\n [1] \"date_time\"                  \"city_area\"                 \n [3] \"state\"                      \"country\"                   \n [5] \"ufo_shape\"                  \"encounter_length\"          \n [7] \"described_encounter_length\" \"description\"               \n [9] \"date_documented\"            \"latitude\"                  \n[11] \"longitude\"                 \n\n\n\ndplyr::glimpse(ufo_sightings)\n\nRows: 80,332\nColumns: 11\n$ date_time                  &lt;chr&gt; \"10/10/1949 20:30\", \"10/10/1949 21:00\", \"10…\n$ city_area                  &lt;chr&gt; \"san marcos\", \"lackland afb\", \"chester (uk/…\n$ state                      &lt;chr&gt; \"tx\", \"tx\", NA, \"tx\", \"hi\", \"tn\", NA, \"ct\",…\n$ country                    &lt;chr&gt; \"us\", NA, \"gb\", \"us\", \"us\", \"us\", \"gb\", \"us…\n$ ufo_shape                  &lt;chr&gt; \"cylinder\", \"light\", \"circle\", \"circle\", \"l…\n$ encounter_length           &lt;dbl&gt; 2700, 7200, 20, 20, 900, 300, 180, 1200, 18…\n$ described_encounter_length &lt;chr&gt; \"45 minutes\", \"1-2 hrs\", \"20 seconds\", \"1/2…\n$ description                &lt;chr&gt; \"This event took place in early fall around…\n$ date_documented            &lt;chr&gt; \"4/27/2004\", \"12/16/2005\", \"1/21/2008\", \"1/…\n$ latitude                   &lt;dbl&gt; 29.88306, 29.38421, 53.20000, 28.97833, 21.…\n$ longitude                  &lt;dbl&gt; -97.941111, -98.581082, -2.916667, -96.6458…\n\n\n\nbase::dim(ufo_sightings)\n\n[1] 80332    11\n\n\n\nutils::str(ufo_sightings)\n\nspc_tbl_ [80,332 × 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ date_time                 : chr [1:80332] \"10/10/1949 20:30\" \"10/10/1949 21:00\" \"10/10/1955 17:00\" \"10/10/1956 21:00\" ...\n $ city_area                 : chr [1:80332] \"san marcos\" \"lackland afb\" \"chester (uk/england)\" \"edna\" ...\n $ state                     : chr [1:80332] \"tx\" \"tx\" NA \"tx\" ...\n $ country                   : chr [1:80332] \"us\" NA \"gb\" \"us\" ...\n $ ufo_shape                 : chr [1:80332] \"cylinder\" \"light\" \"circle\" \"circle\" ...\n $ encounter_length          : num [1:80332] 2700 7200 20 20 900 300 180 1200 180 120 ...\n $ described_encounter_length: chr [1:80332] \"45 minutes\" \"1-2 hrs\" \"20 seconds\" \"1/2 hour\" ...\n $ description               : chr [1:80332] \"This event took place in early fall around 1949-50. It occurred after a Boy Scout meeting in the Baptist Church\"| __truncated__ \"1949 Lackland AFB&#44 TX.  Lights racing across the sky &amp; making 90 degree turns on a dime.\" \"Green/Orange circular disc over Chester&#44 England\" \"My older brother and twin sister were leaving the only Edna theater at about 9 PM&#44...we had our bikes and I \"| __truncated__ ...\n $ date_documented           : chr [1:80332] \"4/27/2004\" \"12/16/2005\" \"1/21/2008\" \"1/17/2004\" ...\n $ latitude                  : num [1:80332] 29.9 29.4 53.2 29 21.4 ...\n $ longitude                 : num [1:80332] -97.94 -98.58 -2.92 -96.65 -157.8 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   date_time = col_character(),\n  ..   city_area = col_character(),\n  ..   state = col_character(),\n  ..   country = col_character(),\n  ..   ufo_shape = col_character(),\n  ..   encounter_length = col_double(),\n  ..   described_encounter_length = col_character(),\n  ..   description = col_character(),\n  ..   date_documented = col_character(),\n  ..   latitude = col_double(),\n  ..   longitude = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\n\n\nvisdat::vis_dat(ufo_sightings)\n\n\n\n\n\n\n\n\n\nvisdat::vis_miss(ufo_sightings)\n\n\n\n\n\n\n\n\n\n\n\n\nufo_sightings_withoutNA &lt;- ufo_sightings %&gt;% drop_na()\nglimpse(ufo_sightings_withoutNA)\n\nRows: 66,516\nColumns: 11\n$ date_time                  &lt;chr&gt; \"10/10/1949 20:30\", \"10/10/1956 21:00\", \"10…\n$ city_area                  &lt;chr&gt; \"san marcos\", \"edna\", \"kaneohe\", \"bristol\",…\n$ state                      &lt;chr&gt; \"tx\", \"tx\", \"hi\", \"tn\", \"ct\", \"al\", \"fl\", \"…\n$ country                    &lt;chr&gt; \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"…\n$ ufo_shape                  &lt;chr&gt; \"cylinder\", \"circle\", \"light\", \"sphere\", \"d…\n$ encounter_length           &lt;dbl&gt; 2700, 20, 900, 300, 1200, 180, 120, 300, 18…\n$ described_encounter_length &lt;chr&gt; \"45 minutes\", \"1/2 hour\", \"15 minutes\", \"5 …\n$ description                &lt;chr&gt; \"This event took place in early fall around…\n$ date_documented            &lt;chr&gt; \"4/27/2004\", \"1/17/2004\", \"1/22/2004\", \"4/2…\n$ latitude                   &lt;dbl&gt; 29.88306, 28.97833, 21.41806, 36.59500, 41.…\n$ longitude                  &lt;dbl&gt; -97.94111, -96.64583, -157.80361, -82.18889…\n\n\n\nsummary(ufo_sightings_withoutNA)\n\n  date_time          city_area            state             country         \n Length:66516       Length:66516       Length:66516       Length:66516      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  ufo_shape         encounter_length   described_encounter_length\n Length:66516       Min.   :       0   Length:66516              \n Class :character   1st Qu.:      30   Class :character          \n Mode  :character   Median :     180   Mode  :character          \n                    Mean   :    6573                             \n                    3rd Qu.:     600                             \n                    Max.   :82800000                             \n description        date_documented       latitude        longitude      \n Length:66516       Length:66516       Min.   :-37.81   Min.   :-176.66  \n Class :character   Class :character   1st Qu.: 34.20   1st Qu.:-114.18  \n Mode  :character   Mode  :character   Median : 39.25   Median : -89.60  \n                                       Mean   : 38.71   Mean   : -95.29  \n                                       3rd Qu.: 42.34   3rd Qu.: -80.40  \n                                       Max.   : 72.70   Max.   : 153.10"
  },
  {
    "objectID": "posts/UFO/UFO.html#setting-up-r-packages",
    "href": "posts/UFO/UFO.html#setting-up-r-packages",
    "title": "UFO Dataset",
    "section": "",
    "text": "library(tidyverse) \n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic) \n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula) \nlibrary(skimr) \n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(janitor) \n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(naniar) \n\n\nAttaching package: 'naniar'\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\nlibrary(visdat) \nlibrary(tinytable) \n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(DT) \nlibrary(crosstable) \n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(RColorBrewer)\nlibrary(naniar)\nlibrary(tidyr)\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/UFO/UFO.html#read-data",
    "href": "posts/UFO/UFO.html#read-data",
    "title": "UFO Dataset",
    "section": "",
    "text": "ufo_sightings &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2019/2019-06-25/ufo_sightings.csv\") %&gt;% \n  janitor::clean_names(case = \"snake\")\n\nRows: 80332 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): date_time, city_area, state, country, ufo_shape, described_encounte...\ndbl (3): encounter_length, latitude, longitude\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "posts/UFO/UFO.html#data-dictionary",
    "href": "posts/UFO/UFO.html#data-dictionary",
    "title": "UFO Dataset",
    "section": "",
    "text": "Variable\nDescription\n\n\n\n\ndate_time\nDate time sighting occurred\n\n\ncity_area\nCity or area of sighting\n\n\nstate\nstate/region of sighting\n\n\ncountry\nCountry of sighting\n\n\nufo_shape\nUFO Shape\n\n\nencounter_length\nEncounter length in seconds\n\n\ndescribed_encounter_length\nEncounter length as described (eg 1 hour, etc\n\n\ndescription\nDescription of encounter\n\n\ndate_documented\nDate documented\n\n\nlatitude\nLatitude\n\n\nlongitude\nLongitude"
  },
  {
    "objectID": "posts/UFO/UFO.html#examine-data",
    "href": "posts/UFO/UFO.html#examine-data",
    "title": "UFO Dataset",
    "section": "",
    "text": "base::names(ufo_sightings)\n\n [1] \"date_time\"                  \"city_area\"                 \n [3] \"state\"                      \"country\"                   \n [5] \"ufo_shape\"                  \"encounter_length\"          \n [7] \"described_encounter_length\" \"description\"               \n [9] \"date_documented\"            \"latitude\"                  \n[11] \"longitude\"                 \n\n\n\ndplyr::glimpse(ufo_sightings)\n\nRows: 80,332\nColumns: 11\n$ date_time                  &lt;chr&gt; \"10/10/1949 20:30\", \"10/10/1949 21:00\", \"10…\n$ city_area                  &lt;chr&gt; \"san marcos\", \"lackland afb\", \"chester (uk/…\n$ state                      &lt;chr&gt; \"tx\", \"tx\", NA, \"tx\", \"hi\", \"tn\", NA, \"ct\",…\n$ country                    &lt;chr&gt; \"us\", NA, \"gb\", \"us\", \"us\", \"us\", \"gb\", \"us…\n$ ufo_shape                  &lt;chr&gt; \"cylinder\", \"light\", \"circle\", \"circle\", \"l…\n$ encounter_length           &lt;dbl&gt; 2700, 7200, 20, 20, 900, 300, 180, 1200, 18…\n$ described_encounter_length &lt;chr&gt; \"45 minutes\", \"1-2 hrs\", \"20 seconds\", \"1/2…\n$ description                &lt;chr&gt; \"This event took place in early fall around…\n$ date_documented            &lt;chr&gt; \"4/27/2004\", \"12/16/2005\", \"1/21/2008\", \"1/…\n$ latitude                   &lt;dbl&gt; 29.88306, 29.38421, 53.20000, 28.97833, 21.…\n$ longitude                  &lt;dbl&gt; -97.941111, -98.581082, -2.916667, -96.6458…\n\n\n\nbase::dim(ufo_sightings)\n\n[1] 80332    11\n\n\n\nutils::str(ufo_sightings)\n\nspc_tbl_ [80,332 × 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ date_time                 : chr [1:80332] \"10/10/1949 20:30\" \"10/10/1949 21:00\" \"10/10/1955 17:00\" \"10/10/1956 21:00\" ...\n $ city_area                 : chr [1:80332] \"san marcos\" \"lackland afb\" \"chester (uk/england)\" \"edna\" ...\n $ state                     : chr [1:80332] \"tx\" \"tx\" NA \"tx\" ...\n $ country                   : chr [1:80332] \"us\" NA \"gb\" \"us\" ...\n $ ufo_shape                 : chr [1:80332] \"cylinder\" \"light\" \"circle\" \"circle\" ...\n $ encounter_length          : num [1:80332] 2700 7200 20 20 900 300 180 1200 180 120 ...\n $ described_encounter_length: chr [1:80332] \"45 minutes\" \"1-2 hrs\" \"20 seconds\" \"1/2 hour\" ...\n $ description               : chr [1:80332] \"This event took place in early fall around 1949-50. It occurred after a Boy Scout meeting in the Baptist Church\"| __truncated__ \"1949 Lackland AFB&#44 TX.  Lights racing across the sky &amp; making 90 degree turns on a dime.\" \"Green/Orange circular disc over Chester&#44 England\" \"My older brother and twin sister were leaving the only Edna theater at about 9 PM&#44...we had our bikes and I \"| __truncated__ ...\n $ date_documented           : chr [1:80332] \"4/27/2004\" \"12/16/2005\" \"1/21/2008\" \"1/17/2004\" ...\n $ latitude                  : num [1:80332] 29.9 29.4 53.2 29 21.4 ...\n $ longitude                 : num [1:80332] -97.94 -98.58 -2.92 -96.65 -157.8 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   date_time = col_character(),\n  ..   city_area = col_character(),\n  ..   state = col_character(),\n  ..   country = col_character(),\n  ..   ufo_shape = col_character(),\n  ..   encounter_length = col_double(),\n  ..   described_encounter_length = col_character(),\n  ..   description = col_character(),\n  ..   date_documented = col_character(),\n  ..   latitude = col_double(),\n  ..   longitude = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "posts/UFO/UFO.html#viewing-missing-data",
    "href": "posts/UFO/UFO.html#viewing-missing-data",
    "title": "UFO Dataset",
    "section": "",
    "text": "visdat::vis_dat(ufo_sightings)\n\n\n\n\n\n\n\n\n\nvisdat::vis_miss(ufo_sightings)"
  },
  {
    "objectID": "posts/UFO/UFO.html#removing-missing-data",
    "href": "posts/UFO/UFO.html#removing-missing-data",
    "title": "UFO Dataset",
    "section": "",
    "text": "ufo_sightings_withoutNA &lt;- ufo_sightings %&gt;% drop_na()\nglimpse(ufo_sightings_withoutNA)\n\nRows: 66,516\nColumns: 11\n$ date_time                  &lt;chr&gt; \"10/10/1949 20:30\", \"10/10/1956 21:00\", \"10…\n$ city_area                  &lt;chr&gt; \"san marcos\", \"edna\", \"kaneohe\", \"bristol\",…\n$ state                      &lt;chr&gt; \"tx\", \"tx\", \"hi\", \"tn\", \"ct\", \"al\", \"fl\", \"…\n$ country                    &lt;chr&gt; \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"…\n$ ufo_shape                  &lt;chr&gt; \"cylinder\", \"circle\", \"light\", \"sphere\", \"d…\n$ encounter_length           &lt;dbl&gt; 2700, 20, 900, 300, 1200, 180, 120, 300, 18…\n$ described_encounter_length &lt;chr&gt; \"45 minutes\", \"1/2 hour\", \"15 minutes\", \"5 …\n$ description                &lt;chr&gt; \"This event took place in early fall around…\n$ date_documented            &lt;chr&gt; \"4/27/2004\", \"1/17/2004\", \"1/22/2004\", \"4/2…\n$ latitude                   &lt;dbl&gt; 29.88306, 28.97833, 21.41806, 36.59500, 41.…\n$ longitude                  &lt;dbl&gt; -97.94111, -96.64583, -157.80361, -82.18889…\n\n\n\nsummary(ufo_sightings_withoutNA)\n\n  date_time          city_area            state             country         \n Length:66516       Length:66516       Length:66516       Length:66516      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  ufo_shape         encounter_length   described_encounter_length\n Length:66516       Min.   :       0   Length:66516              \n Class :character   1st Qu.:      30   Class :character          \n Mode  :character   Median :     180   Mode  :character          \n                    Mean   :    6573                             \n                    3rd Qu.:     600                             \n                    Max.   :82800000                             \n description        date_documented       latitude        longitude      \n Length:66516       Length:66516       Min.   :-37.81   Min.   :-176.66  \n Class :character   Class :character   1st Qu.: 34.20   1st Qu.:-114.18  \n Mode  :character   Mode  :character   Median : 39.25   Median : -89.60  \n                                       Mean   : 38.71   Mean   : -95.29  \n                                       3rd Qu.: 42.34   3rd Qu.: -80.40  \n                                       Max.   : 72.70   Max.   : 153.10"
  },
  {
    "objectID": "posts/UFO/UFO.html#removing-column-described_encounter_length",
    "href": "posts/UFO/UFO.html#removing-column-described_encounter_length",
    "title": "UFO Dataset",
    "section": "Removing column described_encounter_length",
    "text": "Removing column described_encounter_length\n\nufo_sightings_new &lt;- ufo_sightings_withoutNA %&gt;%\n  select(-described_encounter_length)\n\nglimpse(ufo_sightings_new)\n\nRows: 66,516\nColumns: 10\n$ date_time        &lt;chr&gt; \"10/10/1949 20:30\", \"10/10/1956 21:00\", \"10/10/1960 2…\n$ city_area        &lt;chr&gt; \"san marcos\", \"edna\", \"kaneohe\", \"bristol\", \"norwalk\"…\n$ state            &lt;chr&gt; \"tx\", \"tx\", \"hi\", \"tn\", \"ct\", \"al\", \"fl\", \"ca\", \"nc\",…\n$ country          &lt;chr&gt; \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\",…\n$ ufo_shape        &lt;chr&gt; \"cylinder\", \"circle\", \"light\", \"sphere\", \"disk\", \"dis…\n$ encounter_length &lt;dbl&gt; 2700, 20, 900, 300, 1200, 180, 120, 300, 180, 1800, 1…\n$ description      &lt;chr&gt; \"This event took place in early fall around 1949-50. …\n$ date_documented  &lt;chr&gt; \"4/27/2004\", \"1/17/2004\", \"1/22/2004\", \"4/27/2007\", \"…\n$ latitude         &lt;dbl&gt; 29.88306, 28.97833, 21.41806, 36.59500, 41.11750, 33.…\n$ longitude        &lt;dbl&gt; -97.94111, -96.64583, -157.80361, -82.18889, -73.4083…"
  },
  {
    "objectID": "posts/UFO/UFO.html#visualising-data",
    "href": "posts/UFO/UFO.html#visualising-data",
    "title": "UFO Dataset",
    "section": "Visualising Data",
    "text": "Visualising Data\n\n1. UFO Sightings throughout the years (date)\nLooking at ufo sightings found on the same date.\n\nufo_sightings_repeated &lt;- ufo_sightings_new %&gt;%\n  group_by(date_documented) %&gt;%       \n  summarise(count = n()) %&gt;%          \n  filter(count &gt; 1)  \n\nglimpse(ufo_sightings_repeated)\n\nRows: 314\nColumns: 2\n$ date_documented &lt;chr&gt; \"1/10/2009\", \"1/10/2014\", \"1/11/2002\", \"1/11/2005\", \"1…\n$ count           &lt;int&gt; 878, 513, 230, 127, 465, 133, 340, 138, 351, 98, 74, 1…\n\n\nThe above piece of code tells us that there are 314 unique dates where data was documented - dataset that had at least one sighting.\nSince the there will be countless data stored in each date, we plotted a graph where x as a timeline with the range of the first date data was collected and the latest and the y-axis with a count function inbuilt in ggformula.\n\nufo_sightings_new %&gt;%\n  count(date_documented, name = \"count\") %&gt;%\n  mutate(date_documented = mdy(date_documented)) %&gt;%\n  gf_line(count ~ date_documented)\n\n\n\n\n\n\n\n\nSeeing this graph we can see a stark differences around 2010, there is a high point and low point and its very erratic. Lets isolate the high and low points of the graph alone.\n\nufo_sightings_new%&gt;%\n  count(date_documented, name = \"count\") %&gt;%\n  mutate(date_documented = mdy(date_documented)) %&gt;%\n  gf_point(count ~ date_documented,\n           color = \"red\", size = 1.5) %&gt;%\n  gf_labs(\n    title = \"Reported UFO Sightings per Date\",\n    x = \"Date\",\n    y = \"Number of Sightings\"\n  )\n\n\n\n\n\n\n\n\nThis tells us that the data with lesser number of sightings is significantly more than data with higher number of sightings which makes intuitive sense. Lets make this more useful by making a gradient within the graph. Lowest - blue and highest - red\n\nlibrary(RColorBrewer)\n\nufo_sightings_new %&gt;%\n  count(date_documented, name = \"count\") %&gt;%\n  mutate(date_documented = mdy(date_documented)) %&gt;%\n  gf_point(count ~ date_documented, color = ~count, size = 1.5) %&gt;%\n  gf_refine(scale_color_gradient(low = \"blue\", high = \"red\")) %&gt;%\n  gf_labs(\n    title = \"Reported UFO Sightings per Date\",\n    x = \"Date\",\n    y = \"Number of Sightings\",\n    color = \"Sightings Count\"\n  )\n\n\n\n\n\n\n\n\nVisualising the graph with red points and the line graph:\n\nufo_sightings_new %&gt;%\n  mutate(date_documented = mdy(date_documented)) %&gt;%\n  group_by(date_documented) %&gt;%\n  summarise(count = n()) %&gt;%\n  gf_line(count ~ date_documented) %&gt;%\n  gf_point(color = \"red\", size = 1) %&gt;%\n  gf_labs(\n    title = \"Reported UFO Sightings Over Time\",\n    x = \"Date\",\n    y = \"Number of Sightings\"\n  )\n\n\n\n\n\n\n\n\nThe graph looks very congested so faceting it would give more precise graphs. Lets facet it into 8 different segments.\n\nufo_sightings_new %&gt;%\n  mutate(date_documented = mdy(date_documented),\n         segment = ntile(date_documented, 8)) %&gt;%\n  group_by(date_documented, segment) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  gf_line(count ~ date_documented) %&gt;%\n  gf_point(color = \"red\", size = 1) %&gt;%\n  gf_facet_wrap(~segment, scales = \"free_x\") %&gt;%\n  gf_labs(\n    title = \"Reported UFO Sightings Over Time\",\n    x = \"Date\",\n    y = \"Number of Sightings\"\n  )\n\n\n\n\n\n\n\n\nIt would be nice to see the highest and lowest point throughout the years. Lets try doing that:\n\nufo_highest_lowest &lt;-ufo_sightings_new %&gt;%\n  mutate(date_documented = mdy(date_documented)) %&gt;%\n  group_by(date_documented) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  summarise(\n    lowest_count = min(count),\n    lowest_date  = date_documented[which.min(count)],\n    highest_count = max(count),\n    highest_date  = date_documented[which.max(count)]\n  )\n\nglimpse(ufo_highest_lowest)\n\nRows: 1\nColumns: 4\n$ lowest_count  &lt;int&gt; 1\n$ lowest_date   &lt;date&gt; 2002-03-25\n$ highest_count &lt;int&gt; 1268\n$ highest_date  &lt;date&gt; 2009-12-12\n\n\nThe lowest count of 1 during 2002 makes me think whether there are other data with a count of 1, but during a different year making both equally competent dates for the lowest range.\n\nufo_sightings_new %&gt;%\n  mutate(date_documented = mdy(date_documented)) %&gt;%\n  group_by(date_documented) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  filter(count == min(count))\n\n# A tibble: 2 × 2\n  date_documented count\n  &lt;date&gt;          &lt;int&gt;\n1 2002-03-25          1\n2 2003-01-20          1\n\n\nIt turns out there are two dates - but the reason for 2002 showing up first is because it was parsed properly before hand itself.\nThis graph is plotted using the whole date - to make a bar graph or histogram we need to extract the year from the date. We will store this view format of viewing data as ufo_sightings_new1\n\nufo_sightings_new1 &lt;- ufo_sightings_new %&gt;%\n  mutate(\n    date_time_parsed = mdy_hm(date_time),\n    date_only = as.Date(date_time_parsed),\n    time_only = format(date_time_parsed, \"%H:%M\"),\n    year = year(date_time_parsed)\n  )\nglimpse(ufo_sightings_new1)\n\nRows: 66,516\nColumns: 14\n$ date_time        &lt;chr&gt; \"10/10/1949 20:30\", \"10/10/1956 21:00\", \"10/10/1960 2…\n$ city_area        &lt;chr&gt; \"san marcos\", \"edna\", \"kaneohe\", \"bristol\", \"norwalk\"…\n$ state            &lt;chr&gt; \"tx\", \"tx\", \"hi\", \"tn\", \"ct\", \"al\", \"fl\", \"ca\", \"nc\",…\n$ country          &lt;chr&gt; \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\",…\n$ ufo_shape        &lt;chr&gt; \"cylinder\", \"circle\", \"light\", \"sphere\", \"disk\", \"dis…\n$ encounter_length &lt;dbl&gt; 2700, 20, 900, 300, 1200, 180, 120, 300, 180, 1800, 1…\n$ description      &lt;chr&gt; \"This event took place in early fall around 1949-50. …\n$ date_documented  &lt;chr&gt; \"4/27/2004\", \"1/17/2004\", \"1/22/2004\", \"4/27/2007\", \"…\n$ latitude         &lt;dbl&gt; 29.88306, 28.97833, 21.41806, 36.59500, 41.11750, 33.…\n$ longitude        &lt;dbl&gt; -97.94111, -96.64583, -157.80361, -82.18889, -73.4083…\n$ date_time_parsed &lt;dttm&gt; 1949-10-10 20:30:00, 1956-10-10 21:00:00, 1960-10-10…\n$ date_only        &lt;date&gt; 1949-10-10, 1956-10-10, 1960-10-10, 1961-10-10, 1965…\n$ time_only        &lt;chr&gt; \"20:30\", \"21:00\", \"20:00\", \"19:00\", \"23:45\", \"20:00\",…\n$ year             &lt;dbl&gt; 1949, 1956, 1960, 1961, 1965, 1966, 1966, 1968, 1968,…\n\n\nLets parse the date_time and also seperate date and time - which might be useful to look at separately, and store them into ufo_sightings_new1\n\nufo_sightings_new1 &lt;- ufo_sightings_withoutNA %&gt;%\n  mutate(\n    date_time_parsed = mdy_hm(date_time),\n    date_only = as.Date(date_time_parsed),\n    time_only = format(date_time_parsed, \"%H:%M\"),\n    year = year(date_time_parsed)\n  )\n\nglimpse(ufo_sightings_new1)\n\nRows: 66,516\nColumns: 15\n$ date_time                  &lt;chr&gt; \"10/10/1949 20:30\", \"10/10/1956 21:00\", \"10…\n$ city_area                  &lt;chr&gt; \"san marcos\", \"edna\", \"kaneohe\", \"bristol\",…\n$ state                      &lt;chr&gt; \"tx\", \"tx\", \"hi\", \"tn\", \"ct\", \"al\", \"fl\", \"…\n$ country                    &lt;chr&gt; \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"…\n$ ufo_shape                  &lt;chr&gt; \"cylinder\", \"circle\", \"light\", \"sphere\", \"d…\n$ encounter_length           &lt;dbl&gt; 2700, 20, 900, 300, 1200, 180, 120, 300, 18…\n$ described_encounter_length &lt;chr&gt; \"45 minutes\", \"1/2 hour\", \"15 minutes\", \"5 …\n$ description                &lt;chr&gt; \"This event took place in early fall around…\n$ date_documented            &lt;chr&gt; \"4/27/2004\", \"1/17/2004\", \"1/22/2004\", \"4/2…\n$ latitude                   &lt;dbl&gt; 29.88306, 28.97833, 21.41806, 36.59500, 41.…\n$ longitude                  &lt;dbl&gt; -97.94111, -96.64583, -157.80361, -82.18889…\n$ date_time_parsed           &lt;dttm&gt; 1949-10-10 20:30:00, 1956-10-10 21:00:00, …\n$ date_only                  &lt;date&gt; 1949-10-10, 1956-10-10, 1960-10-10, 1961-1…\n$ time_only                  &lt;chr&gt; \"20:30\", \"21:00\", \"20:00\", \"19:00\", \"23:45\"…\n$ year                       &lt;dbl&gt; 1949, 1956, 1960, 1961, 1965, 1966, 1966, 1…\n\n\n\n\n2. UFO Shape count accross timeline\nFaceting the UFO shapes and plotting their counts over time.\n\nsightings_per_year &lt;- ufo_sightings_new1 %&gt;%\n  group_by(year, ufo_shape) %&gt;%\n  summarise(count = n(), .groups = \"drop\")\n\ngf_line(count ~ year, data = sightings_per_year, color = ~ufo_shape) %&gt;%\n  gf_facet_wrap(~ufo_shape)\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n\n\n\nThis tells us that the pyramid, hexagon and changed ufo_shapes have almost no data. But there should exist atleast one data for it to be part of ufo_shape - so lets see how many is its count.\n\nufo_sightings_new %&gt;%\n  filter(ufo_shape %in% c(\"pyramid\", \"hexagon\", \"changed\")) %&gt;%\n  count(ufo_shape)\n\n# A tibble: 3 × 2\n  ufo_shape     n\n  &lt;chr&gt;     &lt;int&gt;\n1 changed       1\n2 hexagon       1\n3 pyramid       1\n\n\nJust like predicted there is only 1 data in these ufo shape categories.\n\n\n3. UFO Shape count accross location\nWe created a cartograph — plotting each sighting by country to make a visual map of where the UFO sightings occurred.\n\ngf_point(latitude ~ longitude, data = ufo_sightings_new1, color = ~ufo_shape, size = ~encounter_length) %&gt;%\n  gf_labs(\n    x = \"Longitude\",\n    y = \"Latitude\",\n    color = \"UFO Shape\",\n    size = \"Encounter Length\",\n    title = \"UFO Sightings by Location\"\n  )\n\n\n\n\n\n\n\n\nThe cartograph shows an overview of the sighting locations and UFO shapes. We can see that U.S. is highlighted prominently.\nNext, the data can be plotted by longitude and latitude while keeping the faceting by UFO shape, to check for possible patterns.\n\ngf_point(latitude ~ longitude, data = ufo_sightings_new1, color = ~ufo_shape) %&gt;%\n  gf_facet_wrap(~ufo_shape) %&gt;%\n  gf_labs(\n    x = \"Longitude\",\n    y = \"Latitude\",\n    color = \"UFO Shape\",\n    title = \"UFO Sightings by Shape\"\n  )\n\n\n\n\n\n\n\n\nThis plot shows the geographic distribution of UFO sightings by shape, helping us see where each type is reported.\nFaceting by shape highlights patterns or rare sightings that might be hidden in the overall dataset.\n\n\nEncounter Length vs Latitude based on UFO shape\nVisualising encounter length instead of Latitude - just to check for interesting patterns.\n\nufo_sightings_new %&gt;%\n  filter(!is.na(ufo_shape)) %&gt;%\n  slice_sample(n = 150) %&gt;%\n  gf_point(encounter_length ~ latitude | ufo_shape,\n           colour = ~ufo_shape,\n           size = 2) %&gt;%\n  gf_labs(\n    title  = \"UFO Sightings Sample\",\n    x      = \"Latitude\",\n    y      = \"Encounter Length\",\n    colour = \"UFO Shape\"\n  )\n\n\n\n\n\n\n\n\nThis plot visualizes a random sample of UFO sightings, showing how encounter lengths vary with latitude for different shapes.\nFaceting by shape and coloring points highlights differences and patterns across UFO types in the sample.\n\n\n4. Reported UFO Sightings by Day\nIt would be interesting to check whether UFO sightings are more common on certain days of the week. A bar graph can help visualize this.\n\nufo_sightings_new %&gt;%\n  count(weekday = wday(mdy_hm(date_time), label = TRUE)) %&gt;%\n  gf_col(n ~ weekday, fill = \"orange\") %&gt;%\n  gf_labs(title = \"Reported UFO Sightings by Day\", x = \"Day\", y = \"No of Reported Sightings\")\n\n\n\n\n\n\n\n\nSaturday has the most number of UFO sightings reported but it isn’t exorbitantly high - but lets see a numeric representation for better understanding\n\nufo_sightings_byweek &lt;- ufo_sightings_new1 %&gt;%\n  mutate(weekday = wday(mdy_hm(date_time), label = TRUE)) %&gt;%\n  count(weekday) %&gt;%\n  arrange(match(weekday, c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\")))\n\nufo_sightings_byweek\n\n# A tibble: 7 × 2\n  weekday     n\n  &lt;ord&gt;   &lt;int&gt;\n1 Sun      9625\n2 Mon      8340\n3 Tue      8954\n4 Wed      9130\n5 Thu      9162\n6 Fri      9641\n7 Sat     11664\n\n\n\n\n5. Reported UFO Sightings by Hours\nLets try doing the same but instead of days of week - we will try hours of week\n\nufo_sightings_new %&gt;%\n  count(hour = hour(mdy_hm(date_time))) %&gt;%\n  gf_col(n ~ hour, fill = \"skyblue\") %&gt;%\n  gf_labs(title = \"Reported UFO Sightings by Hour\", x = \"Hour\", y = \"No of Reported Sightings\")\n\n\n\n\n\n\n\n\n\n\n6. UFO Sightings by US States\nSince US is the biggest factor in ufo sightings - lets take each of US state and view its counts\n\nus_sightings &lt;- ufo_sightings_new1 %&gt;%\n  filter(country == \"us\") %&gt;%\n  count(state, sort = TRUE)\nglimpse(us_sightings)\n\nRows: 52\nColumns: 2\n$ state &lt;chr&gt; \"ca\", \"fl\", \"wa\", \"tx\", \"ny\", \"il\", \"az\", \"pa\", \"oh\", \"mi\", \"nc\"…\n$ n     &lt;int&gt; 8683, 3754, 3707, 3398, 2915, 2447, 2362, 2319, 2251, 1781, 1722…\n\n\nVisualising this into bar graphs\n\nus_sightings %&gt;%\n  gf_col(n ~ state, fill = ~state) %&gt;%\n  gf_labs(\n    title = \"UFO Sightings by US State\",\n    x = \"State\",\n    y = \"No of Reported Sightings\",\n    fill = \"State\"\n  ) \n\n\n\n\n\n\n\n\nThe states since they aren’t abbreviated are very congested but the state coded California has a exorbidantly high number of reportings - lets find its value\n\nus_sightings %&gt;%\n  filter(state == \"ca\") %&gt;%\n  select(state, n)\n\n# A tibble: 1 × 2\n  state     n\n  &lt;chr&gt; &lt;int&gt;\n1 ca     8683\n\n\nCalifornia has 8683 ufo sightings which we can see is pretty high compared to the rest of the states but lets find the mean, median and mode to get an accurate understanding\n\nx &lt;- us_sightings$n\n\nsummary_table &lt;- tibble(\n  Statistic = c(\"Mean\", \"Median\", \"Mode\"),\n  Value = c(mean(x), median(x), as.numeric(names(sort(table(x), decreasing = TRUE)[1])))\n)\n\nsummary_table\n\n# A tibble: 3 × 2\n  Statistic Value\n  &lt;chr&gt;     &lt;dbl&gt;\n1 Mean      1222.\n2 Median     798 \n3 Mode         7 \n\n\nThe UFO sightings in CA is extremely high compared to all three mean, median and mode. So we can assume there is high delusion and hallucination rates in the state of California of the US."
  },
  {
    "objectID": "posts/Fertility/Fertility.html",
    "href": "posts/Fertility/Fertility.html",
    "title": "Fertility Dataset",
    "section": "",
    "text": "Exploring and Analysing patterns of a dataset about fertility, demographics and weeks worked in 1979.\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(dplyr)\nlibrary(naniar)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:naniar':\n\n    n_complete\n\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(tinytable)\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(ggformula)\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\nThe following object is masked from 'package:skimr':\n\n    n_missing\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\n\n\n\n\n\nFertility &lt;- readr::read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Fertility.csv\") %&gt;% \njanitor::clean_names(case=\"snake\")\n\nRows: 254654 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): morekids, gender1, gender2, afam, hispanic, other\ndbl (3): rownames, age, work\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nFertility\n\n# A tibble: 254,654 × 9\n   rownames morekids gender1 gender2   age afam  hispanic other  work\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;\n 1        1 no       male    female     27 no    no       no        0\n 2        2 no       female  male       30 no    no       no       30\n 3        3 no       male    female     27 no    no       no        0\n 4        4 no       male    female     35 yes   no       no        0\n 5        5 no       female  female     30 no    no       no       22\n 6        6 no       male    female     26 no    no       no       40\n 7        7 no       female  male       29 no    no       no        0\n 8        8 no       male    male       33 no    no       no       52\n 9        9 no       female  male       29 no    no       no        0\n10       10 no       male    female     27 no    no       no        0\n# ℹ 254,644 more rows\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nMorekids\nDoes the mother have more than 2 children?\n\n\nGender1\nFactor indicating gender of first child\n\n\nGender2\nFactor indicating gender of second child.\n\n\nAge\nAge of mother at census.\n\n\nAfam factor\nIs the mother African-American?\n\n\nHispanic factor\nIs the mother Hispanic?\n\n\nOther factor\nIs the mother’s ethnicity neither African-American nor Hispanic, nor Caucasian?\n\n\nWork\nNumber of weeks in which the mother worked in 1979.\n\n\n\n\n\n\n\nbase::names(Fertility)\n\n[1] \"rownames\" \"morekids\" \"gender1\"  \"gender2\"  \"age\"      \"afam\"     \"hispanic\"\n[8] \"other\"    \"work\"    \n\n\n\ndplyr::glimpse(Fertility)\n\nRows: 254,654\nColumns: 9\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ morekids &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ gender1  &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"female\",…\n$ gender2  &lt;chr&gt; \"female\", \"male\", \"female\", \"female\", \"female\", \"female\", \"ma…\n$ age      &lt;dbl&gt; 27, 30, 27, 35, 30, 26, 29, 33, 29, 27, 28, 28, 35, 34, 32, 2…\n$ afam     &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ hispanic &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ other    &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ work     &lt;dbl&gt; 0, 30, 0, 0, 22, 40, 0, 52, 0, 0, 0, 52, 52, 52, 8, 7, 0, 40,…\n\n\n\nbase::dim(Fertility)\n\n[1] 254654      9\n\n\n\nutils::str(Fertility)\n\nspc_tbl_ [254,654 × 9] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ rownames: num [1:254654] 1 2 3 4 5 6 7 8 9 10 ...\n $ morekids: chr [1:254654] \"no\" \"no\" \"no\" \"no\" ...\n $ gender1 : chr [1:254654] \"male\" \"female\" \"male\" \"male\" ...\n $ gender2 : chr [1:254654] \"female\" \"male\" \"female\" \"female\" ...\n $ age     : num [1:254654] 27 30 27 35 30 26 29 33 29 27 ...\n $ afam    : chr [1:254654] \"no\" \"no\" \"no\" \"yes\" ...\n $ hispanic: chr [1:254654] \"no\" \"no\" \"no\" \"no\" ...\n $ other   : chr [1:254654] \"no\" \"no\" \"no\" \"no\" ...\n $ work    : num [1:254654] 0 30 0 0 22 40 0 52 0 0 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   rownames = col_double(),\n  ..   morekids = col_character(),\n  ..   gender1 = col_character(),\n  ..   gender2 = col_character(),\n  ..   age = col_double(),\n  ..   afam = col_character(),\n  ..   hispanic = col_character(),\n  ..   other = col_character(),\n  ..   work = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\n\nViewing missing data was not working for the whole data set, so we used slice sample of 100000. The data set did not have any missing data.\n\nFertility_sample &lt;- Fertility %&gt;% dplyr::slice_sample(n = 100000) \nvisdat::vis_dat(Fertility_sample)\n\n\n\n\n\n\n\n\n\nvisdat::vis_miss(Fertility_sample)\n\n\n\n\n\n\n\n\n\n\n\nWe created a new column for ethnicity since the data set did not directly indicate whether a person was Caucasian. Based on the data dictionary, all “no” responses were Caucasian. To make the data easier to understand, we added a column to clearly show the ethnicity of a person.\n\nFertility %&gt;% filter(afam == \"no\", hispanic == \"no\", other == \"no\")\n\n# A tibble: 216,033 × 9\n   rownames morekids gender1 gender2   age afam  hispanic other  work\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;\n 1        1 no       male    female     27 no    no       no        0\n 2        2 no       female  male       30 no    no       no       30\n 3        3 no       male    female     27 no    no       no        0\n 4        5 no       female  female     30 no    no       no       22\n 5        6 no       male    female     26 no    no       no       40\n 6        7 no       female  male       29 no    no       no        0\n 7        8 no       male    male       33 no    no       no       52\n 8        9 no       female  male       29 no    no       no        0\n 9       10 no       male    female     27 no    no       no        0\n10       11 yes      male    male       28 no    no       no        0\n# ℹ 216,023 more rows\n\n\n\nFertility_ethnicity &lt;- Fertility %&gt;%\n  mutate(ethnicity = case_when(\n    afam == \"yes\" & hispanic == \"no\" & other == \"no\" ~ \"Afam\",\n    afam == \"no\" & hispanic == \"yes\" & other == \"no\" ~ \"Hispanic\",\n    afam == \"no\" & hispanic == \"no\" & other == \"yes\" ~ \"Other\",\n    afam == \"no\" & hispanic == \"no\" & other == \"no\" ~ \"Caucasian\",\n    afam == \"yes\" & hispanic == \"yes\" & other == \"no\" ~ \"AfamHispanic\",\n    afam == \"yes\" & hispanic == \"no\" & other == \"yes\" ~ \"AfamOther\",\n    afam == \"no\" & hispanic == \"yes\" & other == \"yes\" ~ \"HispanicOther\"\n  ))\n  \nFertility_ethnicity\n\n# A tibble: 254,654 × 10\n   rownames morekids gender1 gender2   age afam  hispanic other  work ethnicity\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    \n 1        1 no       male    female     27 no    no       no        0 Caucasian\n 2        2 no       female  male       30 no    no       no       30 Caucasian\n 3        3 no       male    female     27 no    no       no        0 Caucasian\n 4        4 no       male    female     35 yes   no       no        0 Afam     \n 5        5 no       female  female     30 no    no       no       22 Caucasian\n 6        6 no       male    female     26 no    no       no       40 Caucasian\n 7        7 no       female  male       29 no    no       no        0 Caucasian\n 8        8 no       male    male       33 no    no       no       52 Caucasian\n 9        9 no       female  male       29 no    no       no        0 Caucasian\n10       10 no       male    female     27 no    no       no        0 Caucasian\n# ℹ 254,644 more rows\n\n\n\n\n\n\nFertility_ethnicity_factor &lt;- Fertility_ethnicity %&gt;%\n  mutate(across(where(is.character), as.factor)) %&gt;% \n  relocate(where(is.factor), .after = rownames)\nglimpse(Fertility_ethnicity_factor)\n\nRows: 254,654\nColumns: 10\n$ rownames  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ morekids  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, yes, no, no, no, no,…\n$ gender1   &lt;fct&gt; male, female, male, male, female, male, female, male, female…\n$ gender2   &lt;fct&gt; female, male, female, female, female, female, male, male, ma…\n$ afam      &lt;fct&gt; no, no, no, yes, no, no, no, no, no, no, no, no, no, no, no,…\n$ hispanic  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ other     &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ ethnicity &lt;fct&gt; Caucasian, Caucasian, Caucasian, Afam, Caucasian, Caucasian,…\n$ age       &lt;dbl&gt; 27, 30, 27, 35, 30, 26, 29, 33, 29, 27, 28, 28, 35, 34, 32, …\n$ work      &lt;dbl&gt; 0, 30, 0, 0, 22, 40, 0, 52, 0, 0, 0, 52, 52, 52, 8, 7, 0, 40…\n\n\n\n\n\n\nFertility_ethnicity_factor\n\n# A tibble: 254,654 × 10\n   rownames morekids gender1 gender2 afam  hispanic other ethnicity   age  work\n      &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;   &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1        1 no       male    female  no    no       no    Caucasian    27     0\n 2        2 no       female  male    no    no       no    Caucasian    30    30\n 3        3 no       male    female  no    no       no    Caucasian    27     0\n 4        4 no       male    female  yes   no       no    Afam         35     0\n 5        5 no       female  female  no    no       no    Caucasian    30    22\n 6        6 no       male    female  no    no       no    Caucasian    26    40\n 7        7 no       female  male    no    no       no    Caucasian    29     0\n 8        8 no       male    male    no    no       no    Caucasian    33    52\n 9        9 no       female  male    no    no       no    Caucasian    29     0\n10       10 no       male    female  no    no       no    Caucasian    27     0\n# ℹ 254,644 more rows\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  dplyr::count(across(.cols = c (gender1 , gender2)))\n\n# A tibble: 4 × 3\n  gender1 gender2     n\n  &lt;fct&gt;   &lt;fct&gt;   &lt;int&gt;\n1 female  female  60946\n2 female  male    62724\n3 male    female  63185\n4 male    male    67799\n\n\n\nFertility_ethnicity_factor %&gt;% \n  group_by(morekids) %&gt;% \n  summarise(average_age=mean(age),count=n()) %&gt;% tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                morekids\n                average_age\n                count\n              \n        \n        \n        \n                \n                  no\n                  30.12810\n                  157742\n                \n                \n                  yes\n                  30.82487\n                  96912\n                \n        \n      \n    \n\n\n\n\ncrosstable(morekids ~ gender2 + gender1,\n  data = Fertility_ethnicity_factor\n) %&gt;%\n  crosstable::as_flextable()\n\ngender1femalemalegender2femalemalefemalemalemorekidsno35057 (22.22%)40987 (25.98%)41304 (26.18%)40394 (25.61%)yes25889 (26.71%)21737 (22.43%)21881 (22.58%)27405 (28.28%)\n\n\n\ncrosstable(ethnicity ~ morekids,\n  data = Fertility_ethnicity_factor\n) %&gt;%\n  crosstable::as_flextable()\n\nlabelvariablemorekidsnoyesethnicityAfam7027 (54.22%)5933 (45.78%)AfamHispanic104 (53.06%)92 (46.94%)Caucasian137344 (63.58%)78689 (36.42%)Hispanic5562 (50.03%)5555 (49.97%)HispanicOther3522 (46.44%)4062 (53.56%)Other4183 (61.84%)2581 (38.16%)\n\n\n\nFertility_ethnicity_factor %&gt;% \n  group_by(morekids) %&gt;% \n  summarize(average_workhours = mean(work)) %&gt;% tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                morekids\n                average_workhours\n              \n        \n        \n        \n                \n                  no\n                  21.06843\n                \n                \n                  yes\n                  15.68143\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n\n\nHypothesis: Families with two daughters (female.female) could have more children.\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  gf_bar(~interaction(gender1,gender2),\n    fill = ~morekids,\n    position = \"dodge\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Morekids vs Gender Composition\",\n    subtitle = \"How morekids is being effected based on current gender of kids\",\n    x=\"Gender of First Two Children\",\n    y=\"Count\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  gf_bar(~interaction(gender1,gender2),\n    fill = ~morekids,\n    position = \"fill\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Morekids vs Gender Composition\",\n    subtitle = \"How morekids is being effected based on current gender of kids\",\n    x=\"Gender of First Two Children\",\n    y=\"Count\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\nInferences\n\nFamilies with two girls are most likely to have more children.\nFamilies with one boy and one girl are least likely to continue growing their family.\nFamilies with two boys also show a high chance of having more kids.\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  gf_bar(~ethnicity,\n    fill = ~interaction(gender1,gender2),\n    position = \"dodge\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Ethnicity vs Gender Composition\",\n    x=\"Gender of First Two Children\",\n    y=\"Count of Families\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set2\"))\n\n\n\n\n\n\n\n\n\n\n\n\nHypothesis: Women who worked less number of weeks would have more kids.\n\n\n\n\ngf_histogram(~work,\n  data = Fertility_ethnicity_factor,\n  bins = 30,                \n  fill = ~morekids,         \n  position = \"dodge\"        \n) %&gt;%\n  gf_labs(\n    title = \"Distribution of Work Weeks by More Kids\",\n    subtitle = \"Number of Work Weeks in 1979 for Mothers with or without more kids\",\n    x = \"Work weeks in 1979\",\n    y = \"Count\",\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;% \n  count(morekids, work) %&gt;% \n  gf_line(n ~ work, color = ~morekids, linewidth = 0.8) %&gt;%\n  gf_labs(\n    title = \"Distribution of Work Weeks by More Kids\",\n    subtitle = \"Number of Work Weeks in 1979 for Mothers with or without more kids\",\n    x = \"Work weeks in 1979\",\n    y = \"Count\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;% \n  gf_boxplot(morekids ~ work, orientation = \"y\", fill=~morekids, color = \"black\") %&gt;%\n  gf_labs(y = \"More kids\", \n          x = \"Work weeks in 1979\", \n          title = \"Distribution of Work Weeks by More Kids\",\n          subtitle = \"Number of Work Weeks in 1979 for Mothers with or without more kids\")\n\n\n\n\n\n\n\n\n\nInferences\n\nMost individuals either worked a full year (52 weeks) or did not work at all (0 weeks)\nNot working mothers dominates - The largest group is those who worked 0 weeks.\nWorking full year (52 weeks) is the second largest group.\nMothers who worked between 2-50 weeks is a minority.\nThe difference between “more kids” and “no kids”:\n\nPeople with no kids lean more towards full-time work.\nPeople with kids lean more towards not working at all or working fewer weeks.\n\n\n\nOverall insight: The “no more kids” category is the largest overall especially among non working mothers. This shows most people in 1979 had only 2 kids.\n\n\n\n\n\nHypothesis: Older women would have more kids.\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  gf_density(~age, color = ~morekids, fill = ~morekids) %&gt;%\n  gf_labs(\n    title = \"Distribution of Age by More Kids\",\n    subtitle = \"Ages of Mothers with or without more kids\",\n    x = \"Age of Mothers\",\n    y = \"Density\",\n    color = \"More Kids\",\n    fill = \"More Kids\"\n  )\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;% \n  gf_boxplot(morekids ~ age, orientation = \"y\", fill=~morekids, color = \"black\") %&gt;%\n  gf_labs(y = \"Morekids\", x = \"Age of Mothers\", \n          title = \"Distribution of Age by More Kids\",\n          subtitle = \"Ages of Mothers with or without more kids\")\n\n\n\n\n\n\n\n\n\nInferences\n\nThe possibility of having more kids increases with age as seen as in the density distribution graph.\nThe age of people who have more kids (median 31) is only slightly higher than the age of people who do not have more kids (median 30)\nThe group that responded “no” (they do not want more kids) has a slightly wider Interquartile Range.\n\n50% of mothers in the “no” category are more spread out in age from 28 to 32 years\n50% of people in the “yes” group are more clustered in age from 30 to 32 years\n\nOutliers: A few mothers who have more kids are younger than others (around age 22-23).\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  count(ethnicity, morekids) %&gt;%  \n  gf_col(n ~ ethnicity, fill = ~morekids, position = \"dodge\") %&gt;%  \n  gf_labs(\n    title = \"Ethnic Group Distribution by More Kids\",\n    subtitle = \"Count of Respondents who have More Children \",\n    x = \"Ethnic Group\",\n    y = \"Number of People\",\n    fill = \"More Kids\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set2\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  count(ethnicity, morekids) %&gt;%  \n  gf_col(n ~ ethnicity, fill = ~morekids, position = \"fill\") %&gt;%  \n  gf_labs(\n    title = \"Ethnic Group Distribution by More Kids\",\n    subtitle = \"Count of Respondents who have More Children \",\n    x = \"Ethnic Group\",\n    y = \"Number of People\",\n    fill = \"More Kids\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set2\"))\n\n\n\n\n\n\n\n\n\nInferences\n\nThe Caucasian group is much larger than all other ethnic groups in the survey, as seen in the first graph.\nAfrican-Americans and Hispanics have the highest proportion of respondents who have more kids.\nThe Caucasian group and the Other group have a lower proportion of having more kids."
  },
  {
    "objectID": "posts/Fertility/Fertility.html#setting-up-r-packages",
    "href": "posts/Fertility/Fertility.html#setting-up-r-packages",
    "title": "Fertility Dataset",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(dplyr)\nlibrary(naniar)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:naniar':\n\n    n_complete\n\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(tinytable)\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(ggformula)\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\nThe following object is masked from 'package:skimr':\n\n    n_missing\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum"
  },
  {
    "objectID": "posts/Fertility/Fertility.html#read-data",
    "href": "posts/Fertility/Fertility.html#read-data",
    "title": "Fertility Dataset",
    "section": "",
    "text": "Fertility &lt;- readr::read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Fertility.csv\") %&gt;% \njanitor::clean_names(case=\"snake\")\n\nRows: 254654 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): morekids, gender1, gender2, afam, hispanic, other\ndbl (3): rownames, age, work\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nFertility\n\n# A tibble: 254,654 × 9\n   rownames morekids gender1 gender2   age afam  hispanic other  work\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;\n 1        1 no       male    female     27 no    no       no        0\n 2        2 no       female  male       30 no    no       no       30\n 3        3 no       male    female     27 no    no       no        0\n 4        4 no       male    female     35 yes   no       no        0\n 5        5 no       female  female     30 no    no       no       22\n 6        6 no       male    female     26 no    no       no       40\n 7        7 no       female  male       29 no    no       no        0\n 8        8 no       male    male       33 no    no       no       52\n 9        9 no       female  male       29 no    no       no        0\n10       10 no       male    female     27 no    no       no        0\n# ℹ 254,644 more rows"
  },
  {
    "objectID": "posts/Fertility/Fertility.html#data-dictionary",
    "href": "posts/Fertility/Fertility.html#data-dictionary",
    "title": "Fertility Dataset",
    "section": "",
    "text": "Variable\nDescription\n\n\n\n\nMorekids\nDoes the mother have more than 2 children?\n\n\nGender1\nFactor indicating gender of first child\n\n\nGender2\nFactor indicating gender of second child.\n\n\nAge\nAge of mother at census.\n\n\nAfam factor\nIs the mother African-American?\n\n\nHispanic factor\nIs the mother Hispanic?\n\n\nOther factor\nIs the mother’s ethnicity neither African-American nor Hispanic, nor Caucasian?\n\n\nWork\nNumber of weeks in which the mother worked in 1979."
  },
  {
    "objectID": "posts/Fertility/Fertility.html#examine-data",
    "href": "posts/Fertility/Fertility.html#examine-data",
    "title": "Fertility Dataset",
    "section": "",
    "text": "base::names(Fertility)\n\n[1] \"rownames\" \"morekids\" \"gender1\"  \"gender2\"  \"age\"      \"afam\"     \"hispanic\"\n[8] \"other\"    \"work\"    \n\n\n\ndplyr::glimpse(Fertility)\n\nRows: 254,654\nColumns: 9\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ morekids &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ gender1  &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"female\",…\n$ gender2  &lt;chr&gt; \"female\", \"male\", \"female\", \"female\", \"female\", \"female\", \"ma…\n$ age      &lt;dbl&gt; 27, 30, 27, 35, 30, 26, 29, 33, 29, 27, 28, 28, 35, 34, 32, 2…\n$ afam     &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ hispanic &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ other    &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ work     &lt;dbl&gt; 0, 30, 0, 0, 22, 40, 0, 52, 0, 0, 0, 52, 52, 52, 8, 7, 0, 40,…\n\n\n\nbase::dim(Fertility)\n\n[1] 254654      9\n\n\n\nutils::str(Fertility)\n\nspc_tbl_ [254,654 × 9] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ rownames: num [1:254654] 1 2 3 4 5 6 7 8 9 10 ...\n $ morekids: chr [1:254654] \"no\" \"no\" \"no\" \"no\" ...\n $ gender1 : chr [1:254654] \"male\" \"female\" \"male\" \"male\" ...\n $ gender2 : chr [1:254654] \"female\" \"male\" \"female\" \"female\" ...\n $ age     : num [1:254654] 27 30 27 35 30 26 29 33 29 27 ...\n $ afam    : chr [1:254654] \"no\" \"no\" \"no\" \"yes\" ...\n $ hispanic: chr [1:254654] \"no\" \"no\" \"no\" \"no\" ...\n $ other   : chr [1:254654] \"no\" \"no\" \"no\" \"no\" ...\n $ work    : num [1:254654] 0 30 0 0 22 40 0 52 0 0 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   rownames = col_double(),\n  ..   morekids = col_character(),\n  ..   gender1 = col_character(),\n  ..   gender2 = col_character(),\n  ..   age = col_double(),\n  ..   afam = col_character(),\n  ..   hispanic = col_character(),\n  ..   other = col_character(),\n  ..   work = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "posts/Fertility/Fertility.html#viewing-missing-data",
    "href": "posts/Fertility/Fertility.html#viewing-missing-data",
    "title": "Fertility Dataset",
    "section": "",
    "text": "Viewing missing data was not working for the whole data set, so we used slice sample of 100000. The data set did not have any missing data.\n\nFertility_sample &lt;- Fertility %&gt;% dplyr::slice_sample(n = 100000) \nvisdat::vis_dat(Fertility_sample)\n\n\n\n\n\n\n\n\n\nvisdat::vis_miss(Fertility_sample)"
  },
  {
    "objectID": "posts/Fertility/Fertility.html#new-column-for-labeling-ethnicity",
    "href": "posts/Fertility/Fertility.html#new-column-for-labeling-ethnicity",
    "title": "Fertility Dataset",
    "section": "",
    "text": "We created a new column for ethnicity since the data set did not directly indicate whether a person was Caucasian. Based on the data dictionary, all “no” responses were Caucasian. To make the data easier to understand, we added a column to clearly show the ethnicity of a person.\n\nFertility %&gt;% filter(afam == \"no\", hispanic == \"no\", other == \"no\")\n\n# A tibble: 216,033 × 9\n   rownames morekids gender1 gender2   age afam  hispanic other  work\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;\n 1        1 no       male    female     27 no    no       no        0\n 2        2 no       female  male       30 no    no       no       30\n 3        3 no       male    female     27 no    no       no        0\n 4        5 no       female  female     30 no    no       no       22\n 5        6 no       male    female     26 no    no       no       40\n 6        7 no       female  male       29 no    no       no        0\n 7        8 no       male    male       33 no    no       no       52\n 8        9 no       female  male       29 no    no       no        0\n 9       10 no       male    female     27 no    no       no        0\n10       11 yes      male    male       28 no    no       no        0\n# ℹ 216,023 more rows\n\n\n\nFertility_ethnicity &lt;- Fertility %&gt;%\n  mutate(ethnicity = case_when(\n    afam == \"yes\" & hispanic == \"no\" & other == \"no\" ~ \"Afam\",\n    afam == \"no\" & hispanic == \"yes\" & other == \"no\" ~ \"Hispanic\",\n    afam == \"no\" & hispanic == \"no\" & other == \"yes\" ~ \"Other\",\n    afam == \"no\" & hispanic == \"no\" & other == \"no\" ~ \"Caucasian\",\n    afam == \"yes\" & hispanic == \"yes\" & other == \"no\" ~ \"AfamHispanic\",\n    afam == \"yes\" & hispanic == \"no\" & other == \"yes\" ~ \"AfamOther\",\n    afam == \"no\" & hispanic == \"yes\" & other == \"yes\" ~ \"HispanicOther\"\n  ))\n  \nFertility_ethnicity\n\n# A tibble: 254,654 × 10\n   rownames morekids gender1 gender2   age afam  hispanic other  work ethnicity\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    \n 1        1 no       male    female     27 no    no       no        0 Caucasian\n 2        2 no       female  male       30 no    no       no       30 Caucasian\n 3        3 no       male    female     27 no    no       no        0 Caucasian\n 4        4 no       male    female     35 yes   no       no        0 Afam     \n 5        5 no       female  female     30 no    no       no       22 Caucasian\n 6        6 no       male    female     26 no    no       no       40 Caucasian\n 7        7 no       female  male       29 no    no       no        0 Caucasian\n 8        8 no       male    male       33 no    no       no       52 Caucasian\n 9        9 no       female  male       29 no    no       no        0 Caucasian\n10       10 no       male    female     27 no    no       no        0 Caucasian\n# ℹ 254,644 more rows"
  },
  {
    "objectID": "posts/Fertility/Fertility.html#munging",
    "href": "posts/Fertility/Fertility.html#munging",
    "title": "Fertility Dataset",
    "section": "",
    "text": "Fertility_ethnicity_factor &lt;- Fertility_ethnicity %&gt;%\n  mutate(across(where(is.character), as.factor)) %&gt;% \n  relocate(where(is.factor), .after = rownames)\nglimpse(Fertility_ethnicity_factor)\n\nRows: 254,654\nColumns: 10\n$ rownames  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ morekids  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, yes, no, no, no, no,…\n$ gender1   &lt;fct&gt; male, female, male, male, female, male, female, male, female…\n$ gender2   &lt;fct&gt; female, male, female, female, female, female, male, male, ma…\n$ afam      &lt;fct&gt; no, no, no, yes, no, no, no, no, no, no, no, no, no, no, no,…\n$ hispanic  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ other     &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ ethnicity &lt;fct&gt; Caucasian, Caucasian, Caucasian, Afam, Caucasian, Caucasian,…\n$ age       &lt;dbl&gt; 27, 30, 27, 35, 30, 26, 29, 33, 29, 27, 28, 28, 35, 34, 32, …\n$ work      &lt;dbl&gt; 0, 30, 0, 0, 22, 40, 0, 52, 0, 0, 0, 52, 52, 52, 8, 7, 0, 40…"
  },
  {
    "objectID": "posts/Fertility/Fertility.html#cleaned-table",
    "href": "posts/Fertility/Fertility.html#cleaned-table",
    "title": "Fertility Dataset",
    "section": "",
    "text": "Fertility_ethnicity_factor\n\n# A tibble: 254,654 × 10\n   rownames morekids gender1 gender2 afam  hispanic other ethnicity   age  work\n      &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;   &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1        1 no       male    female  no    no       no    Caucasian    27     0\n 2        2 no       female  male    no    no       no    Caucasian    30    30\n 3        3 no       male    female  no    no       no    Caucasian    27     0\n 4        4 no       male    female  yes   no       no    Afam         35     0\n 5        5 no       female  female  no    no       no    Caucasian    30    22\n 6        6 no       male    female  no    no       no    Caucasian    26    40\n 7        7 no       female  male    no    no       no    Caucasian    29     0\n 8        8 no       male    male    no    no       no    Caucasian    33    52\n 9        9 no       female  male    no    no       no    Caucasian    29     0\n10       10 no       male    female  no    no       no    Caucasian    27     0\n# ℹ 254,644 more rows"
  },
  {
    "objectID": "posts/Fertility/Fertility.html#summaries-examining-the-data",
    "href": "posts/Fertility/Fertility.html#summaries-examining-the-data",
    "title": "Fertility Dataset",
    "section": "",
    "text": "Fertility_ethnicity_factor %&gt;%\n  dplyr::count(across(.cols = c (gender1 , gender2)))\n\n# A tibble: 4 × 3\n  gender1 gender2     n\n  &lt;fct&gt;   &lt;fct&gt;   &lt;int&gt;\n1 female  female  60946\n2 female  male    62724\n3 male    female  63185\n4 male    male    67799\n\n\n\nFertility_ethnicity_factor %&gt;% \n  group_by(morekids) %&gt;% \n  summarise(average_age=mean(age),count=n()) %&gt;% tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                morekids\n                average_age\n                count\n              \n        \n        \n        \n                \n                  no\n                  30.12810\n                  157742\n                \n                \n                  yes\n                  30.82487\n                  96912\n                \n        \n      \n    \n\n\n\n\ncrosstable(morekids ~ gender2 + gender1,\n  data = Fertility_ethnicity_factor\n) %&gt;%\n  crosstable::as_flextable()\n\ngender1femalemalegender2femalemalefemalemalemorekidsno35057 (22.22%)40987 (25.98%)41304 (26.18%)40394 (25.61%)yes25889 (26.71%)21737 (22.43%)21881 (22.58%)27405 (28.28%)\n\n\n\ncrosstable(ethnicity ~ morekids,\n  data = Fertility_ethnicity_factor\n) %&gt;%\n  crosstable::as_flextable()\n\nlabelvariablemorekidsnoyesethnicityAfam7027 (54.22%)5933 (45.78%)AfamHispanic104 (53.06%)92 (46.94%)Caucasian137344 (63.58%)78689 (36.42%)Hispanic5562 (50.03%)5555 (49.97%)HispanicOther3522 (46.44%)4062 (53.56%)Other4183 (61.84%)2581 (38.16%)\n\n\n\nFertility_ethnicity_factor %&gt;% \n  group_by(morekids) %&gt;% \n  summarize(average_workhours = mean(work)) %&gt;% tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                morekids\n                average_workhours\n              \n        \n        \n        \n                \n                  no\n                  21.06843\n                \n                \n                  yes\n                  15.68143"
  },
  {
    "objectID": "posts/Fertility/Fertility.html#visualizing-the-data",
    "href": "posts/Fertility/Fertility.html#visualizing-the-data",
    "title": "Fertility Dataset",
    "section": "",
    "text": "Hypothesis: Families with two daughters (female.female) could have more children.\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  gf_bar(~interaction(gender1,gender2),\n    fill = ~morekids,\n    position = \"dodge\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Morekids vs Gender Composition\",\n    subtitle = \"How morekids is being effected based on current gender of kids\",\n    x=\"Gender of First Two Children\",\n    y=\"Count\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  gf_bar(~interaction(gender1,gender2),\n    fill = ~morekids,\n    position = \"fill\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Morekids vs Gender Composition\",\n    subtitle = \"How morekids is being effected based on current gender of kids\",\n    x=\"Gender of First Two Children\",\n    y=\"Count\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\nInferences\n\nFamilies with two girls are most likely to have more children.\nFamilies with one boy and one girl are least likely to continue growing their family.\nFamilies with two boys also show a high chance of having more kids.\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  gf_bar(~ethnicity,\n    fill = ~interaction(gender1,gender2),\n    position = \"dodge\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Ethnicity vs Gender Composition\",\n    x=\"Gender of First Two Children\",\n    y=\"Count of Families\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set2\"))\n\n\n\n\n\n\n\n\n\n\n\n\nHypothesis: Women who worked less number of weeks would have more kids.\n\n\n\n\ngf_histogram(~work,\n  data = Fertility_ethnicity_factor,\n  bins = 30,                \n  fill = ~morekids,         \n  position = \"dodge\"        \n) %&gt;%\n  gf_labs(\n    title = \"Distribution of Work Weeks by More Kids\",\n    subtitle = \"Number of Work Weeks in 1979 for Mothers with or without more kids\",\n    x = \"Work weeks in 1979\",\n    y = \"Count\",\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;% \n  count(morekids, work) %&gt;% \n  gf_line(n ~ work, color = ~morekids, linewidth = 0.8) %&gt;%\n  gf_labs(\n    title = \"Distribution of Work Weeks by More Kids\",\n    subtitle = \"Number of Work Weeks in 1979 for Mothers with or without more kids\",\n    x = \"Work weeks in 1979\",\n    y = \"Count\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;% \n  gf_boxplot(morekids ~ work, orientation = \"y\", fill=~morekids, color = \"black\") %&gt;%\n  gf_labs(y = \"More kids\", \n          x = \"Work weeks in 1979\", \n          title = \"Distribution of Work Weeks by More Kids\",\n          subtitle = \"Number of Work Weeks in 1979 for Mothers with or without more kids\")\n\n\n\n\n\n\n\n\n\nInferences\n\nMost individuals either worked a full year (52 weeks) or did not work at all (0 weeks)\nNot working mothers dominates - The largest group is those who worked 0 weeks.\nWorking full year (52 weeks) is the second largest group.\nMothers who worked between 2-50 weeks is a minority.\nThe difference between “more kids” and “no kids”:\n\nPeople with no kids lean more towards full-time work.\nPeople with kids lean more towards not working at all or working fewer weeks.\n\n\n\nOverall insight: The “no more kids” category is the largest overall especially among non working mothers. This shows most people in 1979 had only 2 kids.\n\n\n\n\n\nHypothesis: Older women would have more kids.\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  gf_density(~age, color = ~morekids, fill = ~morekids) %&gt;%\n  gf_labs(\n    title = \"Distribution of Age by More Kids\",\n    subtitle = \"Ages of Mothers with or without more kids\",\n    x = \"Age of Mothers\",\n    y = \"Density\",\n    color = \"More Kids\",\n    fill = \"More Kids\"\n  )\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;% \n  gf_boxplot(morekids ~ age, orientation = \"y\", fill=~morekids, color = \"black\") %&gt;%\n  gf_labs(y = \"Morekids\", x = \"Age of Mothers\", \n          title = \"Distribution of Age by More Kids\",\n          subtitle = \"Ages of Mothers with or without more kids\")\n\n\n\n\n\n\n\n\n\nInferences\n\nThe possibility of having more kids increases with age as seen as in the density distribution graph.\nThe age of people who have more kids (median 31) is only slightly higher than the age of people who do not have more kids (median 30)\nThe group that responded “no” (they do not want more kids) has a slightly wider Interquartile Range.\n\n50% of mothers in the “no” category are more spread out in age from 28 to 32 years\n50% of people in the “yes” group are more clustered in age from 30 to 32 years\n\nOutliers: A few mothers who have more kids are younger than others (around age 22-23).\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  count(ethnicity, morekids) %&gt;%  \n  gf_col(n ~ ethnicity, fill = ~morekids, position = \"dodge\") %&gt;%  \n  gf_labs(\n    title = \"Ethnic Group Distribution by More Kids\",\n    subtitle = \"Count of Respondents who have More Children \",\n    x = \"Ethnic Group\",\n    y = \"Number of People\",\n    fill = \"More Kids\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set2\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFertility_ethnicity_factor %&gt;%\n  count(ethnicity, morekids) %&gt;%  \n  gf_col(n ~ ethnicity, fill = ~morekids, position = \"fill\") %&gt;%  \n  gf_labs(\n    title = \"Ethnic Group Distribution by More Kids\",\n    subtitle = \"Count of Respondents who have More Children \",\n    x = \"Ethnic Group\",\n    y = \"Number of People\",\n    fill = \"More Kids\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set2\"))\n\n\n\n\n\n\n\n\n\nInferences\n\nThe Caucasian group is much larger than all other ethnic groups in the survey, as seen in the first graph.\nAfrican-Americans and Hispanics have the highest proportion of respondents who have more kids.\nThe Caucasian group and the Other group have a lower proportion of having more kids."
  },
  {
    "objectID": "classwork/classwork6/index.html",
    "href": "classwork/classwork6/index.html",
    "title": "Classwork 6",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic) # Our trusted friend\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(ggformula) # Formula interface to ggplot2\nlibrary(vcd) # Michael Friendly's package, Visualizing Categorical\n\nLoading required package: grid\n\nAttaching package: 'vcd'\n\nThe following object is masked from 'package:mosaic':\n\n    mplot\n\nlibrary(vcdExtra) # Categorical Data Sets\n\nLoading required package: gnm\n\nAttaching package: 'gnm'\n\nThe following object is masked from 'package:lattice':\n\n    barley\n\n\nAttaching package: 'vcdExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    summarise\n\nlibrary(resampledata) # More datasets\n\n\nAttaching package: 'resampledata'\n\nThe following object is masked from 'package:vcdExtra':\n\n    TV\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n\nlibrary(visStatistics) # Comprehensive all-in-one stats viz/test package\nlibrary(ggmosaic) # Tidy Mosaic Plots\n\n\nAttaching package: 'ggmosaic'\n\nThe following objects are masked from 'package:vcd':\n\n    mosaic, spine\n\nlibrary(ggpubr) # Colours, Themes and new geometries in ggplot\n##\nlibrary(janitor) # Data Cleaning and Tidying\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(visdat) # Visualize whole dataframes for missing data\nlibrary(naniar) # Clean missing data\n\n\nAttaching package: 'naniar'\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\nlibrary(DT) # Interactive Tables for our data\nlibrary(tinytable) # Elegant Tables for our data\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(ggrepel) # Repelling Text Labels in ggplot\nlibrary(marquee) # Marquee Text in ggplot\n\n\nArthritis %&gt;% class()\n\n[1] \"data.frame\"\n\nvcd::structable(data = Arthritis, Improved ~ Treatment)\n\n          Improved None Some Marked\nTreatment                          \nPlacebo              29    7      7\nTreated              13    7     21\n\nvcd::structable(data = Arthritis, Improved ~ Treatment) %&gt;% \n  as.matrix() %&gt;% # Convert to matrix; \n  addmargins() %&gt;% # Add margins to the table; matrix output\n  class() \n\n[1] \"matrix\" \"array\" \n\nvcd::structable(data = Arthritis, Improved ~ Treatment) %&gt;% \n  as.matrix() %&gt;% # Convert to matrix;\n  addmargins() %&gt;% # Add margins to the table; matrix output\n  as_tibble(rownames = \"Treatment\") # Convert to tibble; ensure row names!\n\n# A tibble: 3 × 5\n  Treatment  None  Some Marked   Sum\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Placebo      29     7      7    43\n2 Treated      13     7     21    41\n3 Sum          42    14     28    84\n\n\n\narthritis_table &lt;- vcd::structable(Improved ~ Treatment,\n                                   data = Arthritis)\narthritis_table\n\n          Improved None Some Marked\nTreatment                          \nPlacebo              29    7      7\nTreated              13    7     21\n\nvcd::mosaic(arthritis_table)\n\n\n\n\n\n\n\n\n\nvcd::mosaic(arthritis_table, \n            gp = shading_max, direction = \"v\",\n            main = \"Arthritis Treatment Dataset\",\nlabeling = labeling_border(\n                varnames = c(\"F\", \"F\"), # Remove variable name labels\n                rot_labels = c(90,0,0,0), #t,r,b,l\n                just_labels = c(\"left\", \n                                \"left\", \n                                \"left\", \n                                \"right\"))) # How?\n\n\n\n\n\n\n\n\n\n# library(ggmosaic)\ndata(\"titanic\", package = \"ggmosaic\")\ntitanic\n\n     Class    Sex   Age Survived\n1      3rd   Male Child       No\n2      3rd   Male Child       No\n3      3rd   Male Child       No\n4      3rd   Male Child       No\n5      3rd   Male Child       No\n6      3rd   Male Child       No\n7      3rd   Male Child       No\n8      3rd   Male Child       No\n9      3rd   Male Child       No\n10     3rd   Male Child       No\n11     3rd   Male Child       No\n12     3rd   Male Child       No\n13     3rd   Male Child       No\n14     3rd   Male Child       No\n15     3rd   Male Child       No\n16     3rd   Male Child       No\n17     3rd   Male Child       No\n18     3rd   Male Child       No\n19     3rd   Male Child       No\n20     3rd   Male Child       No\n21     3rd   Male Child       No\n22     3rd   Male Child       No\n23     3rd   Male Child       No\n24     3rd   Male Child       No\n25     3rd   Male Child       No\n26     3rd   Male Child       No\n27     3rd   Male Child       No\n28     3rd   Male Child       No\n29     3rd   Male Child       No\n30     3rd   Male Child       No\n31     3rd   Male Child       No\n32     3rd   Male Child       No\n33     3rd   Male Child       No\n34     3rd   Male Child       No\n35     3rd   Male Child       No\n36     3rd Female Child       No\n37     3rd Female Child       No\n38     3rd Female Child       No\n39     3rd Female Child       No\n40     3rd Female Child       No\n41     3rd Female Child       No\n42     3rd Female Child       No\n43     3rd Female Child       No\n44     3rd Female Child       No\n45     3rd Female Child       No\n46     3rd Female Child       No\n47     3rd Female Child       No\n48     3rd Female Child       No\n49     3rd Female Child       No\n50     3rd Female Child       No\n51     3rd Female Child       No\n52     3rd Female Child       No\n53     1st   Male Adult       No\n54     1st   Male Adult       No\n55     1st   Male Adult       No\n56     1st   Male Adult       No\n57     1st   Male Adult       No\n58     1st   Male Adult       No\n59     1st   Male Adult       No\n60     1st   Male Adult       No\n61     1st   Male Adult       No\n62     1st   Male Adult       No\n63     1st   Male Adult       No\n64     1st   Male Adult       No\n65     1st   Male Adult       No\n66     1st   Male Adult       No\n67     1st   Male Adult       No\n68     1st   Male Adult       No\n69     1st   Male Adult       No\n70     1st   Male Adult       No\n71     1st   Male Adult       No\n72     1st   Male Adult       No\n73     1st   Male Adult       No\n74     1st   Male Adult       No\n75     1st   Male Adult       No\n76     1st   Male Adult       No\n77     1st   Male Adult       No\n78     1st   Male Adult       No\n79     1st   Male Adult       No\n80     1st   Male Adult       No\n81     1st   Male Adult       No\n82     1st   Male Adult       No\n83     1st   Male Adult       No\n84     1st   Male Adult       No\n85     1st   Male Adult       No\n86     1st   Male Adult       No\n87     1st   Male Adult       No\n88     1st   Male Adult       No\n89     1st   Male Adult       No\n90     1st   Male Adult       No\n91     1st   Male Adult       No\n92     1st   Male Adult       No\n93     1st   Male Adult       No\n94     1st   Male Adult       No\n95     1st   Male Adult       No\n96     1st   Male Adult       No\n97     1st   Male Adult       No\n98     1st   Male Adult       No\n99     1st   Male Adult       No\n100    1st   Male Adult       No\n101    1st   Male Adult       No\n102    1st   Male Adult       No\n103    1st   Male Adult       No\n104    1st   Male Adult       No\n105    1st   Male Adult       No\n106    1st   Male Adult       No\n107    1st   Male Adult       No\n108    1st   Male Adult       No\n109    1st   Male Adult       No\n110    1st   Male Adult       No\n111    1st   Male Adult       No\n112    1st   Male Adult       No\n113    1st   Male Adult       No\n114    1st   Male Adult       No\n115    1st   Male Adult       No\n116    1st   Male Adult       No\n117    1st   Male Adult       No\n118    1st   Male Adult       No\n119    1st   Male Adult       No\n120    1st   Male Adult       No\n121    1st   Male Adult       No\n122    1st   Male Adult       No\n123    1st   Male Adult       No\n124    1st   Male Adult       No\n125    1st   Male Adult       No\n126    1st   Male Adult       No\n127    1st   Male Adult       No\n128    1st   Male Adult       No\n129    1st   Male Adult       No\n130    1st   Male Adult       No\n131    1st   Male Adult       No\n132    1st   Male Adult       No\n133    1st   Male Adult       No\n134    1st   Male Adult       No\n135    1st   Male Adult       No\n136    1st   Male Adult       No\n137    1st   Male Adult       No\n138    1st   Male Adult       No\n139    1st   Male Adult       No\n140    1st   Male Adult       No\n141    1st   Male Adult       No\n142    1st   Male Adult       No\n143    1st   Male Adult       No\n144    1st   Male Adult       No\n145    1st   Male Adult       No\n146    1st   Male Adult       No\n147    1st   Male Adult       No\n148    1st   Male Adult       No\n149    1st   Male Adult       No\n150    1st   Male Adult       No\n151    1st   Male Adult       No\n152    1st   Male Adult       No\n153    1st   Male Adult       No\n154    1st   Male Adult       No\n155    1st   Male Adult       No\n156    1st   Male Adult       No\n157    1st   Male Adult       No\n158    1st   Male Adult       No\n159    1st   Male Adult       No\n160    1st   Male Adult       No\n161    1st   Male Adult       No\n162    1st   Male Adult       No\n163    1st   Male Adult       No\n164    1st   Male Adult       No\n165    1st   Male Adult       No\n166    1st   Male Adult       No\n167    1st   Male Adult       No\n168    1st   Male Adult       No\n169    1st   Male Adult       No\n170    1st   Male Adult       No\n171    2nd   Male Adult       No\n172    2nd   Male Adult       No\n173    2nd   Male Adult       No\n174    2nd   Male Adult       No\n175    2nd   Male Adult       No\n176    2nd   Male Adult       No\n177    2nd   Male Adult       No\n178    2nd   Male Adult       No\n179    2nd   Male Adult       No\n180    2nd   Male Adult       No\n181    2nd   Male Adult       No\n182    2nd   Male Adult       No\n183    2nd   Male Adult       No\n184    2nd   Male Adult       No\n185    2nd   Male Adult       No\n186    2nd   Male Adult       No\n187    2nd   Male Adult       No\n188    2nd   Male Adult       No\n189    2nd   Male Adult       No\n190    2nd   Male Adult       No\n191    2nd   Male Adult       No\n192    2nd   Male Adult       No\n193    2nd   Male Adult       No\n194    2nd   Male Adult       No\n195    2nd   Male Adult       No\n196    2nd   Male Adult       No\n197    2nd   Male Adult       No\n198    2nd   Male Adult       No\n199    2nd   Male Adult       No\n200    2nd   Male Adult       No\n201    2nd   Male Adult       No\n202    2nd   Male Adult       No\n203    2nd   Male Adult       No\n204    2nd   Male Adult       No\n205    2nd   Male Adult       No\n206    2nd   Male Adult       No\n207    2nd   Male Adult       No\n208    2nd   Male Adult       No\n209    2nd   Male Adult       No\n210    2nd   Male Adult       No\n211    2nd   Male Adult       No\n212    2nd   Male Adult       No\n213    2nd   Male Adult       No\n214    2nd   Male Adult       No\n215    2nd   Male Adult       No\n216    2nd   Male Adult       No\n217    2nd   Male Adult       No\n218    2nd   Male Adult       No\n219    2nd   Male Adult       No\n220    2nd   Male Adult       No\n221    2nd   Male Adult       No\n222    2nd   Male Adult       No\n223    2nd   Male Adult       No\n224    2nd   Male Adult       No\n225    2nd   Male Adult       No\n226    2nd   Male Adult       No\n227    2nd   Male Adult       No\n228    2nd   Male Adult       No\n229    2nd   Male Adult       No\n230    2nd   Male Adult       No\n231    2nd   Male Adult       No\n232    2nd   Male Adult       No\n233    2nd   Male Adult       No\n234    2nd   Male Adult       No\n235    2nd   Male Adult       No\n236    2nd   Male Adult       No\n237    2nd   Male Adult       No\n238    2nd   Male Adult       No\n239    2nd   Male Adult       No\n240    2nd   Male Adult       No\n241    2nd   Male Adult       No\n242    2nd   Male Adult       No\n243    2nd   Male Adult       No\n244    2nd   Male Adult       No\n245    2nd   Male Adult       No\n246    2nd   Male Adult       No\n247    2nd   Male Adult       No\n248    2nd   Male Adult       No\n249    2nd   Male Adult       No\n250    2nd   Male Adult       No\n251    2nd   Male Adult       No\n252    2nd   Male Adult       No\n253    2nd   Male Adult       No\n254    2nd   Male Adult       No\n255    2nd   Male Adult       No\n256    2nd   Male Adult       No\n257    2nd   Male Adult       No\n258    2nd   Male Adult       No\n259    2nd   Male Adult       No\n260    2nd   Male Adult       No\n261    2nd   Male Adult       No\n262    2nd   Male Adult       No\n263    2nd   Male Adult       No\n264    2nd   Male Adult       No\n265    2nd   Male Adult       No\n266    2nd   Male Adult       No\n267    2nd   Male Adult       No\n268    2nd   Male Adult       No\n269    2nd   Male Adult       No\n270    2nd   Male Adult       No\n271    2nd   Male Adult       No\n272    2nd   Male Adult       No\n273    2nd   Male Adult       No\n274    2nd   Male Adult       No\n275    2nd   Male Adult       No\n276    2nd   Male Adult       No\n277    2nd   Male Adult       No\n278    2nd   Male Adult       No\n279    2nd   Male Adult       No\n280    2nd   Male Adult       No\n281    2nd   Male Adult       No\n282    2nd   Male Adult       No\n283    2nd   Male Adult       No\n284    2nd   Male Adult       No\n285    2nd   Male Adult       No\n286    2nd   Male Adult       No\n287    2nd   Male Adult       No\n288    2nd   Male Adult       No\n289    2nd   Male Adult       No\n290    2nd   Male Adult       No\n291    2nd   Male Adult       No\n292    2nd   Male Adult       No\n293    2nd   Male Adult       No\n294    2nd   Male Adult       No\n295    2nd   Male Adult       No\n296    2nd   Male Adult       No\n297    2nd   Male Adult       No\n298    2nd   Male Adult       No\n299    2nd   Male Adult       No\n300    2nd   Male Adult       No\n301    2nd   Male Adult       No\n302    2nd   Male Adult       No\n303    2nd   Male Adult       No\n304    2nd   Male Adult       No\n305    2nd   Male Adult       No\n306    2nd   Male Adult       No\n307    2nd   Male Adult       No\n308    2nd   Male Adult       No\n309    2nd   Male Adult       No\n310    2nd   Male Adult       No\n311    2nd   Male Adult       No\n312    2nd   Male Adult       No\n313    2nd   Male Adult       No\n314    2nd   Male Adult       No\n315    2nd   Male Adult       No\n316    2nd   Male Adult       No\n317    2nd   Male Adult       No\n318    2nd   Male Adult       No\n319    2nd   Male Adult       No\n320    2nd   Male Adult       No\n321    2nd   Male Adult       No\n322    2nd   Male Adult       No\n323    2nd   Male Adult       No\n324    2nd   Male Adult       No\n325    3rd   Male Adult       No\n326    3rd   Male Adult       No\n327    3rd   Male Adult       No\n328    3rd   Male Adult       No\n329    3rd   Male Adult       No\n330    3rd   Male Adult       No\n331    3rd   Male Adult       No\n332    3rd   Male Adult       No\n333    3rd   Male Adult       No\n334    3rd   Male Adult       No\n335    3rd   Male Adult       No\n336    3rd   Male Adult       No\n337    3rd   Male Adult       No\n338    3rd   Male Adult       No\n339    3rd   Male Adult       No\n340    3rd   Male Adult       No\n341    3rd   Male Adult       No\n342    3rd   Male Adult       No\n343    3rd   Male Adult       No\n344    3rd   Male Adult       No\n345    3rd   Male Adult       No\n346    3rd   Male Adult       No\n347    3rd   Male Adult       No\n348    3rd   Male Adult       No\n349    3rd   Male Adult       No\n350    3rd   Male Adult       No\n351    3rd   Male Adult       No\n352    3rd   Male Adult       No\n353    3rd   Male Adult       No\n354    3rd   Male Adult       No\n355    3rd   Male Adult       No\n356    3rd   Male Adult       No\n357    3rd   Male Adult       No\n358    3rd   Male Adult       No\n359    3rd   Male Adult       No\n360    3rd   Male Adult       No\n361    3rd   Male Adult       No\n362    3rd   Male Adult       No\n363    3rd   Male Adult       No\n364    3rd   Male Adult       No\n365    3rd   Male Adult       No\n366    3rd   Male Adult       No\n367    3rd   Male Adult       No\n368    3rd   Male Adult       No\n369    3rd   Male Adult       No\n370    3rd   Male Adult       No\n371    3rd   Male Adult       No\n372    3rd   Male Adult       No\n373    3rd   Male Adult       No\n374    3rd   Male Adult       No\n375    3rd   Male Adult       No\n376    3rd   Male Adult       No\n377    3rd   Male Adult       No\n378    3rd   Male Adult       No\n379    3rd   Male Adult       No\n380    3rd   Male Adult       No\n381    3rd   Male Adult       No\n382    3rd   Male Adult       No\n383    3rd   Male Adult       No\n384    3rd   Male Adult       No\n385    3rd   Male Adult       No\n386    3rd   Male Adult       No\n387    3rd   Male Adult       No\n388    3rd   Male Adult       No\n389    3rd   Male Adult       No\n390    3rd   Male Adult       No\n391    3rd   Male Adult       No\n392    3rd   Male Adult       No\n393    3rd   Male Adult       No\n394    3rd   Male Adult       No\n395    3rd   Male Adult       No\n396    3rd   Male Adult       No\n397    3rd   Male Adult       No\n398    3rd   Male Adult       No\n399    3rd   Male Adult       No\n400    3rd   Male Adult       No\n401    3rd   Male Adult       No\n402    3rd   Male Adult       No\n403    3rd   Male Adult       No\n404    3rd   Male Adult       No\n405    3rd   Male Adult       No\n406    3rd   Male Adult       No\n407    3rd   Male Adult       No\n408    3rd   Male Adult       No\n409    3rd   Male Adult       No\n410    3rd   Male Adult       No\n411    3rd   Male Adult       No\n412    3rd   Male Adult       No\n413    3rd   Male Adult       No\n414    3rd   Male Adult       No\n415    3rd   Male Adult       No\n416    3rd   Male Adult       No\n417    3rd   Male Adult       No\n418    3rd   Male Adult       No\n419    3rd   Male Adult       No\n420    3rd   Male Adult       No\n421    3rd   Male Adult       No\n422    3rd   Male Adult       No\n423    3rd   Male Adult       No\n424    3rd   Male Adult       No\n425    3rd   Male Adult       No\n426    3rd   Male Adult       No\n427    3rd   Male Adult       No\n428    3rd   Male Adult       No\n429    3rd   Male Adult       No\n430    3rd   Male Adult       No\n431    3rd   Male Adult       No\n432    3rd   Male Adult       No\n433    3rd   Male Adult       No\n434    3rd   Male Adult       No\n435    3rd   Male Adult       No\n436    3rd   Male Adult       No\n437    3rd   Male Adult       No\n438    3rd   Male Adult       No\n439    3rd   Male Adult       No\n440    3rd   Male Adult       No\n441    3rd   Male Adult       No\n442    3rd   Male Adult       No\n443    3rd   Male Adult       No\n444    3rd   Male Adult       No\n445    3rd   Male Adult       No\n446    3rd   Male Adult       No\n447    3rd   Male Adult       No\n448    3rd   Male Adult       No\n449    3rd   Male Adult       No\n450    3rd   Male Adult       No\n451    3rd   Male Adult       No\n452    3rd   Male Adult       No\n453    3rd   Male Adult       No\n454    3rd   Male Adult       No\n455    3rd   Male Adult       No\n456    3rd   Male Adult       No\n457    3rd   Male Adult       No\n458    3rd   Male Adult       No\n459    3rd   Male Adult       No\n460    3rd   Male Adult       No\n461    3rd   Male Adult       No\n462    3rd   Male Adult       No\n463    3rd   Male Adult       No\n464    3rd   Male Adult       No\n465    3rd   Male Adult       No\n466    3rd   Male Adult       No\n467    3rd   Male Adult       No\n468    3rd   Male Adult       No\n469    3rd   Male Adult       No\n470    3rd   Male Adult       No\n471    3rd   Male Adult       No\n472    3rd   Male Adult       No\n473    3rd   Male Adult       No\n474    3rd   Male Adult       No\n475    3rd   Male Adult       No\n476    3rd   Male Adult       No\n477    3rd   Male Adult       No\n478    3rd   Male Adult       No\n479    3rd   Male Adult       No\n480    3rd   Male Adult       No\n481    3rd   Male Adult       No\n482    3rd   Male Adult       No\n483    3rd   Male Adult       No\n484    3rd   Male Adult       No\n485    3rd   Male Adult       No\n486    3rd   Male Adult       No\n487    3rd   Male Adult       No\n488    3rd   Male Adult       No\n489    3rd   Male Adult       No\n490    3rd   Male Adult       No\n491    3rd   Male Adult       No\n492    3rd   Male Adult       No\n493    3rd   Male Adult       No\n494    3rd   Male Adult       No\n495    3rd   Male Adult       No\n496    3rd   Male Adult       No\n497    3rd   Male Adult       No\n498    3rd   Male Adult       No\n499    3rd   Male Adult       No\n500    3rd   Male Adult       No\n501    3rd   Male Adult       No\n502    3rd   Male Adult       No\n503    3rd   Male Adult       No\n504    3rd   Male Adult       No\n505    3rd   Male Adult       No\n506    3rd   Male Adult       No\n507    3rd   Male Adult       No\n508    3rd   Male Adult       No\n509    3rd   Male Adult       No\n510    3rd   Male Adult       No\n511    3rd   Male Adult       No\n512    3rd   Male Adult       No\n513    3rd   Male Adult       No\n514    3rd   Male Adult       No\n515    3rd   Male Adult       No\n516    3rd   Male Adult       No\n517    3rd   Male Adult       No\n518    3rd   Male Adult       No\n519    3rd   Male Adult       No\n520    3rd   Male Adult       No\n521    3rd   Male Adult       No\n522    3rd   Male Adult       No\n523    3rd   Male Adult       No\n524    3rd   Male Adult       No\n525    3rd   Male Adult       No\n526    3rd   Male Adult       No\n527    3rd   Male Adult       No\n528    3rd   Male Adult       No\n529    3rd   Male Adult       No\n530    3rd   Male Adult       No\n531    3rd   Male Adult       No\n532    3rd   Male Adult       No\n533    3rd   Male Adult       No\n534    3rd   Male Adult       No\n535    3rd   Male Adult       No\n536    3rd   Male Adult       No\n537    3rd   Male Adult       No\n538    3rd   Male Adult       No\n539    3rd   Male Adult       No\n540    3rd   Male Adult       No\n541    3rd   Male Adult       No\n542    3rd   Male Adult       No\n543    3rd   Male Adult       No\n544    3rd   Male Adult       No\n545    3rd   Male Adult       No\n546    3rd   Male Adult       No\n547    3rd   Male Adult       No\n548    3rd   Male Adult       No\n549    3rd   Male Adult       No\n550    3rd   Male Adult       No\n551    3rd   Male Adult       No\n552    3rd   Male Adult       No\n553    3rd   Male Adult       No\n554    3rd   Male Adult       No\n555    3rd   Male Adult       No\n556    3rd   Male Adult       No\n557    3rd   Male Adult       No\n558    3rd   Male Adult       No\n559    3rd   Male Adult       No\n560    3rd   Male Adult       No\n561    3rd   Male Adult       No\n562    3rd   Male Adult       No\n563    3rd   Male Adult       No\n564    3rd   Male Adult       No\n565    3rd   Male Adult       No\n566    3rd   Male Adult       No\n567    3rd   Male Adult       No\n568    3rd   Male Adult       No\n569    3rd   Male Adult       No\n570    3rd   Male Adult       No\n571    3rd   Male Adult       No\n572    3rd   Male Adult       No\n573    3rd   Male Adult       No\n574    3rd   Male Adult       No\n575    3rd   Male Adult       No\n576    3rd   Male Adult       No\n577    3rd   Male Adult       No\n578    3rd   Male Adult       No\n579    3rd   Male Adult       No\n580    3rd   Male Adult       No\n581    3rd   Male Adult       No\n582    3rd   Male Adult       No\n583    3rd   Male Adult       No\n584    3rd   Male Adult       No\n585    3rd   Male Adult       No\n586    3rd   Male Adult       No\n587    3rd   Male Adult       No\n588    3rd   Male Adult       No\n589    3rd   Male Adult       No\n590    3rd   Male Adult       No\n591    3rd   Male Adult       No\n592    3rd   Male Adult       No\n593    3rd   Male Adult       No\n594    3rd   Male Adult       No\n595    3rd   Male Adult       No\n596    3rd   Male Adult       No\n597    3rd   Male Adult       No\n598    3rd   Male Adult       No\n599    3rd   Male Adult       No\n600    3rd   Male Adult       No\n601    3rd   Male Adult       No\n602    3rd   Male Adult       No\n603    3rd   Male Adult       No\n604    3rd   Male Adult       No\n605    3rd   Male Adult       No\n606    3rd   Male Adult       No\n607    3rd   Male Adult       No\n608    3rd   Male Adult       No\n609    3rd   Male Adult       No\n610    3rd   Male Adult       No\n611    3rd   Male Adult       No\n612    3rd   Male Adult       No\n613    3rd   Male Adult       No\n614    3rd   Male Adult       No\n615    3rd   Male Adult       No\n616    3rd   Male Adult       No\n617    3rd   Male Adult       No\n618    3rd   Male Adult       No\n619    3rd   Male Adult       No\n620    3rd   Male Adult       No\n621    3rd   Male Adult       No\n622    3rd   Male Adult       No\n623    3rd   Male Adult       No\n624    3rd   Male Adult       No\n625    3rd   Male Adult       No\n626    3rd   Male Adult       No\n627    3rd   Male Adult       No\n628    3rd   Male Adult       No\n629    3rd   Male Adult       No\n630    3rd   Male Adult       No\n631    3rd   Male Adult       No\n632    3rd   Male Adult       No\n633    3rd   Male Adult       No\n634    3rd   Male Adult       No\n635    3rd   Male Adult       No\n636    3rd   Male Adult       No\n637    3rd   Male Adult       No\n638    3rd   Male Adult       No\n639    3rd   Male Adult       No\n640    3rd   Male Adult       No\n641    3rd   Male Adult       No\n642    3rd   Male Adult       No\n643    3rd   Male Adult       No\n644    3rd   Male Adult       No\n645    3rd   Male Adult       No\n646    3rd   Male Adult       No\n647    3rd   Male Adult       No\n648    3rd   Male Adult       No\n649    3rd   Male Adult       No\n650    3rd   Male Adult       No\n651    3rd   Male Adult       No\n652    3rd   Male Adult       No\n653    3rd   Male Adult       No\n654    3rd   Male Adult       No\n655    3rd   Male Adult       No\n656    3rd   Male Adult       No\n657    3rd   Male Adult       No\n658    3rd   Male Adult       No\n659    3rd   Male Adult       No\n660    3rd   Male Adult       No\n661    3rd   Male Adult       No\n662    3rd   Male Adult       No\n663    3rd   Male Adult       No\n664    3rd   Male Adult       No\n665    3rd   Male Adult       No\n666    3rd   Male Adult       No\n667    3rd   Male Adult       No\n668    3rd   Male Adult       No\n669    3rd   Male Adult       No\n670    3rd   Male Adult       No\n671    3rd   Male Adult       No\n672    3rd   Male Adult       No\n673    3rd   Male Adult       No\n674    3rd   Male Adult       No\n675    3rd   Male Adult       No\n676    3rd   Male Adult       No\n677    3rd   Male Adult       No\n678    3rd   Male Adult       No\n679    3rd   Male Adult       No\n680    3rd   Male Adult       No\n681    3rd   Male Adult       No\n682    3rd   Male Adult       No\n683    3rd   Male Adult       No\n684    3rd   Male Adult       No\n685    3rd   Male Adult       No\n686    3rd   Male Adult       No\n687    3rd   Male Adult       No\n688    3rd   Male Adult       No\n689    3rd   Male Adult       No\n690    3rd   Male Adult       No\n691    3rd   Male Adult       No\n692    3rd   Male Adult       No\n693    3rd   Male Adult       No\n694    3rd   Male Adult       No\n695    3rd   Male Adult       No\n696    3rd   Male Adult       No\n697    3rd   Male Adult       No\n698    3rd   Male Adult       No\n699    3rd   Male Adult       No\n700    3rd   Male Adult       No\n701    3rd   Male Adult       No\n702    3rd   Male Adult       No\n703    3rd   Male Adult       No\n704    3rd   Male Adult       No\n705    3rd   Male Adult       No\n706    3rd   Male Adult       No\n707    3rd   Male Adult       No\n708    3rd   Male Adult       No\n709    3rd   Male Adult       No\n710    3rd   Male Adult       No\n711    3rd   Male Adult       No\n712   Crew   Male Adult       No\n713   Crew   Male Adult       No\n714   Crew   Male Adult       No\n715   Crew   Male Adult       No\n716   Crew   Male Adult       No\n717   Crew   Male Adult       No\n718   Crew   Male Adult       No\n719   Crew   Male Adult       No\n720   Crew   Male Adult       No\n721   Crew   Male Adult       No\n722   Crew   Male Adult       No\n723   Crew   Male Adult       No\n724   Crew   Male Adult       No\n725   Crew   Male Adult       No\n726   Crew   Male Adult       No\n727   Crew   Male Adult       No\n728   Crew   Male Adult       No\n729   Crew   Male Adult       No\n730   Crew   Male Adult       No\n731   Crew   Male Adult       No\n732   Crew   Male Adult       No\n733   Crew   Male Adult       No\n734   Crew   Male Adult       No\n735   Crew   Male Adult       No\n736   Crew   Male Adult       No\n737   Crew   Male Adult       No\n738   Crew   Male Adult       No\n739   Crew   Male Adult       No\n740   Crew   Male Adult       No\n741   Crew   Male Adult       No\n742   Crew   Male Adult       No\n743   Crew   Male Adult       No\n744   Crew   Male Adult       No\n745   Crew   Male Adult       No\n746   Crew   Male Adult       No\n747   Crew   Male Adult       No\n748   Crew   Male Adult       No\n749   Crew   Male Adult       No\n750   Crew   Male Adult       No\n751   Crew   Male Adult       No\n752   Crew   Male Adult       No\n753   Crew   Male Adult       No\n754   Crew   Male Adult       No\n755   Crew   Male Adult       No\n756   Crew   Male Adult       No\n757   Crew   Male Adult       No\n758   Crew   Male Adult       No\n759   Crew   Male Adult       No\n760   Crew   Male Adult       No\n761   Crew   Male Adult       No\n762   Crew   Male Adult       No\n763   Crew   Male Adult       No\n764   Crew   Male Adult       No\n765   Crew   Male Adult       No\n766   Crew   Male Adult       No\n767   Crew   Male Adult       No\n768   Crew   Male Adult       No\n769   Crew   Male Adult       No\n770   Crew   Male Adult       No\n771   Crew   Male Adult       No\n772   Crew   Male Adult       No\n773   Crew   Male Adult       No\n774   Crew   Male Adult       No\n775   Crew   Male Adult       No\n776   Crew   Male Adult       No\n777   Crew   Male Adult       No\n778   Crew   Male Adult       No\n779   Crew   Male Adult       No\n780   Crew   Male Adult       No\n781   Crew   Male Adult       No\n782   Crew   Male Adult       No\n783   Crew   Male Adult       No\n784   Crew   Male Adult       No\n785   Crew   Male Adult       No\n786   Crew   Male Adult       No\n787   Crew   Male Adult       No\n788   Crew   Male Adult       No\n789   Crew   Male Adult       No\n790   Crew   Male Adult       No\n791   Crew   Male Adult       No\n792   Crew   Male Adult       No\n793   Crew   Male Adult       No\n794   Crew   Male Adult       No\n795   Crew   Male Adult       No\n796   Crew   Male Adult       No\n797   Crew   Male Adult       No\n798   Crew   Male Adult       No\n799   Crew   Male Adult       No\n800   Crew   Male Adult       No\n801   Crew   Male Adult       No\n802   Crew   Male Adult       No\n803   Crew   Male Adult       No\n804   Crew   Male Adult       No\n805   Crew   Male Adult       No\n806   Crew   Male Adult       No\n807   Crew   Male Adult       No\n808   Crew   Male Adult       No\n809   Crew   Male Adult       No\n810   Crew   Male Adult       No\n811   Crew   Male Adult       No\n812   Crew   Male Adult       No\n813   Crew   Male Adult       No\n814   Crew   Male Adult       No\n815   Crew   Male Adult       No\n816   Crew   Male Adult       No\n817   Crew   Male Adult       No\n818   Crew   Male Adult       No\n819   Crew   Male Adult       No\n820   Crew   Male Adult       No\n821   Crew   Male Adult       No\n822   Crew   Male Adult       No\n823   Crew   Male Adult       No\n824   Crew   Male Adult       No\n825   Crew   Male Adult       No\n826   Crew   Male Adult       No\n827   Crew   Male Adult       No\n828   Crew   Male Adult       No\n829   Crew   Male Adult       No\n830   Crew   Male Adult       No\n831   Crew   Male Adult       No\n832   Crew   Male Adult       No\n833   Crew   Male Adult       No\n834   Crew   Male Adult       No\n835   Crew   Male Adult       No\n836   Crew   Male Adult       No\n837   Crew   Male Adult       No\n838   Crew   Male Adult       No\n839   Crew   Male Adult       No\n840   Crew   Male Adult       No\n841   Crew   Male Adult       No\n842   Crew   Male Adult       No\n843   Crew   Male Adult       No\n844   Crew   Male Adult       No\n845   Crew   Male Adult       No\n846   Crew   Male Adult       No\n847   Crew   Male Adult       No\n848   Crew   Male Adult       No\n849   Crew   Male Adult       No\n850   Crew   Male Adult       No\n851   Crew   Male Adult       No\n852   Crew   Male Adult       No\n853   Crew   Male Adult       No\n854   Crew   Male Adult       No\n855   Crew   Male Adult       No\n856   Crew   Male Adult       No\n857   Crew   Male Adult       No\n858   Crew   Male Adult       No\n859   Crew   Male Adult       No\n860   Crew   Male Adult       No\n861   Crew   Male Adult       No\n862   Crew   Male Adult       No\n863   Crew   Male Adult       No\n864   Crew   Male Adult       No\n865   Crew   Male Adult       No\n866   Crew   Male Adult       No\n867   Crew   Male Adult       No\n868   Crew   Male Adult       No\n869   Crew   Male Adult       No\n870   Crew   Male Adult       No\n871   Crew   Male Adult       No\n872   Crew   Male Adult       No\n873   Crew   Male Adult       No\n874   Crew   Male Adult       No\n875   Crew   Male Adult       No\n876   Crew   Male Adult       No\n877   Crew   Male Adult       No\n878   Crew   Male Adult       No\n879   Crew   Male Adult       No\n880   Crew   Male Adult       No\n881   Crew   Male Adult       No\n882   Crew   Male Adult       No\n883   Crew   Male Adult       No\n884   Crew   Male Adult       No\n885   Crew   Male Adult       No\n886   Crew   Male Adult       No\n887   Crew   Male Adult       No\n888   Crew   Male Adult       No\n889   Crew   Male Adult       No\n890   Crew   Male Adult       No\n891   Crew   Male Adult       No\n892   Crew   Male Adult       No\n893   Crew   Male Adult       No\n894   Crew   Male Adult       No\n895   Crew   Male Adult       No\n896   Crew   Male Adult       No\n897   Crew   Male Adult       No\n898   Crew   Male Adult       No\n899   Crew   Male Adult       No\n900   Crew   Male Adult       No\n901   Crew   Male Adult       No\n902   Crew   Male Adult       No\n903   Crew   Male Adult       No\n904   Crew   Male Adult       No\n905   Crew   Male Adult       No\n906   Crew   Male Adult       No\n907   Crew   Male Adult       No\n908   Crew   Male Adult       No\n909   Crew   Male Adult       No\n910   Crew   Male Adult       No\n911   Crew   Male Adult       No\n912   Crew   Male Adult       No\n913   Crew   Male Adult       No\n914   Crew   Male Adult       No\n915   Crew   Male Adult       No\n916   Crew   Male Adult       No\n917   Crew   Male Adult       No\n918   Crew   Male Adult       No\n919   Crew   Male Adult       No\n920   Crew   Male Adult       No\n921   Crew   Male Adult       No\n922   Crew   Male Adult       No\n923   Crew   Male Adult       No\n924   Crew   Male Adult       No\n925   Crew   Male Adult       No\n926   Crew   Male Adult       No\n927   Crew   Male Adult       No\n928   Crew   Male Adult       No\n929   Crew   Male Adult       No\n930   Crew   Male Adult       No\n931   Crew   Male Adult       No\n932   Crew   Male Adult       No\n933   Crew   Male Adult       No\n934   Crew   Male Adult       No\n935   Crew   Male Adult       No\n936   Crew   Male Adult       No\n937   Crew   Male Adult       No\n938   Crew   Male Adult       No\n939   Crew   Male Adult       No\n940   Crew   Male Adult       No\n941   Crew   Male Adult       No\n942   Crew   Male Adult       No\n943   Crew   Male Adult       No\n944   Crew   Male Adult       No\n945   Crew   Male Adult       No\n946   Crew   Male Adult       No\n947   Crew   Male Adult       No\n948   Crew   Male Adult       No\n949   Crew   Male Adult       No\n950   Crew   Male Adult       No\n951   Crew   Male Adult       No\n952   Crew   Male Adult       No\n953   Crew   Male Adult       No\n954   Crew   Male Adult       No\n955   Crew   Male Adult       No\n956   Crew   Male Adult       No\n957   Crew   Male Adult       No\n958   Crew   Male Adult       No\n959   Crew   Male Adult       No\n960   Crew   Male Adult       No\n961   Crew   Male Adult       No\n962   Crew   Male Adult       No\n963   Crew   Male Adult       No\n964   Crew   Male Adult       No\n965   Crew   Male Adult       No\n966   Crew   Male Adult       No\n967   Crew   Male Adult       No\n968   Crew   Male Adult       No\n969   Crew   Male Adult       No\n970   Crew   Male Adult       No\n971   Crew   Male Adult       No\n972   Crew   Male Adult       No\n973   Crew   Male Adult       No\n974   Crew   Male Adult       No\n975   Crew   Male Adult       No\n976   Crew   Male Adult       No\n977   Crew   Male Adult       No\n978   Crew   Male Adult       No\n979   Crew   Male Adult       No\n980   Crew   Male Adult       No\n981   Crew   Male Adult       No\n982   Crew   Male Adult       No\n983   Crew   Male Adult       No\n984   Crew   Male Adult       No\n985   Crew   Male Adult       No\n986   Crew   Male Adult       No\n987   Crew   Male Adult       No\n988   Crew   Male Adult       No\n989   Crew   Male Adult       No\n990   Crew   Male Adult       No\n991   Crew   Male Adult       No\n992   Crew   Male Adult       No\n993   Crew   Male Adult       No\n994   Crew   Male Adult       No\n995   Crew   Male Adult       No\n996   Crew   Male Adult       No\n997   Crew   Male Adult       No\n998   Crew   Male Adult       No\n999   Crew   Male Adult       No\n1000  Crew   Male Adult       No\n1001  Crew   Male Adult       No\n1002  Crew   Male Adult       No\n1003  Crew   Male Adult       No\n1004  Crew   Male Adult       No\n1005  Crew   Male Adult       No\n1006  Crew   Male Adult       No\n1007  Crew   Male Adult       No\n1008  Crew   Male Adult       No\n1009  Crew   Male Adult       No\n1010  Crew   Male Adult       No\n1011  Crew   Male Adult       No\n1012  Crew   Male Adult       No\n1013  Crew   Male Adult       No\n1014  Crew   Male Adult       No\n1015  Crew   Male Adult       No\n1016  Crew   Male Adult       No\n1017  Crew   Male Adult       No\n1018  Crew   Male Adult       No\n1019  Crew   Male Adult       No\n1020  Crew   Male Adult       No\n1021  Crew   Male Adult       No\n1022  Crew   Male Adult       No\n1023  Crew   Male Adult       No\n1024  Crew   Male Adult       No\n1025  Crew   Male Adult       No\n1026  Crew   Male Adult       No\n1027  Crew   Male Adult       No\n1028  Crew   Male Adult       No\n1029  Crew   Male Adult       No\n1030  Crew   Male Adult       No\n1031  Crew   Male Adult       No\n1032  Crew   Male Adult       No\n1033  Crew   Male Adult       No\n1034  Crew   Male Adult       No\n1035  Crew   Male Adult       No\n1036  Crew   Male Adult       No\n1037  Crew   Male Adult       No\n1038  Crew   Male Adult       No\n1039  Crew   Male Adult       No\n1040  Crew   Male Adult       No\n1041  Crew   Male Adult       No\n1042  Crew   Male Adult       No\n1043  Crew   Male Adult       No\n1044  Crew   Male Adult       No\n1045  Crew   Male Adult       No\n1046  Crew   Male Adult       No\n1047  Crew   Male Adult       No\n1048  Crew   Male Adult       No\n1049  Crew   Male Adult       No\n1050  Crew   Male Adult       No\n1051  Crew   Male Adult       No\n1052  Crew   Male Adult       No\n1053  Crew   Male Adult       No\n1054  Crew   Male Adult       No\n1055  Crew   Male Adult       No\n1056  Crew   Male Adult       No\n1057  Crew   Male Adult       No\n1058  Crew   Male Adult       No\n1059  Crew   Male Adult       No\n1060  Crew   Male Adult       No\n1061  Crew   Male Adult       No\n1062  Crew   Male Adult       No\n1063  Crew   Male Adult       No\n1064  Crew   Male Adult       No\n1065  Crew   Male Adult       No\n1066  Crew   Male Adult       No\n1067  Crew   Male Adult       No\n1068  Crew   Male Adult       No\n1069  Crew   Male Adult       No\n1070  Crew   Male Adult       No\n1071  Crew   Male Adult       No\n1072  Crew   Male Adult       No\n1073  Crew   Male Adult       No\n1074  Crew   Male Adult       No\n1075  Crew   Male Adult       No\n1076  Crew   Male Adult       No\n1077  Crew   Male Adult       No\n1078  Crew   Male Adult       No\n1079  Crew   Male Adult       No\n1080  Crew   Male Adult       No\n1081  Crew   Male Adult       No\n1082  Crew   Male Adult       No\n1083  Crew   Male Adult       No\n1084  Crew   Male Adult       No\n1085  Crew   Male Adult       No\n1086  Crew   Male Adult       No\n1087  Crew   Male Adult       No\n1088  Crew   Male Adult       No\n1089  Crew   Male Adult       No\n1090  Crew   Male Adult       No\n1091  Crew   Male Adult       No\n1092  Crew   Male Adult       No\n1093  Crew   Male Adult       No\n1094  Crew   Male Adult       No\n1095  Crew   Male Adult       No\n1096  Crew   Male Adult       No\n1097  Crew   Male Adult       No\n1098  Crew   Male Adult       No\n1099  Crew   Male Adult       No\n1100  Crew   Male Adult       No\n1101  Crew   Male Adult       No\n1102  Crew   Male Adult       No\n1103  Crew   Male Adult       No\n1104  Crew   Male Adult       No\n1105  Crew   Male Adult       No\n1106  Crew   Male Adult       No\n1107  Crew   Male Adult       No\n1108  Crew   Male Adult       No\n1109  Crew   Male Adult       No\n1110  Crew   Male Adult       No\n1111  Crew   Male Adult       No\n1112  Crew   Male Adult       No\n1113  Crew   Male Adult       No\n1114  Crew   Male Adult       No\n1115  Crew   Male Adult       No\n1116  Crew   Male Adult       No\n1117  Crew   Male Adult       No\n1118  Crew   Male Adult       No\n1119  Crew   Male Adult       No\n1120  Crew   Male Adult       No\n1121  Crew   Male Adult       No\n1122  Crew   Male Adult       No\n1123  Crew   Male Adult       No\n1124  Crew   Male Adult       No\n1125  Crew   Male Adult       No\n1126  Crew   Male Adult       No\n1127  Crew   Male Adult       No\n1128  Crew   Male Adult       No\n1129  Crew   Male Adult       No\n1130  Crew   Male Adult       No\n1131  Crew   Male Adult       No\n1132  Crew   Male Adult       No\n1133  Crew   Male Adult       No\n1134  Crew   Male Adult       No\n1135  Crew   Male Adult       No\n1136  Crew   Male Adult       No\n1137  Crew   Male Adult       No\n1138  Crew   Male Adult       No\n1139  Crew   Male Adult       No\n1140  Crew   Male Adult       No\n1141  Crew   Male Adult       No\n1142  Crew   Male Adult       No\n1143  Crew   Male Adult       No\n1144  Crew   Male Adult       No\n1145  Crew   Male Adult       No\n1146  Crew   Male Adult       No\n1147  Crew   Male Adult       No\n1148  Crew   Male Adult       No\n1149  Crew   Male Adult       No\n1150  Crew   Male Adult       No\n1151  Crew   Male Adult       No\n1152  Crew   Male Adult       No\n1153  Crew   Male Adult       No\n1154  Crew   Male Adult       No\n1155  Crew   Male Adult       No\n1156  Crew   Male Adult       No\n1157  Crew   Male Adult       No\n1158  Crew   Male Adult       No\n1159  Crew   Male Adult       No\n1160  Crew   Male Adult       No\n1161  Crew   Male Adult       No\n1162  Crew   Male Adult       No\n1163  Crew   Male Adult       No\n1164  Crew   Male Adult       No\n1165  Crew   Male Adult       No\n1166  Crew   Male Adult       No\n1167  Crew   Male Adult       No\n1168  Crew   Male Adult       No\n1169  Crew   Male Adult       No\n1170  Crew   Male Adult       No\n1171  Crew   Male Adult       No\n1172  Crew   Male Adult       No\n1173  Crew   Male Adult       No\n1174  Crew   Male Adult       No\n1175  Crew   Male Adult       No\n1176  Crew   Male Adult       No\n1177  Crew   Male Adult       No\n1178  Crew   Male Adult       No\n1179  Crew   Male Adult       No\n1180  Crew   Male Adult       No\n1181  Crew   Male Adult       No\n1182  Crew   Male Adult       No\n1183  Crew   Male Adult       No\n1184  Crew   Male Adult       No\n1185  Crew   Male Adult       No\n1186  Crew   Male Adult       No\n1187  Crew   Male Adult       No\n1188  Crew   Male Adult       No\n1189  Crew   Male Adult       No\n1190  Crew   Male Adult       No\n1191  Crew   Male Adult       No\n1192  Crew   Male Adult       No\n1193  Crew   Male Adult       No\n1194  Crew   Male Adult       No\n1195  Crew   Male Adult       No\n1196  Crew   Male Adult       No\n1197  Crew   Male Adult       No\n1198  Crew   Male Adult       No\n1199  Crew   Male Adult       No\n1200  Crew   Male Adult       No\n1201  Crew   Male Adult       No\n1202  Crew   Male Adult       No\n1203  Crew   Male Adult       No\n1204  Crew   Male Adult       No\n1205  Crew   Male Adult       No\n1206  Crew   Male Adult       No\n1207  Crew   Male Adult       No\n1208  Crew   Male Adult       No\n1209  Crew   Male Adult       No\n1210  Crew   Male Adult       No\n1211  Crew   Male Adult       No\n1212  Crew   Male Adult       No\n1213  Crew   Male Adult       No\n1214  Crew   Male Adult       No\n1215  Crew   Male Adult       No\n1216  Crew   Male Adult       No\n1217  Crew   Male Adult       No\n1218  Crew   Male Adult       No\n1219  Crew   Male Adult       No\n1220  Crew   Male Adult       No\n1221  Crew   Male Adult       No\n1222  Crew   Male Adult       No\n1223  Crew   Male Adult       No\n1224  Crew   Male Adult       No\n1225  Crew   Male Adult       No\n1226  Crew   Male Adult       No\n1227  Crew   Male Adult       No\n1228  Crew   Male Adult       No\n1229  Crew   Male Adult       No\n1230  Crew   Male Adult       No\n1231  Crew   Male Adult       No\n1232  Crew   Male Adult       No\n1233  Crew   Male Adult       No\n1234  Crew   Male Adult       No\n1235  Crew   Male Adult       No\n1236  Crew   Male Adult       No\n1237  Crew   Male Adult       No\n1238  Crew   Male Adult       No\n1239  Crew   Male Adult       No\n1240  Crew   Male Adult       No\n1241  Crew   Male Adult       No\n1242  Crew   Male Adult       No\n1243  Crew   Male Adult       No\n1244  Crew   Male Adult       No\n1245  Crew   Male Adult       No\n1246  Crew   Male Adult       No\n1247  Crew   Male Adult       No\n1248  Crew   Male Adult       No\n1249  Crew   Male Adult       No\n1250  Crew   Male Adult       No\n1251  Crew   Male Adult       No\n1252  Crew   Male Adult       No\n1253  Crew   Male Adult       No\n1254  Crew   Male Adult       No\n1255  Crew   Male Adult       No\n1256  Crew   Male Adult       No\n1257  Crew   Male Adult       No\n1258  Crew   Male Adult       No\n1259  Crew   Male Adult       No\n1260  Crew   Male Adult       No\n1261  Crew   Male Adult       No\n1262  Crew   Male Adult       No\n1263  Crew   Male Adult       No\n1264  Crew   Male Adult       No\n1265  Crew   Male Adult       No\n1266  Crew   Male Adult       No\n1267  Crew   Male Adult       No\n1268  Crew   Male Adult       No\n1269  Crew   Male Adult       No\n1270  Crew   Male Adult       No\n1271  Crew   Male Adult       No\n1272  Crew   Male Adult       No\n1273  Crew   Male Adult       No\n1274  Crew   Male Adult       No\n1275  Crew   Male Adult       No\n1276  Crew   Male Adult       No\n1277  Crew   Male Adult       No\n1278  Crew   Male Adult       No\n1279  Crew   Male Adult       No\n1280  Crew   Male Adult       No\n1281  Crew   Male Adult       No\n1282  Crew   Male Adult       No\n1283  Crew   Male Adult       No\n1284  Crew   Male Adult       No\n1285  Crew   Male Adult       No\n1286  Crew   Male Adult       No\n1287  Crew   Male Adult       No\n1288  Crew   Male Adult       No\n1289  Crew   Male Adult       No\n1290  Crew   Male Adult       No\n1291  Crew   Male Adult       No\n1292  Crew   Male Adult       No\n1293  Crew   Male Adult       No\n1294  Crew   Male Adult       No\n1295  Crew   Male Adult       No\n1296  Crew   Male Adult       No\n1297  Crew   Male Adult       No\n1298  Crew   Male Adult       No\n1299  Crew   Male Adult       No\n1300  Crew   Male Adult       No\n1301  Crew   Male Adult       No\n1302  Crew   Male Adult       No\n1303  Crew   Male Adult       No\n1304  Crew   Male Adult       No\n1305  Crew   Male Adult       No\n1306  Crew   Male Adult       No\n1307  Crew   Male Adult       No\n1308  Crew   Male Adult       No\n1309  Crew   Male Adult       No\n1310  Crew   Male Adult       No\n1311  Crew   Male Adult       No\n1312  Crew   Male Adult       No\n1313  Crew   Male Adult       No\n1314  Crew   Male Adult       No\n1315  Crew   Male Adult       No\n1316  Crew   Male Adult       No\n1317  Crew   Male Adult       No\n1318  Crew   Male Adult       No\n1319  Crew   Male Adult       No\n1320  Crew   Male Adult       No\n1321  Crew   Male Adult       No\n1322  Crew   Male Adult       No\n1323  Crew   Male Adult       No\n1324  Crew   Male Adult       No\n1325  Crew   Male Adult       No\n1326  Crew   Male Adult       No\n1327  Crew   Male Adult       No\n1328  Crew   Male Adult       No\n1329  Crew   Male Adult       No\n1330  Crew   Male Adult       No\n1331  Crew   Male Adult       No\n1332  Crew   Male Adult       No\n1333  Crew   Male Adult       No\n1334  Crew   Male Adult       No\n1335  Crew   Male Adult       No\n1336  Crew   Male Adult       No\n1337  Crew   Male Adult       No\n1338  Crew   Male Adult       No\n1339  Crew   Male Adult       No\n1340  Crew   Male Adult       No\n1341  Crew   Male Adult       No\n1342  Crew   Male Adult       No\n1343  Crew   Male Adult       No\n1344  Crew   Male Adult       No\n1345  Crew   Male Adult       No\n1346  Crew   Male Adult       No\n1347  Crew   Male Adult       No\n1348  Crew   Male Adult       No\n1349  Crew   Male Adult       No\n1350  Crew   Male Adult       No\n1351  Crew   Male Adult       No\n1352  Crew   Male Adult       No\n1353  Crew   Male Adult       No\n1354  Crew   Male Adult       No\n1355  Crew   Male Adult       No\n1356  Crew   Male Adult       No\n1357  Crew   Male Adult       No\n1358  Crew   Male Adult       No\n1359  Crew   Male Adult       No\n1360  Crew   Male Adult       No\n1361  Crew   Male Adult       No\n1362  Crew   Male Adult       No\n1363  Crew   Male Adult       No\n1364  Crew   Male Adult       No\n1365  Crew   Male Adult       No\n1366  Crew   Male Adult       No\n1367  Crew   Male Adult       No\n1368  Crew   Male Adult       No\n1369  Crew   Male Adult       No\n1370  Crew   Male Adult       No\n1371  Crew   Male Adult       No\n1372  Crew   Male Adult       No\n1373  Crew   Male Adult       No\n1374  Crew   Male Adult       No\n1375  Crew   Male Adult       No\n1376  Crew   Male Adult       No\n1377  Crew   Male Adult       No\n1378  Crew   Male Adult       No\n1379  Crew   Male Adult       No\n1380  Crew   Male Adult       No\n1381  Crew   Male Adult       No\n1382   1st Female Adult       No\n1383   1st Female Adult       No\n1384   1st Female Adult       No\n1385   1st Female Adult       No\n1386   2nd Female Adult       No\n1387   2nd Female Adult       No\n1388   2nd Female Adult       No\n1389   2nd Female Adult       No\n1390   2nd Female Adult       No\n1391   2nd Female Adult       No\n1392   2nd Female Adult       No\n1393   2nd Female Adult       No\n1394   2nd Female Adult       No\n1395   2nd Female Adult       No\n1396   2nd Female Adult       No\n1397   2nd Female Adult       No\n1398   2nd Female Adult       No\n1399   3rd Female Adult       No\n1400   3rd Female Adult       No\n1401   3rd Female Adult       No\n1402   3rd Female Adult       No\n1403   3rd Female Adult       No\n1404   3rd Female Adult       No\n1405   3rd Female Adult       No\n1406   3rd Female Adult       No\n1407   3rd Female Adult       No\n1408   3rd Female Adult       No\n1409   3rd Female Adult       No\n1410   3rd Female Adult       No\n1411   3rd Female Adult       No\n1412   3rd Female Adult       No\n1413   3rd Female Adult       No\n1414   3rd Female Adult       No\n1415   3rd Female Adult       No\n1416   3rd Female Adult       No\n1417   3rd Female Adult       No\n1418   3rd Female Adult       No\n1419   3rd Female Adult       No\n1420   3rd Female Adult       No\n1421   3rd Female Adult       No\n1422   3rd Female Adult       No\n1423   3rd Female Adult       No\n1424   3rd Female Adult       No\n1425   3rd Female Adult       No\n1426   3rd Female Adult       No\n1427   3rd Female Adult       No\n1428   3rd Female Adult       No\n1429   3rd Female Adult       No\n1430   3rd Female Adult       No\n1431   3rd Female Adult       No\n1432   3rd Female Adult       No\n1433   3rd Female Adult       No\n1434   3rd Female Adult       No\n1435   3rd Female Adult       No\n1436   3rd Female Adult       No\n1437   3rd Female Adult       No\n1438   3rd Female Adult       No\n1439   3rd Female Adult       No\n1440   3rd Female Adult       No\n1441   3rd Female Adult       No\n1442   3rd Female Adult       No\n1443   3rd Female Adult       No\n1444   3rd Female Adult       No\n1445   3rd Female Adult       No\n1446   3rd Female Adult       No\n1447   3rd Female Adult       No\n1448   3rd Female Adult       No\n1449   3rd Female Adult       No\n1450   3rd Female Adult       No\n1451   3rd Female Adult       No\n1452   3rd Female Adult       No\n1453   3rd Female Adult       No\n1454   3rd Female Adult       No\n1455   3rd Female Adult       No\n1456   3rd Female Adult       No\n1457   3rd Female Adult       No\n1458   3rd Female Adult       No\n1459   3rd Female Adult       No\n1460   3rd Female Adult       No\n1461   3rd Female Adult       No\n1462   3rd Female Adult       No\n1463   3rd Female Adult       No\n1464   3rd Female Adult       No\n1465   3rd Female Adult       No\n1466   3rd Female Adult       No\n1467   3rd Female Adult       No\n1468   3rd Female Adult       No\n1469   3rd Female Adult       No\n1470   3rd Female Adult       No\n1471   3rd Female Adult       No\n1472   3rd Female Adult       No\n1473   3rd Female Adult       No\n1474   3rd Female Adult       No\n1475   3rd Female Adult       No\n1476   3rd Female Adult       No\n1477   3rd Female Adult       No\n1478   3rd Female Adult       No\n1479   3rd Female Adult       No\n1480   3rd Female Adult       No\n1481   3rd Female Adult       No\n1482   3rd Female Adult       No\n1483   3rd Female Adult       No\n1484   3rd Female Adult       No\n1485   3rd Female Adult       No\n1486   3rd Female Adult       No\n1487   3rd Female Adult       No\n1488  Crew Female Adult       No\n1489  Crew Female Adult       No\n1490  Crew Female Adult       No\n1491   1st   Male Child      Yes\n1492   1st   Male Child      Yes\n1493   1st   Male Child      Yes\n1494   1st   Male Child      Yes\n1495   1st   Male Child      Yes\n1496   2nd   Male Child      Yes\n1497   2nd   Male Child      Yes\n1498   2nd   Male Child      Yes\n1499   2nd   Male Child      Yes\n1500   2nd   Male Child      Yes\n1501   2nd   Male Child      Yes\n1502   2nd   Male Child      Yes\n1503   2nd   Male Child      Yes\n1504   2nd   Male Child      Yes\n1505   2nd   Male Child      Yes\n1506   2nd   Male Child      Yes\n1507   3rd   Male Child      Yes\n1508   3rd   Male Child      Yes\n1509   3rd   Male Child      Yes\n1510   3rd   Male Child      Yes\n1511   3rd   Male Child      Yes\n1512   3rd   Male Child      Yes\n1513   3rd   Male Child      Yes\n1514   3rd   Male Child      Yes\n1515   3rd   Male Child      Yes\n1516   3rd   Male Child      Yes\n1517   3rd   Male Child      Yes\n1518   3rd   Male Child      Yes\n1519   3rd   Male Child      Yes\n1520   1st Female Child      Yes\n1521   2nd Female Child      Yes\n1522   2nd Female Child      Yes\n1523   2nd Female Child      Yes\n1524   2nd Female Child      Yes\n1525   2nd Female Child      Yes\n1526   2nd Female Child      Yes\n1527   2nd Female Child      Yes\n1528   2nd Female Child      Yes\n1529   2nd Female Child      Yes\n1530   2nd Female Child      Yes\n1531   2nd Female Child      Yes\n1532   2nd Female Child      Yes\n1533   2nd Female Child      Yes\n1534   3rd Female Child      Yes\n1535   3rd Female Child      Yes\n1536   3rd Female Child      Yes\n1537   3rd Female Child      Yes\n1538   3rd Female Child      Yes\n1539   3rd Female Child      Yes\n1540   3rd Female Child      Yes\n1541   3rd Female Child      Yes\n1542   3rd Female Child      Yes\n1543   3rd Female Child      Yes\n1544   3rd Female Child      Yes\n1545   3rd Female Child      Yes\n1546   3rd Female Child      Yes\n1547   3rd Female Child      Yes\n1548   1st   Male Adult      Yes\n1549   1st   Male Adult      Yes\n1550   1st   Male Adult      Yes\n1551   1st   Male Adult      Yes\n1552   1st   Male Adult      Yes\n1553   1st   Male Adult      Yes\n1554   1st   Male Adult      Yes\n1555   1st   Male Adult      Yes\n1556   1st   Male Adult      Yes\n1557   1st   Male Adult      Yes\n1558   1st   Male Adult      Yes\n1559   1st   Male Adult      Yes\n1560   1st   Male Adult      Yes\n1561   1st   Male Adult      Yes\n1562   1st   Male Adult      Yes\n1563   1st   Male Adult      Yes\n1564   1st   Male Adult      Yes\n1565   1st   Male Adult      Yes\n1566   1st   Male Adult      Yes\n1567   1st   Male Adult      Yes\n1568   1st   Male Adult      Yes\n1569   1st   Male Adult      Yes\n1570   1st   Male Adult      Yes\n1571   1st   Male Adult      Yes\n1572   1st   Male Adult      Yes\n1573   1st   Male Adult      Yes\n1574   1st   Male Adult      Yes\n1575   1st   Male Adult      Yes\n1576   1st   Male Adult      Yes\n1577   1st   Male Adult      Yes\n1578   1st   Male Adult      Yes\n1579   1st   Male Adult      Yes\n1580   1st   Male Adult      Yes\n1581   1st   Male Adult      Yes\n1582   1st   Male Adult      Yes\n1583   1st   Male Adult      Yes\n1584   1st   Male Adult      Yes\n1585   1st   Male Adult      Yes\n1586   1st   Male Adult      Yes\n1587   1st   Male Adult      Yes\n1588   1st   Male Adult      Yes\n1589   1st   Male Adult      Yes\n1590   1st   Male Adult      Yes\n1591   1st   Male Adult      Yes\n1592   1st   Male Adult      Yes\n1593   1st   Male Adult      Yes\n1594   1st   Male Adult      Yes\n1595   1st   Male Adult      Yes\n1596   1st   Male Adult      Yes\n1597   1st   Male Adult      Yes\n1598   1st   Male Adult      Yes\n1599   1st   Male Adult      Yes\n1600   1st   Male Adult      Yes\n1601   1st   Male Adult      Yes\n1602   1st   Male Adult      Yes\n1603   1st   Male Adult      Yes\n1604   1st   Male Adult      Yes\n1605   2nd   Male Adult      Yes\n1606   2nd   Male Adult      Yes\n1607   2nd   Male Adult      Yes\n1608   2nd   Male Adult      Yes\n1609   2nd   Male Adult      Yes\n1610   2nd   Male Adult      Yes\n1611   2nd   Male Adult      Yes\n1612   2nd   Male Adult      Yes\n1613   2nd   Male Adult      Yes\n1614   2nd   Male Adult      Yes\n1615   2nd   Male Adult      Yes\n1616   2nd   Male Adult      Yes\n1617   2nd   Male Adult      Yes\n1618   2nd   Male Adult      Yes\n1619   3rd   Male Adult      Yes\n1620   3rd   Male Adult      Yes\n1621   3rd   Male Adult      Yes\n1622   3rd   Male Adult      Yes\n1623   3rd   Male Adult      Yes\n1624   3rd   Male Adult      Yes\n1625   3rd   Male Adult      Yes\n1626   3rd   Male Adult      Yes\n1627   3rd   Male Adult      Yes\n1628   3rd   Male Adult      Yes\n1629   3rd   Male Adult      Yes\n1630   3rd   Male Adult      Yes\n1631   3rd   Male Adult      Yes\n1632   3rd   Male Adult      Yes\n1633   3rd   Male Adult      Yes\n1634   3rd   Male Adult      Yes\n1635   3rd   Male Adult      Yes\n1636   3rd   Male Adult      Yes\n1637   3rd   Male Adult      Yes\n1638   3rd   Male Adult      Yes\n1639   3rd   Male Adult      Yes\n1640   3rd   Male Adult      Yes\n1641   3rd   Male Adult      Yes\n1642   3rd   Male Adult      Yes\n1643   3rd   Male Adult      Yes\n1644   3rd   Male Adult      Yes\n1645   3rd   Male Adult      Yes\n1646   3rd   Male Adult      Yes\n1647   3rd   Male Adult      Yes\n1648   3rd   Male Adult      Yes\n1649   3rd   Male Adult      Yes\n1650   3rd   Male Adult      Yes\n1651   3rd   Male Adult      Yes\n1652   3rd   Male Adult      Yes\n1653   3rd   Male Adult      Yes\n1654   3rd   Male Adult      Yes\n1655   3rd   Male Adult      Yes\n1656   3rd   Male Adult      Yes\n1657   3rd   Male Adult      Yes\n1658   3rd   Male Adult      Yes\n1659   3rd   Male Adult      Yes\n1660   3rd   Male Adult      Yes\n1661   3rd   Male Adult      Yes\n1662   3rd   Male Adult      Yes\n1663   3rd   Male Adult      Yes\n1664   3rd   Male Adult      Yes\n1665   3rd   Male Adult      Yes\n1666   3rd   Male Adult      Yes\n1667   3rd   Male Adult      Yes\n1668   3rd   Male Adult      Yes\n1669   3rd   Male Adult      Yes\n1670   3rd   Male Adult      Yes\n1671   3rd   Male Adult      Yes\n1672   3rd   Male Adult      Yes\n1673   3rd   Male Adult      Yes\n1674   3rd   Male Adult      Yes\n1675   3rd   Male Adult      Yes\n1676   3rd   Male Adult      Yes\n1677   3rd   Male Adult      Yes\n1678   3rd   Male Adult      Yes\n1679   3rd   Male Adult      Yes\n1680   3rd   Male Adult      Yes\n1681   3rd   Male Adult      Yes\n1682   3rd   Male Adult      Yes\n1683   3rd   Male Adult      Yes\n1684   3rd   Male Adult      Yes\n1685   3rd   Male Adult      Yes\n1686   3rd   Male Adult      Yes\n1687   3rd   Male Adult      Yes\n1688   3rd   Male Adult      Yes\n1689   3rd   Male Adult      Yes\n1690   3rd   Male Adult      Yes\n1691   3rd   Male Adult      Yes\n1692   3rd   Male Adult      Yes\n1693   3rd   Male Adult      Yes\n1694  Crew   Male Adult      Yes\n1695  Crew   Male Adult      Yes\n1696  Crew   Male Adult      Yes\n1697  Crew   Male Adult      Yes\n1698  Crew   Male Adult      Yes\n1699  Crew   Male Adult      Yes\n1700  Crew   Male Adult      Yes\n1701  Crew   Male Adult      Yes\n1702  Crew   Male Adult      Yes\n1703  Crew   Male Adult      Yes\n1704  Crew   Male Adult      Yes\n1705  Crew   Male Adult      Yes\n1706  Crew   Male Adult      Yes\n1707  Crew   Male Adult      Yes\n1708  Crew   Male Adult      Yes\n1709  Crew   Male Adult      Yes\n1710  Crew   Male Adult      Yes\n1711  Crew   Male Adult      Yes\n1712  Crew   Male Adult      Yes\n1713  Crew   Male Adult      Yes\n1714  Crew   Male Adult      Yes\n1715  Crew   Male Adult      Yes\n1716  Crew   Male Adult      Yes\n1717  Crew   Male Adult      Yes\n1718  Crew   Male Adult      Yes\n1719  Crew   Male Adult      Yes\n1720  Crew   Male Adult      Yes\n1721  Crew   Male Adult      Yes\n1722  Crew   Male Adult      Yes\n1723  Crew   Male Adult      Yes\n1724  Crew   Male Adult      Yes\n1725  Crew   Male Adult      Yes\n1726  Crew   Male Adult      Yes\n1727  Crew   Male Adult      Yes\n1728  Crew   Male Adult      Yes\n1729  Crew   Male Adult      Yes\n1730  Crew   Male Adult      Yes\n1731  Crew   Male Adult      Yes\n1732  Crew   Male Adult      Yes\n1733  Crew   Male Adult      Yes\n1734  Crew   Male Adult      Yes\n1735  Crew   Male Adult      Yes\n1736  Crew   Male Adult      Yes\n1737  Crew   Male Adult      Yes\n1738  Crew   Male Adult      Yes\n1739  Crew   Male Adult      Yes\n1740  Crew   Male Adult      Yes\n1741  Crew   Male Adult      Yes\n1742  Crew   Male Adult      Yes\n1743  Crew   Male Adult      Yes\n1744  Crew   Male Adult      Yes\n1745  Crew   Male Adult      Yes\n1746  Crew   Male Adult      Yes\n1747  Crew   Male Adult      Yes\n1748  Crew   Male Adult      Yes\n1749  Crew   Male Adult      Yes\n1750  Crew   Male Adult      Yes\n1751  Crew   Male Adult      Yes\n1752  Crew   Male Adult      Yes\n1753  Crew   Male Adult      Yes\n1754  Crew   Male Adult      Yes\n1755  Crew   Male Adult      Yes\n1756  Crew   Male Adult      Yes\n1757  Crew   Male Adult      Yes\n1758  Crew   Male Adult      Yes\n1759  Crew   Male Adult      Yes\n1760  Crew   Male Adult      Yes\n1761  Crew   Male Adult      Yes\n1762  Crew   Male Adult      Yes\n1763  Crew   Male Adult      Yes\n1764  Crew   Male Adult      Yes\n1765  Crew   Male Adult      Yes\n1766  Crew   Male Adult      Yes\n1767  Crew   Male Adult      Yes\n1768  Crew   Male Adult      Yes\n1769  Crew   Male Adult      Yes\n1770  Crew   Male Adult      Yes\n1771  Crew   Male Adult      Yes\n1772  Crew   Male Adult      Yes\n1773  Crew   Male Adult      Yes\n1774  Crew   Male Adult      Yes\n1775  Crew   Male Adult      Yes\n1776  Crew   Male Adult      Yes\n1777  Crew   Male Adult      Yes\n1778  Crew   Male Adult      Yes\n1779  Crew   Male Adult      Yes\n1780  Crew   Male Adult      Yes\n1781  Crew   Male Adult      Yes\n1782  Crew   Male Adult      Yes\n1783  Crew   Male Adult      Yes\n1784  Crew   Male Adult      Yes\n1785  Crew   Male Adult      Yes\n1786  Crew   Male Adult      Yes\n1787  Crew   Male Adult      Yes\n1788  Crew   Male Adult      Yes\n1789  Crew   Male Adult      Yes\n1790  Crew   Male Adult      Yes\n1791  Crew   Male Adult      Yes\n1792  Crew   Male Adult      Yes\n1793  Crew   Male Adult      Yes\n1794  Crew   Male Adult      Yes\n1795  Crew   Male Adult      Yes\n1796  Crew   Male Adult      Yes\n1797  Crew   Male Adult      Yes\n1798  Crew   Male Adult      Yes\n1799  Crew   Male Adult      Yes\n1800  Crew   Male Adult      Yes\n1801  Crew   Male Adult      Yes\n1802  Crew   Male Adult      Yes\n1803  Crew   Male Adult      Yes\n1804  Crew   Male Adult      Yes\n1805  Crew   Male Adult      Yes\n1806  Crew   Male Adult      Yes\n1807  Crew   Male Adult      Yes\n1808  Crew   Male Adult      Yes\n1809  Crew   Male Adult      Yes\n1810  Crew   Male Adult      Yes\n1811  Crew   Male Adult      Yes\n1812  Crew   Male Adult      Yes\n1813  Crew   Male Adult      Yes\n1814  Crew   Male Adult      Yes\n1815  Crew   Male Adult      Yes\n1816  Crew   Male Adult      Yes\n1817  Crew   Male Adult      Yes\n1818  Crew   Male Adult      Yes\n1819  Crew   Male Adult      Yes\n1820  Crew   Male Adult      Yes\n1821  Crew   Male Adult      Yes\n1822  Crew   Male Adult      Yes\n1823  Crew   Male Adult      Yes\n1824  Crew   Male Adult      Yes\n1825  Crew   Male Adult      Yes\n1826  Crew   Male Adult      Yes\n1827  Crew   Male Adult      Yes\n1828  Crew   Male Adult      Yes\n1829  Crew   Male Adult      Yes\n1830  Crew   Male Adult      Yes\n1831  Crew   Male Adult      Yes\n1832  Crew   Male Adult      Yes\n1833  Crew   Male Adult      Yes\n1834  Crew   Male Adult      Yes\n1835  Crew   Male Adult      Yes\n1836  Crew   Male Adult      Yes\n1837  Crew   Male Adult      Yes\n1838  Crew   Male Adult      Yes\n1839  Crew   Male Adult      Yes\n1840  Crew   Male Adult      Yes\n1841  Crew   Male Adult      Yes\n1842  Crew   Male Adult      Yes\n1843  Crew   Male Adult      Yes\n1844  Crew   Male Adult      Yes\n1845  Crew   Male Adult      Yes\n1846  Crew   Male Adult      Yes\n1847  Crew   Male Adult      Yes\n1848  Crew   Male Adult      Yes\n1849  Crew   Male Adult      Yes\n1850  Crew   Male Adult      Yes\n1851  Crew   Male Adult      Yes\n1852  Crew   Male Adult      Yes\n1853  Crew   Male Adult      Yes\n1854  Crew   Male Adult      Yes\n1855  Crew   Male Adult      Yes\n1856  Crew   Male Adult      Yes\n1857  Crew   Male Adult      Yes\n1858  Crew   Male Adult      Yes\n1859  Crew   Male Adult      Yes\n1860  Crew   Male Adult      Yes\n1861  Crew   Male Adult      Yes\n1862  Crew   Male Adult      Yes\n1863  Crew   Male Adult      Yes\n1864  Crew   Male Adult      Yes\n1865  Crew   Male Adult      Yes\n1866  Crew   Male Adult      Yes\n1867  Crew   Male Adult      Yes\n1868  Crew   Male Adult      Yes\n1869  Crew   Male Adult      Yes\n1870  Crew   Male Adult      Yes\n1871  Crew   Male Adult      Yes\n1872  Crew   Male Adult      Yes\n1873  Crew   Male Adult      Yes\n1874  Crew   Male Adult      Yes\n1875  Crew   Male Adult      Yes\n1876  Crew   Male Adult      Yes\n1877  Crew   Male Adult      Yes\n1878  Crew   Male Adult      Yes\n1879  Crew   Male Adult      Yes\n1880  Crew   Male Adult      Yes\n1881  Crew   Male Adult      Yes\n1882  Crew   Male Adult      Yes\n1883  Crew   Male Adult      Yes\n1884  Crew   Male Adult      Yes\n1885  Crew   Male Adult      Yes\n1886   1st Female Adult      Yes\n1887   1st Female Adult      Yes\n1888   1st Female Adult      Yes\n1889   1st Female Adult      Yes\n1890   1st Female Adult      Yes\n1891   1st Female Adult      Yes\n1892   1st Female Adult      Yes\n1893   1st Female Adult      Yes\n1894   1st Female Adult      Yes\n1895   1st Female Adult      Yes\n1896   1st Female Adult      Yes\n1897   1st Female Adult      Yes\n1898   1st Female Adult      Yes\n1899   1st Female Adult      Yes\n1900   1st Female Adult      Yes\n1901   1st Female Adult      Yes\n1902   1st Female Adult      Yes\n1903   1st Female Adult      Yes\n1904   1st Female Adult      Yes\n1905   1st Female Adult      Yes\n1906   1st Female Adult      Yes\n1907   1st Female Adult      Yes\n1908   1st Female Adult      Yes\n1909   1st Female Adult      Yes\n1910   1st Female Adult      Yes\n1911   1st Female Adult      Yes\n1912   1st Female Adult      Yes\n1913   1st Female Adult      Yes\n1914   1st Female Adult      Yes\n1915   1st Female Adult      Yes\n1916   1st Female Adult      Yes\n1917   1st Female Adult      Yes\n1918   1st Female Adult      Yes\n1919   1st Female Adult      Yes\n1920   1st Female Adult      Yes\n1921   1st Female Adult      Yes\n1922   1st Female Adult      Yes\n1923   1st Female Adult      Yes\n1924   1st Female Adult      Yes\n1925   1st Female Adult      Yes\n1926   1st Female Adult      Yes\n1927   1st Female Adult      Yes\n1928   1st Female Adult      Yes\n1929   1st Female Adult      Yes\n1930   1st Female Adult      Yes\n1931   1st Female Adult      Yes\n1932   1st Female Adult      Yes\n1933   1st Female Adult      Yes\n1934   1st Female Adult      Yes\n1935   1st Female Adult      Yes\n1936   1st Female Adult      Yes\n1937   1st Female Adult      Yes\n1938   1st Female Adult      Yes\n1939   1st Female Adult      Yes\n1940   1st Female Adult      Yes\n1941   1st Female Adult      Yes\n1942   1st Female Adult      Yes\n1943   1st Female Adult      Yes\n1944   1st Female Adult      Yes\n1945   1st Female Adult      Yes\n1946   1st Female Adult      Yes\n1947   1st Female Adult      Yes\n1948   1st Female Adult      Yes\n1949   1st Female Adult      Yes\n1950   1st Female Adult      Yes\n1951   1st Female Adult      Yes\n1952   1st Female Adult      Yes\n1953   1st Female Adult      Yes\n1954   1st Female Adult      Yes\n1955   1st Female Adult      Yes\n1956   1st Female Adult      Yes\n1957   1st Female Adult      Yes\n1958   1st Female Adult      Yes\n1959   1st Female Adult      Yes\n1960   1st Female Adult      Yes\n1961   1st Female Adult      Yes\n1962   1st Female Adult      Yes\n1963   1st Female Adult      Yes\n1964   1st Female Adult      Yes\n1965   1st Female Adult      Yes\n1966   1st Female Adult      Yes\n1967   1st Female Adult      Yes\n1968   1st Female Adult      Yes\n1969   1st Female Adult      Yes\n1970   1st Female Adult      Yes\n1971   1st Female Adult      Yes\n1972   1st Female Adult      Yes\n1973   1st Female Adult      Yes\n1974   1st Female Adult      Yes\n1975   1st Female Adult      Yes\n1976   1st Female Adult      Yes\n1977   1st Female Adult      Yes\n1978   1st Female Adult      Yes\n1979   1st Female Adult      Yes\n1980   1st Female Adult      Yes\n1981   1st Female Adult      Yes\n1982   1st Female Adult      Yes\n1983   1st Female Adult      Yes\n1984   1st Female Adult      Yes\n1985   1st Female Adult      Yes\n1986   1st Female Adult      Yes\n1987   1st Female Adult      Yes\n1988   1st Female Adult      Yes\n1989   1st Female Adult      Yes\n1990   1st Female Adult      Yes\n1991   1st Female Adult      Yes\n1992   1st Female Adult      Yes\n1993   1st Female Adult      Yes\n1994   1st Female Adult      Yes\n1995   1st Female Adult      Yes\n1996   1st Female Adult      Yes\n1997   1st Female Adult      Yes\n1998   1st Female Adult      Yes\n1999   1st Female Adult      Yes\n2000   1st Female Adult      Yes\n2001   1st Female Adult      Yes\n2002   1st Female Adult      Yes\n2003   1st Female Adult      Yes\n2004   1st Female Adult      Yes\n2005   1st Female Adult      Yes\n2006   1st Female Adult      Yes\n2007   1st Female Adult      Yes\n2008   1st Female Adult      Yes\n2009   1st Female Adult      Yes\n2010   1st Female Adult      Yes\n2011   1st Female Adult      Yes\n2012   1st Female Adult      Yes\n2013   1st Female Adult      Yes\n2014   1st Female Adult      Yes\n2015   1st Female Adult      Yes\n2016   1st Female Adult      Yes\n2017   1st Female Adult      Yes\n2018   1st Female Adult      Yes\n2019   1st Female Adult      Yes\n2020   1st Female Adult      Yes\n2021   1st Female Adult      Yes\n2022   1st Female Adult      Yes\n2023   1st Female Adult      Yes\n2024   1st Female Adult      Yes\n2025   1st Female Adult      Yes\n2026   2nd Female Adult      Yes\n2027   2nd Female Adult      Yes\n2028   2nd Female Adult      Yes\n2029   2nd Female Adult      Yes\n2030   2nd Female Adult      Yes\n2031   2nd Female Adult      Yes\n2032   2nd Female Adult      Yes\n2033   2nd Female Adult      Yes\n2034   2nd Female Adult      Yes\n2035   2nd Female Adult      Yes\n2036   2nd Female Adult      Yes\n2037   2nd Female Adult      Yes\n2038   2nd Female Adult      Yes\n2039   2nd Female Adult      Yes\n2040   2nd Female Adult      Yes\n2041   2nd Female Adult      Yes\n2042   2nd Female Adult      Yes\n2043   2nd Female Adult      Yes\n2044   2nd Female Adult      Yes\n2045   2nd Female Adult      Yes\n2046   2nd Female Adult      Yes\n2047   2nd Female Adult      Yes\n2048   2nd Female Adult      Yes\n2049   2nd Female Adult      Yes\n2050   2nd Female Adult      Yes\n2051   2nd Female Adult      Yes\n2052   2nd Female Adult      Yes\n2053   2nd Female Adult      Yes\n2054   2nd Female Adult      Yes\n2055   2nd Female Adult      Yes\n2056   2nd Female Adult      Yes\n2057   2nd Female Adult      Yes\n2058   2nd Female Adult      Yes\n2059   2nd Female Adult      Yes\n2060   2nd Female Adult      Yes\n2061   2nd Female Adult      Yes\n2062   2nd Female Adult      Yes\n2063   2nd Female Adult      Yes\n2064   2nd Female Adult      Yes\n2065   2nd Female Adult      Yes\n2066   2nd Female Adult      Yes\n2067   2nd Female Adult      Yes\n2068   2nd Female Adult      Yes\n2069   2nd Female Adult      Yes\n2070   2nd Female Adult      Yes\n2071   2nd Female Adult      Yes\n2072   2nd Female Adult      Yes\n2073   2nd Female Adult      Yes\n2074   2nd Female Adult      Yes\n2075   2nd Female Adult      Yes\n2076   2nd Female Adult      Yes\n2077   2nd Female Adult      Yes\n2078   2nd Female Adult      Yes\n2079   2nd Female Adult      Yes\n2080   2nd Female Adult      Yes\n2081   2nd Female Adult      Yes\n2082   2nd Female Adult      Yes\n2083   2nd Female Adult      Yes\n2084   2nd Female Adult      Yes\n2085   2nd Female Adult      Yes\n2086   2nd Female Adult      Yes\n2087   2nd Female Adult      Yes\n2088   2nd Female Adult      Yes\n2089   2nd Female Adult      Yes\n2090   2nd Female Adult      Yes\n2091   2nd Female Adult      Yes\n2092   2nd Female Adult      Yes\n2093   2nd Female Adult      Yes\n2094   2nd Female Adult      Yes\n2095   2nd Female Adult      Yes\n2096   2nd Female Adult      Yes\n2097   2nd Female Adult      Yes\n2098   2nd Female Adult      Yes\n2099   2nd Female Adult      Yes\n2100   2nd Female Adult      Yes\n2101   2nd Female Adult      Yes\n2102   2nd Female Adult      Yes\n2103   2nd Female Adult      Yes\n2104   2nd Female Adult      Yes\n2105   2nd Female Adult      Yes\n2106   3rd Female Adult      Yes\n2107   3rd Female Adult      Yes\n2108   3rd Female Adult      Yes\n2109   3rd Female Adult      Yes\n2110   3rd Female Adult      Yes\n2111   3rd Female Adult      Yes\n2112   3rd Female Adult      Yes\n2113   3rd Female Adult      Yes\n2114   3rd Female Adult      Yes\n2115   3rd Female Adult      Yes\n2116   3rd Female Adult      Yes\n2117   3rd Female Adult      Yes\n2118   3rd Female Adult      Yes\n2119   3rd Female Adult      Yes\n2120   3rd Female Adult      Yes\n2121   3rd Female Adult      Yes\n2122   3rd Female Adult      Yes\n2123   3rd Female Adult      Yes\n2124   3rd Female Adult      Yes\n2125   3rd Female Adult      Yes\n2126   3rd Female Adult      Yes\n2127   3rd Female Adult      Yes\n2128   3rd Female Adult      Yes\n2129   3rd Female Adult      Yes\n2130   3rd Female Adult      Yes\n2131   3rd Female Adult      Yes\n2132   3rd Female Adult      Yes\n2133   3rd Female Adult      Yes\n2134   3rd Female Adult      Yes\n2135   3rd Female Adult      Yes\n2136   3rd Female Adult      Yes\n2137   3rd Female Adult      Yes\n2138   3rd Female Adult      Yes\n2139   3rd Female Adult      Yes\n2140   3rd Female Adult      Yes\n2141   3rd Female Adult      Yes\n2142   3rd Female Adult      Yes\n2143   3rd Female Adult      Yes\n2144   3rd Female Adult      Yes\n2145   3rd Female Adult      Yes\n2146   3rd Female Adult      Yes\n2147   3rd Female Adult      Yes\n2148   3rd Female Adult      Yes\n2149   3rd Female Adult      Yes\n2150   3rd Female Adult      Yes\n2151   3rd Female Adult      Yes\n2152   3rd Female Adult      Yes\n2153   3rd Female Adult      Yes\n2154   3rd Female Adult      Yes\n2155   3rd Female Adult      Yes\n2156   3rd Female Adult      Yes\n2157   3rd Female Adult      Yes\n2158   3rd Female Adult      Yes\n2159   3rd Female Adult      Yes\n2160   3rd Female Adult      Yes\n2161   3rd Female Adult      Yes\n2162   3rd Female Adult      Yes\n2163   3rd Female Adult      Yes\n2164   3rd Female Adult      Yes\n2165   3rd Female Adult      Yes\n2166   3rd Female Adult      Yes\n2167   3rd Female Adult      Yes\n2168   3rd Female Adult      Yes\n2169   3rd Female Adult      Yes\n2170   3rd Female Adult      Yes\n2171   3rd Female Adult      Yes\n2172   3rd Female Adult      Yes\n2173   3rd Female Adult      Yes\n2174   3rd Female Adult      Yes\n2175   3rd Female Adult      Yes\n2176   3rd Female Adult      Yes\n2177   3rd Female Adult      Yes\n2178   3rd Female Adult      Yes\n2179   3rd Female Adult      Yes\n2180   3rd Female Adult      Yes\n2181   3rd Female Adult      Yes\n2182  Crew Female Adult      Yes\n2183  Crew Female Adult      Yes\n2184  Crew Female Adult      Yes\n2185  Crew Female Adult      Yes\n2186  Crew Female Adult      Yes\n2187  Crew Female Adult      Yes\n2188  Crew Female Adult      Yes\n2189  Crew Female Adult      Yes\n2190  Crew Female Adult      Yes\n2191  Crew Female Adult      Yes\n2192  Crew Female Adult      Yes\n2193  Crew Female Adult      Yes\n2194  Crew Female Adult      Yes\n2195  Crew Female Adult      Yes\n2196  Crew Female Adult      Yes\n2197  Crew Female Adult      Yes\n2198  Crew Female Adult      Yes\n2199  Crew Female Adult      Yes\n2200  Crew Female Adult      Yes\n2201  Crew Female Adult      Yes\n\n\n\ntitanic_table &lt;- vcd::structable(Survived ~ Sex, data = titanic)\nvcd::mosaic(titanic_table,\n            gp = shading_max, direction = \"v\",\n            main = \"Arthritis Treatment Dataset\",\nlabeling = labeling_border(\n                varnames = c(\"F\", \"F\"), # Remove variable name labels\n                rot_labels = c(90,0,0,0), #t,r,b,l\n                just_labels = c(\"left\", \n                                \"left\", \n                                \"left\", \n                                \"right\")))\n\n\n\n\n\n\n\n\n\ntitanic_table &lt;- vcd::structable(Sex ~ Survived, data = titanic)\nvcd::mosaic(titanic_table,\n            gp = shading_max, direction = \"v\",\n            main = \"Arthritis Treatment Dataset\",\nlabeling = labeling_border(\n                varnames = c(\"F\", \"F\"), # Remove variable name labels\n                rot_labels = c(90,0,0,0), #t,r,b,l\n                just_labels = c(\"left\", \n                                \"left\", \n                                \"left\", \n                                \"right\"))) \n\n\n\n\n\n\n\n\n\nvcd::mosaic(Improved ~ Treatment, data = Arthritis, \n            direction = \"v\", gp = shading_max)\n\n\n\n\n\n\n\n\n\nvcd::mosaic(Improved ~ Treatment, data = Arthritis, \n            type = \"expected\", direction = \"v\", gp = shading_max)\n\n\n\n\n\n\n\n\n\nvcd::assoc(Improved ~ Treatment, # Note formula direction!\n           data = Arthritis, \n           gp = shading_max, \n           legend = FALSE) \n\n\n\n\n\n\n\n\n\nvcd::assoc(Treatment ~ Improved, # Note formula direction!\n           data = Arthritis, \n           gp = shading_max, \n           legend = FALSE) \n\n\n\n\n\n\n\n\n\nFertility &lt;- readr::read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Fertility.csv\") %&gt;% \njanitor::clean_names(case=\"snake\")\n\nRows: 254654 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): morekids, gender1, gender2, afam, hispanic, other\ndbl (3): rownames, age, work\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(Fertility)\n\nRows: 254,654\nColumns: 9\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ morekids &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ gender1  &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"female\",…\n$ gender2  &lt;chr&gt; \"female\", \"male\", \"female\", \"female\", \"female\", \"female\", \"ma…\n$ age      &lt;dbl&gt; 27, 30, 27, 35, 30, 26, 29, 33, 29, 27, 28, 28, 35, 34, 32, 2…\n$ afam     &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ hispanic &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ other    &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ work     &lt;dbl&gt; 0, 30, 0, 0, 22, 40, 0, 52, 0, 0, 0, 52, 52, 52, 8, 7, 0, 40,…\n\n\n\nFertility_ethnicity &lt;- Fertility %&gt;%\n  mutate(ethnicity = case_when(\n    afam == \"yes\" & hispanic == \"no\" & other == \"no\" ~ \"Afam\",\n    afam == \"no\" & hispanic == \"yes\" & other == \"no\" ~ \"Hispanic\",\n    afam == \"no\" & hispanic == \"no\" & other == \"yes\" ~ \"Other\",\n    afam == \"no\" & hispanic == \"no\" & other == \"no\" ~ \"Caucasian\",\n    afam == \"yes\" & hispanic == \"yes\" & other == \"no\" ~ \"AfamHispanic\",\n    afam == \"yes\" & hispanic == \"no\" & other == \"yes\" ~ \"AfamOther\",\n    afam == \"no\" & hispanic == \"yes\" & other == \"yes\" ~ \"HispanicOther\"\n  ))\n  \nFertility_ethnicity\n\n# A tibble: 254,654 × 10\n   rownames morekids gender1 gender2   age afam  hispanic other  work ethnicity\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    \n 1        1 no       male    female     27 no    no       no        0 Caucasian\n 2        2 no       female  male       30 no    no       no       30 Caucasian\n 3        3 no       male    female     27 no    no       no        0 Caucasian\n 4        4 no       male    female     35 yes   no       no        0 Afam     \n 5        5 no       female  female     30 no    no       no       22 Caucasian\n 6        6 no       male    female     26 no    no       no       40 Caucasian\n 7        7 no       female  male       29 no    no       no        0 Caucasian\n 8        8 no       male    male       33 no    no       no       52 Caucasian\n 9        9 no       female  male       29 no    no       no        0 Caucasian\n10       10 no       male    female     27 no    no       no        0 Caucasian\n# ℹ 254,644 more rows\n\n\n\nvcd::mosaic(morekids ~ ethnicity, data = Fertility_ethnicity, \n            direction = \"v\", gp = shading_max)"
  },
  {
    "objectID": "classwork/classwork4/index.html",
    "href": "classwork/classwork4/index.html",
    "title": "Classwork 4",
    "section": "",
    "text": "Setup\n\nlibrary(tidyverse) # Sine qua non\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic) # Out all-in-one package\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula) # Graphing package\nlibrary(skimr) # Looking at Data\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(janitor) # Clean the data\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(naniar) # Handle missing data\n\n\nAttaching package: 'naniar'\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\nlibrary(visdat) # Visualise missing data\nlibrary(tinytable) # Printing Static Tables for our data\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(DT) # Interactive Tables for our data\nlibrary(crosstable) # Multiple variable summaries\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\n\n\n\nReading csv file\n\ntaxi &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/taxi.csv\")\n\nRows: 10000 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): tip, company, local, dow, month\ndbl (3): rownames, distance, hour\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntaxi_modified &lt;- taxi %&gt;%\n  naniar::replace_with_na_all(condition = ~ .x %in% common_na_strings) %&gt;%\n  naniar::replace_with_na_all(condition = ~ .x %in% common_na_numbers) %&gt;%\n  janitor::clean_names(case = \"snake\") %&gt;%\n  janitor::remove_empty()\n\nvalue for \"which\" not specified, defaulting to c(\"rows\", \"cols\")\n\ntaxi_modified\n\n# A tibble: 10,000 × 8\n   rownames tip   distance company                      local dow   month  hour\n      &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;                        &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1        1 yes      17.2  Chicago Independents         no    Thu   Feb      16\n 2        2 yes       0.88 City Service                 yes   Thu   Mar       8\n 3        3 yes      18.1  other                        no    Mon   Feb      18\n 4        4 yes      20.7  Chicago Independents         no    Mon   Apr       8\n 5        5 yes      12.2  Chicago Independents         no    Sun   Mar      21\n 6        6 yes       0.94 Sun Taxi                     yes   Sat   Apr      23\n 7        7 yes      17.5  Flash Cab                    no    Fri   Mar      12\n 8        8 yes      17.7  other                        no    Sun   Jan       6\n 9        9 yes       1.85 Taxicab Insurance Agency Llc no    Fri   Apr      12\n10       10 yes       1.47 City Service                 no    Tue   Mar      14\n# ℹ 9,990 more rows\n\n\n\n\nTheme chosing\n\nRColorBrewer::display.brewer.all()\n\n\n\n\n\n\n\n\n\n\nData Munging\n\n## Convert `dow`, `local`, `month`, and `hour` into ordered factors\ntaxi_modified &lt;- taxi_modified %&gt;%\n  dplyr::mutate(\n\n    ## Variable \"tip\"\n    tip = base::factor(tip,\n      levels = c(\"yes\", \"no\"),\n      labels = c(\"yes\", \"no\"),\n      ordered = TRUE\n    ),\n\n    ## Variable \"company\"\n    company = base::factor(company), # Any order is OK.\n\n    ## Variable \"dow\"\n    dow = base::factor(dow,\n      levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"),\n      labels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"),\n      ordered = TRUE\n    ),\n\n    ## Variable \"local\"\n    local = base::factor(local,\n      levels = c(\"yes\", \"no\"),\n      labels = c(\"yes\", \"no\"),\n      ordered = TRUE\n    ),\n\n    ## Variable \"month\"\n    month = base::factor(month,\n      levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\"),\n      labels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\"),\n      ordered = TRUE\n    ),\n\n    ## Variable \"hour\"\n    hour = base::factor(hour,\n      levels = c(0:23), labels = c(0:23),\n      ordered = TRUE\n    )\n  ) %&gt;%\n  dplyr::relocate(where(is.factor), .after = rownames) # Move all factors to the left\n\ntaxi_modified %&gt;% glimpse()\n\nRows: 10,000\nColumns: 8\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ tip      &lt;ord&gt; yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, y…\n$ company  &lt;fct&gt; Chicago Independents, City Service, other, Chicago Independen…\n$ local    &lt;ord&gt; no, yes, no, no, no, yes, no, no, no, no, no, no, no, yes, no…\n$ dow      &lt;ord&gt; Thu, Thu, Mon, Mon, Sun, Sat, Fri, Sun, Fri, Tue, Tue, Sun, W…\n$ month    &lt;ord&gt; Feb, Mar, Feb, Apr, Mar, Apr, Mar, Jan, Apr, Mar, Mar, Apr, A…\n$ hour     &lt;ord&gt; 16, 8, 18, 8, 21, 23, 12, 6, 12, 14, 18, 11, 12, 19, 17, 13, …\n$ distance &lt;dbl&gt; 17.19, 0.88, 18.11, 20.70, 12.23, 0.94, 17.47, 17.67, 1.85, 1…\n\n\n\n\nPosition dodge\n\ntaxi_modified %&gt;%\n  gf_bar(~local,\n    fill = ~tip,\n    position = \"dodge\"\n  ) %&gt;%\n  gf_labs(title = \"Plot 2A: Dodged Bar Chart\") %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\nPosition stack\n\ntaxi_modified %&gt;%\n  gf_bar(~local,\n    fill = ~tip,\n    position = \"stack\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Plot 2B: Stacked Bar Chart\",\n    subtitle = \"Can we spot per group differences in proportions??\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\nPosition fill\n\ntaxi_modified %&gt;%\n  gf_bar(~local,\n    fill = ~tip,\n    position = \"fill\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Plot 2C: Filled Bar Chart\",\n    subtitle = \"Shows Per group differences in Proportions!\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n\n\n\n\n\n\n\n\n\nHistogram\n\ndata(\"diamonds\", package = \"ggplot2\")\nglimpse(diamonds)\n\nRows: 53,940\nColumns: 10\n$ carat   &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…\n\n\n\ndiamonds_modified &lt;- diamonds %&gt;%\n  janitor::clean_names(case = \"snake\") %&gt;%\n  janitor::remove_empty(which = c(\"rows\", \"cols\")) # Empty columns and rows if any\ndiamonds_modified %&gt;% glimpse()\n\nRows: 53,940\nColumns: 10\n$ carat   &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…\n\n\n\ngf_histogram(~price, data = diamonds_modified, fill=~cut, color=\"black\") %&gt;%\n  gf_labs(\n    title = \"Plot 1A: Diamond Prices\",\n    caption = \"ggformula\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_histogram(~price | cut, data = diamonds_modified, fill=~cut, color=\"black\") %&gt;%\n  gf_labs(\n    title = \"Plot 1A: Diamond Prices\",\n    caption = \"ggformula\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set8\"))\n\nWarning: Unknown palette: \"Set8\"\n\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_histogram(~price | color, data = diamonds_modified, fill=~color, color=\"black\") %&gt;%\n  gf_labs(\n    title = \"Plot 1A: Diamond Prices\",\n    caption = \"ggformula\"\n  ) %&gt;% \n  gf_refine(scale_fill_brewer(palette = \"Set1\"))\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\nglimpse(diamonds_modified)\n\nRows: 53,940\nColumns: 10\n$ carat   &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…\n\n\n\ndiamonds_modified %&gt;%\n  gf_boxplot(cut ~ carat | clarity, orientation = \"y\") %&gt;%\n  gf_labs(y = \"Gender\", x = \"Income\", title = \"Plot 2A: Income by Gender\")\n\n\n\n\n\n\n\n\n\ndiamonds_modified %&gt;%\n  gf_boxplot(clarity ~ depth, orientation = \"y\") %&gt;%\n  gf_labs(y = \"Gender\", x = \"Income\", title = \"Plot 2A: Income by Gender\")\n\n\n\n\n\n\n\n\n\ndiamonds_modified %&gt;%\n  gf_boxplot(color ~ price, orientation = \"y\", fill = \"pink\", color = \"black\") %&gt;%\n  gf_labs(y = \"Gender\", x = \"Income\", title = \"Plot 2A: Income by Gender\")\n\n\n\n\n\n\n\n\n\ndiamonds_modified %&gt;%\n  gf_boxplot(clarity ~ price, orientation = \"y\") %&gt;%\n  gf_labs(y = \"Clarity\", x = \"Price\", title = \"Plot 2A: Income by Gender\")\n\n\n\n\n\n\n\n\n\ndiamonds_modified %&gt;%\n  gf_boxplot(cut ~ carat, orientation = \"y\") %&gt;%\n  gf_labs(y = \"Clarity\", x = \"Price\", title = \"Plot 2A: Income by Gender\")"
  },
  {
    "objectID": "classwork/classwork2/index.html",
    "href": "classwork/classwork2/index.html",
    "title": "Classwork 2",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\nAttaching package: 'mosaic'\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\n\n\nAttaching package: 'naniar'\n\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\n\nAttaching package: 'tinytable'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void"
  },
  {
    "objectID": "classwork/classwork2/index.html#setup-r-packages",
    "href": "classwork/classwork2/index.html#setup-r-packages",
    "title": "Classwork 2",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\nAttaching package: 'mosaic'\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\n\n\nAttaching package: 'naniar'\n\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\n\nAttaching package: 'tinytable'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void"
  },
  {
    "objectID": "classwork/classwork2/index.html#reading-csv-file",
    "href": "classwork/classwork2/index.html#reading-csv-file",
    "title": "Classwork 2",
    "section": "Reading csv file",
    "text": "Reading csv file\n\nfastfood &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/fastfood.csv\") %&gt;% \nclean_names(case=\"snake\")\n\nRows: 515 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): restaurant, item, salad\ndbl (15): rownames, calories, cal_fat, total_fat, sat_fat, trans_fat, choles...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nfastfood\n\n# A tibble: 515 × 18\n   rownames restaurant item         calories cal_fat total_fat sat_fat trans_fat\n      &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n 1        1 Mcdonalds  Artisan Gri…      380      60         7       2       0  \n 2        2 Mcdonalds  Single Baco…      840     410        45      17       1.5\n 3        3 Mcdonalds  Double Baco…     1130     600        67      27       3  \n 4        4 Mcdonalds  Grilled Bac…      750     280        31      10       0.5\n 5        5 Mcdonalds  Crispy Baco…      920     410        45      12       0.5\n 6        6 Mcdonalds  Big Mac           540     250        28      10       1  \n 7        7 Mcdonalds  Cheeseburger      300     100        12       5       0.5\n 8        8 Mcdonalds  Classic Chi…      510     210        24       4       0  \n 9        9 Mcdonalds  Double Chee…      430     190        21      11       1  \n10       10 Mcdonalds  Double Quar…      770     400        45      21       2.5\n# ℹ 505 more rows\n# ℹ 10 more variables: cholesterol &lt;dbl&gt;, sodium &lt;dbl&gt;, total_carb &lt;dbl&gt;,\n#   fiber &lt;dbl&gt;, sugar &lt;dbl&gt;, protein &lt;dbl&gt;, vit_a &lt;dbl&gt;, vit_c &lt;dbl&gt;,\n#   calcium &lt;dbl&gt;, salad &lt;chr&gt;"
  },
  {
    "objectID": "classwork/classwork2/index.html#names-function",
    "href": "classwork/classwork2/index.html#names-function",
    "title": "Classwork 2",
    "section": "Names function",
    "text": "Names function\n\nnames(fastfood)\n\n [1] \"rownames\"    \"restaurant\"  \"item\"        \"calories\"    \"cal_fat\"    \n [6] \"total_fat\"   \"sat_fat\"     \"trans_fat\"   \"cholesterol\" \"sodium\"     \n[11] \"total_carb\"  \"fiber\"       \"sugar\"       \"protein\"     \"vit_a\"      \n[16] \"vit_c\"       \"calcium\"     \"salad\""
  },
  {
    "objectID": "classwork/classwork2/index.html#glimpse-dim-str",
    "href": "classwork/classwork2/index.html#glimpse-dim-str",
    "title": "Classwork 2",
    "section": "Glimpse, Dim, str",
    "text": "Glimpse, Dim, str\n\ndplyr::glimpse(fastfood)\n\nRows: 515\nColumns: 18\n$ rownames    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ restaurant  &lt;chr&gt; \"Mcdonalds\", \"Mcdonalds\", \"Mcdonalds\", \"Mcdonalds\", \"Mcdon…\n$ item        &lt;chr&gt; \"Artisan Grilled Chicken Sandwich\", \"Single Bacon Smokehou…\n$ calories    &lt;dbl&gt; 380, 840, 1130, 750, 920, 540, 300, 510, 430, 770, 380, 62…\n$ cal_fat     &lt;dbl&gt; 60, 410, 600, 280, 410, 250, 100, 210, 190, 400, 170, 300,…\n$ total_fat   &lt;dbl&gt; 7, 45, 67, 31, 45, 28, 12, 24, 21, 45, 18, 34, 20, 34, 8, …\n$ sat_fat     &lt;dbl&gt; 2.0, 17.0, 27.0, 10.0, 12.0, 10.0, 5.0, 4.0, 11.0, 21.0, 4…\n$ trans_fat   &lt;dbl&gt; 0.0, 1.5, 3.0, 0.5, 0.5, 1.0, 0.5, 0.0, 1.0, 2.5, 0.0, 1.5…\n$ cholesterol &lt;dbl&gt; 95, 130, 220, 155, 120, 80, 40, 65, 85, 175, 40, 95, 125, …\n$ sodium      &lt;dbl&gt; 1110, 1580, 1920, 1940, 1980, 950, 680, 1040, 1040, 1290, …\n$ total_carb  &lt;dbl&gt; 44, 62, 63, 62, 81, 46, 33, 49, 35, 42, 38, 48, 48, 67, 31…\n$ fiber       &lt;dbl&gt; 3, 2, 3, 2, 4, 3, 2, 3, 2, 3, 2, 3, 3, 5, 2, 2, 3, 3, 5, 2…\n$ sugar       &lt;dbl&gt; 11, 18, 18, 18, 18, 9, 7, 6, 7, 10, 5, 11, 11, 11, 6, 3, 1…\n$ protein     &lt;dbl&gt; 37, 46, 70, 55, 46, 25, 15, 25, 25, 51, 15, 32, 42, 33, 13…\n$ vit_a       &lt;dbl&gt; 4, 6, 10, 6, 6, 10, 10, 0, 20, 20, 2, 10, 10, 10, 2, 4, 6,…\n$ vit_c       &lt;dbl&gt; 20, 20, 20, 25, 20, 2, 2, 4, 4, 6, 0, 10, 20, 15, 2, 6, 15…\n$ calcium     &lt;dbl&gt; 20, 20, 50, 20, 20, 15, 10, 2, 15, 20, 15, 35, 35, 35, 4, …\n$ salad       &lt;chr&gt; \"Other\", \"Other\", \"Other\", \"Other\", \"Other\", \"Other\", \"Oth…\n\n\n\nbase::dim(fastfood)\n\n[1] 515  18\n\n\n\nutils::str(fastfood)\n\nspc_tbl_ [515 × 18] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ rownames   : num [1:515] 1 2 3 4 5 6 7 8 9 10 ...\n $ restaurant : chr [1:515] \"Mcdonalds\" \"Mcdonalds\" \"Mcdonalds\" \"Mcdonalds\" ...\n $ item       : chr [1:515] \"Artisan Grilled Chicken Sandwich\" \"Single Bacon Smokehouse Burger\" \"Double Bacon Smokehouse Burger\" \"Grilled Bacon Smokehouse Chicken Sandwich\" ...\n $ calories   : num [1:515] 380 840 1130 750 920 540 300 510 430 770 ...\n $ cal_fat    : num [1:515] 60 410 600 280 410 250 100 210 190 400 ...\n $ total_fat  : num [1:515] 7 45 67 31 45 28 12 24 21 45 ...\n $ sat_fat    : num [1:515] 2 17 27 10 12 10 5 4 11 21 ...\n $ trans_fat  : num [1:515] 0 1.5 3 0.5 0.5 1 0.5 0 1 2.5 ...\n $ cholesterol: num [1:515] 95 130 220 155 120 80 40 65 85 175 ...\n $ sodium     : num [1:515] 1110 1580 1920 1940 1980 950 680 1040 1040 1290 ...\n $ total_carb : num [1:515] 44 62 63 62 81 46 33 49 35 42 ...\n $ fiber      : num [1:515] 3 2 3 2 4 3 2 3 2 3 ...\n $ sugar      : num [1:515] 11 18 18 18 18 9 7 6 7 10 ...\n $ protein    : num [1:515] 37 46 70 55 46 25 15 25 25 51 ...\n $ vit_a      : num [1:515] 4 6 10 6 6 10 10 0 20 20 ...\n $ vit_c      : num [1:515] 20 20 20 25 20 2 2 4 4 6 ...\n $ calcium    : num [1:515] 20 20 50 20 20 15 10 2 15 20 ...\n $ salad      : chr [1:515] \"Other\" \"Other\" \"Other\" \"Other\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   rownames = col_double(),\n  ..   restaurant = col_character(),\n  ..   item = col_character(),\n  ..   calories = col_double(),\n  ..   cal_fat = col_double(),\n  ..   total_fat = col_double(),\n  ..   sat_fat = col_double(),\n  ..   trans_fat = col_double(),\n  ..   cholesterol = col_double(),\n  ..   sodium = col_double(),\n  ..   total_carb = col_double(),\n  ..   fiber = col_double(),\n  ..   sugar = col_double(),\n  ..   protein = col_double(),\n  ..   vit_a = col_double(),\n  ..   vit_c = col_double(),\n  ..   calcium = col_double(),\n  ..   salad = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "classwork/classwork2/index.html#finding-missing-values",
    "href": "classwork/classwork2/index.html#finding-missing-values",
    "title": "Classwork 2",
    "section": "Finding Missing values",
    "text": "Finding Missing values\n\nvisdat::vis_dat(fastfood) +\n  labs(title = \"Missing Data\", subtitle = \"Showing variable types\") + \n  theme(plot.title = element_text(size = 20), plot.subtitle = element_text(size = 14))\n\n\n\n\n\n\n\n\n\nvis_miss(fastfood) +\n  labs(title =\"Missing Data in the FastFood Dataset\", subtitle = \"Showing missing & present data\") +\n  theme(plot.title = element_text(size = 20), plot.subtitle = element_text(size = 14))"
  },
  {
    "objectID": "classwork/classwork2/index.html#removing-missing-data",
    "href": "classwork/classwork2/index.html#removing-missing-data",
    "title": "Classwork 2",
    "section": "Removing missing data",
    "text": "Removing missing data\n\nfastfood_modified &lt;- fastfood %&gt;% tidyr::drop_na()"
  },
  {
    "objectID": "classwork/classwork2/index.html#displaying-modified-data-table",
    "href": "classwork/classwork2/index.html#displaying-modified-data-table",
    "title": "Classwork 2",
    "section": "Displaying modified data table",
    "text": "Displaying modified data table\n\nfastfood_modified\n\n# A tibble: 301 × 18\n   rownames restaurant item         calories cal_fat total_fat sat_fat trans_fat\n      &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n 1        1 Mcdonalds  Artisan Gri…      380      60         7       2       0  \n 2        2 Mcdonalds  Single Baco…      840     410        45      17       1.5\n 3        3 Mcdonalds  Double Baco…     1130     600        67      27       3  \n 4        4 Mcdonalds  Grilled Bac…      750     280        31      10       0.5\n 5        5 Mcdonalds  Crispy Baco…      920     410        45      12       0.5\n 6        6 Mcdonalds  Big Mac           540     250        28      10       1  \n 7        7 Mcdonalds  Cheeseburger      300     100        12       5       0.5\n 8        8 Mcdonalds  Classic Chi…      510     210        24       4       0  \n 9        9 Mcdonalds  Double Chee…      430     190        21      11       1  \n10       10 Mcdonalds  Double Quar…      770     400        45      21       2.5\n# ℹ 291 more rows\n# ℹ 10 more variables: cholesterol &lt;dbl&gt;, sodium &lt;dbl&gt;, total_carb &lt;dbl&gt;,\n#   fiber &lt;dbl&gt;, sugar &lt;dbl&gt;, protein &lt;dbl&gt;, vit_a &lt;dbl&gt;, vit_c &lt;dbl&gt;,\n#   calcium &lt;dbl&gt;, salad &lt;chr&gt;"
  },
  {
    "objectID": "classwork/classwork2/index.html#removing-the-column-entirely",
    "href": "classwork/classwork2/index.html#removing-the-column-entirely",
    "title": "Classwork 2",
    "section": "Removing the column entirely",
    "text": "Removing the column entirely\n\nfastfood_modified2 &lt;- fastfood %&gt;%\n  dplyr::select(-vit_a)\n\nfastfood_modified2 &lt;- fastfood %&gt;%\n  dplyr::select(-c(vit_a, vit_c))"
  },
  {
    "objectID": "classwork/classwork2/index.html#converting-into-factors",
    "href": "classwork/classwork2/index.html#converting-into-factors",
    "title": "Classwork 2",
    "section": "Converting into Factors",
    "text": "Converting into Factors\n\nfastfood_modified1 &lt;- fastfood %&gt;%\n  mutate(\n    restaurant = as.factor(restaurant),\n    salad = as.factor(salad),\n    item = as.factor(item))\ndplyr::glimpse(fastfood_modified1)\n\nRows: 515\nColumns: 18\n$ rownames    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ restaurant  &lt;fct&gt; Mcdonalds, Mcdonalds, Mcdonalds, Mcdonalds, Mcdonalds, Mcd…\n$ item        &lt;fct&gt; \"Artisan Grilled Chicken Sandwich\", \"Single Bacon Smokehou…\n$ calories    &lt;dbl&gt; 380, 840, 1130, 750, 920, 540, 300, 510, 430, 770, 380, 62…\n$ cal_fat     &lt;dbl&gt; 60, 410, 600, 280, 410, 250, 100, 210, 190, 400, 170, 300,…\n$ total_fat   &lt;dbl&gt; 7, 45, 67, 31, 45, 28, 12, 24, 21, 45, 18, 34, 20, 34, 8, …\n$ sat_fat     &lt;dbl&gt; 2.0, 17.0, 27.0, 10.0, 12.0, 10.0, 5.0, 4.0, 11.0, 21.0, 4…\n$ trans_fat   &lt;dbl&gt; 0.0, 1.5, 3.0, 0.5, 0.5, 1.0, 0.5, 0.0, 1.0, 2.5, 0.0, 1.5…\n$ cholesterol &lt;dbl&gt; 95, 130, 220, 155, 120, 80, 40, 65, 85, 175, 40, 95, 125, …\n$ sodium      &lt;dbl&gt; 1110, 1580, 1920, 1940, 1980, 950, 680, 1040, 1040, 1290, …\n$ total_carb  &lt;dbl&gt; 44, 62, 63, 62, 81, 46, 33, 49, 35, 42, 38, 48, 48, 67, 31…\n$ fiber       &lt;dbl&gt; 3, 2, 3, 2, 4, 3, 2, 3, 2, 3, 2, 3, 3, 5, 2, 2, 3, 3, 5, 2…\n$ sugar       &lt;dbl&gt; 11, 18, 18, 18, 18, 9, 7, 6, 7, 10, 5, 11, 11, 11, 6, 3, 1…\n$ protein     &lt;dbl&gt; 37, 46, 70, 55, 46, 25, 15, 25, 25, 51, 15, 32, 42, 33, 13…\n$ vit_a       &lt;dbl&gt; 4, 6, 10, 6, 6, 10, 10, 0, 20, 20, 2, 10, 10, 10, 2, 4, 6,…\n$ vit_c       &lt;dbl&gt; 20, 20, 20, 25, 20, 2, 2, 4, 4, 6, 0, 10, 20, 15, 2, 6, 15…\n$ calcium     &lt;dbl&gt; 20, 20, 50, 20, 20, 15, 10, 2, 15, 20, 15, 35, 35, 35, 4, …\n$ salad       &lt;fct&gt; Other, Other, Other, Other, Other, Other, Other, Other, Ot…"
  },
  {
    "objectID": "classwork/classwork2/index.html#relocate",
    "href": "classwork/classwork2/index.html#relocate",
    "title": "Classwork 2",
    "section": "Relocate",
    "text": "Relocate\n\nfast_food_modified &lt;- fastfood_modified %&gt;%\n  mutate(\n    restaurant = as.factor(restaurant),\n    salad = as.factor(salad),\n    item = as.factor(item)\n  ) %&gt;%\n  rename(\"dish\" = item) %&gt;% # rename item to dish\n\n  # arrange the Qual variables first, Quant next\n  dplyr::relocate(where(is.factor), .after = rownames)\n\nglimpse(fast_food_modified)\n\nRows: 301\nColumns: 18\n$ rownames    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ restaurant  &lt;fct&gt; Mcdonalds, Mcdonalds, Mcdonalds, Mcdonalds, Mcdonalds, Mcd…\n$ dish        &lt;fct&gt; \"Artisan Grilled Chicken Sandwich\", \"Single Bacon Smokehou…\n$ salad       &lt;fct&gt; Other, Other, Other, Other, Other, Other, Other, Other, Ot…\n$ calories    &lt;dbl&gt; 380, 840, 1130, 750, 920, 540, 300, 510, 430, 770, 380, 62…\n$ cal_fat     &lt;dbl&gt; 60, 410, 600, 280, 410, 250, 100, 210, 190, 400, 170, 300,…\n$ total_fat   &lt;dbl&gt; 7, 45, 67, 31, 45, 28, 12, 24, 21, 45, 18, 34, 20, 34, 8, …\n$ sat_fat     &lt;dbl&gt; 2.0, 17.0, 27.0, 10.0, 12.0, 10.0, 5.0, 4.0, 11.0, 21.0, 4…\n$ trans_fat   &lt;dbl&gt; 0.0, 1.5, 3.0, 0.5, 0.5, 1.0, 0.5, 0.0, 1.0, 2.5, 0.0, 1.5…\n$ cholesterol &lt;dbl&gt; 95, 130, 220, 155, 120, 80, 40, 65, 85, 175, 40, 95, 125, …\n$ sodium      &lt;dbl&gt; 1110, 1580, 1920, 1940, 1980, 950, 680, 1040, 1040, 1290, …\n$ total_carb  &lt;dbl&gt; 44, 62, 63, 62, 81, 46, 33, 49, 35, 42, 38, 48, 48, 67, 31…\n$ fiber       &lt;dbl&gt; 3, 2, 3, 2, 4, 3, 2, 3, 2, 3, 2, 3, 3, 5, 2, 2, 3, 3, 5, 2…\n$ sugar       &lt;dbl&gt; 11, 18, 18, 18, 18, 9, 7, 6, 7, 10, 5, 11, 11, 11, 6, 3, 1…\n$ protein     &lt;dbl&gt; 37, 46, 70, 55, 46, 25, 15, 25, 25, 51, 15, 32, 42, 33, 13…\n$ vit_a       &lt;dbl&gt; 4, 6, 10, 6, 6, 10, 10, 0, 20, 20, 2, 10, 10, 10, 2, 4, 6,…\n$ vit_c       &lt;dbl&gt; 20, 20, 20, 25, 20, 2, 2, 4, 4, 6, 0, 10, 20, 15, 2, 6, 15…\n$ calcium     &lt;dbl&gt; 20, 20, 50, 20, 20, 15, 10, 2, 15, 20, 15, 35, 35, 35, 4, …"
  },
  {
    "objectID": "classwork/classwork2/index.html#displaying-data",
    "href": "classwork/classwork2/index.html#displaying-data",
    "title": "Classwork 2",
    "section": "Displaying Data",
    "text": "Displaying Data\n\nfast_food_modified %&gt;%\n  head(10) %&gt;%\n  tinytable::tt(caption = \"Fast Food Dataset (Clean)\")\n\n\n\n    \n\n    \n    \n      \n        \n        Fast Food Dataset (Clean)\n              \n                rownames\n                restaurant\n                dish\n                salad\n                calories\n                cal_fat\n                total_fat\n                sat_fat\n                trans_fat\n                cholesterol\n                sodium\n                total_carb\n                fiber\n                sugar\n                protein\n                vit_a\n                vit_c\n                calcium\n              \n        \n        \n        \n                \n                  1\n                  Mcdonalds\n                  Artisan Grilled Chicken Sandwich\n                  Other\n                  380\n                  60\n                  7\n                  2\n                  0.0\n                  95\n                  1110\n                  44\n                  3\n                  11\n                  37\n                  4\n                  20\n                  20\n                \n                \n                  2\n                  Mcdonalds\n                  Single Bacon Smokehouse Burger\n                  Other\n                  840\n                  410\n                  45\n                  17\n                  1.5\n                  130\n                  1580\n                  62\n                  2\n                  18\n                  46\n                  6\n                  20\n                  20\n                \n                \n                  3\n                  Mcdonalds\n                  Double Bacon Smokehouse Burger\n                  Other\n                  1130\n                  600\n                  67\n                  27\n                  3.0\n                  220\n                  1920\n                  63\n                  3\n                  18\n                  70\n                  10\n                  20\n                  50\n                \n                \n                  4\n                  Mcdonalds\n                  Grilled Bacon Smokehouse Chicken Sandwich\n                  Other\n                  750\n                  280\n                  31\n                  10\n                  0.5\n                  155\n                  1940\n                  62\n                  2\n                  18\n                  55\n                  6\n                  25\n                  20\n                \n                \n                  5\n                  Mcdonalds\n                  Crispy Bacon Smokehouse Chicken Sandwich\n                  Other\n                  920\n                  410\n                  45\n                  12\n                  0.5\n                  120\n                  1980\n                  81\n                  4\n                  18\n                  46\n                  6\n                  20\n                  20\n                \n                \n                  6\n                  Mcdonalds\n                  Big Mac\n                  Other\n                  540\n                  250\n                  28\n                  10\n                  1.0\n                  80\n                  950\n                  46\n                  3\n                  9\n                  25\n                  10\n                  2\n                  15\n                \n                \n                  7\n                  Mcdonalds\n                  Cheeseburger\n                  Other\n                  300\n                  100\n                  12\n                  5\n                  0.5\n                  40\n                  680\n                  33\n                  2\n                  7\n                  15\n                  10\n                  2\n                  10\n                \n                \n                  8\n                  Mcdonalds\n                  Classic Chicken Sandwich\n                  Other\n                  510\n                  210\n                  24\n                  4\n                  0.0\n                  65\n                  1040\n                  49\n                  3\n                  6\n                  25\n                  0\n                  4\n                  2\n                \n                \n                  9\n                  Mcdonalds\n                  Double Cheeseburger\n                  Other\n                  430\n                  190\n                  21\n                  11\n                  1.0\n                  85\n                  1040\n                  35\n                  2\n                  7\n                  25\n                  20\n                  4\n                  15\n                \n                \n                  10\n                  Mcdonalds\n                  Double Quarter Pounder® with Cheese\n                  Other\n                  770\n                  400\n                  45\n                  21\n                  2.5\n                  175\n                  1290\n                  42\n                  3\n                  10\n                  51\n                  20\n                  6\n                  20"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "classwork/classwork1/index.html",
    "href": "classwork/classwork1/index.html",
    "title": "Classwork 1",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(babynames)\nlibrary(ggformula)\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\n\n\nbabynames\n\n# A tibble: 1,924,665 × 5\n    year sex   name          n   prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt;\n 1  1880 F     Mary       7065 0.0724\n 2  1880 F     Anna       2604 0.0267\n 3  1880 F     Emma       2003 0.0205\n 4  1880 F     Elizabeth  1939 0.0199\n 5  1880 F     Minnie     1746 0.0179\n 6  1880 F     Margaret   1578 0.0162\n 7  1880 F     Ida        1472 0.0151\n 8  1880 F     Alice      1414 0.0145\n 9  1880 F     Bertha     1320 0.0135\n10  1880 F     Sarah      1288 0.0132\n# ℹ 1,924,655 more rows\n\n\n\n\n\n\nbabynames %&gt;% filter(name==\"Diya\")\n\n# A tibble: 27 × 5\n    year sex   name      n       prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt;      &lt;dbl&gt;\n 1  1991 F     Diya      5 0.00000246\n 2  1992 F     Diya      5 0.00000249\n 3  1995 F     Diya      6 0.00000312\n 4  1996 F     Diya      7 0.00000365\n 5  1997 F     Diya     12 0.00000629\n 6  1998 F     Diya     12 0.00000619\n 7  1999 F     Diya     14 0.00000719\n 8  2000 F     Diya     18 0.00000902\n 9  2001 F     Diya     54 0.0000273 \n10  2002 F     Diya     92 0.0000466 \n# ℹ 17 more rows\n\n\n\n\n\nbabynames %&gt;% filter(name == \"Diya\" | name == \"Dia\" | name == \"Deeya\") %&gt;%\n  gf_area(n ~ year, color = ~ name) %&gt;% \n  gf_labs(title = \"Number of babies named Diya or Dia or Diyaa in the USA\",\n         x = \"Year\",\n         y = \"Number of babies\") %&gt;% gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\n\nbabynames %&gt;% filter(name == \"Diya\" | name == \"Dia\" | name == \"Deeya\") %&gt;%\n  gf_point(n ~ year, color = ~ name) %&gt;% \n  gf_labs(title = \"Number of babies named Diya or Dia or Diyaa in the USA\",\n         x = \"Year\",\n         y = \"Number of babies\") %&gt;% gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\n\nbabynames %&gt;% filter(name == \"Diya\" | name == \"Dia\" | name == \"Deeya\") %&gt;%\n  gf_bar(n ~ year, color = ~ name) %&gt;% \n  gf_labs(title = \"Number of babies named Diya or Dia or Diyaa in the USA\",\n         x = \"Year\",\n         y = \"Number of babies\") %&gt;% gf_theme(theme_light())\n\nWarning: Ignoring unknown aesthetics: .\n\n\nWarning: The following aesthetics were dropped during statistical transformation: ..\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\n\n\nbabynames %&gt;% filter(name == \"Diya\" | name == \"Dia\" | name == \"Deeya\") %&gt;% filter(year == \"1989\" | year == \"2010\") %&gt;%\n  gf_point(n ~ year, color = ~ name) %&gt;% \n  gf_labs(title = \"Number of babies named Diya or Dia or Diyaa in the USA\",\n         x = \"Year\",\n         y = \"Number of babies\") %&gt;% gf_theme(theme_light())"
  },
  {
    "objectID": "classwork/classwork1/index.html#this-is-my-first-quarto-document",
    "href": "classwork/classwork1/index.html#this-is-my-first-quarto-document",
    "title": "Classwork 1",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(babynames)\nlibrary(ggformula)\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\n\n\nbabynames\n\n# A tibble: 1,924,665 × 5\n    year sex   name          n   prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt;\n 1  1880 F     Mary       7065 0.0724\n 2  1880 F     Anna       2604 0.0267\n 3  1880 F     Emma       2003 0.0205\n 4  1880 F     Elizabeth  1939 0.0199\n 5  1880 F     Minnie     1746 0.0179\n 6  1880 F     Margaret   1578 0.0162\n 7  1880 F     Ida        1472 0.0151\n 8  1880 F     Alice      1414 0.0145\n 9  1880 F     Bertha     1320 0.0135\n10  1880 F     Sarah      1288 0.0132\n# ℹ 1,924,655 more rows\n\n\n\n\n\n\nbabynames %&gt;% filter(name==\"Diya\")\n\n# A tibble: 27 × 5\n    year sex   name      n       prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt;      &lt;dbl&gt;\n 1  1991 F     Diya      5 0.00000246\n 2  1992 F     Diya      5 0.00000249\n 3  1995 F     Diya      6 0.00000312\n 4  1996 F     Diya      7 0.00000365\n 5  1997 F     Diya     12 0.00000629\n 6  1998 F     Diya     12 0.00000619\n 7  1999 F     Diya     14 0.00000719\n 8  2000 F     Diya     18 0.00000902\n 9  2001 F     Diya     54 0.0000273 \n10  2002 F     Diya     92 0.0000466 \n# ℹ 17 more rows\n\n\n\n\n\nbabynames %&gt;% filter(name == \"Diya\" | name == \"Dia\" | name == \"Deeya\") %&gt;%\n  gf_area(n ~ year, color = ~ name) %&gt;% \n  gf_labs(title = \"Number of babies named Diya or Dia or Diyaa in the USA\",\n         x = \"Year\",\n         y = \"Number of babies\") %&gt;% gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\n\nbabynames %&gt;% filter(name == \"Diya\" | name == \"Dia\" | name == \"Deeya\") %&gt;%\n  gf_point(n ~ year, color = ~ name) %&gt;% \n  gf_labs(title = \"Number of babies named Diya or Dia or Diyaa in the USA\",\n         x = \"Year\",\n         y = \"Number of babies\") %&gt;% gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\n\nbabynames %&gt;% filter(name == \"Diya\" | name == \"Dia\" | name == \"Deeya\") %&gt;%\n  gf_bar(n ~ year, color = ~ name) %&gt;% \n  gf_labs(title = \"Number of babies named Diya or Dia or Diyaa in the USA\",\n         x = \"Year\",\n         y = \"Number of babies\") %&gt;% gf_theme(theme_light())\n\nWarning: Ignoring unknown aesthetics: .\n\n\nWarning: The following aesthetics were dropped during statistical transformation: ..\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\n\n\nbabynames %&gt;% filter(name == \"Diya\" | name == \"Dia\" | name == \"Deeya\") %&gt;% filter(year == \"1989\" | year == \"2010\") %&gt;%\n  gf_point(n ~ year, color = ~ name) %&gt;% \n  gf_labs(title = \"Number of babies named Diya or Dia or Diyaa in the USA\",\n         x = \"Year\",\n         y = \"Number of babies\") %&gt;% gf_theme(theme_light())"
  },
  {
    "objectID": "classwork/classwork3/index.html",
    "href": "classwork/classwork3/index.html",
    "title": "Classwork 3",
    "section": "",
    "text": "library(tidyverse) # Sine qua non\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic) # Out all-in-one package\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula) # Graphing package\nlibrary(skimr) # Looking at Data\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(janitor) # Clean the data\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(naniar) # Handle missing data\n\n\nAttaching package: 'naniar'\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\nlibrary(visdat) # Visualise missing data\nlibrary(tinytable) # Printing Static Tables for our data\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(DT) # Interactive Tables for our data\nlibrary(crosstable) # Multiple variable summaries\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(ggplot2)\n\n\ndocVisits &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/AER/DoctorVisits.csv\")\n\nRows: 5190 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): gender, private, freepoor, freerepat, nchronic, lchronic\ndbl (7): rownames, visits, age, income, illness, reduced, health\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(docVisits)\n\nRows: 5,190\nColumns: 13\n$ rownames  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ visits    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, …\n$ gender    &lt;chr&gt; \"female\", \"female\", \"male\", \"male\", \"male\", \"female\", \"femal…\n$ age       &lt;dbl&gt; 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, …\n$ income    &lt;dbl&gt; 0.55, 0.45, 0.90, 0.15, 0.45, 0.35, 0.55, 0.15, 0.65, 0.15, …\n$ illness   &lt;dbl&gt; 1, 1, 3, 1, 2, 5, 4, 3, 2, 1, 1, 2, 3, 4, 3, 2, 1, 1, 1, 1, …\n$ reduced   &lt;dbl&gt; 4, 2, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 13, 7, 1, 0, 0, 1, 0, 0,…\n$ health    &lt;dbl&gt; 1, 1, 0, 0, 1, 9, 2, 6, 5, 0, 0, 2, 1, 6, 0, 7, 5, 0, 0, 0, …\n$ private   &lt;chr&gt; \"yes\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"yes\", \"ye…\n$ freepoor  &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ freerepat &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ nchronic  &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"yes\", \"yes\", \"no\", \"no\", \"no\", \"no\"…\n$ lchronic  &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n\n\n\ndocVisits_modified &lt;- docVisits %&gt;%\n  # Replace common NA strings and numbers with actual NA\n  naniar::replace_with_na_all(condition = ~ .x %in% common_na_strings) %&gt;%\n  naniar::replace_with_na_all(condition = ~ .x %in% common_na_numbers) %&gt;%\n  # Clean variable names\n  janitor::clean_names(case = \"snake\") %&gt;% # clean names\n\n  # Convert character variables to factors\n  mutate(\n    gender = as_factor(gender),\n    private = as_factor(private),\n    freepoor = as_factor(freepoor),\n    freerepat = as_factor(freerepat),\n    nchronic = as_factor(nchronic),\n    lchronic = as_factor(lchronic)\n  ) %&gt;%\n  # arrange the character variables first\n  dplyr::relocate(where(is.factor), .after = rownames)\n\n\ndocVisits_modified %&gt;% glimpse()\n\nRows: 5,190\nColumns: 13\n$ rownames  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ gender    &lt;fct&gt; female, female, male, male, male, female, female, female, fe…\n$ private   &lt;fct&gt; yes, yes, no, no, no, no, no, no, yes, yes, no, no, no, no, …\n$ freepoor  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ freerepat &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, yes, no, no, no,…\n$ nchronic  &lt;fct&gt; no, no, no, no, yes, yes, no, no, no, no, no, no, yes, yes, …\n$ lchronic  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ visits    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, …\n$ age       &lt;dbl&gt; 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, …\n$ income    &lt;dbl&gt; 0.55, 0.45, 0.90, 0.15, 0.45, 0.35, 0.55, 0.15, 0.65, 0.15, …\n$ illness   &lt;dbl&gt; 1, 1, 3, 1, 2, 5, 4, 3, 2, 1, 1, 2, 3, 4, 3, 2, 1, 1, 1, 1, …\n$ reduced   &lt;dbl&gt; 4, 2, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 13, 7, 1, 0, 0, 1, 0, 0,…\n$ health    &lt;dbl&gt; 1, 1, 0, 0, 1, 9, 2, 6, 5, 0, 0, 2, 1, 6, 0, 7, 5, 0, 0, 0, …\n\n\n\ndocVisits_modified %&gt;%\n  DT::datatable(\n    caption = htmltools::tags$caption(\n      style = \"caption-side: top; text-align: left; color: black; font-size: 150%;\",\n      \"Doctor Visits Dataset (Clean)\"\n    ),\n    options = list(pageLength = 10, autoWidth = TRUE)\n  ) %&gt;%\n  DT::formatStyle(\n    columns = names(docVisits_modified),\n    fontFamily = \"Roboto Condensed\",\n    fontSize = \"12px\"\n  )"
  },
  {
    "objectID": "classwork/classwork3/index.html#setup",
    "href": "classwork/classwork3/index.html#setup",
    "title": "Classwork 3",
    "section": "",
    "text": "library(tidyverse) # Sine qua non\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic) # Out all-in-one package\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula) # Graphing package\nlibrary(skimr) # Looking at Data\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(janitor) # Clean the data\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(naniar) # Handle missing data\n\n\nAttaching package: 'naniar'\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\nlibrary(visdat) # Visualise missing data\nlibrary(tinytable) # Printing Static Tables for our data\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(DT) # Interactive Tables for our data\nlibrary(crosstable) # Multiple variable summaries\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(ggplot2)\n\n\ndocVisits &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/AER/DoctorVisits.csv\")\n\nRows: 5190 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): gender, private, freepoor, freerepat, nchronic, lchronic\ndbl (7): rownames, visits, age, income, illness, reduced, health\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(docVisits)\n\nRows: 5,190\nColumns: 13\n$ rownames  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ visits    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, …\n$ gender    &lt;chr&gt; \"female\", \"female\", \"male\", \"male\", \"male\", \"female\", \"femal…\n$ age       &lt;dbl&gt; 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, …\n$ income    &lt;dbl&gt; 0.55, 0.45, 0.90, 0.15, 0.45, 0.35, 0.55, 0.15, 0.65, 0.15, …\n$ illness   &lt;dbl&gt; 1, 1, 3, 1, 2, 5, 4, 3, 2, 1, 1, 2, 3, 4, 3, 2, 1, 1, 1, 1, …\n$ reduced   &lt;dbl&gt; 4, 2, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 13, 7, 1, 0, 0, 1, 0, 0,…\n$ health    &lt;dbl&gt; 1, 1, 0, 0, 1, 9, 2, 6, 5, 0, 0, 2, 1, 6, 0, 7, 5, 0, 0, 0, …\n$ private   &lt;chr&gt; \"yes\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"yes\", \"ye…\n$ freepoor  &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ freerepat &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ nchronic  &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"yes\", \"yes\", \"no\", \"no\", \"no\", \"no\"…\n$ lchronic  &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n\n\n\ndocVisits_modified &lt;- docVisits %&gt;%\n  # Replace common NA strings and numbers with actual NA\n  naniar::replace_with_na_all(condition = ~ .x %in% common_na_strings) %&gt;%\n  naniar::replace_with_na_all(condition = ~ .x %in% common_na_numbers) %&gt;%\n  # Clean variable names\n  janitor::clean_names(case = \"snake\") %&gt;% # clean names\n\n  # Convert character variables to factors\n  mutate(\n    gender = as_factor(gender),\n    private = as_factor(private),\n    freepoor = as_factor(freepoor),\n    freerepat = as_factor(freerepat),\n    nchronic = as_factor(nchronic),\n    lchronic = as_factor(lchronic)\n  ) %&gt;%\n  # arrange the character variables first\n  dplyr::relocate(where(is.factor), .after = rownames)\n\n\ndocVisits_modified %&gt;% glimpse()\n\nRows: 5,190\nColumns: 13\n$ rownames  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ gender    &lt;fct&gt; female, female, male, male, male, female, female, female, fe…\n$ private   &lt;fct&gt; yes, yes, no, no, no, no, no, no, yes, yes, no, no, no, no, …\n$ freepoor  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ freerepat &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, yes, no, no, no,…\n$ nchronic  &lt;fct&gt; no, no, no, no, yes, yes, no, no, no, no, no, no, yes, yes, …\n$ lchronic  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ visits    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, …\n$ age       &lt;dbl&gt; 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, …\n$ income    &lt;dbl&gt; 0.55, 0.45, 0.90, 0.15, 0.45, 0.35, 0.55, 0.15, 0.65, 0.15, …\n$ illness   &lt;dbl&gt; 1, 1, 3, 1, 2, 5, 4, 3, 2, 1, 1, 2, 3, 4, 3, 2, 1, 1, 1, 1, …\n$ reduced   &lt;dbl&gt; 4, 2, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 13, 7, 1, 0, 0, 1, 0, 0,…\n$ health    &lt;dbl&gt; 1, 1, 0, 0, 1, 9, 2, 6, 5, 0, 0, 2, 1, 6, 0, 7, 5, 0, 0, 0, …\n\n\n\ndocVisits_modified %&gt;%\n  DT::datatable(\n    caption = htmltools::tags$caption(\n      style = \"caption-side: top; text-align: left; color: black; font-size: 150%;\",\n      \"Doctor Visits Dataset (Clean)\"\n    ),\n    options = list(pageLength = 10, autoWidth = TRUE)\n  ) %&gt;%\n  DT::formatStyle(\n    columns = names(docVisits_modified),\n    fontFamily = \"Roboto Condensed\",\n    fontSize = \"12px\"\n  )"
  },
  {
    "objectID": "classwork/classwork3/index.html#summarising-qual-variables",
    "href": "classwork/classwork3/index.html#summarising-qual-variables",
    "title": "Classwork 3",
    "section": "Summarising Qual Variables",
    "text": "Summarising Qual Variables\n\ndocVisits_modified %&gt;% count(gender) %&gt;% tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                gender\n                n\n              \n        \n        \n        \n                \n                  female\n                  2702\n                \n                \n                  male\n                  2488\n                \n        \n      \n    \n\n\n\n\ndocVisits_modified %&gt;% count(private) %&gt;% tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                private\n                n\n              \n        \n        \n        \n                \n                  yes\n                  2298\n                \n                \n                  no\n                  2892\n                \n        \n      \n    \n\n\n\n\ndocVisits_modified %&gt;% count(across(.cols = c(gender,private))) %&gt;% tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                gender\n                private\n                n\n              \n        \n        \n        \n                \n                  female\n                  yes\n                  1269\n                \n                \n                  female\n                  no\n                  1433\n                \n                \n                  male\n                  yes\n                  1029\n                \n                \n                  male\n                  no\n                  1459\n                \n        \n      \n    \n\n\n\n\ndocVisits_modified %&gt;% count(across(where(is.character))) %&gt;% tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                n\n              \n        \n        \n        \n                \n                  5190"
  },
  {
    "objectID": "classwork/classwork3/index.html#summarising-quant-variables",
    "href": "classwork/classwork3/index.html#summarising-quant-variables",
    "title": "Classwork 3",
    "section": "Summarising Quant Variables",
    "text": "Summarising Quant Variables\n\ndocVisits_modified %&gt;% dplyr::summarise(mean_income = mean(income, na.rm = T))\n\n# A tibble: 1 × 1\n  mean_income\n        &lt;dbl&gt;\n1       0.583\n\n\n\nSingle Variable, Multiple Summaries\n\ndocVisits_modified %&gt;%\n  dplyr::summarise(\n    mean_visits = mean(visits, na.rm = T),\n    sd_visits = sd(visits, na.rm = T),\n    min_visits = min(visits, na.rm = T),\n    max_visits = max(visits, na.rm = T)\n  )\n\n# A tibble: 1 × 4\n  mean_visits sd_visits min_visits max_visits\n        &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1       0.302     0.798          0          9\n\n\n\n\nMultiple Variables, Multiple Summaries\n\ndocVisits_modified %&gt;%\n  dplyr::summarise(across(.cols = c(visits, income), # select columns\n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 1 × 8\n  visits_mean visits_sd visits_min visits_max income_mean income_sd income_min\n        &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1       0.302     0.798          0          9       0.583     0.369          0\n# ℹ 1 more variable: income_max &lt;dbl&gt;\n\n\n\n\nGrouped Summaries\n\nOne qual variable\n\ndocVisits_modified %&gt;%\n  group_by(gender) %&gt;%\n  summarize(average_visits = mean(visits), count = n())\n\n# A tibble: 2 × 3\n  gender average_visits count\n  &lt;fct&gt;           &lt;dbl&gt; &lt;int&gt;\n1 female          0.362  2702\n2 male            0.236  2488\n\n\n\n\nTwo qual variable\n\ndocVisits_modified %&gt;%\n  group_by(age, gender) %&gt;%\n  summarize(average_visits = mean(visits), \n            max_visits = max(visits),\n            min_visits = min(visits),count = n())\n\n`summarise()` has grouped output by 'age'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 24 × 6\n# Groups:   age [12]\n     age gender average_visits max_visits min_visits count\n   &lt;dbl&gt; &lt;fct&gt;           &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;\n 1  0.19 female          0.276          8          0   351\n 2  0.19 male            0.157          4          0   401\n 3  0.22 female          0.229          5          0   484\n 4  0.22 male            0.182          7          0   729\n 5  0.27 female          0.425          7          0   186\n 6  0.27 male            0.166          5          0   337\n 7  0.32 female          0.356          7          0   104\n 8  0.32 male            0.183          3          0   197\n 9  0.37 female          0.377          3          0    61\n10  0.37 male            0.153          3          0    85\n# ℹ 14 more rows\n\n\n\n\nMultiple Variables, Multiple Summaries\n\ndocVisits_modified %&gt;%\n  dplyr::summarise(across(\n    .cols = c(visits, income),\n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 1 × 8\n  visits_mean visits_sd visits_min visits_max income_mean income_sd income_min\n        &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1       0.302     0.798          0          9       0.583     0.369          0\n# ℹ 1 more variable: income_max &lt;dbl&gt;\n\n\n\n\nCross Table\n\ncrosstable(visits + income ~ gender + freepoor,\n  data = docVisits_modified\n) %&gt;%\n  crosstable::as_flextable()\n\nfreepoornoyesgenderfemalemalefemalemalevisitsMin / Max0 / 8.00 / 9.00 / 5.00 / 7.0Med [IQR]0 [0;0]0 [0;0]0 [0;0]0 [0;0]Mean (std)0.4 (0.9)0.2 (0.7)0.2 (0.8)0.1 (0.6)N (NA)2618 (0)2350 (0)84 (0)138 (0)incomeMin / Max0 / 1.50 / 1.50 / 1.10 / 1.1Med [IQR]0.3 [0.2;0.6]0.6 [0.3;0.9]0.2 [0.1;0.3]0.2 [0.1;0.4]Mean (std)0.5 (0.3)0.7 (0.4)0.2 (0.2)0.3 (0.2)N (NA)2618 (0)2350 (0)84 (0)138 (0)\n\n\n\nUsing Qualitative variables\n\ncrosstable(freerepat + private ~ gender + freepoor,\n  data = docVisits_modified\n) %&gt;%\n  crosstable::as_flextable()\n\nfreepoornoyesgenderfemalemalefemalemalefreerepatno1801 (43.94%)2076 (50.65%)84 (2.05%)138 (3.37%)yes817 (74.89%)274 (25.11%)0 (0%)0 (0%)privateyes1269 (55.22%)1029 (44.78%)0 (0%)0 (0%)no1349 (46.65%)1321 (45.68%)84 (2.90%)138 (4.77%)\n\n\n\nglimpse(docVisits_modified)\n\nRows: 5,190\nColumns: 13\n$ rownames  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ gender    &lt;fct&gt; female, female, male, male, male, female, female, female, fe…\n$ private   &lt;fct&gt; yes, yes, no, no, no, no, no, no, yes, yes, no, no, no, no, …\n$ freepoor  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ freerepat &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, yes, no, no, no,…\n$ nchronic  &lt;fct&gt; no, no, no, no, yes, yes, no, no, no, no, no, no, yes, yes, …\n$ lchronic  &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ visits    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, …\n$ age       &lt;dbl&gt; 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, …\n$ income    &lt;dbl&gt; 0.55, 0.45, 0.90, 0.15, 0.45, 0.35, 0.55, 0.15, 0.65, 0.15, …\n$ illness   &lt;dbl&gt; 1, 1, 3, 1, 2, 5, 4, 3, 2, 1, 1, 2, 3, 4, 3, 2, 1, 1, 1, 1, …\n$ reduced   &lt;dbl&gt; 4, 2, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 13, 7, 1, 0, 0, 1, 0, 0,…\n$ health    &lt;dbl&gt; 1, 1, 0, 0, 1, 9, 2, 6, 5, 0, 0, 2, 1, 6, 0, 7, 5, 0, 0, 0, …"
  },
  {
    "objectID": "classwork/classwork5/classwork5.html",
    "href": "classwork/classwork5/classwork5.html",
    "title": "Classwork 5",
    "section": "",
    "text": "library(tidyverse) # Tidy data processing and plotting\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggformula)# Formula based plots\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(ggplot2)\nlibrary(mosaic) # Our go-to package\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(skimr) # Another Data inspection package\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(GGally) # Corr plots\nlibrary(broom) # Clean reports from Stats / ML outputs\n\n# library(devtools)\n# devtools::install_github(\"rpruim/Lock5withR\")\nlibrary(Lock5withR) # Datasets\n\nlibrary(easystats) # Easy Statistical Analysis and Charts\n\n# Attaching packages: easystats 0.7.5 (red = needs update)\n✔ bayestestR  0.17.0   ✔ correlation 0.8.8 \n✔ datawizard  1.2.0    ✔ effectsize  1.0.1 \n✔ insight     1.4.2    ✔ modelbased  0.13.0\n✖ performance 0.15.1   ✔ parameters  0.28.2\n✔ report      0.6.1    ✔ see         0.12.0\n\nRestart the R-Session and update packages with `easystats::easystats_update()`.\n\nlibrary(correlation) # Different Types of Correlations\n\nlibrary(janitor) # Data cleaning and tidying package\n\n\nAttaching package: 'janitor'\n\nThe following object is masked from 'package:insight':\n\n    clean_names\n\nThe following objects are masked from 'package:datawizard':\n\n    remove_empty, remove_empty_rows\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(visdat) # Visualize whole dataframes for missing data\nlibrary(naniar) # Clean missing data\n\n\nAttaching package: 'naniar'\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\nlibrary(DT) # Interactive Tables for our data\nlibrary(tinytable) # Elegant Tables for our data\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(ggrepel) # Repelled Text Labels in ggplot\nlibrary(marquee) # Marquee Text Labels in ggplot\nlibrary(dplyr)\n\n\ndata(HollywoodMovies2011, package = \"Lock5withR\")\nmovies_modified &lt;- HollywoodMovies2011 %&gt;%\n  janitor::clean_names(case = \"snake\") %&gt;%\n  janitor::remove_empty(which = c(\"rows\", \"cols\")) %&gt;%\n  dplyr::mutate(\n    across(where(is.character), as.factor)\n  ) %&gt;%\n  dplyr::relocate(where(is.factor))\n\n\nmovies_quant &lt;- movies_modified %&gt;%\n  drop_na() %&gt;%\n  select(where(is.numeric))\nmovies_quant %&gt;% names()\n\n [1] \"rotten_tomatoes\"      \"audience_score\"       \"theaters_open_week\"  \n [4] \"bo_average_open_week\" \"domestic_gross\"       \"foreign_gross\"       \n [7] \"world_gross\"          \"budget\"               \"profitability\"       \n[10] \"opening_weekend\"     \n\n\n\nmovies_modified %&gt;%\n  drop_na() %&gt;%\n  gf_point(profitability ~ budget) %&gt;%\n  gf_smooth() %&gt;%\n  gf_labs(\n    title = \"Profitability vs budget\",\n    subtitle = \"Movie profitability: Does budget affect profitability?\"\n  )\n\n`geom_smooth()` using method = 'loess'\n\n\n\n\n\n\n\n\n\n\nmovies_modified %&gt;%\n  drop_na() %&gt;%\n  gf_point(profitability ~ budget, color = ~story) %&gt;%\n  gf_lm() %&gt;%\n  gf_labs(\n    title = \"Profitability vs budget\",\n    subtitle = \"Movie profitability: Does budget affect profitability?\"\n  )\n\n\n\n\n\n\n\n\n\nmovies_modified %&gt;% count(lead_studio) %&gt;% slice_min(n = 10, order_by = n)\n\n                 lead_studio n\n1         Aardman Animations 1\n2                  CBS Films 1\n3       DreamWorks Animation 1\n4  Happy Madison Productions 1\n5              Miramax Films 1\n6   Morgan Creek Productions 1\n7            New Line Cinema 1\n8                      Pixar 1\n9        Regency Enterprises 1\n10               Relativity  1\n11    Reliance Entertainment 1\n12   Sony Pictures Animation 1\n13     Vertigo Entertainment 1\n14 Village Roadshow Pictures 1\n15                    Virgin 1\n\n\n\nmovies_modified %&gt;% count(lead_studio) %&gt;% arrange(desc(n)) %&gt;% head(5)\n\n       lead_studio  n\n1      Independent 32\n2      Warner Bros 12\n3 20th Century Fox  9\n4        Universal  9\n5           Disney  8\n\n\n\nGGally::ggpairs(\n  movies_modified %&gt;% drop_na(),\n  columns = c(\n    \"profitability\", \"budget\", \"domestic_gross\",\"theaters_open_week\",\"opening_weekend\",\"rotten_tomatoes\"),\n  switch = \"both\",\n  progress = FALSE,\n  diag = list(continuous = \"densityDiag\"),\n  lower = list(continuous = wrap(\"smooth\", alpha = 0.3, se = FALSE)),\n  title = \"Movies Data Correlations Plot #1\"\n)\n\n\n\n\n\n\n\n\n\nGGally::ggpairs(\n  movies_modified %&gt;% drop_na(),\n  columns = c(\n    \"profitability\", \"budget\", \"domestic_gross\",\"theaters_open_week\",\"genre\",\"rotten_tomatoes\"),\n  switch = \"both\",\n  progress = FALSE,\n  diag = list(continuous = \"barDiag\"),\n  lower = list(continuous = wrap(\"smooth\", alpha = 0.3, se = FALSE)),\n  title = \"Movies Data Correlations Plot #1\"\n)\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\nmosaic::cor_test(domestic_gross ~ budget, data = movies_modified) %&gt;%\n  broom::tidy() %&gt;%\n  knitr::kable(\n    digits = 2,\n    caption = \"Movie Domestic Gross vs budget\"\n  )\n\n\nMovie Domestic Gross vs budget\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n0.7\n11.06\n0\n131\n0.6\n0.77\nPearson’s product-moment correlation\ntwo.sided"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fundamentals of Statistics and Exploratory Data Analysis",
    "section": "",
    "text": "Sep 28, 2025\n\n\nDiya Bijoy, Swetha KV, Abhinav, Aanya Pandith\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2025\n\n\nDiya Bijoy, Swetha KV, Abhinav R, Aanya Pandith\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2025\n\n\nDiya Bijoy, Swetha KV, Abhinav, Aanya Pandith\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#assignments",
    "href": "index.html#assignments",
    "title": "Fundamentals of Statistics and Exploratory Data Analysis",
    "section": "",
    "text": "Sep 28, 2025\n\n\nDiya Bijoy, Swetha KV, Abhinav, Aanya Pandith\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2025\n\n\nDiya Bijoy, Swetha KV, Abhinav R, Aanya Pandith\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2025\n\n\nDiya Bijoy, Swetha KV, Abhinav, Aanya Pandith\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#classwork",
    "href": "index.html#classwork",
    "title": "Fundamentals of Statistics and Exploratory Data Analysis",
    "section": "Classwork",
    "text": "Classwork\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 7, 2025\n\n\nClasswork 6\n\n\nDiya Bijoy\n\n\n\n\nOct 6, 2025\n\n\nClasswork 5\n\n\nDiya Bijoy\n\n\n\n\nSep 23, 2025\n\n\nClasswork 4\n\n\nDiya Bijoy\n\n\n\n\nSep 22, 2025\n\n\nClasswork 3\n\n\nDiya Bijoy\n\n\n\n\nSep 16, 2025\n\n\nClasswork 2\n\n\nDiya Bijoy\n\n\n\n\nSep 15, 2025\n\n\nClasswork 1\n\n\nDiya Bijoy\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "Math, math, math… for some an absolute nightmare for others the holy grail of existence. Let’s break it down\n\n\n\nThis section handles loading the dataset, cleaning missing values, and initial transformations like converting variables to factors.\nLoad necessary libraries for data manipulation, visualization, and interactive elements.\n\n\n\nlibrary(ggformula)\n\nLoading required package: ggplot2\n\n\nLoading required package: scales\n\n\nLoading required package: ggridges\n\n\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(naniar)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:naniar':\n\n    n_complete\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.0.4     ✔ tidyr     1.3.1\n✔ readr     2.1.5     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ mosaic::count()     masks dplyr::count()\n✖ purrr::cross()      masks mosaic::cross()\n✖ purrr::discard()    masks scales::discard()\n✖ mosaic::do()        masks dplyr::do()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ mosaic::stat()      masks ggplot2::stat()\n✖ mosaic::tally()     masks dplyr::tally()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tinytable)\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(visdat)\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(RColorBrewer)\n\n\n\n\n\n\nmeth &lt;- readr::read_delim(\"MathAnxiety.csv\",\n                          delim = \";\",\n                          locale = locale(decimal_mark = \",\")) %&gt;% \n  janitor::clean_names(\"snake\")\n\nRows: 599 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (2): Gender, Grade\ndbl (4): Age, AMAS, RCMAS, Arith\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmeth\n\n# A tibble: 599 × 6\n     age gender grade      amas rcmas arith\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  138. Boy    Secondary     9    20     6\n 2  141. Boy    Secondary    18     8     6\n 3  138. Girl   Secondary    23    26     5\n 4  143. Girl   Secondary    19    18     7\n 5  136. Boy    Secondary    23    20     1\n 6  135  Girl   Secondary    27    33     1\n 7  134. Boy    Secondary    22    23     4\n 8  139. Boy    Secondary    17    11     7\n 9  132. Girl   Secondary    28    32     2\n10  135. Boy    Secondary    20    30     6\n# ℹ 589 more rows\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nAge\nThe age of the child in months.\n\n\nGender\nThe gender of the child (Boy or Girl).\n\n\nGrade\nThe educational level of the child (Primary or Secondary).\n\n\nAMAS\nThe score on the Abbreviated Math Anxiety Scale, where a higher score indicates greater math anxiety.\n\n\nRCMAS\nThe score on the Revised Children’s Manifest Anxiety Scale, measuring general anxiety\n\n\nArith\nThe score on an arithmetic test.\n\n\n\n\n\n\nThis section inspects the dataset structure, summaries, counts, and missing values through various diagnostic functions.\n\nsummary(meth)\n\n      age           gender             grade                amas      \n Min.   :  3.7   Length:599         Length:599         Min.   : 4.00  \n 1st Qu.:106.2   Class :character   Class :character   1st Qu.:18.00  \n Median :120.8   Mode  :character   Mode  :character   Median :22.00  \n Mean   :124.6                                         Mean   :21.98  \n 3rd Qu.:141.8                                         3rd Qu.:26.50  \n Max.   :187.5                                         Max.   :45.00  \n     rcmas           arith      \n Min.   : 1.00   Min.   :0.000  \n 1st Qu.:14.00   1st Qu.:4.000  \n Median :19.00   Median :6.000  \n Mean   :19.24   Mean   :5.302  \n 3rd Qu.:25.00   3rd Qu.:7.000  \n Max.   :41.00   Max.   :8.000  \n\n\n\nskimr::skim(meth)\n\n\nData summary\n\n\nName\nmeth\n\n\nNumber of rows\n599\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ngender\n0\n1\n3\n4\n0\n2\n0\n\n\ngrade\n0\n1\n7\n9\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nage\n0\n1\n124.65\n22.31\n3.7\n106.15\n120.8\n141.85\n187.5\n▁▁▇▇▃\n\n\namas\n0\n1\n21.98\n6.60\n4.0\n18.00\n22.0\n26.50\n45.0\n▂▆▇▃▁\n\n\nrcmas\n0\n1\n19.24\n7.57\n1.0\n14.00\n19.0\n25.00\n41.0\n▂▇▇▅▁\n\n\narith\n0\n1\n5.30\n2.11\n0.0\n4.00\n6.0\n7.00\n8.0\n▂▃▃▇▇\n\n\n\n\n\nShow the structure of the dataset including data types.\n\nstr(meth)\n\nspc_tbl_ [599 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ age   : num [1:599] 138 141 138 143 136 ...\n $ gender: chr [1:599] \"Boy\" \"Boy\" \"Girl\" \"Girl\" ...\n $ grade : chr [1:599] \"Secondary\" \"Secondary\" \"Secondary\" \"Secondary\" ...\n $ amas  : num [1:599] 9 18 23 19 23 27 22 17 28 20 ...\n $ rcmas : num [1:599] 20 8 26 18 20 33 23 11 32 30 ...\n $ arith : num [1:599] 6 6 5 7 1 1 4 7 2 6 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Age = col_double(),\n  ..   Gender = col_character(),\n  ..   Grade = col_character(),\n  ..   AMAS = col_double(),\n  ..   RCMAS = col_double(),\n  ..   Arith = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nCount occurrences by gender.\n\ncount(meth, gender)\n\n# A tibble: 2 × 2\n  gender     n\n  &lt;chr&gt;  &lt;int&gt;\n1 Boy      323\n2 Girl     276\n\n\nReturn the dimensions of the dataset.\n\ndim(meth)\n\n[1] 599   6\n\n\nList the column names of the dataset.\n\nbase::names(meth)\n\n[1] \"age\"    \"gender\" \"grade\"  \"amas\"   \"rcmas\"  \"arith\" \n\n\nProvide a glimpse of the dataset showing types and sample value\n\ndplyr::glimpse(meth)\n\nRows: 599\nColumns: 6\n$ age    &lt;dbl&gt; 137.8, 140.7, 137.9, 142.8, 135.6, 135.0, 133.6, 139.3, 131.7, …\n$ gender &lt;chr&gt; \"Boy\", \"Boy\", \"Girl\", \"Girl\", \"Boy\", \"Girl\", \"Boy\", \"Boy\", \"Gir…\n$ grade  &lt;chr&gt; \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\"…\n$ amas   &lt;dbl&gt; 9, 18, 23, 19, 23, 27, 22, 17, 28, 20, 16, 20, 21, 36, 16, 27, …\n$ rcmas  &lt;dbl&gt; 20, 8, 26, 18, 20, 33, 23, 11, 32, 30, 10, 4, 23, 26, 24, 21, 3…\n$ arith  &lt;dbl&gt; 6, 6, 5, 7, 1, 1, 4, 7, 2, 6, 2, 5, 2, 6, 2, 7, 2, 4, 7, 3, 8, …\n\n\nReplace common NA representations with actual NA values in the dataset.\n\nmeth_modified &lt;- meth %&gt;%\n  naniar::replace_with_na_all(data = ., condition = ~ .x %in% common_na_numbers) %&gt;%\n  naniar::replace_with_na_all(data = ., condition = ~ .x %in% common_na_strings)\nglimpse(meth_modified)\n\nRows: 599\nColumns: 6\n$ age    &lt;dbl&gt; 137.8, 140.7, 137.9, 142.8, 135.6, 135.0, 133.6, 139.3, 131.7, …\n$ gender &lt;chr&gt; \"Boy\", \"Boy\", \"Girl\", \"Girl\", \"Boy\", \"Girl\", \"Boy\", \"Boy\", \"Gir…\n$ grade  &lt;chr&gt; \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\"…\n$ amas   &lt;dbl&gt; 9, 18, 23, 19, 23, 27, 22, 17, 28, 20, 16, 20, 21, 36, 16, 27, …\n$ rcmas  &lt;dbl&gt; 20, 8, 26, 18, 20, 33, 23, 11, 32, 30, 10, 4, 23, 26, 24, 21, 3…\n$ arith  &lt;dbl&gt; 6, 6, 5, 7, 1, 1, 4, 7, 2, 6, 2, 5, 2, 6, 2, 7, 2, 4, 7, 3, 8, …\n\n\n\n\n\n\nvisdat::vis_miss(meth_modified)\n\n\n\n\n\n\n\nvisdat::vis_dat(meth_modified)\n\n\n\n\n\n\n\n\n\n\n\nThis section performs further data wrangling, such as binning age and factoring variables.\nConvert gender and grade to factors and relocate them before age for better organization.\n\nmeth_modified &lt;- meth_modified %&gt;%\n  mutate(\n    gender = as.factor(gender),\n    grade = as.factor(grade),\n  ) %&gt;%\n  dplyr::relocate(where(is.factor), .before = age)\nglimpse(meth_modified)\n\nRows: 599\nColumns: 6\n$ gender &lt;fct&gt; Boy, Boy, Girl, Girl, Boy, Girl, Boy, Boy, Girl, Boy, Boy, Boy,…\n$ grade  &lt;fct&gt; Secondary, Secondary, Secondary, Secondary, Secondary, Secondar…\n$ age    &lt;dbl&gt; 137.8, 140.7, 137.9, 142.8, 135.6, 135.0, 133.6, 139.3, 131.7, …\n$ amas   &lt;dbl&gt; 9, 18, 23, 19, 23, 27, 22, 17, 28, 20, 16, 20, 21, 36, 16, 27, …\n$ rcmas  &lt;dbl&gt; 20, 8, 26, 18, 20, 33, 23, 11, 32, 30, 10, 4, 23, 26, 24, 21, 3…\n$ arith  &lt;dbl&gt; 6, 6, 5, 7, 1, 1, 4, 7, 2, 6, 2, 5, 2, 6, 2, 7, 2, 4, 7, 3, 8, …\n\n\n\nmeth_modified %&gt;%\n  head(10) %&gt;%\n  dplyr::rename(\n    \"Gender\" = gender,\n    \"Grade\" = grade,\n    \"Age (months)\" = age,\n    \"AMAS (Math Anxiety)\" = amas,\n    \"RCMAS (General Anxiety)\" = rcmas,\n    \"Arithmetic Score\" = arith\n  ) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Gender\n                Grade\n                Age (months)\n                AMAS (Math Anxiety)\n                RCMAS (General Anxiety)\n                Arithmetic Score\n              \n        \n        \n        \n                \n                  Boy\n                  Secondary\n                  137.8\n                  9\n                  20\n                  6\n                \n                \n                  Boy\n                  Secondary\n                  140.7\n                  18\n                  8\n                  6\n                \n                \n                  Girl\n                  Secondary\n                  137.9\n                  23\n                  26\n                  5\n                \n                \n                  Girl\n                  Secondary\n                  142.8\n                  19\n                  18\n                  7\n                \n                \n                  Boy\n                  Secondary\n                  135.6\n                  23\n                  20\n                  1\n                \n                \n                  Girl\n                  Secondary\n                  135.0\n                  27\n                  33\n                  1\n                \n                \n                  Boy\n                  Secondary\n                  133.6\n                  22\n                  23\n                  4\n                \n                \n                  Boy\n                  Secondary\n                  139.3\n                  17\n                  11\n                  7\n                \n                \n                  Girl\n                  Secondary\n                  131.7\n                  28\n                  32\n                  2\n                \n                \n                  Boy\n                  Secondary\n                  134.8\n                  20\n                  30\n                  6\n                \n        \n      \n    \n\n\n\n\n\n\n\nmeth_modified %&gt;% dplyr::count(across(.cols = c(gender, grade)))\n\n# A tibble: 4 × 3\n  gender grade         n\n  &lt;fct&gt;  &lt;fct&gt;     &lt;int&gt;\n1 Boy    Primary     199\n2 Boy    Secondary   124\n3 Girl   Primary     202\n4 Girl   Secondary    74\n\n\n\nmeth_modified %&gt;%\n  dplyr::summarise(\n    mean_amas = mean(amas, na.rm = T),\n    sd_amas = sd(amas, na.rm = T),\n    min_amas = min(amas, na.rm = T),\n    max_amas = max(amas, na.rm = T)\n  )\n\n# A tibble: 1 × 4\n  mean_amas sd_amas min_amas max_amas\n      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1      22.0    6.60        4       45\n\n\n\nmeth_modified %&gt;%\n  dplyr::summarise(across(\n    .cols = c(amas, rcmas), \n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 1 × 8\n  amas_mean amas_sd amas_min amas_max rcmas_mean rcmas_sd rcmas_min rcmas_max\n      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1      22.0    6.60        4       45       19.2     7.57         1        41\n\n\n\nmeth_modified %&gt;%\n  dplyr::summarise(\n    mean_arith = mean(arith, na.rm = T),\n    sd_arith = sd(arith, na.rm = T),\n    min_arith = min(arith, na.rm = T),\n    max_arith = max(arith, na.rm = T)\n  )\n\n# A tibble: 1 × 4\n  mean_arith sd_arith min_arith max_arith\n       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1       5.30     2.11         0         8\n\n\n\nmeth_modified %&gt;%\n  dplyr::summarise(\n    mean_age = mean(age, na.rm = T),\n    sd_age = sd(age, na.rm = T),\n    min_age = min(age, na.rm = T),\n    max_age = max(age, na.rm = T)\n  )\n\n# A tibble: 1 × 4\n  mean_age sd_age min_age max_age\n     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     125.   22.3     3.7    188.\n\n\n\nmeth_modified %&gt;%\n  group_by(gender) %&gt;%\n  dplyr::summarise(across(\n    .cols = c(age, amas, rcmas, arith),\n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 2 × 17\n  gender age_mean age_sd age_min age_max amas_mean amas_sd amas_min amas_max\n  &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Boy        128.   22.9    93.1    188.      21.2    6.51        4       45\n2 Girl       121.   21.1     3.7    180.      22.9    6.59        9       40\n# ℹ 8 more variables: rcmas_mean &lt;dbl&gt;, rcmas_sd &lt;dbl&gt;, rcmas_min &lt;dbl&gt;,\n#   rcmas_max &lt;dbl&gt;, arith_mean &lt;dbl&gt;, arith_sd &lt;dbl&gt;, arith_min &lt;dbl&gt;,\n#   arith_max &lt;dbl&gt;\n\n\n\ncrosstable(age + rcmas + amas + arith ~ gender,\n  data = meth_modified\n) %&gt;%\n  crosstable::as_flextable()\n\nlabelvariablegenderBoyGirlageMin / Max93.1 / 187.53.7 / 180.3Med [IQR]124.9 [107.4;147.2]117.8 [105.8;133.4]Mean (std)127.6 (22.9)121.1 (21.1)N (NA)323 (0)276 (0)rcmasMin / Max1.0 / 41.03.0 / 38.0Med [IQR]18.0 [13.0;23.0]20.0 [15.0;26.0]Mean (std)18.1 (7.5)20.6 (7.4)N (NA)323 (0)276 (0)amasMin / Max4.0 / 45.09.0 / 40.0Med [IQR]21.0 [17.0;26.0]23.0 [19.0;28.0]Mean (std)21.2 (6.5)22.9 (6.6)N (NA)323 (0)276 (0)arithMin / Max0 / 8.00 / 8.0Med [IQR]6.0 [4.0;7.0]6.0 [4.0;7.0]Mean (std)5.3 (2.1)5.3 (2.1)N (NA)323 (0)276 (0)\n\n\n\nmeth_modified %&gt;%\n  group_by(gender) %&gt;%\n  dplyr::summarise(across(\n    .cols = c(age, amas, rcmas, arith),\n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 2 × 17\n  gender age_mean age_sd age_min age_max amas_mean amas_sd amas_min amas_max\n  &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Boy        128.   22.9    93.1    188.      21.2    6.51        4       45\n2 Girl       121.   21.1     3.7    180.      22.9    6.59        9       40\n# ℹ 8 more variables: rcmas_mean &lt;dbl&gt;, rcmas_sd &lt;dbl&gt;, rcmas_min &lt;dbl&gt;,\n#   rcmas_max &lt;dbl&gt;, arith_mean &lt;dbl&gt;, arith_sd &lt;dbl&gt;, arith_min &lt;dbl&gt;,\n#   arith_max &lt;dbl&gt;\n\n\n\nmeth_modified %&gt;%\n  group_by(grade) %&gt;%\n  dplyr::summarise(across(\n    .cols = c(age, amas, rcmas, arith),\n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 2 × 17\n  grade     age_mean age_sd age_min age_max amas_mean amas_sd amas_min amas_max\n  &lt;fct&gt;        &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Primary       111.   12.1     3.7    135.      21.8    6.53        4       38\n2 Secondary     151.   12.1   132.     188.      22.3    6.75        9       45\n# ℹ 8 more variables: rcmas_mean &lt;dbl&gt;, rcmas_sd &lt;dbl&gt;, rcmas_min &lt;dbl&gt;,\n#   rcmas_max &lt;dbl&gt;, arith_mean &lt;dbl&gt;, arith_sd &lt;dbl&gt;, arith_min &lt;dbl&gt;,\n#   arith_max &lt;dbl&gt;\n\n\n\ngf_histogram(~age, data = meth_modified) %&gt;%\n  gf_labs(title = \"Histogram of Age\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_histogram(~amas, data = meth_modified) %&gt;%\n  gf_labs(title = \"Histogram of AMAS\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_histogram(~rcmas, data = meth_modified) %&gt;%\n  gf_labs(title = \"Histogram of RCMAS\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_bar(~grade, data = meth_modified) %&gt;%\n  gf_labs(title = \"Bar Plot of Grade\")\n\n\n\n\n\n\n\n\n\ngf_bar(~gender, data = meth_modified) %&gt;%\n  gf_labs(title = \"Bar Plot of Gender\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_bar(~grade,\n         fill=~gender,\n         position = \"dodge\") +\n  labs(title= \"Grade count for both genders\", subtitle = \"Dodged Bar Chart\", x =\"Grade\", y =\"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\nWhy is the count reducing in secondary grade? Assuming lesser students have enrolled for Secondary grade compared to Primary grade.\n\nmeth_modified %&gt;%\n  gf_bar(~grade,\n         fill=~gender,\n         position = \"stack\") +\n  labs(title= \"Grade count for both genders\", subtitle = \"Stacked Bar Chart\", x =\"Grade\", y =\"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\nComparing Count of Girl’s Grade\n\nmeth_modified %&gt;%\n  gf_bar(~grade,\n         fill=~gender,\n         position = \"fill\") +\n  labs(title= \"Comparing count of both gender's grade\", subtitle = \"Filled Bar Chart\", x =\"Grade\", y =\"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_bar(~age,\n         fill=~gender,\n         position = \"stack\") +\n  labs(title= \"Age count for both genders\", subtitle = \"Stacked Bar Chart\", x =\"Age\", y =\"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\n\n\nAfter age 150 months (12.5 years), there’s a significant drop, which confirms that as students get older, fewer people enroll in math.\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_histogram(~amas| grade~gender,\n               bins = 5,\n               fill = \"steelblue\",\n               color=\"white\") %&gt;% \n  gf_labs(title=\"Histogram of AMAS Scores\",\n          subtitle =\"Faceted by Grade and Gender\",\n          x=\"AMAS Score\",\n          y=\"Count\")\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_histogram(~amas | grade,\n               fill=~gender,\n               colour=\"black\") %&gt;%\n  gf_labs(\n    title = \"AMAS by Filled and Faceted by Grade\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_boxplot(amas~gender | grade,\n             fill=~gender,\n             orientation = \"x\") %&gt;% \n  gf_labs(title = \"Boxplots of AMAS Scores by Grade\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Gender\",\n       y = \"AMAS Score\")\n\n\n\n\n\n\n\n\n\n\n\nGirls face more math anxiety: Box plots show higher medians, wider ranges. For girls, means are higher in both Primary & Secondary Grades.\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_histogram(~rcmas| grade~gender,\n               bins = 5,\n               fill = \"steelblue\",\n               color=\"white\") %&gt;% \n  gf_labs(title=\"Histogram of RCMAS Scores\",\n          subtitle =\"Faceted by Grade and Gender\",\n          x=\"RCMAS Score\",\n          y=\"Count\")\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_histogram(~rcmas | grade,\n               fill=~gender,\n               colour=\"black\") %&gt;%\n  gf_labs(\n    title = \"RCMAS by Filled and Faceted by Grade\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_boxplot(rcmas~gender | grade,\n             fill=~gender,\n             orientation = \"x\") %&gt;% \n  gf_labs(title = \"Boxplots of RCMAS Scores by Grade\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Gender\",\n       y = \"RCMAS Score\")\n\n\n\n\n\n\n\n\n\n\n\nAnxiety appears to be higher for Girls than for Boys\nAnxiety appears to be highest in Primary Girls\nAnxiety appears to be lowest in Secondary Boys\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_bar(~arith | grade,\n               fill = ~gender,\n               position=\"dodge\",\n               color=\"black\") %&gt;% \n  gf_labs(title = \"Dodged Bar Graph of Arith Scores\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Arith Score\",\n       y = \"Count\") %&gt;% \n  gf_refine(scale_color_brewer(palette = \"Set 2\"))\n\nWarning: Unknown palette: \"Set 2\"\n\n\n\n\n\n\n\n\n\n\n\n\nIn general, girls have a lower arith score than boys.\nIn Primary Grade, it is seen that the difference between girls and boys score is less when compared to Secondary grade where the gap is bigger.\n\n\nmeth_modified %&gt;%\n  gf_bar(~arith | grade,\n               fill = ~gender,\n               position=\"fill\",\n               color=\"black\") %&gt;% \n  gf_labs(title = \"Filled Bar Graph of Arith Scores\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Arith Score\",\n       y = \"Count\") %&gt;% \n  gf_refine(scale_color_brewer(palette = \"Set 2\"))\n\nWarning: Unknown palette: \"Set 2\"\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_bar(~arith | grade,\n               fill=~grade,\n               colour=\"black\") %&gt;%\n  gf_labs(\n    title = \"Arith by Filled and Faceted by Grade\",\n    x=\"Arith Scores\",\n    y=\"Count\")\n\n\n\n\n\n\n\n\n\n\n\nPrimary Grade have higher arith scores than Secondary Grade.\n\nmeth_modified %&gt;% \n  gf_boxplot(arith ~gender | grade,\n             fill=~gender,\n             orientation = \"x\") %&gt;% \n  gf_labs(title = \"Boxplots of Arith Scores by Grade\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Gender\",\n       y = \"Arith Score\")\n\n\n\n\n\n\n\n\n\n\n\n\nPrimary grades ranges from 5 to 7 & Median is 6, while Secondary grades ranges from 3 to 6 & median is 4.\nSecondary students lag in arithmetic: Box plots shows lower medians and wider ranges for Secondary Grade.\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_point(arith ~ age | gender, color = ~ grade) %&gt;%\n  gf_labs(\n    title = \"Scatter Plot of Age vs Arithmetic Score\",\n    subtitle = \"Faceted by Gender, Colored by Grade\",\n    x = \"Age\",\n    y = \"Arithmetic Score\",\n    color = \"Grade\"\n  ) %&gt;%\n  gf_refine(scale_color_brewer(palette = \"Spectral\")) %&gt;% \n  gf_theme(theme_dark())\n\n\n\n\n\n\n\n\n\n\n\nScatter plots shows similar Arith trends across both genders, but primary tend to have higher Arith scores.\n\n\nmeth_modified %&gt;% \n  gf_boxplot(arith ~ grade | gender, orientation = \"x\", fill=~grade, color = \"black\") %&gt;%\n gf_labs(\n    x = \"Grade\",\n    y = \"Arithmetic Score\",\n    title = \"Arithmetic Scores by Grade\",\n    subtitle = \"Faceted by Gender\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set3\")) %&gt;%\n  gf_theme(theme_dark())\n\n\n\n\n\n\n\n\n\n\n\n\nPrimary grade students (both genders) have higher arithmetic scores compared to secondary grade.\nSecondary grade students have wider range for arithmetic scores compared to Primary grade.\nAmong genders within each grade there’s no difference in score .\n\n\n\n\n\n\nHypothesis: From previous visualization we think that Math Anxiety (AMAS) is affects Arithmetic scores.\n\n\nmeth_modified %&gt;%\n  gf_boxplot(arith ~ amas | gender ~ grade, fill = ~ gender, orientation = \"x\") %&gt;%\n  gf_labs(\n    title = \"Relationship between Math Anxiety and Arithmetic Performance\",\n    subtitle = \"Across Gender and Grade\",\n    x = \"Math Anxiety (AMAS)\",\n    y = \"Arithmetic Performance (Arith)\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set2\")) %&gt;%\n  gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\nAs math anxiety (AMAS) increases, arithmetic performance tends to go down for both genders.\nIn both primary and secondary grade, Boys perform better than girls.\nPrimary Grade students have higher math score than Secondary.\nThe Secondary grade has more Math anxeity and this affects their Arithmatic scores.\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_density(~ age | gender, fill = ~ grade, color=\"black\") %&gt;%\n  gf_labs(\n    title = \"Density Plots of Age\",\n    subtitle = \"Faceted by Gender, Filled by Grade\",\n    x = \"Age\",\n    y = \"Density\",\n    color = \"Grade\"\n  ) %&gt;% \n  gf_refine(scale_color_brewer(palette = \"Set 3\")) %&gt;% \n  gf_theme(theme_light())\n\nWarning: Unknown palette: \"Set 3\"\n\n\nIgnoring unknown labels:\n• colour : \"Grade\"\n\n\n\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_point(rcmas ~ amas, color = ~ gender, shape = ~ gender) %&gt;%\n  gf_labs(\n    title = \"Scatter Plot of Amas vs Rcmas\",\n    subtitle = \"Colored by Gender\",\n    x = \"Amas Score\",\n    y = \"Rcmas Score\"\n  ) %&gt;%\n  gf_refine(scale_color_brewer(palette = \"Set1\")) %&gt;% \n  gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\nIn general, both Genders have higher amas and lower rcmas\n\n\nmeth_modified %&gt;%\n  gf_boxplot(rcmas ~ amas | gender~grade, fill =~gender, orientation = \"y\") %&gt;%\n  gf_labs(\n    title = \"Box Plot of Amas vs Rcmas\",\n    subtitle = \"Colored by Grade\",\n    x = \"Amas Score\",\n    y = \"Rcmas Score\"\n  ) %&gt;%\n  gf_refine(scale_color_brewer(palette = \"Set2\")) %&gt;% \n  gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\n\nAs seen in the boxplot graphs, Boys tend to have a wider range of RCMAS than girls.\nComparing Primary and Secondary Boys -\n\nPrimary Boys have lower general anxiety (rcmas) and higher math anxiety (amas).\nSecondary Boys have higher general anxiety (rcmas) and lower math anxiety (amas).\n\nComparing Primary and Secondary Girls -\n\nPrimary Girls have higher general anxiety(rcmas) and lower math anxiety (amas)\nSecondary Girls have lower general anxiety (rcmas) and higher math anxiety (amas)\n\nComparing Primary Boys and Girls -\n\nBoys have lesser median but wider range for math anxiety (amas)\nGirls have higher median but narrower range for math anxiety (amas)\nBoys & Girls have same range for general anxiety (rcmas)\n\nComparing Secondary Boys & Girls -\n\nBoys have lesser median and narrower range for math anxiety (amas)\nGirls have higher median and wider range for math anxiety (amas)\nBoys have wider range of general anxiety compared to girls (rcmas)\n\n\n\n\n\n\n\n\nMost visualizations show that girls have higher anxieties (both math and general), while boys have higher arithmetic scores. This could be due to boys possibly having a better support system.\nMany visualizations confirm: primary grade students do better in Math,"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#data-cleaning",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#data-cleaning",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "This section handles loading the dataset, cleaning missing values, and initial transformations like converting variables to factors.\nLoad necessary libraries for data manipulation, visualization, and interactive elements.\n\n\n\nlibrary(ggformula)\n\nLoading required package: ggplot2\n\n\nLoading required package: scales\n\n\nLoading required package: ggridges\n\n\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(naniar)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:naniar':\n\n    n_complete\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.0.4     ✔ tidyr     1.3.1\n✔ readr     2.1.5     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ mosaic::count()     masks dplyr::count()\n✖ purrr::cross()      masks mosaic::cross()\n✖ purrr::discard()    masks scales::discard()\n✖ mosaic::do()        masks dplyr::do()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ mosaic::stat()      masks ggplot2::stat()\n✖ mosaic::tally()     masks dplyr::tally()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tinytable)\n\n\nAttaching package: 'tinytable'\n\nThe following object is masked from 'package:ggplot2':\n\n    theme_void\n\nlibrary(visdat)\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\nlibrary(RColorBrewer)"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#read-data",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#read-data",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "meth &lt;- readr::read_delim(\"MathAnxiety.csv\",\n                          delim = \";\",\n                          locale = locale(decimal_mark = \",\")) %&gt;% \n  janitor::clean_names(\"snake\")\n\nRows: 599 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (2): Gender, Grade\ndbl (4): Age, AMAS, RCMAS, Arith\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmeth\n\n# A tibble: 599 × 6\n     age gender grade      amas rcmas arith\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  138. Boy    Secondary     9    20     6\n 2  141. Boy    Secondary    18     8     6\n 3  138. Girl   Secondary    23    26     5\n 4  143. Girl   Secondary    19    18     7\n 5  136. Boy    Secondary    23    20     1\n 6  135  Girl   Secondary    27    33     1\n 7  134. Boy    Secondary    22    23     4\n 8  139. Boy    Secondary    17    11     7\n 9  132. Girl   Secondary    28    32     2\n10  135. Boy    Secondary    20    30     6\n# ℹ 589 more rows"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#data-dictionary",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#data-dictionary",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "Variable\nDescription\n\n\n\n\nAge\nThe age of the child in months.\n\n\nGender\nThe gender of the child (Boy or Girl).\n\n\nGrade\nThe educational level of the child (Primary or Secondary).\n\n\nAMAS\nThe score on the Abbreviated Math Anxiety Scale, where a higher score indicates greater math anxiety.\n\n\nRCMAS\nThe score on the Revised Children’s Manifest Anxiety Scale, measuring general anxiety\n\n\nArith\nThe score on an arithmetic test."
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#examine-data",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#examine-data",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "This section inspects the dataset structure, summaries, counts, and missing values through various diagnostic functions.\n\nsummary(meth)\n\n      age           gender             grade                amas      \n Min.   :  3.7   Length:599         Length:599         Min.   : 4.00  \n 1st Qu.:106.2   Class :character   Class :character   1st Qu.:18.00  \n Median :120.8   Mode  :character   Mode  :character   Median :22.00  \n Mean   :124.6                                         Mean   :21.98  \n 3rd Qu.:141.8                                         3rd Qu.:26.50  \n Max.   :187.5                                         Max.   :45.00  \n     rcmas           arith      \n Min.   : 1.00   Min.   :0.000  \n 1st Qu.:14.00   1st Qu.:4.000  \n Median :19.00   Median :6.000  \n Mean   :19.24   Mean   :5.302  \n 3rd Qu.:25.00   3rd Qu.:7.000  \n Max.   :41.00   Max.   :8.000  \n\n\n\nskimr::skim(meth)\n\n\nData summary\n\n\nName\nmeth\n\n\nNumber of rows\n599\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ngender\n0\n1\n3\n4\n0\n2\n0\n\n\ngrade\n0\n1\n7\n9\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nage\n0\n1\n124.65\n22.31\n3.7\n106.15\n120.8\n141.85\n187.5\n▁▁▇▇▃\n\n\namas\n0\n1\n21.98\n6.60\n4.0\n18.00\n22.0\n26.50\n45.0\n▂▆▇▃▁\n\n\nrcmas\n0\n1\n19.24\n7.57\n1.0\n14.00\n19.0\n25.00\n41.0\n▂▇▇▅▁\n\n\narith\n0\n1\n5.30\n2.11\n0.0\n4.00\n6.0\n7.00\n8.0\n▂▃▃▇▇\n\n\n\n\n\nShow the structure of the dataset including data types.\n\nstr(meth)\n\nspc_tbl_ [599 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ age   : num [1:599] 138 141 138 143 136 ...\n $ gender: chr [1:599] \"Boy\" \"Boy\" \"Girl\" \"Girl\" ...\n $ grade : chr [1:599] \"Secondary\" \"Secondary\" \"Secondary\" \"Secondary\" ...\n $ amas  : num [1:599] 9 18 23 19 23 27 22 17 28 20 ...\n $ rcmas : num [1:599] 20 8 26 18 20 33 23 11 32 30 ...\n $ arith : num [1:599] 6 6 5 7 1 1 4 7 2 6 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Age = col_double(),\n  ..   Gender = col_character(),\n  ..   Grade = col_character(),\n  ..   AMAS = col_double(),\n  ..   RCMAS = col_double(),\n  ..   Arith = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nCount occurrences by gender.\n\ncount(meth, gender)\n\n# A tibble: 2 × 2\n  gender     n\n  &lt;chr&gt;  &lt;int&gt;\n1 Boy      323\n2 Girl     276\n\n\nReturn the dimensions of the dataset.\n\ndim(meth)\n\n[1] 599   6\n\n\nList the column names of the dataset.\n\nbase::names(meth)\n\n[1] \"age\"    \"gender\" \"grade\"  \"amas\"   \"rcmas\"  \"arith\" \n\n\nProvide a glimpse of the dataset showing types and sample value\n\ndplyr::glimpse(meth)\n\nRows: 599\nColumns: 6\n$ age    &lt;dbl&gt; 137.8, 140.7, 137.9, 142.8, 135.6, 135.0, 133.6, 139.3, 131.7, …\n$ gender &lt;chr&gt; \"Boy\", \"Boy\", \"Girl\", \"Girl\", \"Boy\", \"Girl\", \"Boy\", \"Boy\", \"Gir…\n$ grade  &lt;chr&gt; \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\"…\n$ amas   &lt;dbl&gt; 9, 18, 23, 19, 23, 27, 22, 17, 28, 20, 16, 20, 21, 36, 16, 27, …\n$ rcmas  &lt;dbl&gt; 20, 8, 26, 18, 20, 33, 23, 11, 32, 30, 10, 4, 23, 26, 24, 21, 3…\n$ arith  &lt;dbl&gt; 6, 6, 5, 7, 1, 1, 4, 7, 2, 6, 2, 5, 2, 6, 2, 7, 2, 4, 7, 3, 8, …\n\n\nReplace common NA representations with actual NA values in the dataset.\n\nmeth_modified &lt;- meth %&gt;%\n  naniar::replace_with_na_all(data = ., condition = ~ .x %in% common_na_numbers) %&gt;%\n  naniar::replace_with_na_all(data = ., condition = ~ .x %in% common_na_strings)\nglimpse(meth_modified)\n\nRows: 599\nColumns: 6\n$ age    &lt;dbl&gt; 137.8, 140.7, 137.9, 142.8, 135.6, 135.0, 133.6, 139.3, 131.7, …\n$ gender &lt;chr&gt; \"Boy\", \"Boy\", \"Girl\", \"Girl\", \"Boy\", \"Girl\", \"Boy\", \"Boy\", \"Gir…\n$ grade  &lt;chr&gt; \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\", \"Secondary\"…\n$ amas   &lt;dbl&gt; 9, 18, 23, 19, 23, 27, 22, 17, 28, 20, 16, 20, 21, 36, 16, 27, …\n$ rcmas  &lt;dbl&gt; 20, 8, 26, 18, 20, 33, 23, 11, 32, 30, 10, 4, 23, 26, 24, 21, 3…\n$ arith  &lt;dbl&gt; 6, 6, 5, 7, 1, 1, 4, 7, 2, 6, 2, 5, 2, 6, 2, 7, 2, 4, 7, 3, 8, …"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#viewing-missing-data",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#viewing-missing-data",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "visdat::vis_miss(meth_modified)\n\n\n\n\n\n\n\nvisdat::vis_dat(meth_modified)"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#munging",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#munging",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "This section performs further data wrangling, such as binning age and factoring variables.\nConvert gender and grade to factors and relocate them before age for better organization.\n\nmeth_modified &lt;- meth_modified %&gt;%\n  mutate(\n    gender = as.factor(gender),\n    grade = as.factor(grade),\n  ) %&gt;%\n  dplyr::relocate(where(is.factor), .before = age)\nglimpse(meth_modified)\n\nRows: 599\nColumns: 6\n$ gender &lt;fct&gt; Boy, Boy, Girl, Girl, Boy, Girl, Boy, Boy, Girl, Boy, Boy, Boy,…\n$ grade  &lt;fct&gt; Secondary, Secondary, Secondary, Secondary, Secondary, Secondar…\n$ age    &lt;dbl&gt; 137.8, 140.7, 137.9, 142.8, 135.6, 135.0, 133.6, 139.3, 131.7, …\n$ amas   &lt;dbl&gt; 9, 18, 23, 19, 23, 27, 22, 17, 28, 20, 16, 20, 21, 36, 16, 27, …\n$ rcmas  &lt;dbl&gt; 20, 8, 26, 18, 20, 33, 23, 11, 32, 30, 10, 4, 23, 26, 24, 21, 3…\n$ arith  &lt;dbl&gt; 6, 6, 5, 7, 1, 1, 4, 7, 2, 6, 2, 5, 2, 6, 2, 7, 2, 4, 7, 3, 8, …\n\n\n\nmeth_modified %&gt;%\n  head(10) %&gt;%\n  dplyr::rename(\n    \"Gender\" = gender,\n    \"Grade\" = grade,\n    \"Age (months)\" = age,\n    \"AMAS (Math Anxiety)\" = amas,\n    \"RCMAS (General Anxiety)\" = rcmas,\n    \"Arithmetic Score\" = arith\n  ) %&gt;%\n  tt()\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Gender\n                Grade\n                Age (months)\n                AMAS (Math Anxiety)\n                RCMAS (General Anxiety)\n                Arithmetic Score\n              \n        \n        \n        \n                \n                  Boy\n                  Secondary\n                  137.8\n                  9\n                  20\n                  6\n                \n                \n                  Boy\n                  Secondary\n                  140.7\n                  18\n                  8\n                  6\n                \n                \n                  Girl\n                  Secondary\n                  137.9\n                  23\n                  26\n                  5\n                \n                \n                  Girl\n                  Secondary\n                  142.8\n                  19\n                  18\n                  7\n                \n                \n                  Boy\n                  Secondary\n                  135.6\n                  23\n                  20\n                  1\n                \n                \n                  Girl\n                  Secondary\n                  135.0\n                  27\n                  33\n                  1\n                \n                \n                  Boy\n                  Secondary\n                  133.6\n                  22\n                  23\n                  4\n                \n                \n                  Boy\n                  Secondary\n                  139.3\n                  17\n                  11\n                  7\n                \n                \n                  Girl\n                  Secondary\n                  131.7\n                  28\n                  32\n                  2\n                \n                \n                  Boy\n                  Secondary\n                  134.8\n                  20\n                  30\n                  6"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#summaries-examining-the-data",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#summaries-examining-the-data",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "meth_modified %&gt;% dplyr::count(across(.cols = c(gender, grade)))\n\n# A tibble: 4 × 3\n  gender grade         n\n  &lt;fct&gt;  &lt;fct&gt;     &lt;int&gt;\n1 Boy    Primary     199\n2 Boy    Secondary   124\n3 Girl   Primary     202\n4 Girl   Secondary    74\n\n\n\nmeth_modified %&gt;%\n  dplyr::summarise(\n    mean_amas = mean(amas, na.rm = T),\n    sd_amas = sd(amas, na.rm = T),\n    min_amas = min(amas, na.rm = T),\n    max_amas = max(amas, na.rm = T)\n  )\n\n# A tibble: 1 × 4\n  mean_amas sd_amas min_amas max_amas\n      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1      22.0    6.60        4       45\n\n\n\nmeth_modified %&gt;%\n  dplyr::summarise(across(\n    .cols = c(amas, rcmas), \n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 1 × 8\n  amas_mean amas_sd amas_min amas_max rcmas_mean rcmas_sd rcmas_min rcmas_max\n      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1      22.0    6.60        4       45       19.2     7.57         1        41\n\n\n\nmeth_modified %&gt;%\n  dplyr::summarise(\n    mean_arith = mean(arith, na.rm = T),\n    sd_arith = sd(arith, na.rm = T),\n    min_arith = min(arith, na.rm = T),\n    max_arith = max(arith, na.rm = T)\n  )\n\n# A tibble: 1 × 4\n  mean_arith sd_arith min_arith max_arith\n       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1       5.30     2.11         0         8\n\n\n\nmeth_modified %&gt;%\n  dplyr::summarise(\n    mean_age = mean(age, na.rm = T),\n    sd_age = sd(age, na.rm = T),\n    min_age = min(age, na.rm = T),\n    max_age = max(age, na.rm = T)\n  )\n\n# A tibble: 1 × 4\n  mean_age sd_age min_age max_age\n     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     125.   22.3     3.7    188.\n\n\n\nmeth_modified %&gt;%\n  group_by(gender) %&gt;%\n  dplyr::summarise(across(\n    .cols = c(age, amas, rcmas, arith),\n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 2 × 17\n  gender age_mean age_sd age_min age_max amas_mean amas_sd amas_min amas_max\n  &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Boy        128.   22.9    93.1    188.      21.2    6.51        4       45\n2 Girl       121.   21.1     3.7    180.      22.9    6.59        9       40\n# ℹ 8 more variables: rcmas_mean &lt;dbl&gt;, rcmas_sd &lt;dbl&gt;, rcmas_min &lt;dbl&gt;,\n#   rcmas_max &lt;dbl&gt;, arith_mean &lt;dbl&gt;, arith_sd &lt;dbl&gt;, arith_min &lt;dbl&gt;,\n#   arith_max &lt;dbl&gt;\n\n\n\ncrosstable(age + rcmas + amas + arith ~ gender,\n  data = meth_modified\n) %&gt;%\n  crosstable::as_flextable()\n\nlabelvariablegenderBoyGirlageMin / Max93.1 / 187.53.7 / 180.3Med [IQR]124.9 [107.4;147.2]117.8 [105.8;133.4]Mean (std)127.6 (22.9)121.1 (21.1)N (NA)323 (0)276 (0)rcmasMin / Max1.0 / 41.03.0 / 38.0Med [IQR]18.0 [13.0;23.0]20.0 [15.0;26.0]Mean (std)18.1 (7.5)20.6 (7.4)N (NA)323 (0)276 (0)amasMin / Max4.0 / 45.09.0 / 40.0Med [IQR]21.0 [17.0;26.0]23.0 [19.0;28.0]Mean (std)21.2 (6.5)22.9 (6.6)N (NA)323 (0)276 (0)arithMin / Max0 / 8.00 / 8.0Med [IQR]6.0 [4.0;7.0]6.0 [4.0;7.0]Mean (std)5.3 (2.1)5.3 (2.1)N (NA)323 (0)276 (0)\n\n\n\nmeth_modified %&gt;%\n  group_by(gender) %&gt;%\n  dplyr::summarise(across(\n    .cols = c(age, amas, rcmas, arith),\n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 2 × 17\n  gender age_mean age_sd age_min age_max amas_mean amas_sd amas_min amas_max\n  &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Boy        128.   22.9    93.1    188.      21.2    6.51        4       45\n2 Girl       121.   21.1     3.7    180.      22.9    6.59        9       40\n# ℹ 8 more variables: rcmas_mean &lt;dbl&gt;, rcmas_sd &lt;dbl&gt;, rcmas_min &lt;dbl&gt;,\n#   rcmas_max &lt;dbl&gt;, arith_mean &lt;dbl&gt;, arith_sd &lt;dbl&gt;, arith_min &lt;dbl&gt;,\n#   arith_max &lt;dbl&gt;\n\n\n\nmeth_modified %&gt;%\n  group_by(grade) %&gt;%\n  dplyr::summarise(across(\n    .cols = c(age, amas, rcmas, arith),\n\n    .fns = list(\n      mean = ~ mean(., na.rm = T),\n      sd = sd,\n      min = min, max = max\n    )\n  ))\n\n# A tibble: 2 × 17\n  grade     age_mean age_sd age_min age_max amas_mean amas_sd amas_min amas_max\n  &lt;fct&gt;        &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Primary       111.   12.1     3.7    135.      21.8    6.53        4       38\n2 Secondary     151.   12.1   132.     188.      22.3    6.75        9       45\n# ℹ 8 more variables: rcmas_mean &lt;dbl&gt;, rcmas_sd &lt;dbl&gt;, rcmas_min &lt;dbl&gt;,\n#   rcmas_max &lt;dbl&gt;, arith_mean &lt;dbl&gt;, arith_sd &lt;dbl&gt;, arith_min &lt;dbl&gt;,\n#   arith_max &lt;dbl&gt;\n\n\n\ngf_histogram(~age, data = meth_modified) %&gt;%\n  gf_labs(title = \"Histogram of Age\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_histogram(~amas, data = meth_modified) %&gt;%\n  gf_labs(title = \"Histogram of AMAS\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_histogram(~rcmas, data = meth_modified) %&gt;%\n  gf_labs(title = \"Histogram of RCMAS\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\ngf_bar(~grade, data = meth_modified) %&gt;%\n  gf_labs(title = \"Bar Plot of Grade\")\n\n\n\n\n\n\n\n\n\ngf_bar(~gender, data = meth_modified) %&gt;%\n  gf_labs(title = \"Bar Plot of Gender\")"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#visualizing-the-data",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#visualizing-the-data",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "meth_modified %&gt;%\n  gf_bar(~grade,\n         fill=~gender,\n         position = \"dodge\") +\n  labs(title= \"Grade count for both genders\", subtitle = \"Dodged Bar Chart\", x =\"Grade\", y =\"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\nWhy is the count reducing in secondary grade? Assuming lesser students have enrolled for Secondary grade compared to Primary grade.\n\nmeth_modified %&gt;%\n  gf_bar(~grade,\n         fill=~gender,\n         position = \"stack\") +\n  labs(title= \"Grade count for both genders\", subtitle = \"Stacked Bar Chart\", x =\"Grade\", y =\"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\nComparing Count of Girl’s Grade\n\nmeth_modified %&gt;%\n  gf_bar(~grade,\n         fill=~gender,\n         position = \"fill\") +\n  labs(title= \"Comparing count of both gender's grade\", subtitle = \"Filled Bar Chart\", x =\"Grade\", y =\"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_bar(~age,\n         fill=~gender,\n         position = \"stack\") +\n  labs(title= \"Age count for both genders\", subtitle = \"Stacked Bar Chart\", x =\"Age\", y =\"Count\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\n\n\nAfter age 150 months (12.5 years), there’s a significant drop, which confirms that as students get older, fewer people enroll in math.\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_histogram(~amas| grade~gender,\n               bins = 5,\n               fill = \"steelblue\",\n               color=\"white\") %&gt;% \n  gf_labs(title=\"Histogram of AMAS Scores\",\n          subtitle =\"Faceted by Grade and Gender\",\n          x=\"AMAS Score\",\n          y=\"Count\")\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_histogram(~amas | grade,\n               fill=~gender,\n               colour=\"black\") %&gt;%\n  gf_labs(\n    title = \"AMAS by Filled and Faceted by Grade\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_boxplot(amas~gender | grade,\n             fill=~gender,\n             orientation = \"x\") %&gt;% \n  gf_labs(title = \"Boxplots of AMAS Scores by Grade\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Gender\",\n       y = \"AMAS Score\")\n\n\n\n\n\n\n\n\n\n\n\nGirls face more math anxiety: Box plots show higher medians, wider ranges. For girls, means are higher in both Primary & Secondary Grades.\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_histogram(~rcmas| grade~gender,\n               bins = 5,\n               fill = \"steelblue\",\n               color=\"white\") %&gt;% \n  gf_labs(title=\"Histogram of RCMAS Scores\",\n          subtitle =\"Faceted by Grade and Gender\",\n          x=\"RCMAS Score\",\n          y=\"Count\")\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_histogram(~rcmas | grade,\n               fill=~gender,\n               colour=\"black\") %&gt;%\n  gf_labs(\n    title = \"RCMAS by Filled and Faceted by Grade\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_boxplot(rcmas~gender | grade,\n             fill=~gender,\n             orientation = \"x\") %&gt;% \n  gf_labs(title = \"Boxplots of RCMAS Scores by Grade\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Gender\",\n       y = \"RCMAS Score\")\n\n\n\n\n\n\n\n\n\n\n\nAnxiety appears to be higher for Girls than for Boys\nAnxiety appears to be highest in Primary Girls\nAnxiety appears to be lowest in Secondary Boys\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_bar(~arith | grade,\n               fill = ~gender,\n               position=\"dodge\",\n               color=\"black\") %&gt;% \n  gf_labs(title = \"Dodged Bar Graph of Arith Scores\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Arith Score\",\n       y = \"Count\") %&gt;% \n  gf_refine(scale_color_brewer(palette = \"Set 2\"))\n\nWarning: Unknown palette: \"Set 2\"\n\n\n\n\n\n\n\n\n\n\n\n\nIn general, girls have a lower arith score than boys.\nIn Primary Grade, it is seen that the difference between girls and boys score is less when compared to Secondary grade where the gap is bigger.\n\n\nmeth_modified %&gt;%\n  gf_bar(~arith | grade,\n               fill = ~gender,\n               position=\"fill\",\n               color=\"black\") %&gt;% \n  gf_labs(title = \"Filled Bar Graph of Arith Scores\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Arith Score\",\n       y = \"Count\") %&gt;% \n  gf_refine(scale_color_brewer(palette = \"Set 2\"))\n\nWarning: Unknown palette: \"Set 2\"\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;% \n  gf_bar(~arith | grade,\n               fill=~grade,\n               colour=\"black\") %&gt;%\n  gf_labs(\n    title = \"Arith by Filled and Faceted by Grade\",\n    x=\"Arith Scores\",\n    y=\"Count\")\n\n\n\n\n\n\n\n\n\n\n\nPrimary Grade have higher arith scores than Secondary Grade.\n\nmeth_modified %&gt;% \n  gf_boxplot(arith ~gender | grade,\n             fill=~gender,\n             orientation = \"x\") %&gt;% \n  gf_labs(title = \"Boxplots of Arith Scores by Grade\",\n       subtitle = \"Faceted by Grade\",\n       x = \"Gender\",\n       y = \"Arith Score\")\n\n\n\n\n\n\n\n\n\n\n\n\nPrimary grades ranges from 5 to 7 & Median is 6, while Secondary grades ranges from 3 to 6 & median is 4.\nSecondary students lag in arithmetic: Box plots shows lower medians and wider ranges for Secondary Grade.\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_point(arith ~ age | gender, color = ~ grade) %&gt;%\n  gf_labs(\n    title = \"Scatter Plot of Age vs Arithmetic Score\",\n    subtitle = \"Faceted by Gender, Colored by Grade\",\n    x = \"Age\",\n    y = \"Arithmetic Score\",\n    color = \"Grade\"\n  ) %&gt;%\n  gf_refine(scale_color_brewer(palette = \"Spectral\")) %&gt;% \n  gf_theme(theme_dark())\n\n\n\n\n\n\n\n\n\n\n\nScatter plots shows similar Arith trends across both genders, but primary tend to have higher Arith scores.\n\n\nmeth_modified %&gt;% \n  gf_boxplot(arith ~ grade | gender, orientation = \"x\", fill=~grade, color = \"black\") %&gt;%\n gf_labs(\n    x = \"Grade\",\n    y = \"Arithmetic Score\",\n    title = \"Arithmetic Scores by Grade\",\n    subtitle = \"Faceted by Gender\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set3\")) %&gt;%\n  gf_theme(theme_dark())\n\n\n\n\n\n\n\n\n\n\n\n\nPrimary grade students (both genders) have higher arithmetic scores compared to secondary grade.\nSecondary grade students have wider range for arithmetic scores compared to Primary grade.\nAmong genders within each grade there’s no difference in score .\n\n\n\n\n\n\nHypothesis: From previous visualization we think that Math Anxiety (AMAS) is affects Arithmetic scores.\n\n\nmeth_modified %&gt;%\n  gf_boxplot(arith ~ amas | gender ~ grade, fill = ~ gender, orientation = \"x\") %&gt;%\n  gf_labs(\n    title = \"Relationship between Math Anxiety and Arithmetic Performance\",\n    subtitle = \"Across Gender and Grade\",\n    x = \"Math Anxiety (AMAS)\",\n    y = \"Arithmetic Performance (Arith)\"\n  ) %&gt;%\n  gf_refine(scale_fill_brewer(palette = \"Set2\")) %&gt;%\n  gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\nAs math anxiety (AMAS) increases, arithmetic performance tends to go down for both genders.\nIn both primary and secondary grade, Boys perform better than girls.\nPrimary Grade students have higher math score than Secondary.\nThe Secondary grade has more Math anxeity and this affects their Arithmatic scores.\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_density(~ age | gender, fill = ~ grade, color=\"black\") %&gt;%\n  gf_labs(\n    title = \"Density Plots of Age\",\n    subtitle = \"Faceted by Gender, Filled by Grade\",\n    x = \"Age\",\n    y = \"Density\",\n    color = \"Grade\"\n  ) %&gt;% \n  gf_refine(scale_color_brewer(palette = \"Set 3\")) %&gt;% \n  gf_theme(theme_light())\n\nWarning: Unknown palette: \"Set 3\"\n\n\nIgnoring unknown labels:\n• colour : \"Grade\"\n\n\n\n\n\n\n\n\n\n\n\n\n\nmeth_modified %&gt;%\n  gf_point(rcmas ~ amas, color = ~ gender, shape = ~ gender) %&gt;%\n  gf_labs(\n    title = \"Scatter Plot of Amas vs Rcmas\",\n    subtitle = \"Colored by Gender\",\n    x = \"Amas Score\",\n    y = \"Rcmas Score\"\n  ) %&gt;%\n  gf_refine(scale_color_brewer(palette = \"Set1\")) %&gt;% \n  gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\nIn general, both Genders have higher amas and lower rcmas\n\n\nmeth_modified %&gt;%\n  gf_boxplot(rcmas ~ amas | gender~grade, fill =~gender, orientation = \"y\") %&gt;%\n  gf_labs(\n    title = \"Box Plot of Amas vs Rcmas\",\n    subtitle = \"Colored by Grade\",\n    x = \"Amas Score\",\n    y = \"Rcmas Score\"\n  ) %&gt;%\n  gf_refine(scale_color_brewer(palette = \"Set2\")) %&gt;% \n  gf_theme(theme_light())\n\n\n\n\n\n\n\n\n\n\n\n\nAs seen in the boxplot graphs, Boys tend to have a wider range of RCMAS than girls.\nComparing Primary and Secondary Boys -\n\nPrimary Boys have lower general anxiety (rcmas) and higher math anxiety (amas).\nSecondary Boys have higher general anxiety (rcmas) and lower math anxiety (amas).\n\nComparing Primary and Secondary Girls -\n\nPrimary Girls have higher general anxiety(rcmas) and lower math anxiety (amas)\nSecondary Girls have lower general anxiety (rcmas) and higher math anxiety (amas)\n\nComparing Primary Boys and Girls -\n\nBoys have lesser median but wider range for math anxiety (amas)\nGirls have higher median but narrower range for math anxiety (amas)\nBoys & Girls have same range for general anxiety (rcmas)\n\nComparing Secondary Boys & Girls -\n\nBoys have lesser median and narrower range for math anxiety (amas)\nGirls have higher median and wider range for math anxiety (amas)\nBoys have wider range of general anxiety compared to girls (rcmas)"
  },
  {
    "objectID": "posts/MathAnxietyV2/MathAnxiety1_V2.html#conclusion",
    "href": "posts/MathAnxietyV2/MathAnxiety1_V2.html#conclusion",
    "title": "Math Anxiety Dataset",
    "section": "",
    "text": "Most visualizations show that girls have higher anxieties (both math and general), while boys have higher arithmetic scores. This could be due to boys possibly having a better support system.\nMany visualizations confirm: primary grade students do better in Math,"
  }
]